{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca664dff-ed10-4def-a98f-f30ccfa3365c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install torch\n",
    "#pip install --upgrade tensorflow\n",
    "#pip install --upgrade pip\n",
    "# Carica il modulo CUDA 11.7\n",
    "#!module load cuda/11.7\n",
    "#!pip install shap\n",
    "#!pip install numpy --upgrade\n",
    "#!pip install numpy --upgrade pip\n",
    "#!pip install pandas --upgrade\n",
    "#!pip uninstall pandas -y\n",
    "#!pip install pandas\n",
    "#!pip install pycocotools\n",
    "#pip install \"numpy<2.0.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7de4bec-868e-40b7-9b50-b77a2936d061",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-06 12:58:49.791020: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-06 12:58:50.164919: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1733486330.382342 3719979 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1733486330.430339 3719979 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-06 12:58:50.688111: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/orfeo/cephfs/home/dssc/adellasiega/jupyter/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/orfeo/cephfs/home/dssc/adellasiega/jupyter/lib/python3.9/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.21 (you have 1.4.18). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "##Imports\n",
    "import numpy as np \n",
    "import torch\n",
    "import os, sys, argparse, datetime, shutil\n",
    "import torchvision.models as models\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.keras.models import model_from_json\n",
    "from keras.utils import to_categorical\n",
    "import shap \n",
    "import tensorflow as tf\n",
    "import torchvision\n",
    "import time, json\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "\n",
    "#Import from current folder\n",
    "from utils.config import *\n",
    "from utils.dataloader import *\n",
    "from utils.engine import train_one_epoch, evaluate\n",
    "from utils.train import compute_json_detection\n",
    "from utils.knowledge_graph import compare_shap_and_KG, reduce_shap, GED_metric, get_bbox_weight\n",
    "import utils.utils as uti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33880cb6-f384-4454-bc64-afee96922a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6798abe-d511-442c-b1f5-94dff05d3ae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/orfeo/cephfs/home/dssc/adellasiega/XAI_Monuments'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ae622d2-2e0d-4c4a-b57d-f80ef9adb2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TF_XLA_FLAGS\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acb4e43e-af6f-4627-96f8-d50af5eb90e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "#os.environ[\"XLA_FLAGS\"] = \"--xla_gpu_cuda_data_dir=/usr/local/cuda-11.7\"\n",
    "#os.environ[\"PATH\"] = \"/usr/local/cuda-11.7/bin:\" + os.environ[\"PATH\"]\n",
    "#os.environ[\"LD_LIBRARY_PATH\"] = \"/usr/local/cuda-11.7/lib64:\" + os.environ.get(\"LD_LIBRARY_PATH\", \"\")\n",
    "#pip uninstall -y numpy tensorflow\n",
    "#pip install numpy==1.24 tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc4742e7-b664-445d-9bb4-864e034634fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imposta il percorso della directory manualmente\n",
    "os.chdir(os.path.expanduser('~/XAI_Monuments/tools'))\n",
    "notebook_dir = os.getcwd()\n",
    "sys.path.append(notebook_dir)\n",
    "from pickle_tools import *\n",
    "from metadata_tools import *\n",
    "from monumai.monument import Monument\n",
    "\n",
    "TMP_TRAIN = TMP_PATH + '/train'\n",
    "TMP_VAL = TMP_PATH + '/val'\n",
    "TMP_TEST = TMP_PATH + '/test'\n",
    "\n",
    "os.makedirs(TMP_VAL, exist_ok=True)\n",
    "os.makedirs(TMP_TRAIN, exist_ok=True)\n",
    "os.makedirs(TMP_TEST, exist_ok=True)\n",
    "\n",
    "# Argparse\n",
    "parser = argparse.ArgumentParser(description='Arguments needed to prepare the metadata files')\n",
    "parser.add_argument('--resume', dest='resume', help='Whether or not to resume a training', default=False)\n",
    "parser.add_argument('--path_resume', dest='path_resume', help='Path to the model to load', default='./model/model_monumenai.pth')\n",
    "parser.add_argument('--epoch_classif', dest='epoch_classif', help='Number of epochs to train the classification model', default=50)\n",
    "parser.add_argument('--batch_size', dest='batch_size', help='Batch size to train the classification model', default=32)\n",
    "parser.add_argument('--neuron_classif', dest='neuron_classif', help='Number of neurons in the classification model', default=11)\n",
    "parser.add_argument('--epoch_detection', dest='epoch_detection', help='Number of epochs to train the detection model', default=0)\n",
    "parser.add_argument('--lr', dest='lr', help='Learning rate of the detection model', default=0.0003)\n",
    "parser.add_argument('--stepLR', dest='stepLR', help='Step of the learning rate scheduler', default=9)\n",
    "parser.add_argument('--gammaLR', dest='gammaLR', help='Gamma parameter of the learning rate scheduler', default=0.1)\n",
    "parser.add_argument('--weight', dest='weight', help='Type of weighting', default='None')\n",
    "parser.add_argument('--exp_weights', dest='exp_weights', help='linear or exponential weighting', default='linear')\n",
    "parser.add_argument('--data', dest='data', help='MonumenAI or PascalPart', default='MonumenAI')\n",
    "\n",
    "# Se stai usando un ambiente Jupyter, ignora gli argomenti aggiuntivi\n",
    "if 'ipykernel_launcher' in sys.argv[0]:\n",
    "    sys.argv = sys.argv[:1]\n",
    "\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e5291e6-e84a-4d67-8686-c07fb48c102c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters classification\n",
    "n_neurons_classification = int(args.neuron_classif)\n",
    "num_epochs_classification = int(args.epoch_classif)\n",
    "batch_size_classification = int(args.batch_size)\n",
    "learning_rate_classification = None\n",
    "\n",
    "#Hyperparameters detection\n",
    "args.epoch_detection = 50\n",
    "num_epochs_detection = int(args.epoch_detection)\n",
    "learning_rate_detection = float(args.lr)\n",
    "stepLR = float(args.stepLR)\n",
    "gammaLR = float(args.gammaLR)\n",
    "data = args.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b54b508-69c8-4900-bb43-e0b560bd948a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if data == 'MonumenAI':\n",
    "    archi_features = [el for sublist in list(Monument.ELEMENT_DIC.values()) for el in sublist]\n",
    "    styles = FOLDERS_DATA\n",
    "    #Loaders for detection\n",
    "    PATH_DATA = \"../\"+PATH_DATA\n",
    "    train_loader = ArchitectureDetectionDataset(os.path.join(PATH_DATA, 'train.csv'), os.path.join(PATH_DATA, CSV_XML), transform_detection)\n",
    "\n",
    "    if num_epochs_detection != 0:\n",
    "        val_loader = ArchitectureDetectionDataset(os.path.join(PATH_DATA,'val.csv'), os.path.join(PATH_DATA, CSV_XML), transform_detection)\n",
    "    else:\n",
    "        #Actually loading the test set\n",
    "        val_loader = ArchitectureDetectionDataset(os.path.join(PATH_DATA,'val.csv'), os.path.join(PATH_DATA, CSV_XML), transform_detection)\n",
    "        test_loader = ArchitectureDetectionDataset(os.path.join(PATH_DATA,'test.csv'), os.path.join(PATH_DATA, CSV_XML), transform_detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6df99016-b966-4058-9702-7df7e78423bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Hyperparameters for detection\n",
    "num_archi_features = len(archi_features)\n",
    "num_classes_detection = num_archi_features + 1  # num_archi_features + background\n",
    "num_styles = len(styles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93df370e-c64e-4da4-ba64-179bbf062c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/adellasiega/jupyter/lib64/python3.9/site-packages/torchvision/models/_utils.py:135: UserWarning: Using 'weights' as positional parameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) instead.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/adellasiega/jupyter/lib64/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "##Build detection model\n",
    "if args.weight == \"bbox_level\":\n",
    "    from utils.pytorch_utils import fasterrcnn_resnet50_fpn_custom\n",
    "    detector = fasterrcnn_resnet50_fpn_custom(True)\n",
    "    in_features = detector.roi_heads.box_predictor.cls_score.in_features\n",
    "    detector.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes_detection)\n",
    "else:\n",
    "    detector = models.detection.fasterrcnn_resnet50_fpn(True)\n",
    "    in_features = detector.roi_heads.box_predictor.cls_score.in_features\n",
    "    detector.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes_detection)\n",
    "\n",
    "if args.exp_weights == 'exponential':\n",
    "    is_exponential = True\n",
    "elif args.exp_weights == 'linear':\n",
    "    is_exponential = False\n",
    "else:\n",
    "    print(\"Unrecognized type of weighting, defaulted to linear\")\n",
    "    is_exponential = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6791577-e707-4bb1-96ba-5831528d1683",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/adellasiega/jupyter/lib64/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/adellasiega/jupyter/lib/python3.9/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "W0000 00:00:1733486348.083536 3719979 gpu_device.cc:2344] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "detector = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "detector.to(device)\n",
    "\n",
    "optimizer = torch.optim.SGD(detector.parameters(), lr=learning_rate_detection, momentum=0.9)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, stepLR, gamma=gammaLR, last_epoch=-1)\n",
    "\n",
    "if args.resume:\n",
    "    detector.load_state_dict(torch.load(args.path_resume, map_location=device))\n",
    "\n",
    "# Classificatore\n",
    "classificator = keras.Sequential([\n",
    "    keras.layers.Dense(units=n_neurons_classification, activation='relu', input_shape=(num_archi_features,)),\n",
    "    keras.layers.Dense(units=num_styles, activation='softmax')\n",
    "])\n",
    "classificator.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "642b5213-0d43-4868-a46e-eee3899f7313",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_json_detection(detector, loader, path, dataset = 'MonumenAI'):\n",
    "    #Run inference on all data to prepare for classification\n",
    "    detector.eval()\n",
    "    \n",
    "    if dataset == 'MonumenAI':\n",
    "        information_about_class = ['M', 'G', 'R', 'B']\n",
    "        elemen_dic = SUB_ELEMENTS\n",
    "        reverse_dic = SUB_ELEMENTS_REVERSED\n",
    "    \n",
    "    for k in range(len(loader)):\n",
    "        if k > 20: break\n",
    "        percent = k/len(loader)*100\n",
    "        print(f\"Detection inference for `{path}`: {percent:.1f}%\", end='\\r')\n",
    "        \n",
    "        img = loader[k][0][0].cuda()\n",
    "        results = detector([img])[0]\n",
    "        r_b = results['boxes'].detach().cpu().numpy()\n",
    "        scores = results['scores'].detach().cpu().numpy()\n",
    "        classes = results['labels'].detach().cpu().numpy()\n",
    "        unique, counts = np.unique(classes, return_counts=True)\n",
    "        counter = dict(zip(unique, counts))\n",
    "\n",
    "        if dataset == 'MonumenAI':\n",
    "            img_name = loader.images_loc.iloc[k, 0]\n",
    "\n",
    "        results = {}\n",
    "        results[\"num_predictions\"] = []\n",
    "        results[\"image\"] = img_name\n",
    "        results[\"object\"] = []\n",
    "        \n",
    "        if dataset == 'MonumenAI':\n",
    "            results[\"true_label\"] = int(loader.images_loc.iloc[k, 1])\n",
    "\n",
    "        for name in elemen_dic:\n",
    "            if elemen_dic[name] in counter:\n",
    "                results[\"num_predictions\"].append({\n",
    "                    name :  int(counter[elemen_dic[name]])\n",
    "                })\n",
    "            else:\n",
    "                results[\"num_predictions\"].append({\n",
    "                    name :  0\n",
    "                })\n",
    "            \n",
    "        for k in range(len(r_b)):\n",
    "            if classes[k] in reverse_dic:\n",
    "                box = r_b[k]/224.\n",
    "                local_result = {\n",
    "                    \"bndbox\" : {\n",
    "                        \"xmin\": str(box[0]),\n",
    "                        \"ymin\": str(box[1]),\n",
    "                        \"ymax\": str(box[3]),\n",
    "                        \"xmax\": str(box[2])\n",
    "                    },\n",
    "                    \"score\" : str(scores[k]),\n",
    "                    \"class\" : reverse_dic[classes[k]]\n",
    "                }\n",
    "                results[\"object\"].append(local_result)\n",
    "        \n",
    "        local_path = os.path.join(path, information_about_class[results[\"true_label\"]] + '_' + img_name.split('/')[-1][:-4] + '.json')\n",
    "        \n",
    "        with open(local_path, 'w') as fp:\n",
    "            json.dump(results, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7661cac9-633b-4249-9db0-89617299276e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint caricato: ./checkpoints3/detector_epoch_1.pth\n"
     ]
    }
   ],
   "source": [
    "# Configurazione directory checkpoint\n",
    "CHECKPOINT_DIR = \"./checkpoints3/\"\n",
    "\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "\n",
    "# Funzione per caricare il checkpoint più recente\n",
    "def load_checkpoint():\n",
    "    checkpoints = [f for f in os.listdir(CHECKPOINT_DIR) if f.startswith(\"detector\")]\n",
    "    if checkpoints:\n",
    "        last_checkpoint = max(checkpoints, key=lambda x: int(x.split('_')[2].split('.')[0]))\n",
    "        checkpoint_path = os.path.join(CHECKPOINT_DIR, last_checkpoint)\n",
    "        checkpoint = torch.load(checkpoint_path)\n",
    "        print(f\"Checkpoint caricato: {checkpoint_path}\")\n",
    "        return checkpoint\n",
    "    return None\n",
    "\n",
    "checkpoint = load_checkpoint()\n",
    "start_epoch = checkpoint['epoch'] + 1 if checkpoint else 0\n",
    "\n",
    "# Caricamento del modello e dello stato ottimizzatore\n",
    "if checkpoint:\n",
    "    detector.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "\n",
    "# Funzione per preparare i dati per il classificatore\n",
    "def prepare_data(loader, TMP, dataset):\n",
    "    matrix_metadata = metadata_to_matrix(TMP, \"json\")\n",
    "    names = matrix_metadata[:, -1]\n",
    "    data = np.zeros((len(names), num_archi_features))\n",
    "    labels = np.zeros(len(names))\n",
    "\n",
    "    if dataset == \"MonumenAI\":\n",
    "        for i, name in enumerate(names):\n",
    "            im_name = name[2:-4]\n",
    "            idx = loader.images_loc['path'].str.contains(im_name)\n",
    "            data[idx] = matrix_metadata[i, :num_archi_features]\n",
    "            labels[idx] = matrix_metadata[i, num_archi_features]\n",
    "            \n",
    "    data = data.astype(np.float32)\n",
    "    labels = to_categorical(labels.astype(np.float32).astype(np.int8))\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed191cf-6059-41e2-82d4-5eaaf14370c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caricamento ultimo checkpoint del detector da: ./checkpoints3/detector_epoch_1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/adellasiega/jupyter/lib/python3.9/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 10 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caricamento ultimo checkpoint del classificatore da: ./checkpoints3/classificator_epoch_2.weights.h5\n",
      "Inizio training del detector e classificatore...\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Detector:   0%|                                       | 0/908 [00:00<?, ?batch/s]/orfeo/cephfs/home/dssc/adellasiega/jupyter/lib64/python3.9/site-packages/torch/nn/modules/conv.py:456: UserWarning: Attempt to open cnn_infer failed: handle=0 error: libcudnn_cnn_infer.so.8: cannot open shared object file: No such file or directory (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:81.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "Epoch 2 - Detector:   7%|█▏               | 64/908 [00:22<03:48,  3.69batch/s, loss=0.2519]/orfeo/cephfs/home/dssc/adellasiega/jupyter/lib/python3.9/site-packages/albumentations/core/bbox_utils.py:476: RuntimeWarning: invalid value encountered in divide\n",
      "  & (clipped_box_areas / denormalized_box_areas >= min_visibility - epsilon)\n",
      "Epoch 2 - Detector: 100%|████████████████| 908/908 [04:38<00:00,  3.27batch/s, loss=0.1490]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detector completato. Loss media: 0.3815\n",
      "Distribuzione delle classi nel training set:\n",
      "Classe 0: 196 campioni\n",
      "Classe 1: 215 campioni\n",
      "Classe 2: 187 campioni\n",
      "Classe 3: 310 campioni\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Classificator:   0%| | 3/908 [00:00<03:10,  4.75batch/s, accuracy=0.5000, loss=0."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_train_function.<locals>.one_step_on_iterator at 0x7f0b6473a3a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Classificator:   1%| | 5/908 [00:00<02:13,  6.75batch/s, accuracy=0.4000, loss=0."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_train_function.<locals>.one_step_on_iterator at 0x7f0b6473a3a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Classificator: 100%|█| 908/908 [02:00<00:00,  7.51batch/s, accuracy=0.6850, loss=\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classificatore completato. Loss media: 0.7395, Accuracy media: 0.6559\n",
      "Epoch 3/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Detector:  85%|█████████████▌  | 772/908 [03:37<00:38,  3.56batch/s, loss=0.0637]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm  # Libreria per le barre di progresso\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow import keras\n",
    "\n",
    "# Configurazione directory checkpoint\n",
    "CHECKPOINT_DIR = \"./checkpoints3/\"\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "\n",
    "# Funzione per caricare l'ultimo checkpoint salvato\n",
    "def load_latest_checkpoints(detector, classificator, optimizer, scheduler):\n",
    "    checkpoints = [f for f in os.listdir(CHECKPOINT_DIR) if f.startswith(\"detector_epoch\")]\n",
    "    if checkpoints:\n",
    "        last_checkpoint = max(checkpoints, key=lambda x: int(x.split('_')[2].split('.')[0]))\n",
    "        checkpoint_path = os.path.join(CHECKPOINT_DIR, last_checkpoint)\n",
    "        print(f\"Caricamento ultimo checkpoint del detector da: {checkpoint_path}\")\n",
    "\n",
    "        checkpoint = torch.load(checkpoint_path)\n",
    "        detector.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "        start_epoch = checkpoint['epoch'] + 1\n",
    "    else:\n",
    "        print(\"Nessun checkpoint rilevato per il detector, avvio del training da zero.\")\n",
    "        start_epoch = 0\n",
    "\n",
    "    classificator_checkpoints = [f for f in os.listdir(CHECKPOINT_DIR) if f.startswith(\"classificator_epoch\")]\n",
    "    if classificator_checkpoints:\n",
    "        last_classificator_checkpoint = max(classificator_checkpoints, key=lambda x: int(x.split('_')[2].split('.')[0]))\n",
    "        classificator_path = os.path.join(CHECKPOINT_DIR, last_classificator_checkpoint)\n",
    "        print(f\"Caricamento ultimo checkpoint del classificatore da: {classificator_path}\")\n",
    "        classificator.load_weights(classificator_path)\n",
    "    else:\n",
    "        print(\"Nessun checkpoint del classificatore trovato, avvio del training da zero.\")\n",
    "\n",
    "    return start_epoch\n",
    "\n",
    "# Funzione per calcolare la perdita SHAP\n",
    "def calculate_shap_loss(shap_values, kg_matrix, threshold=0.05):\n",
    "    loss = 0\n",
    "    for i in range(shap_values.shape[0]):  # Loop su ogni immagine\n",
    "        for j in range(shap_values.shape[1]):  # Loop su ogni caratteristica\n",
    "            shap_value = shap_values[i, j]\n",
    "            expected = kg_matrix[j]\n",
    "            if abs(shap_value) > threshold:  # Caratteristica considerata rilevante\n",
    "                if shap_value * expected < 0:  # Segno opposto a quanto previsto dal KG\n",
    "                    loss += abs(shap_value)\n",
    "    return loss / shap_values.shape[0]  # Normalizza la perdita\n",
    "\n",
    "# Funzione per calcolare la perdita combinata\n",
    "def compute_combined_loss(detector_loss, shap_loss, lambda_weight=0.1):\n",
    "    return detector_loss + lambda_weight * shap_loss\n",
    "\n",
    "# Funzione per preparare i dati per il classificatore\n",
    "def prepare_data(loader, TMP, dataset):\n",
    "    matrix_metadata = metadata_to_matrix(TMP, \"json\")\n",
    "    names = matrix_metadata[:, -1]\n",
    "    data = np.zeros((len(names), num_archi_features))\n",
    "    labels = np.zeros(len(names))\n",
    "\n",
    "    if dataset == \"MonumenAI\":\n",
    "        for i, name in enumerate(names):\n",
    "            im_name = name[2:-4]\n",
    "            idx = loader.images_loc['path'].str.contains(im_name)\n",
    "            data[idx] = matrix_metadata[i, :num_archi_features]\n",
    "            labels[idx] = matrix_metadata[i, num_archi_features]\n",
    "    elif dataset == \"PascalPart\":\n",
    "        for i, name in enumerate(names):\n",
    "            im_name = os.path.join(PATH_PASCAL + PASCAL_IMG, name.split('_')[1][:-5] + '.jpg')\n",
    "            idx = loader.images_loc.index(im_name)\n",
    "            data[idx] = matrix_metadata[i, :num_archi_features]\n",
    "            labels[idx] = matrix_metadata[i, num_archi_features]\n",
    "\n",
    "    data = data.astype(np.float32)\n",
    "    labels = to_categorical(labels.astype(np.float32).astype(np.int8))\n",
    "    return data, labels\n",
    "\n",
    "# Definizione del classificatore\n",
    "classificator = keras.Sequential([\n",
    "    keras.layers.Dense(units=n_neurons_classification, activation='relu', input_shape=(num_archi_features,)),\n",
    "    keras.layers.Dense(units=num_styles, activation='softmax')\n",
    "])\n",
    "classificator.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "start_epoch = load_latest_checkpoints(detector, classificator, optimizer, scheduler)\n",
    "\n",
    "print(\"Inizio training del detector e classificatore...\")\n",
    "for epoch in range(start_epoch, num_epochs_detection):\n",
    "    print(f\"Epoch {epoch}/{num_epochs_detection}\")\n",
    "\n",
    "    # Training del detector\n",
    "    detector.train()\n",
    "    epoch_detector_loss = 0\n",
    "    with tqdm(total=len(train_loader), desc=f\"Epoch {epoch} - Detector\", unit=\"batch\") as pbar_detector:\n",
    "        for batch_idx, (images, targets) in enumerate(train_loader):\n",
    "            images = [img.to('cuda') for img in images]\n",
    "            targets = [{k: v.to('cuda') for k, v in t.items()} for t in targets]\n",
    "\n",
    "            loss_dict = detector(images, targets)\n",
    "            losses = sum(loss for loss in loss_dict.values())\n",
    "            epoch_detector_loss += losses.item()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            losses.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            pbar_detector.set_postfix(loss=f\"{losses.item():.4f}\")\n",
    "            pbar_detector.update(1)\n",
    "\n",
    "    scheduler.step()\n",
    "    print(f\"Detector completato. Loss media: {epoch_detector_loss / len(train_loader):.4f}\")\n",
    "\n",
    "    # Preparazione dei dati per il classificatore\n",
    "    train_data, train_label = prepare_data(train_loader, TMP_TRAIN, data)\n",
    "    \n",
    "    # Calcolo e stampa della distribuzione delle classi\n",
    "    unique, counts = np.unique(np.argmax(train_label, axis=1), return_counts=True)\n",
    "    class_distribution = dict(zip(unique, counts))\n",
    "    \n",
    "    print(\"Distribuzione delle classi nel training set:\")\n",
    "    for class_id, count in class_distribution.items():\n",
    "        print(f\"Classe {class_id}: {count} campioni\")\n",
    "\n",
    "\n",
    "    # Training del classificatore\n",
    "    epoch_classificator_loss = 0\n",
    "    epoch_classificator_accuracy = 0\n",
    "    with tqdm(total=len(train_data), desc=f\"Epoch {epoch} - Classificator\", unit=\"batch\") as pbar_classificator:\n",
    "        for batch_idx, (batch_data, batch_labels) in enumerate(zip(train_data, train_label)):\n",
    "            batch_data = np.expand_dims(batch_data, axis=0)\n",
    "            batch_labels = np.expand_dims(batch_labels, axis=0)\n",
    "\n",
    "            history = classificator.train_on_batch(batch_data, batch_labels)\n",
    "            batch_loss, batch_accuracy = history[0], history[1]\n",
    "            epoch_classificator_loss += batch_loss\n",
    "            epoch_classificator_accuracy += batch_accuracy\n",
    "\n",
    "            pbar_classificator.set_postfix(loss=f\"{batch_loss:.4f}\", accuracy=f\"{batch_accuracy:.4f}\")\n",
    "            pbar_classificator.update(1)\n",
    "\n",
    "    print(f\"Classificatore completato. Loss media: {epoch_classificator_loss / len(train_data):.4f}, \"\n",
    "          f\"Accuracy media: {epoch_classificator_accuracy / len(train_data):.4f}\")\n",
    "\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': detector.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scheduler_state_dict': scheduler.state_dict(),\n",
    "    }, os.path.join(CHECKPOINT_DIR, f\"detector_epoch_{epoch}.pth\"))\n",
    "    classificator.save_weights(os.path.join(CHECKPOINT_DIR, f\"classificator_epoch_{epoch}.weights.h5\"))\n",
    "\n",
    "print(\"Training completato.\")\n",
    "\n",
    "# Calcolo degli SHAP values rispetto alla predizione finale\n",
    "print(\"Calcolo degli SHAP values...\")\n",
    "shap_explainer = shap.KernelExplainer(classificator.predict, train_data)\n",
    "shap_values = shap_explainer.shap_values(test_data, nsamples=30)\n",
    "\n",
    "# Analisi dei contributi SHAP\n",
    "for i, shap_val in enumerate(shap_values):\n",
    "    print(f\"SHAP values per classe {i}: {shap_val[:5]}\")  # Mostra i primi 5 contributi\n",
    "\n",
    "# Carica il Knowledge Graph\n",
    "print(\"Caricamento del Knowledge Graph...\")\n",
    "kg_matrix = load_knowledge_graph()\n",
    "\n",
    "# Calcolo della perdita SHAP\n",
    "print(\"Calcolo della perdita SHAP...\")\n",
    "shap_loss = calculate_shap_loss(shap_values, kg_matrix)\n",
    "print(f\"Perdita SHAP calcolata: {shap_loss:.4f}\")\n",
    "\n",
    "# Fine-tuning del detector con L_SHAP\n",
    "print(\"Inizio fine-tuning del detector...\")\n",
    "for epoch in range(fine_tuning_epochs):\n",
    "    detector.train()\n",
    "    epoch_fine_tuning_loss = 0\n",
    "    with tqdm(total=len(train_loader), desc=f\"Epoch {epoch}/{fine_tuning_epochs} - Fine-Tuning Detector\", unit=\"batch\") as pbar:\n",
    "        for batch_idx, (images, targets) in enumerate(train_loader):\n",
    "            images = [img.to('cuda') for img in images]\n",
    "            targets = [{k: v.to('cuda') for k, v in t.items()} for t in targets]\n",
    "\n",
    "            # Perdita standard del detector\n",
    "            loss_dict = detector(images, targets)\n",
    "            base_loss = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "            # Perdita totale\n",
    "            total_loss = compute_combined_loss(base_loss, shap_loss)\n",
    "            epoch_fine_tuning_loss += total_loss.item()\n",
    "\n",
    "            # Backpropagazione e aggiornamento pesi\n",
    "            optimizer.zero_grad()\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Aggiorna la barra di avanzamento\n",
    "            pbar.set_postfix(total_loss=f\"{total_loss.item():.4f}\")\n",
    "            pbar.update(1)\n",
    "\n",
    "    print(f\"Fine-Tuning Epoch {epoch} completata. Loss media: {epoch_fine_tuning_loss / len(train_loader):.4f}\")\n",
    "\n",
    "# Valutazione finale\n",
    "print(\"Valutazione finale del classificatore...\")\n",
    "loss, accuracy = classificator.evaluate(test_data, test_label, verbose=1)\n",
    "print(f\"Loss finale: {loss:.4f}, Accuracy finale: {accuracy:.4f}\")\n",
    "\n",
    "# Calcolo della metrica GED\n",
    "print(\"Calcolo della metrica GED...\")\n",
    "d = GED_metric(test_data, shap_values, dataset=data)\n",
    "print(f\"SHAP GED: {d:.4f}\")\n",
    "\n",
    "# Visualizzazione matrice di confusione\n",
    "print(\"Creazione della matrice di confusione...\")\n",
    "predict_test = classificator.predict(test_data)\n",
    "prediction = np.argmax(predict_test, axis=1)\n",
    "true_labels = np.argmax(test_label, axis=1)\n",
    "\n",
    "cm = confusion_matrix(true_labels, prediction)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=STYLES_HOTONE_ENCODE.keys())\n",
    "disp.plot(include_values=True, cmap='viridis')\n",
    "plt.savefig('confmatDeLDECAS.png')\n",
    "print(\"Matrice di confusione salvata.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597b40a0-acb8-4cce-8152-f5f596ab2e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(TMP_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
