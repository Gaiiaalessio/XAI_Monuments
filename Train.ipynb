{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca664dff-ed10-4def-a98f-f30ccfa3365c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages (2.3.1)\n",
      "Requirement already satisfied: filelock in /orfeo/cephfs/home/dssc/galessio/jupyter/lib/python3.9/site-packages (from torch) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /orfeo/cephfs/home/dssc/galessio/jupyter/lib/python3.9/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /orfeo/cephfs/home/dssc/galessio/jupyter/lib/python3.9/site-packages (from torch) (1.12.1)\n",
      "Requirement already satisfied: networkx in /orfeo/cephfs/home/dssc/galessio/jupyter/lib/python3.9/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /orfeo/cephfs/home/dssc/galessio/jupyter/lib/python3.9/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /orfeo/cephfs/home/dssc/galessio/jupyter/lib/python3.9/site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /orfeo/cephfs/home/dssc/galessio/jupyter/lib/python3.9/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /orfeo/cephfs/home/dssc/galessio/jupyter/lib/python3.9/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /orfeo/cephfs/home/dssc/galessio/jupyter/lib/python3.9/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /orfeo/cephfs/home/dssc/galessio/jupyter/lib/python3.9/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /orfeo/cephfs/home/dssc/galessio/jupyter/lib/python3.9/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /orfeo/cephfs/home/dssc/galessio/jupyter/lib/python3.9/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /orfeo/cephfs/home/dssc/galessio/jupyter/lib/python3.9/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /orfeo/cephfs/home/dssc/galessio/jupyter/lib/python3.9/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /orfeo/cephfs/home/dssc/galessio/jupyter/lib/python3.9/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /orfeo/cephfs/home/dssc/galessio/jupyter/lib/python3.9/site-packages (from torch) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /orfeo/cephfs/home/dssc/galessio/jupyter/lib/python3.9/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.1 in /orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages (from torch) (2.3.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /orfeo/cephfs/home/dssc/galessio/jupyter/lib/python3.9/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.82)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /orfeo/cephfs/home/dssc/galessio/jupyter/lib/python3.9/site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "033f27ef-aa1b-4dd3-be12-92054abd3d34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /orfeo/cephfs/home/dssc/galessio/jupyter/lib/python3.9/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /orfeo/cephfs/home/dssc/galessio/jupyter/lib/python3.9/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /orfeo/cephfs/home/dssc/galessio/jupyter/lib/python3.9/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /orfeo/cephfs/home/dssc/galessio/jupyter/lib/python3.9/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /orfeo/cephfs/home/dssc/galessio/jupyter/lib/python3.9/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /orfeo/cephfs/home/dssc/galessio/jupyter/lib/python3.9/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /orfeo/cephfs/home/dssc/galessio/jupyter/lib/python3.9/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in /orfeo/cephfs/home/dssc/galessio/jupyter/lib/python3.9/site-packages (from tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages (from tensorflow) (4.25.5)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /orfeo/cephfs/home/dssc/galessio/jupyter/lib/python3.9/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /orfeo/cephfs/home/dssc/galessio/jupyter/lib/python3.9/site-packages (from tensorflow) (53.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /orfeo/cephfs/home/dssc/galessio/jupyter/lib/python3.9/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /orfeo/cephfs/home/dssc/galessio/jupyter/lib/python3.9/site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /orfeo/cephfs/home/dssc/galessio/jupyter/lib/python3.9/site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages (from tensorflow) (1.67.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in /orfeo/cephfs/home/dssc/galessio/jupyter/lib/python3.9/site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in /orfeo/cephfs/home/dssc/galessio/jupyter/lib/python3.9/site-packages (from tensorflow) (3.6.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages (from tensorflow) (2.0.2)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages (from tensorflow) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages (from tensorflow) (0.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages (from tensorflow) (0.37.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /orfeo/cephfs/home/dssc/galessio/jupyter/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow) (0.36.2)\n",
      "Requirement already satisfied: rich in /orfeo/cephfs/home/dssc/galessio/jupyter/lib/python3.9/site-packages (from keras>=3.5.0->tensorflow) (13.9.2)\n",
      "Requirement already satisfied: namex in /orfeo/cephfs/home/dssc/galessio/jupyter/lib/python3.9/site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages (from keras>=3.5.0->tensorflow) (0.13.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /orfeo/cephfs/home/dssc/galessio/jupyter/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /orfeo/cephfs/home/dssc/galessio/jupyter/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /orfeo/cephfs/home/dssc/galessio/jupyter/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.7.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /orfeo/cephfs/home/dssc/galessio/jupyter/lib/python3.9/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /orfeo/cephfs/home/dssc/galessio/jupyter/lib/python3.9/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /orfeo/cephfs/home/dssc/galessio/jupyter/lib/python3.9/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /orfeo/cephfs/home/dssc/galessio/jupyter/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<2.19,>=2.18->tensorflow) (8.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /orfeo/cephfs/home/dssc/galessio/jupyter/lib/python3.9/site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /orfeo/cephfs/home/dssc/galessio/jupyter/lib/python3.9/site-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /orfeo/cephfs/home/dssc/galessio/jupyter/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.19,>=2.18->tensorflow) (3.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /orfeo/cephfs/home/dssc/galessio/jupyter/lib/python3.9/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a780bdef-be3e-41fd-a186-f24520b1cb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "828a018f-fe50-4d67-916f-838b93abef5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carica il modulo CUDA 11.7\n",
    "#!module load cuda/11.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a04bfa74-dce5-410a-b6d3-08c580f968ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2d1187a-6f9f-4a29-a647-4f7fce6a5869",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install numpy --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "411821e2-fb28-419e-b36d-c2d121906079",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install numpy --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf5c261d-9576-4656-b89a-72dfa3eae7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pandas --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9441b8f-02ba-40f9-a9f7-abcb7186b195",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip uninstall pandas -y\n",
    "#!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a454191-94b2-45c0-8389-8a3912ba30d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pycocotools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23f4b6ac-4b2e-4fc3-a5a2-fa499493bd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install \"numpy<2.0.0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7de4bec-868e-40b7-9b50-b77a2936d061",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-19 22:24:35.071267: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-19 22:24:35.086413: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1732051475.104375 1594522 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1732051475.109906 1594522 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-19 22:24:35.134502: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib/python3.9/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.21 (you have 1.4.18). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "##Imports\n",
    "import numpy as np \n",
    "import torch\n",
    "import os, sys, argparse, datetime, shutil\n",
    "import torchvision.models as models\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.keras.models import model_from_json\n",
    "from keras.utils import to_categorical\n",
    "import shap \n",
    "import tensorflow as tf\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "\n",
    "#Import from current folder\n",
    "from utils.config import *\n",
    "from utils.dataloader import *\n",
    "from utils.engine import train_one_epoch, evaluate\n",
    "from utils.train import compute_json_detection\n",
    "from utils.coco_utils import get_coco_api_from_dataset\n",
    "from utils.coco_eval import CocoEvaluator\n",
    "from utils.knowledge_graph import compare_shap_and_KG, reduce_shap, GED_metric, get_bbox_weight\n",
    "import utils.utils as uti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ae622d2-2e0d-4c4a-b57d-f80ef9adb2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TF_XLA_FLAGS\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "acb4e43e-af6f-4627-96f8-d50af5eb90e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bdb34a83-a647-4602-b6ef-46556f499609",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.environ[\"XLA_FLAGS\"] = \"--xla_gpu_cuda_data_dir=/usr/local/cuda-11.7\"\n",
    "#os.environ[\"PATH\"] = \"/usr/local/cuda-11.7/bin:\" + os.environ[\"PATH\"]\n",
    "#os.environ[\"LD_LIBRARY_PATH\"] = \"/usr/local/cuda-11.7/lib64:\" + os.environ.get(\"LD_LIBRARY_PATH\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5186f306-772b-4886-966c-65ff55aad131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/which: no ptxas in (/orfeo/cephfs/home/dssc/galessio/jupyter/bin:/usr/local/cuda/bin:/opt/bin/:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin)\n",
      "/bin/bash: line 1: nvcc: command not found\n"
     ]
    }
   ],
   "source": [
    "!which ptxas\n",
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29224100-b419-447f-8c72-712a0aafe89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "53dfad0d-f080-4b0e-bb6c-db596c1a754c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/usr/lib64/python39.zip',\n",
       " '/usr/lib64/python3.9',\n",
       " '/usr/lib64/python3.9/lib-dynload',\n",
       " '',\n",
       " '/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages',\n",
       " '/orfeo/cephfs/home/dssc/galessio/jupyter/lib/python3.9/site-packages',\n",
       " '../monumai']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "63c3188c-f693-4a16-88c0-4831c62e464d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip uninstall -y numpy tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9f68e5d3-ff24-4c2f-8fcc-8ce2d98683fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install numpy==1.24 tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc4742e7-b664-445d-9bb4-864e034634fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Imposta il percorso della directory manualmente\n",
    "os.chdir(os.path.expanduser('~/XAI_Monuments/tools'))\n",
    "notebook_dir = os.getcwd()\n",
    "sys.path.append(notebook_dir)\n",
    "\n",
    "from pickle_tools import *\n",
    "\n",
    "TMP_TRAIN = TMP_PATH + '/train'\n",
    "TMP_VAL = TMP_PATH + '/val'\n",
    "TMP_TEST = TMP_PATH + '/test'\n",
    "\n",
    "os.makedirs(TMP_VAL, exist_ok=True)\n",
    "os.makedirs(TMP_TRAIN, exist_ok=True)\n",
    "os.makedirs(TMP_TEST, exist_ok=True)\n",
    "\n",
    "# Argparse\n",
    "parser = argparse.ArgumentParser(description='Arguments needed to prepare the metadata files')\n",
    "parser.add_argument('--resume', dest='resume', help='Whether or not to resume a training', default=False)\n",
    "parser.add_argument('--path_resume', dest='path_resume', help='Path to the model to load', default='./model/model_monumenai.pth')\n",
    "parser.add_argument('--epoch_classif', dest='epoch_classif', help='Number of epochs to train the classification model', default=150)\n",
    "parser.add_argument('--batch_size', dest='batch_size', help='Batch size to train the classification model', default=8)\n",
    "parser.add_argument('--neuron_classif', dest='neuron_classif', help='Number of neurons in the classification model', default=11)\n",
    "parser.add_argument('--epoch_detection', dest='epoch_detection', help='Number of epochs to train the detection model', default=0)\n",
    "parser.add_argument('--lr', dest='lr', help='Learning rate of the detection model', default=0.0003)\n",
    "parser.add_argument('--stepLR', dest='stepLR', help='Step of the learning rate scheduler', default=9)\n",
    "parser.add_argument('--gammaLR', dest='gammaLR', help='Gamma parameter of the learning rate scheduler', default=0.1)\n",
    "parser.add_argument('--weight', dest='weight', help='Type of weighting', default='None')\n",
    "parser.add_argument('--exp_weights', dest='exp_weights', help='linear or exponential weighting', default='linear')\n",
    "parser.add_argument('--data', dest='data', help='MonumenAI or PascalPart', default='MonumenAI')\n",
    "\n",
    "# Se stai usando un ambiente Jupyter, ignora gli argomenti aggiuntivi\n",
    "if 'ipykernel_launcher' in sys.argv[0]:\n",
    "    sys.argv = sys.argv[:1]\n",
    "\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2e5291e6-e84a-4d67-8686-c07fb48c102c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters classification\n",
    "n_neurons_classification = int(args.neuron_classif)\n",
    "num_epochs_classification = int(args.epoch_classif)\n",
    "batch_size_classification = int(args.batch_size)\n",
    "learning_rate_classification = None\n",
    "\n",
    "#Hyperparameters detection\n",
    "args.epoch_detection = 150\n",
    "num_epochs_detection = int(args.epoch_detection)\n",
    "learning_rate_detection = float(args.lr)\n",
    "stepLR = float(args.stepLR)\n",
    "gammaLR = float(args.gammaLR)\n",
    "data = args.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8b54b508-69c8-4900-bb43-e0b560bd948a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import sys\n",
    "os.chdir(os.path.expanduser('~/XAI_Monuments/tools'))\n",
    "notebook_dir = os.getcwd()\n",
    "sys.path.append(notebook_dir)\n",
    "if data == 'MonumenAI':\n",
    "    from metadata_tools import *\n",
    "    from monumai.monument import Monument\n",
    "    archi_features = [el for sublist in list(Monument.ELEMENT_DIC.values()) for el in sublist]\n",
    "    styles = FOLDERS_DATA\n",
    "    #Loaders for detection\n",
    "    PATH_DATA = \"../\"+PATH_DATA\n",
    "    train_loader = ArchitectureDetectionDataset(os.path.join(PATH_DATA, 'train.csv'), os.path.join(PATH_DATA, CSV_XML), transform_detection)\n",
    "\n",
    "    if num_epochs_detection != 0:\n",
    "        val_loader = ArchitectureDetectionDataset(os.path.join(PATH_DATA,'val.csv'), os.path.join(PATH_DATA, CSV_XML), transform_detection)\n",
    "    else:\n",
    "        #Actually loading the test set\n",
    "        val_loader = ArchitectureDetectionDataset(os.path.join(PATH_DATA,'val.csv'), os.path.join(PATH_DATA, CSV_XML), transform_detection)\n",
    "        test_loader = ArchitectureDetectionDataset(os.path.join(PATH_DATA,'test.csv'), os.path.join(PATH_DATA, CSV_XML), transform_detection)\n",
    "if data == 'PascalPart':\n",
    "    from tools.metadata_tools_pascal import *\n",
    "    from monumai.pascal import Monument\n",
    "    archi_features = [el for sublist in list(Monument.ELEMENT_DIC.values()) for el in sublist]\n",
    "    styles = list(PASCAL_EL_DIC.keys())\n",
    "    #Loaders for detection\n",
    "    train_loader = PascalDetectionDataset(train_pascal, PATH_PASCAL+PASCAL_IMG,PATH_PASCAL+PASCAL_XML, transform_detection_pascal)\n",
    "    if num_epochs_detection != 0:\n",
    "        val_loader = PascalDetectionDataset(val_pascal, PATH_PASCAL+PASCAL_IMG,PATH_PASCAL+PASCAL_XML, transform_detection_pascal)\n",
    "    else:\n",
    "        #Actually loading the test set\n",
    "        val_loader = PascalDetectionDataset(val_pascal, PATH_PASCAL+PASCAL_IMG,PATH_PASCAL+PASCAL_XML, transform_detection_pascal)\n",
    "        test_loader = PascalDetectionDataset(test_pascal, PATH_PASCAL+PASCAL_IMG,PATH_PASCAL+PASCAL_XML, transform_detection_pascal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6df99016-b966-4058-9702-7df7e78423bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Hyperparameters for detection\n",
    "\n",
    "num_archi_features = len(archi_features)\n",
    "num_classes_detection = num_archi_features + 1  # num_archi_features + background\n",
    "num_styles = len(styles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "93df370e-c64e-4da4-ba64-179bbf062c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/torchvision/models/_utils.py:135: UserWarning: Using 'weights' as positional parameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) instead.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "##Build detection model\n",
    "if args.weight == \"bbox_level\":\n",
    "    from utils.pytorch_utils import fasterrcnn_resnet50_fpn_custom\n",
    "    detector = fasterrcnn_resnet50_fpn_custom(True)\n",
    "    in_features = detector.roi_heads.box_predictor.cls_score.in_features\n",
    "    detector.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes_detection)\n",
    "else:\n",
    "    detector = models.detection.fasterrcnn_resnet50_fpn(True)\n",
    "    in_features = detector.roi_heads.box_predictor.cls_score.in_features\n",
    "    detector.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes_detection)\n",
    "\n",
    "if args.exp_weights == 'exponential':\n",
    "    is_exponential = True\n",
    "elif args.exp_weights == 'linear':\n",
    "    is_exponential = False\n",
    "else:\n",
    "    print(\"Unrecognized type of weighting, defaulted to linear\")\n",
    "    is_exponential = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f6791577-e707-4bb1-96ba-5831528d1683",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "detector = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "detector.to(device)\n",
    "\n",
    "optimizer = torch.optim.SGD(detector.parameters(), lr=learning_rate_detection, momentum=0.9)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, stepLR, gamma=gammaLR, last_epoch=-1)\n",
    "\n",
    "if args.resume:\n",
    "    detector.load_state_dict(torch.load(args.path_resume, map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "642b5213-0d43-4868-a46e-eee3899f7313",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, json, os\n",
    "def compute_json_detection(detector, loader, path, dataset = 'MonumenAI'):\n",
    "    #Run inference on all data to prepare for classification\n",
    "    detector.eval()\n",
    "    if dataset == 'MonumenAI':\n",
    "        information_about_class = ['M', 'G', 'R', 'B']\n",
    "        elemen_dic = SUB_ELEMENTS\n",
    "        reverse_dic = SUB_ELEMENTS_REVERSED\n",
    "    if dataset == 'PascalPart':\n",
    "        information_about_class = list(PASCAL_EL_DIC.keys())\n",
    "        elemen_dic = PASCAL_PART_DIC\n",
    "        reverse_dic = PASCAL_PART_DIC_REVERSED\n",
    "    for k in range(len(loader)):\n",
    "        print(f\"{k/len(loader)*100}\", end='\\r')\n",
    "        img = loader[k][0][0].cuda()\n",
    "        results = detector([img])[0]\n",
    "        r_b = results['boxes'].detach().cpu().numpy()\n",
    "        scores = results['scores'].detach().cpu().numpy()\n",
    "        classes = results['labels'].detach().cpu().numpy()\n",
    "        unique, counts = np.unique(classes, return_counts=True)\n",
    "        counter = dict(zip(unique, counts))\n",
    "\n",
    "        if dataset == 'MonumenAI':\n",
    "            img_name = loader.images_loc.iloc[k, 0]\n",
    "        if dataset == 'PascalPart':\n",
    "            img_name = loader.images_loc[k]\n",
    "\n",
    "        condensced_results = {}\n",
    "        condensced_results[\"num_predictions\"] = []\n",
    "        condensced_results[\"image\"] = img_name\n",
    "        condensced_results[\"object\"] = []\n",
    "        if dataset == 'MonumenAI':\n",
    "            condensced_results[\"true_label\"] = int(loader.images_loc.iloc[k, 1])\n",
    "        if dataset == 'PascalPart':\n",
    "            condensced_results[\"true_label\"] = get_label(loader.xml_loc[k], PASCAL_EL_DIC)\n",
    "\n",
    "        for name in elemen_dic:\n",
    "\n",
    "            if elemen_dic[name] in counter:\n",
    "                condensced_results[\"num_predictions\"].append({\n",
    "                    name :  int(counter[elemen_dic[name]])\n",
    "                })\n",
    "            else:\n",
    "                condensced_results[\"num_predictions\"].append({\n",
    "                    name :  0\n",
    "                })\n",
    "            \n",
    "        for k in range(len(r_b)):\n",
    "            if classes[k] in reverse_dic:\n",
    "                box = r_b[k]/224.\n",
    "                local_result = {\n",
    "                    \"bndbox\" : {\n",
    "                        \"xmin\": str(box[0]),\n",
    "                        \"ymin\": str(box[1]),\n",
    "                        \"ymax\": str(box[3]),\n",
    "                        \"xmax\": str(box[2])\n",
    "                    },\n",
    "                    \"score\" : str(scores[k]),\n",
    "                    \"class\" : reverse_dic[classes[k]]\n",
    "                }\n",
    "                condensced_results[\"object\"].append(local_result)\n",
    "        local_path = os.path.join(path,information_about_class[condensced_results[\"true_label\"]] + '_' + img_name.split('/')[-1][:-4] + '.json')\n",
    "        with open(local_path, 'w') as fp:\n",
    "            json.dump(condensced_results, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eac8a69c-d8a2-4a15-ac10-3d69ce6bf175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint caricato: ./checkpoints2/detector_epoch_8.pth\n",
      "------------------\n",
      "Epoch 10/150\n",
      "0.0\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/torch/nn/modules/conv.py:456: UserWarning: Attempt to open cnn_infer failed: handle=0 error: libcudnn_cnn_infer.so.8: cannot open shared object file: No such file or directory (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:81.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.04845814977973656\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib/python3.9/site-packages/albumentations/core/bbox_utils.py:476: RuntimeWarning: invalid value encountered in divide\n",
      "  & (clipped_box_areas / denormalized_box_areas >= min_visibility - epsilon)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference completata\n",
      "Load .json metadata:  ./tmp/train/B_20181212_110313.json\n",
      "Load .json metadata:  ./tmp/train/B_5bed71eae40c4.json\n",
      "Load .json metadata:  ./tmp/train/B_20181212_110321.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_mihrab_mezquita_cordoba.json\n",
      "Load .json metadata:  ./tmp/train/B_5bad4cbc18c44.json\n",
      "Load .json metadata:  ./tmp/train/R_5c1f82413637d.json\n",
      "Load .json metadata:  ./tmp/train/G_5c67d991a4cf7.json\n",
      "Load .json metadata:  ./tmp/train/B_5dd7d6e26f601.json\n",
      "Load .json metadata:  ./tmp/train/M_alcazaba_malaga3.json\n",
      "Load .json metadata:  ./tmp/train/G_casa_bailio_cordoba.json\n",
      "Load .json metadata:  ./tmp/train/G_5babc82fc022f.json\n",
      "Load .json metadata:  ./tmp/train/M_5e4fb912bf15b.json\n",
      "Load .json metadata:  ./tmp/train/R_5c75195fbb8f2.json\n",
      "Load .json metadata:  ./tmp/train/G_5bb8f33edfa1f.json\n",
      "Load .json metadata:  ./tmp/train/M_5bb0d93bcd653.json\n",
      "Load .json metadata:  ./tmp/train/B_5c15322219e6f.json\n",
      "Load .json metadata:  ./tmp/train/B_facultad_derecho_granada2.json\n",
      "Load .json metadata:  ./tmp/train/M_patio_yeso_reales_alcazares_sevilla3.json\n",
      "Load .json metadata:  ./tmp/train/B_iglesia_caridad_sevilla2.json\n",
      "Load .json metadata:  ./tmp/train/M_20181212_112649.json\n",
      "Load .json metadata:  ./tmp/train/R_ayuntamiento_baeza3.json\n",
      "Load .json metadata:  ./tmp/train/R_5bc0b3ee639ce.json\n",
      "Load .json metadata:  ./tmp/train/B_convento_siervas_de_maria_granada.json\n",
      "Load .json metadata:  ./tmp/train/B_casa_almirante_cadiz2.json\n",
      "Load .json metadata:  ./tmp/train/G_20181212_105119.json\n",
      "Load .json metadata:  ./tmp/train/G_catedral_leon12.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc76ea8caf7b.json\n",
      "Load .json metadata:  ./tmp/train/M_medina_azahara3.json\n",
      "Load .json metadata:  ./tmp/train/G_5baeaa86ac71e.json\n",
      "Load .json metadata:  ./tmp/train/B_catedral_granada4.json\n",
      "Load .json metadata:  ./tmp/train/M_5bae5bf050e24.json\n",
      "Load .json metadata:  ./tmp/train/M_5baf14eb92e6d.json\n",
      "Load .json metadata:  ./tmp/train/B_5c80ebc6ddf27.json\n",
      "Load .json metadata:  ./tmp/train/B_iglesia_gracia_granada.json\n",
      "Load .json metadata:  ./tmp/train/G_iglesia_san_nicolas_ubeda4.json\n",
      "Load .json metadata:  ./tmp/train/R_5bf7c972311d4.json\n",
      "Load .json metadata:  ./tmp/train/M_5bec1e4b72f12.json\n",
      "Load .json metadata:  ./tmp/train/B_iglesia_caridad_sevilla5.json\n",
      "Load .json metadata:  ./tmp/train/M_5bd579c5023a7.json\n",
      "Load .json metadata:  ./tmp/train/R_5bb5f3109fda8.json\n",
      "Load .json metadata:  ./tmp/train/B_santos_justo_pastor_granada8.json\n",
      "Load .json metadata:  ./tmp/train/G_casa_bailio_cordoba2.json\n",
      "Load .json metadata:  ./tmp/train/B_iglesia_san_jeronimo_granada3.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_del_vino_granada6.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_de_las_pesas_granada4.json\n",
      "Load .json metadata:  ./tmp/train/M_5bec1e6a04058.json\n",
      "Load .json metadata:  ./tmp/train/M_5de6b189c985e.json\n",
      "Load .json metadata:  ./tmp/train/B_museo_bellas_artes_sevilla6.json\n",
      "Load .json metadata:  ./tmp/train/M_5bae5eef7467f.json\n",
      "Load .json metadata:  ./tmp/train/M_20181212_115504.json\n",
      "Load .json metadata:  ./tmp/train/R_puerta_puente_cordoba15.json\n",
      "Load .json metadata:  ./tmp/train/B_5baff8c138f48.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc0ca38b7006.json\n",
      "Load .json metadata:  ./tmp/train/G_5cadb7eb3a84a.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_monaita_granada6.json\n",
      "Load .json metadata:  ./tmp/train/B_5bdb2454edef4.json\n",
      "Load .json metadata:  ./tmp/train/G_catedral_leon10.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_san_isidro_mezquita_cordoba5.json\n",
      "Load .json metadata:  ./tmp/train/B_5bebfefce3f27.json\n",
      "Load .json metadata:  ./tmp/train/G_5b8ecc4c3cde4.json\n",
      "Load .json metadata:  ./tmp/train/G_5baf18213b6f1.json\n",
      "Load .json metadata:  ./tmp/train/G_iglesia_santa_maría_del_pi_barcelona3.json\n",
      "Load .json metadata:  ./tmp/train/R_casa_cabildo_jerez6.json\n",
      "Load .json metadata:  ./tmp/train/B_5c48452e4af47.json\n",
      "Load .json metadata:  ./tmp/train/M_5d99bad3a10f2.json\n",
      "Load .json metadata:  ./tmp/train/R_puerta_puente_cordoba4.json\n",
      "Load .json metadata:  ./tmp/train/R_plaza_santa_teresa_ubeda3.json\n",
      "Load .json metadata:  ./tmp/train/B_casa_marqueses_de_cartagena_granada4.json\n",
      "Load .json metadata:  ./tmp/train/B_colegio_bartolome_santiago_granada.json\n",
      "Load .json metadata:  ./tmp/train/G_5b8d77afb94e9.json\n",
      "Load .json metadata:  ./tmp/train/R_5bd6baf8e455c.json\n",
      "Load .json metadata:  ./tmp/train/B_basilica_angustias_granada3.json\n",
      "Load .json metadata:  ./tmp/train/B_5bacbbeed360e.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_monaita_granada5.json\n",
      "Load .json metadata:  ./tmp/train/B_casa-mariana_pineda_granada.json\n",
      "Load .json metadata:  ./tmp/train/R_5bdefaf7351c6.json\n",
      "Load .json metadata:  ./tmp/train/R_palacio_cadenas_ubeda.json\n",
      "Load .json metadata:  ./tmp/train/G_hospital_san_sebastian_cordoba9.json\n",
      "Load .json metadata:  ./tmp/train/G_torre_fadrique2.json\n",
      "Load .json metadata:  ./tmp/train/G_convento_clarisas_palencia4.json\n",
      "Load .json metadata:  ./tmp/train/M_medina_azahara23.json\n",
      "Load .json metadata:  ./tmp/train/G_casa_abrantes_granada6.json\n",
      "Load .json metadata:  ./tmp/train/B_catedral_guadix2.json\n",
      "Load .json metadata:  ./tmp/train/B_5c878e7d3d3f0.json\n",
      "Load .json metadata:  ./tmp/train/G_5de139e53bea1.json\n",
      "Load .json metadata:  ./tmp/train/M_dintel_adovelado5.json\n",
      "Load .json metadata:  ./tmp/train/B_san_felipe_neri_baeza.json\n",
      "Load .json metadata:  ./tmp/train/M_5bafb615991d4.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc765746e381.json\n",
      "Load .json metadata:  ./tmp/train/B_5c14f6b287d17.json\n",
      "Load .json metadata:  ./tmp/train/G_5c62923184bbc.json\n",
      "Load .json metadata:  ./tmp/train/B_casa_cadenas_cadiz3.json\n",
      "Load .json metadata:  ./tmp/train/G_casa_zafra_granada.json\n",
      "Load .json metadata:  ./tmp/train/B_iglesia_caridad_sevilla6.json\n",
      "Load .json metadata:  ./tmp/train/B_5bb0aaee9afc9.json\n",
      "Load .json metadata:  ./tmp/train/B_5dd8f69aee967.json\n",
      "Load .json metadata:  ./tmp/train/M_5c38860a8e338.json\n",
      "Load .json metadata:  ./tmp/train/R_5bb35143c8292.json\n",
      "Load .json metadata:  ./tmp/train/R_20181212_110343.json\n",
      "Load .json metadata:  ./tmp/train/M_5bbe3f16a2771.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc7645ea64dc.json\n",
      "Load .json metadata:  ./tmp/train/G_puerta_apostoles_catedra_valencia3.json\n",
      "Load .json metadata:  ./tmp/train/M_20181212_115516.json\n",
      "Load .json metadata:  ./tmp/train/B_casa_museo_sefardi_granada2.json\n",
      "Load .json metadata:  ./tmp/train/M_5defb57b27d8b.json\n",
      "Load .json metadata:  ./tmp/train/R_5c07fc9b36ec9.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_monaita_granada2.json\n",
      "Load .json metadata:  ./tmp/train/B_palacio_quemadas_cordoba2.json\n",
      "Load .json metadata:  ./tmp/train/R_iglesia_guadahortuna3.json\n",
      "Load .json metadata:  ./tmp/train/M_5e4fb8674b6b0.json\n",
      "Load .json metadata:  ./tmp/train/M_corral_carbon_granada4.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_del_vino_granada12.json\n",
      "Load .json metadata:  ./tmp/train/R_casa_lonja_sevilla_patio.json\n",
      "Load .json metadata:  ./tmp/train/G_puerta_apostoles_catedra_valencia5.json\n",
      "Load .json metadata:  ./tmp/train/G_iglesia_san_nicolas_ubeda2.json\n",
      "Load .json metadata:  ./tmp/train/B_5ce90d44c81b5.json\n",
      "Load .json metadata:  ./tmp/train/M_medina_azahara16.json\n",
      "Load .json metadata:  ./tmp/train/M_5db2c2a620a94.json\n",
      "Load .json metadata:  ./tmp/train/R_san_pedro_cordoba6.json\n",
      "Load .json metadata:  ./tmp/train/R_5bc601592c5ae.json\n",
      "Load .json metadata:  ./tmp/train/B_iglesia_san_juan_de_dios_granada.json\n",
      "Load .json metadata:  ./tmp/train/B_5c4c5d588f969.json\n",
      "Load .json metadata:  ./tmp/train/G_catedral_burgos11.json\n",
      "Load .json metadata:  ./tmp/train/R_5bae51ba6d784.json\n",
      "Load .json metadata:  ./tmp/train/M_5bd35122f11d2.json\n",
      "Load .json metadata:  ./tmp/train/B_5d9e1bfaeb1b0.json\n",
      "Load .json metadata:  ./tmp/train/M_5db2e7f92118d.json\n",
      "Load .json metadata:  ./tmp/train/G_puerta_apostoles_catedra_valencia7.json\n",
      "Load .json metadata:  ./tmp/train/R_5bc2c464cce14.json\n",
      "Load .json metadata:  ./tmp/train/R_iglesia_salvador_ubeda3.json\n",
      "Load .json metadata:  ./tmp/train/M_5bdec6139317d.json\n",
      "Load .json metadata:  ./tmp/train/B_5bbb3a49e5e1d.json\n",
      "Load .json metadata:  ./tmp/train/B_5d98e54e59775.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_elvira_granada3.json\n",
      "Load .json metadata:  ./tmp/train/G_puerta_apostoles_catedral_valencia.json\n",
      "Load .json metadata:  ./tmp/train/B_5c7be6a013c47.json\n",
      "Load .json metadata:  ./tmp/train/M_5bba4d3b86c50.json\n",
      "Load .json metadata:  ./tmp/train/R_5bc4cf3b20c2e.json\n",
      "Load .json metadata:  ./tmp/train/G_iglesia_san_pablo_ubeda5.json\n",
      "Load .json metadata:  ./tmp/train/B_convento_esclavas_puerto_santa_maria.json\n",
      "Load .json metadata:  ./tmp/train/B_5da39ec706056.json\n",
      "Load .json metadata:  ./tmp/train/M_medina_azahara5.json\n",
      "Load .json metadata:  ./tmp/train/G_catedral_burgos9.json\n",
      "Load .json metadata:  ./tmp/train/G_iglesia_san_pablo_ubeda8.json\n",
      "Load .json metadata:  ./tmp/train/R_carcel_martos5.json\n",
      "Load .json metadata:  ./tmp/train/M_5e4fb7d4eb466.json\n",
      "Load .json metadata:  ./tmp/train/G_5cb4506788a6c.json\n",
      "Load .json metadata:  ./tmp/train/G_casa_inquisicion_alhama.json\n",
      "Load .json metadata:  ./tmp/train/B_chancilleria_granada5.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc4cdf0585e4.json\n",
      "Load .json metadata:  ./tmp/train/M_20181212_145543.json\n",
      "Load .json metadata:  ./tmp/train/G_alcazaba-almeria.json\n",
      "Load .json metadata:  ./tmp/train/R_casa_cabildo_jerez5.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc76500a43e5.json\n",
      "Load .json metadata:  ./tmp/train/R_5bcaed60a57a5.json\n",
      "Load .json metadata:  ./tmp/train/M_dintel_adovelado4.json\n",
      "Load .json metadata:  ./tmp/train/B_5bae520c3096f.json\n",
      "Load .json metadata:  ./tmp/train/M_patio_yeso_reales_alcazares_sevilla4.json\n",
      "Load .json metadata:  ./tmp/train/G_monasterio_concepcion_granada4.json\n",
      "Load .json metadata:  ./tmp/train/G_catedral_leon8.json\n",
      "Load .json metadata:  ./tmp/train/R_5bae6379a7219.json\n",
      "Load .json metadata:  ./tmp/train/B_5d90ba3786f84.json\n",
      "Load .json metadata:  ./tmp/train/B_5bacbc2c46129.json\n",
      "Load .json metadata:  ./tmp/train/G_5d853bf14c54f.json\n",
      "Load .json metadata:  ./tmp/train/M_aljibe_san_miguel_bajo.json\n",
      "Load .json metadata:  ./tmp/train/M_5bb0a6a0a9219.json\n",
      "Load .json metadata:  ./tmp/train/M_alcazaba_malaga2.json\n",
      "Load .json metadata:  ./tmp/train/R_5da5cd3e7a1ca.json\n",
      "Load .json metadata:  ./tmp/train/B_5baff87c5d061.json\n",
      "Load .json metadata:  ./tmp/train/B_5bd34562c7157.json\n",
      "Load .json metadata:  ./tmp/train/G_palacio_jabalquinto_baeza13.json\n",
      "Load .json metadata:  ./tmp/train/G_5bac8c5becc42.json\n",
      "Load .json metadata:  ./tmp/train/B_5c191ae226d3d.json\n",
      "Load .json metadata:  ./tmp/train/B_palacio_quemadas_cordoba3.json\n",
      "Load .json metadata:  ./tmp/train/G_5cf2f7b8bb83b.json\n",
      "Load .json metadata:  ./tmp/train/M_5e4fd06f4005c.json\n",
      "Load .json metadata:  ./tmp/train/G_hospital_san_sebastian_cordoba4.json\n",
      "Load .json metadata:  ./tmp/train/M_medina_azahara22.json\n",
      "Load .json metadata:  ./tmp/train/R_puerta_puente_cordoba16.json\n",
      "Load .json metadata:  ./tmp/train/R_5bb897329f5cd.json\n",
      "Load .json metadata:  ./tmp/train/R_5bb90da49c913.json\n",
      "Load .json metadata:  ./tmp/train/B_5c13837ca48df.json\n",
      "Load .json metadata:  ./tmp/train/G_catedral_sevilla6.json\n",
      "Load .json metadata:  ./tmp/train/M_5bf678c169e06.json\n",
      "Load .json metadata:  ./tmp/train/B_5cadbcbc0e666.json\n",
      "Load .json metadata:  ./tmp/train/M_5bcaecccd162f.json\n",
      "Load .json metadata:  ./tmp/train/G_catedral_leon2.json\n",
      "Load .json metadata:  ./tmp/train/B_5df7681a6a1d3.json\n",
      "Load .json metadata:  ./tmp/train/M_alminar_san_jose_granada6.json\n",
      "Load .json metadata:  ./tmp/train/M_20181212_115543.json\n",
      "Load .json metadata:  ./tmp/train/B_santos_justo_pastor_granada3.json\n",
      "Load .json metadata:  ./tmp/train/R_5c1914b7dafda.json\n",
      "Load .json metadata:  ./tmp/train/M_5dd41d557867b.json\n",
      "Load .json metadata:  ./tmp/train/M_5c879cd0ed2cc.json\n",
      "Load .json metadata:  ./tmp/train/R_puerta_puente_cordoba10.json\n",
      "Load .json metadata:  ./tmp/train/G_puerta_bautismo_catedral_sevilla9.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_justicia_granada2.json\n",
      "Load .json metadata:  ./tmp/train/M_5bdedf6d54d29.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_justicia_granada.json\n",
      "Load .json metadata:  ./tmp/train/R_carcel_martos3.json\n",
      "Load .json metadata:  ./tmp/train/R_5c1903a4925ea.json\n",
      "Load .json metadata:  ./tmp/train/B_colegio_san_telmo_sevilla6.json\n",
      "Load .json metadata:  ./tmp/train/G_5d3da546e111e.json\n",
      "Load .json metadata:  ./tmp/train/G_casa_zafra_granada5.json\n",
      "Load .json metadata:  ./tmp/train/G_catedral_toledo2.json\n",
      "Load .json metadata:  ./tmp/train/R_5df9f2036b740.json\n",
      "Load .json metadata:  ./tmp/train/G_5de134de77277.json\n",
      "Load .json metadata:  ./tmp/train/B_convento_magdalena_granada.json\n",
      "Load .json metadata:  ./tmp/train/G_5cc07126bd06d.json\n",
      "Load .json metadata:  ./tmp/train/R_5bb350a2e289a.json\n",
      "Load .json metadata:  ./tmp/train/B_5c4065a551b5d.json\n",
      "Load .json metadata:  ./tmp/train/B_5bd07567077f8.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_elvira_granada2.json\n",
      "Load .json metadata:  ./tmp/train/R_casa_torres_ubeda3.json\n",
      "Load .json metadata:  ./tmp/train/G_catedral_burgos.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc0c8c89fd21.json\n",
      "Load .json metadata:  ./tmp/train/G_casa_abrantes_granada4.json\n",
      "Load .json metadata:  ./tmp/train/M_5db2c2d58820d.json\n",
      "Load .json metadata:  ./tmp/train/B_5ce8393752ba0.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc7645dbbec1.json\n",
      "Load .json metadata:  ./tmp/train/R_iglesia_san_andres.json\n",
      "Load .json metadata:  ./tmp/train/B_chancilleria_granada14.json\n",
      "Load .json metadata:  ./tmp/train/G_palacio_jabalquinto_baeza11.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_monaita_granada.json\n",
      "Load .json metadata:  ./tmp/train/G_5bc1d52645376.json\n",
      "Load .json metadata:  ./tmp/train/R_5c9d17dc28b0e.json\n",
      "Load .json metadata:  ./tmp/train/M_alminar_san_jose_granada4.json\n",
      "Load .json metadata:  ./tmp/train/M_corral_carbon_granada2.json\n",
      "Load .json metadata:  ./tmp/train/G_puerta_apostoles_catedra_valencia2.json\n",
      "Load .json metadata:  ./tmp/train/R_puerta_puente_cordoba5.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc765017d63d.json\n",
      "Load .json metadata:  ./tmp/train/G_casa_abrantes_granada7.json\n",
      "Load .json metadata:  ./tmp/train/R_5bf67925573b1.json\n",
      "Load .json metadata:  ./tmp/train/B_casa_almirante_cadiz5.json\n",
      "Load .json metadata:  ./tmp/train/B_palacio_quemadas_cordoba.json\n",
      "Load .json metadata:  ./tmp/train/G_palacio_jabalquinto_baeza2.json\n",
      "Load .json metadata:  ./tmp/train/B_5bb0b452a19f9.json\n",
      "Load .json metadata:  ./tmp/train/G_catedral_leon6.json\n",
      "Load .json metadata:  ./tmp/train/R_ayuntamiento_baeza13.json\n",
      "Load .json metadata:  ./tmp/train/B_palacio_ansoti_granada9.json\n",
      "Load .json metadata:  ./tmp/train/B_5b8a5bebf2b05.json\n",
      "Load .json metadata:  ./tmp/train/M_20181212_145535.json\n",
      "Load .json metadata:  ./tmp/train/R_palacio_cadenas_ubeda6.json\n",
      "Load .json metadata:  ./tmp/train/G_5d9f62eb395ce.json\n",
      "Load .json metadata:  ./tmp/train/M_5c879cb97a78b.json\n",
      "Load .json metadata:  ./tmp/train/G_hospital_san_sebastian_cordoba3.json\n",
      "Load .json metadata:  ./tmp/train/G_torre_fadrique.json\n",
      "Load .json metadata:  ./tmp/train/G_5cc07109e57de.json\n",
      "Load .json metadata:  ./tmp/train/G_5c4838d6e0fd8.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc8b5000bde2.json\n",
      "Load .json metadata:  ./tmp/train/B_iglesia_angustias_granada2.json\n",
      "Load .json metadata:  ./tmp/train/M_medina_azahara32.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc765338c390.json\n",
      "Load .json metadata:  ./tmp/train/M_5cad9cd45d2e9.json\n",
      "Load .json metadata:  ./tmp/train/G_5bb28d496a53a.json\n",
      "Load .json metadata:  ./tmp/train/M_medina_azahara28.json\n",
      "Load .json metadata:  ./tmp/train/B_5baf982ee2bfd.json\n",
      "Load .json metadata:  ./tmp/train/M_5d31db347e7fe.json\n",
      "Load .json metadata:  ./tmp/train/B_5e3ec0560f9a0.json\n",
      "Load .json metadata:  ./tmp/train/G_5c13847fdc587.json\n",
      "Load .json metadata:  ./tmp/train/B_casa_almirante_cadiz3.json\n",
      "Load .json metadata:  ./tmp/train/G_iglesia_san_pablo_ubeda7.json\n",
      "Load .json metadata:  ./tmp/train/R_5bb78e09c8a9a.json\n",
      "Load .json metadata:  ./tmp/train/B_IMG_0357.json\n",
      "Load .json metadata:  ./tmp/train/R_5c7134cd2811e.json\n",
      "Load .json metadata:  ./tmp/train/M_5d9dcd1b591de.json\n",
      "Load .json metadata:  ./tmp/train/B_catedral_jaen3.json\n",
      "Load .json metadata:  ./tmp/train/R_iglesia_san_cecilio_granada5.json\n",
      "Load .json metadata:  ./tmp/train/R_palacio_carlos_v_granada18.json\n",
      "Load .json metadata:  ./tmp/train/B_compas_convento_santa_isabel_granada3.json\n",
      "Load .json metadata:  ./tmp/train/G_casa_abrantes_granada3.json\n",
      "Load .json metadata:  ./tmp/train/B_casa_museo_sefardi_granada.json\n",
      "Load .json metadata:  ./tmp/train/B_5df11afa505fc.json\n",
      "Load .json metadata:  ./tmp/train/G_iglesia_sabiote.json\n",
      "Load .json metadata:  ./tmp/train/M_5dd41b35bc692.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc75ff931f5d.json\n",
      "Load .json metadata:  ./tmp/train/B_iglesia_san_pedro_pablo_granada3.json\n",
      "Load .json metadata:  ./tmp/train/M_5bbcca54787e1.json\n",
      "Load .json metadata:  ./tmp/train/M_5bec3b41cead0.json\n",
      "Load .json metadata:  ./tmp/train/B_convento_carmelitas_descalzas_granada4.json\n",
      "Load .json metadata:  ./tmp/train/R_iglesia_asuncion_jodar.json\n",
      "Load .json metadata:  ./tmp/train/G_monasterio_concepcion_granada3.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc75fefdc08e.json\n",
      "Load .json metadata:  ./tmp/train/B_5baf578813fe8.json\n",
      "Load .json metadata:  ./tmp/train/B_5be5b11d168b4.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc75e0d6a8e0.json\n",
      "Load .json metadata:  ./tmp/train/G_iglesia_sabiote5.json\n",
      "Load .json metadata:  ./tmp/train/B_5bacb65418a73.json\n",
      "Load .json metadata:  ./tmp/train/B_casa_marqueses_caicedo_granada.json\n",
      "Load .json metadata:  ./tmp/train/R_iglesia_anunciacion_sevilla.json\n",
      "Load .json metadata:  ./tmp/train/B_5bb0a2afa286c.json\n",
      "Load .json metadata:  ./tmp/train/M_20181212_113410.json\n",
      "Load .json metadata:  ./tmp/train/G_catedral_burgos10.json\n",
      "Load .json metadata:  ./tmp/train/G_catedral_leon3.json\n",
      "Load .json metadata:  ./tmp/train/M_5bec3b6fce57a.json\n",
      "Load .json metadata:  ./tmp/train/R_iglesia_guadahortuna2.json\n",
      "Load .json metadata:  ./tmp/train/M_5d99bc04097a3.json\n",
      "Load .json metadata:  ./tmp/train/B_catedral_granada6.json\n",
      "Load .json metadata:  ./tmp/train/G_5bdf14be71c61.json\n",
      "Load .json metadata:  ./tmp/train/B_IMG_0330.json\n",
      "Load .json metadata:  ./tmp/train/M_5baf1bc3da161.json\n",
      "Load .json metadata:  ./tmp/train/R_iglesia_del_sagrario_jaen2.json\n",
      "Load .json metadata:  ./tmp/train/M_alminar_san_jose_granada3.json\n",
      "Load .json metadata:  ./tmp/train/G_iglesia_san_pablo_ubeda4.json\n",
      "Load .json metadata:  ./tmp/train/M_5c7bc23b3c8df.json\n",
      "Load .json metadata:  ./tmp/train/R_5bf817556125f.json\n",
      "Load .json metadata:  ./tmp/train/R_palacio_carlos_v_granada2.json\n",
      "Load .json metadata:  ./tmp/train/B_5ddba404ec262.json\n",
      "Load .json metadata:  ./tmp/train/B_5bd33eb67044c.json\n",
      "Load .json metadata:  ./tmp/train/B_5bb5f3dfac1c3.json\n",
      "Load .json metadata:  ./tmp/train/G_casa_zafra_granada3.json\n",
      "Load .json metadata:  ./tmp/train/M_medina_azahara34.json\n",
      "Load .json metadata:  ./tmp/train/G_capilla_real_granada3.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_de_las_pesas_granada5.json\n",
      "Load .json metadata:  ./tmp/train/G_5bcaece80705a.json\n",
      "Load .json metadata:  ./tmp/train/R_iglesia_san_jeronimo_granada.json\n",
      "Load .json metadata:  ./tmp/train/B_5bad4af6cbe6a.json\n",
      "Load .json metadata:  ./tmp/train/G_5da5cf2a09f80.json\n",
      "Load .json metadata:  ./tmp/train/R_5bf817543af18.json\n",
      "Load .json metadata:  ./tmp/train/B_palacio_ansoti2.json\n",
      "Load .json metadata:  ./tmp/train/B_casa_marqueses_caicedo_granada2.json\n",
      "Load .json metadata:  ./tmp/train/R_5bd575da84afe.json\n",
      "Load .json metadata:  ./tmp/train/R_iglesia_del_sagrario_jaen.json\n",
      "Load .json metadata:  ./tmp/train/B_convento_carmelitas_descalzas_granada6.json\n",
      "Load .json metadata:  ./tmp/train/G_5da6fe91a1b08.json\n",
      "Load .json metadata:  ./tmp/train/M_5c82f4cdc538e.json\n",
      "Load .json metadata:  ./tmp/train/R_puerta_puente_cordoba13.json\n",
      "Load .json metadata:  ./tmp/train/M_5bdee1652730b.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc7649e7f853.json\n",
      "Load .json metadata:  ./tmp/train/M_5db444d933327.json\n",
      "Load .json metadata:  ./tmp/train/G_catedral_burgos8.json\n",
      "Load .json metadata:  ./tmp/train/M_medina_azahara8.json\n",
      "Load .json metadata:  ./tmp/train/B_san_felipe_neri_baeza2.json\n",
      "Load .json metadata:  ./tmp/train/M_5c45b1d2472c7.json\n",
      "Load .json metadata:  ./tmp/train/M_5b8eceba8b412.json\n",
      "Load .json metadata:  ./tmp/train/G_5db2fc59d9b68.json\n",
      "Load .json metadata:  ./tmp/train/R_5bded6103ee40.json\n",
      "Load .json metadata:  ./tmp/train/B_5bb71c65a6474.json\n",
      "Load .json metadata:  ./tmp/train/B_5cb9a29a5424f.json\n",
      "Load .json metadata:  ./tmp/train/R_5bc9b16bd7277.json\n",
      "Load .json metadata:  ./tmp/train/R_palacio_cadenas_ubeda16.json\n",
      "Load .json metadata:  ./tmp/train/M_medina_azahara6.json\n",
      "Load .json metadata:  ./tmp/train/B_iglesia_caridad_sevilla9.json\n",
      "Load .json metadata:  ./tmp/train/G_5ced8dfa04cf1.json\n",
      "Load .json metadata:  ./tmp/train/R_5bcdbfa0a31fb.json\n",
      "Load .json metadata:  ./tmp/train/R_san_grabiel_loja2.json\n",
      "Load .json metadata:  ./tmp/train/B_iglesia_caridad_sevilla8.json\n",
      "Load .json metadata:  ./tmp/train/B_iglesia_san_francisco_cordoba.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc764f8d06ab.json\n",
      "Load .json metadata:  ./tmp/train/R_colegio_niñas_nobles_granada3.json\n",
      "Load .json metadata:  ./tmp/train/B_5bd354095e856.json\n",
      "Load .json metadata:  ./tmp/train/B_5bdb228d13793.json\n",
      "Load .json metadata:  ./tmp/train/G_5dd41b5a94b5e.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc75e652da1b.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc4d231daaf1.json\n",
      "Load .json metadata:  ./tmp/train/B_5c14f51720f9a.json\n",
      "Load .json metadata:  ./tmp/train/G_5c010d67518b6.json\n",
      "Load .json metadata:  ./tmp/train/M_5bd753b475e1b.json\n",
      "Load .json metadata:  ./tmp/train/G_5bc8af93c364c.json\n",
      "Load .json metadata:  ./tmp/train/B_iglesia_señora_gracia_estepa.json\n",
      "Load .json metadata:  ./tmp/train/G_monasterio_concepcion_granada.json\n",
      "Load .json metadata:  ./tmp/train/B_5c2ba60f43651.json\n",
      "Load .json metadata:  ./tmp/train/B_5bb0b4dfa6fc4.json\n",
      "Load .json metadata:  ./tmp/train/M_5bd3504ad94ce.json\n",
      "Load .json metadata:  ./tmp/train/B_5bccafb89cf2f.json\n",
      "Load .json metadata:  ./tmp/train/M_aljibe_san_miguel_bajo4.json\n",
      "Load .json metadata:  ./tmp/train/G_catedral_leon9.json\n",
      "Load .json metadata:  ./tmp/train/R_convento_santa_clara_ubeda2.json\n",
      "Load .json metadata:  ./tmp/train/G_5b8ecc074657b.json\n",
      "Load .json metadata:  ./tmp/train/R_iglesia_del_sagrario_jaen5.json\n",
      "Load .json metadata:  ./tmp/train/B_5bec3a03c184c.json\n",
      "Load .json metadata:  ./tmp/train/G_5c82f51ed64ae.json\n",
      "Load .json metadata:  ./tmp/train/M_20181212_122859.json\n",
      "Load .json metadata:  ./tmp/train/G_torre_fadrique4.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc764753c2e3.json\n",
      "Load .json metadata:  ./tmp/train/G_5bad4abe0539c.json\n",
      "Load .json metadata:  ./tmp/train/G_puerta_bautismo_catedral_sevilla3.json\n",
      "Load .json metadata:  ./tmp/train/B_5e53b78a07e5e.json\n",
      "Load .json metadata:  ./tmp/train/M_5bacb800b40e1.json\n",
      "Load .json metadata:  ./tmp/train/R_ayuntamiento_baeza5.json\n",
      "Load .json metadata:  ./tmp/train/R_5bd19e2979917.json\n",
      "Load .json metadata:  ./tmp/train/M_5c9d17c407acd.json\n",
      "Load .json metadata:  ./tmp/train/R_ayuntamiento_baeza8.json\n",
      "Load .json metadata:  ./tmp/train/M_5e4fbfcdcf33a.json\n",
      "Load .json metadata:  ./tmp/train/B_chancilleria_granada13.json\n",
      "Load .json metadata:  ./tmp/train/G_iglesia_san_miguel_cordoba2.json\n",
      "Load .json metadata:  ./tmp/train/R_5bb8b808d52c6.json\n",
      "Load .json metadata:  ./tmp/train/R_5bb28db47335d.json\n",
      "Load .json metadata:  ./tmp/train/B_fabrica_tabaco_sevilla8.json\n",
      "Load .json metadata:  ./tmp/train/G_catedral_burgos3.json\n",
      "Load .json metadata:  ./tmp/train/B_5bcdf5e2a5c10.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc306e82d209.json\n",
      "Load .json metadata:  ./tmp/train/G_puerta_bautismo_catedral_sevilla11.json\n",
      "Load .json metadata:  ./tmp/train/G_puerta_bautismo_catedral_sevilla12.json\n",
      "Load .json metadata:  ./tmp/train/B_5cf8001418164.json\n",
      "Load .json metadata:  ./tmp/train/G_5bdf0bf35d6ef.json\n",
      "Load .json metadata:  ./tmp/train/M_20181212_113415.json\n",
      "Load .json metadata:  ./tmp/train/M_5c7026209438f.json\n",
      "Load .json metadata:  ./tmp/train/B_santos_justo_pastor_granada7.json\n",
      "Load .json metadata:  ./tmp/train/M_patio_doncella_reales_alcazares_sevilla13.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc9a5fe2bed8.json\n",
      "Load .json metadata:  ./tmp/train/R_palacio_carlos_v_granada14.json\n",
      "Load .json metadata:  ./tmp/train/M_5bae64dc35949.json\n",
      "Load .json metadata:  ./tmp/train/M_corral_carbon_granada11.json\n",
      "Load .json metadata:  ./tmp/train/B_casa_marqueses_de_cartagena_granada3.json\n",
      "Load .json metadata:  ./tmp/train/B_IMG_0339.json\n",
      "Load .json metadata:  ./tmp/train/B_5b8ecb55cc725.json\n",
      "Load .json metadata:  ./tmp/train/R_5c024c2323973.json\n",
      "Load .json metadata:  ./tmp/train/B_5bf6cf1b04611.json\n",
      "Load .json metadata:  ./tmp/train/B_5c8cdc1b5564c.json\n",
      "Load .json metadata:  ./tmp/train/G_5b8eccf9cacde.json\n",
      "Load .json metadata:  ./tmp/train/B_carmelitas_calzadas_granada.json\n",
      "Load .json metadata:  ./tmp/train/G_5d98cc88e4a26.json\n",
      "Load .json metadata:  ./tmp/train/G_5ccefd1dbdf9e.json\n",
      "Load .json metadata:  ./tmp/train/R_20181212_110248.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc75e8d06c33.json\n",
      "Load .json metadata:  ./tmp/train/B_5be6b71806804.json\n",
      "Load .json metadata:  ./tmp/train/G_hospital_san_sebastian_cordoba7.json\n",
      "Load .json metadata:  ./tmp/train/R_ayuntamiento_sevilla3.json\n",
      "Load .json metadata:  ./tmp/train/B_iglesia_san_pedro_pablo_granada2.json\n",
      "Load .json metadata:  ./tmp/train/B_iglesia_angustias_granada3.json\n",
      "Load .json metadata:  ./tmp/train/R_5bd3450596f60.json\n",
      "Load .json metadata:  ./tmp/train/B_5bae52157ff90.json\n",
      "Load .json metadata:  ./tmp/train/B_5bb4ea3b75f38.json\n",
      "Load .json metadata:  ./tmp/train/R_5c09688c5bd6d.json\n",
      "Load .json metadata:  ./tmp/train/M_5c0bb6ad8a829.json\n",
      "Load .json metadata:  ./tmp/train/R_iglesia_santa_ana_granada.json\n",
      "Load .json metadata:  ./tmp/train/G_5ddab25a85cf9.json\n",
      "Load .json metadata:  ./tmp/train/R_puerta_compas_cartuja_granada.json\n",
      "Load .json metadata:  ./tmp/train/M_medina_azahara27.json\n",
      "Load .json metadata:  ./tmp/train/R_palacio_carlos_v_granada4.json\n",
      "Load .json metadata:  ./tmp/train/M_dintel_adovelado7.json\n",
      "Load .json metadata:  ./tmp/train/R_5de6b1e7a7256.json\n",
      "Load .json metadata:  ./tmp/train/B_5c0a71a53b060.json\n",
      "Load .json metadata:  ./tmp/train/B_catedral_granada7.json\n",
      "Load .json metadata:  ./tmp/train/B_5bddc20b3a228.json\n",
      "Load .json metadata:  ./tmp/train/B_convento_carmelitas_descalzas_granada3.json\n",
      "Load .json metadata:  ./tmp/train/R_5bdd586f9ce77.json\n",
      "Load .json metadata:  ./tmp/train/B_convento_carmelitas_descalzas_granada.json\n",
      "Load .json metadata:  ./tmp/train/R_puerta_perdon_catedral_granada6.json\n",
      "Load .json metadata:  ./tmp/train/B_5bec3a053928b.json\n",
      "Load .json metadata:  ./tmp/train/R_curia_granada.json\n",
      "Load .json metadata:  ./tmp/train/G_5bb2417649091.json\n",
      "Load .json metadata:  ./tmp/train/B_5cadbc893b98b.json\n",
      "Load .json metadata:  ./tmp/train/B_casa_cadenas_cadiz4.json\n",
      "Load .json metadata:  ./tmp/train/B_5da8720703692.json\n",
      "Load .json metadata:  ./tmp/train/M_5bd34f039bd23.json\n",
      "Load .json metadata:  ./tmp/train/B_palacio_mendoza_granada.json\n",
      "Load .json metadata:  ./tmp/train/G_5dd2b36c2d262.json\n",
      "Load .json metadata:  ./tmp/train/G_cathedral.json\n",
      "Load .json metadata:  ./tmp/train/G_puerta_infierno_catedral_toledo3.json\n",
      "Load .json metadata:  ./tmp/train/M_5bec3b4e60282.json\n",
      "Load .json metadata:  ./tmp/train/G_5bc06c2a9953c.json\n",
      "Load .json metadata:  ./tmp/train/R_catedral_santa_maria_sevilla.json\n",
      "Load .json metadata:  ./tmp/train/M_medina_azahara.json\n",
      "Load .json metadata:  ./tmp/train/G_basilica_santa_maria_arcos_frontera4.json\n",
      "Load .json metadata:  ./tmp/train/B_hospital_real_granada.json\n",
      "Load .json metadata:  ./tmp/train/G_hospital_san_sebastian_cordoba10.json\n",
      "Load .json metadata:  ./tmp/train/B_5cb31f11d9127.json\n",
      "Load .json metadata:  ./tmp/train/B_iglesia_san_francisco_cordoba2.json\n",
      "Load .json metadata:  ./tmp/train/G_5c0d0f01f22fb.json\n",
      "Load .json metadata:  ./tmp/train/B_5ddd37fa3005f.json\n",
      "Load .json metadata:  ./tmp/train/M_corral_carbon_granada10.json\n",
      "Load .json metadata:  ./tmp/train/B_5c2c923e98eb3.json\n",
      "Load .json metadata:  ./tmp/train/G_convento_clarisas_palencia.json\n",
      "Load .json metadata:  ./tmp/train/B_facultad_derecho_granada6.json\n",
      "Load .json metadata:  ./tmp/train/M_5bd34e85bb4d0.json\n",
      "Load .json metadata:  ./tmp/train/B_5d90d036cd46d.json\n",
      "Load .json metadata:  ./tmp/train/B_5cadb8073058a.json\n",
      "Load .json metadata:  ./tmp/train/R_5c0a52d721023.json\n",
      "Load .json metadata:  ./tmp/train/G_catedral_sevilla2.json\n",
      "Load .json metadata:  ./tmp/train/R_puerta_puente_cordoba.json\n",
      "Load .json metadata:  ./tmp/train/B_colegio_san_telmo_sevilla4.json\n",
      "Load .json metadata:  ./tmp/train/M_alhambra2.json\n",
      "Load .json metadata:  ./tmp/train/B_hospital_san_juan_de_dios_granada3.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc76e871b47e.json\n",
      "Load .json metadata:  ./tmp/train/B_colegio_san_telmo_sevilla5.json\n",
      "Load .json metadata:  ./tmp/train/G_5cd4510ecd2a1.json\n",
      "Load .json metadata:  ./tmp/train/G_5d98cbcf8b124.json\n",
      "Load .json metadata:  ./tmp/train/G_5d07bb5a78cf0.json\n",
      "Load .json metadata:  ./tmp/train/B_5b8ecac4ebfae.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc4cdce3fab8.json\n",
      "Load .json metadata:  ./tmp/train/G_5bc743ec098e2.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_atarazanas_malaga8.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_atarazanas_malaga4.json\n",
      "Load .json metadata:  ./tmp/train/B_5bacb69c505b0.json\n",
      "Load .json metadata:  ./tmp/train/M_5e4fb9bc9e1ae.json\n",
      "Load .json metadata:  ./tmp/train/G_iglesia_sabiote6.json\n",
      "Load .json metadata:  ./tmp/train/G_5bc76dba8ef2f.json\n",
      "Load .json metadata:  ./tmp/train/R_iglesia_salvador_ubeda4.json\n",
      "Load .json metadata:  ./tmp/train/B_5cf7f31d58a0d.json\n",
      "Load .json metadata:  ./tmp/train/M_medina_azahara19.json\n",
      "Load .json metadata:  ./tmp/train/G_5cb6fbc6f2a4a.json\n",
      "Load .json metadata:  ./tmp/train/G_5bec3a78bce6d.json\n",
      "Load .json metadata:  ./tmp/train/G_5c62926eae2a5.json\n",
      "Load .json metadata:  ./tmp/train/B_5cada1e3cfdea.json\n",
      "Load .json metadata:  ./tmp/train/G_iglesia_nuestra_señora_de_la_o_chipiona2.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc765452f841.json\n",
      "Load .json metadata:  ./tmp/train/R_5bd5a68809887.json\n",
      "Load .json metadata:  ./tmp/train/G_5bec50ea6cb7f.json\n",
      "Load .json metadata:  ./tmp/train/M_medina_azahara18.json\n",
      "Load .json metadata:  ./tmp/train/M_5c879cb402953.json\n",
      "Load .json metadata:  ./tmp/train/G_5d62cfd4039d2.json\n",
      "Load .json metadata:  ./tmp/train/M_medina_azahara20.json\n",
      "Load .json metadata:  ./tmp/train/B_5d6648730c69e.json\n",
      "Load .json metadata:  ./tmp/train/G_20181212_105125.json\n",
      "Load .json metadata:  ./tmp/train/R_iglesia_del_sagrario_jaen3.json\n",
      "Load .json metadata:  ./tmp/train/R_iglesia_salvador_ubeda2.json\n",
      "Load .json metadata:  ./tmp/train/B_20181212_105924.json\n",
      "Load .json metadata:  ./tmp/train/B_santos_justo_pastor_granada6.json\n",
      "Load .json metadata:  ./tmp/train/B_5bb5f605c1f88.json\n",
      "Load .json metadata:  ./tmp/train/M_ermita_sansebastian.json\n",
      "Load .json metadata:  ./tmp/train/M_5be5e804a3167.json\n",
      "Load .json metadata:  ./tmp/train/G_5c877f6795355.json\n",
      "Load .json metadata:  ./tmp/train/G_5cadb87f04f94.json\n",
      "Load .json metadata:  ./tmp/train/G_puerta_bautismo_catedral_sevilla10.json\n",
      "Load .json metadata:  ./tmp/train/B_san_juan_cordoba.json\n",
      "Load .json metadata:  ./tmp/train/B_5d9dcbaf77eae.json\n",
      "Load .json metadata:  ./tmp/train/B_catedral_granada.json\n",
      "Load .json metadata:  ./tmp/train/B_5da5d013f0299.json\n",
      "Load .json metadata:  ./tmp/train/M_5db2e772b2a7e.json\n",
      "Load .json metadata:  ./tmp/train/M_5ced1021171f9.json\n",
      "Load .json metadata:  ./tmp/train/R_santa_maria_antequera4.json\n",
      "Load .json metadata:  ./tmp/train/G_iglesia_san_nicolas_ubeda5.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_elvira_granada4.json\n",
      "Load .json metadata:  ./tmp/train/G_5bdf0bbee1eb6.json\n",
      "Load .json metadata:  ./tmp/train/B_convento_merced_granada.json\n",
      "Load .json metadata:  ./tmp/train/R_5c191267b06b1.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_san_isidro_mezquita_cordoba7.json\n",
      "Load .json metadata:  ./tmp/train/B_20181212_105011.json\n",
      "Load .json metadata:  ./tmp/train/M_20181212_115640.json\n",
      "Load .json metadata:  ./tmp/train/B_5bcaedfc23bdb.json\n",
      "Load .json metadata:  ./tmp/train/M_dintel_adovelado2.json\n",
      "Load .json metadata:  ./tmp/train/G_5bdf0b71aba0a.json\n",
      "Load .json metadata:  ./tmp/train/G_5b8ecbee59495.json\n",
      "Load .json metadata:  ./tmp/train/R_5c4066194de97.json\n",
      "Load .json metadata:  ./tmp/train/M_medina_azahara26.json\n",
      "Load .json metadata:  ./tmp/train/R_5db1cfe3aed90.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_elvira_granada6.json\n",
      "Load .json metadata:  ./tmp/train/B_5d66482a8551f.json\n",
      "Load .json metadata:  ./tmp/train/B_5bb4e71f205dd.json\n",
      "Load .json metadata:  ./tmp/train/R_5bb8b7efe4c9c.json\n",
      "Load .json metadata:  ./tmp/train/B_5bd5754e6f78b.json\n",
      "Load .json metadata:  ./tmp/train/G_5c2f2f40203c3.json\n",
      "Load .json metadata:  ./tmp/train/G_5da4ce32a9cbf.json\n",
      "Load .json metadata:  ./tmp/train/R_ayuntamiento_sevilla6.json\n",
      "Load .json metadata:  ./tmp/train/G_5ddc200ecb1a5.json\n",
      "Load .json metadata:  ./tmp/train/G_catedral_toledo4.json\n",
      "Load .json metadata:  ./tmp/train/G_5bb24276e44cc.json\n",
      "Load .json metadata:  ./tmp/train/B_5bb78d37dd05b.json\n",
      "Load .json metadata:  ./tmp/train/M_patio_doncella_reales_alcazares_sevilla6.json\n",
      "Load .json metadata:  ./tmp/train/G_iglesia_san_miguel_cordoba.json\n",
      "Load .json metadata:  ./tmp/train/R_santa_maria_antequera.json\n",
      "Load .json metadata:  ./tmp/train/M_5bad538f2022e.json\n",
      "Load .json metadata:  ./tmp/train/B_5bded5483c8c8.json\n",
      "Load .json metadata:  ./tmp/train/B_5ce83a2b2d61c.json\n",
      "Load .json metadata:  ./tmp/train/B_5def64aa85fc0.json\n",
      "Load .json metadata:  ./tmp/train/R_ayuntamiento_baeza6.json\n",
      "Load .json metadata:  ./tmp/train/B_5c096afcab1bf.json\n",
      "Load .json metadata:  ./tmp/train/G_san_bartolome_andujar2.json\n",
      "Load .json metadata:  ./tmp/train/M_dintel_adovelado.json\n",
      "Load .json metadata:  ./tmp/train/M_5cad9d871f944.json\n",
      "Load .json metadata:  ./tmp/train/M_5baf14b3d8aec.json\n",
      "Load .json metadata:  ./tmp/train/M_5c1385195448d.json\n",
      "Load .json metadata:  ./tmp/train/G_monasterio_concepcion_granada2.json\n",
      "Load .json metadata:  ./tmp/train/R_5be9a1419232a.json\n",
      "Load .json metadata:  ./tmp/train/G_basilica_santa_maria_arcos_frontera7.json\n",
      "Load .json metadata:  ./tmp/train/B_5c0acbbb675b5.json\n",
      "Load .json metadata:  ./tmp/train/M_corral_carbon_granada6.json\n",
      "Load .json metadata:  ./tmp/train/G_5bc76b1661432.json\n",
      "Load .json metadata:  ./tmp/train/M_corral_carbon_granada7.json\n",
      "Load .json metadata:  ./tmp/train/B_palacio_ansoti4.json\n",
      "Load .json metadata:  ./tmp/train/M_medina_azahara11.json\n",
      "Load .json metadata:  ./tmp/train/R_palacio_carlos_v_granada3.json\n",
      "Load .json metadata:  ./tmp/train/G_5bd3513c8e708.json\n",
      "Load .json metadata:  ./tmp/train/B_colegio_san_fernando_granada.json\n",
      "Load .json metadata:  ./tmp/train/M_5e4fb99bb2bc3.json\n",
      "Load .json metadata:  ./tmp/train/B_IMG_1131.json\n",
      "Load .json metadata:  ./tmp/train/B_5c794e4eb432a.json\n",
      "Load .json metadata:  ./tmp/train/M_5e4fb8cac7644.json\n",
      "Load .json metadata:  ./tmp/train/M_ermita_sansebastian2.json\n",
      "Load .json metadata:  ./tmp/train/B_hospital_real_granada2.json\n",
      "Load .json metadata:  ./tmp/train/B_casa_calle_san_matias_granada2.json\n",
      "Load .json metadata:  ./tmp/train/G_5c67dcd823270.json\n",
      "Load .json metadata:  ./tmp/train/R_5bde0353e3682.json\n",
      "Load .json metadata:  ./tmp/train/R_5bb5f42a2c989.json\n",
      "Load .json metadata:  ./tmp/train/R_5bdef0fa697b6.json\n",
      "Load .json metadata:  ./tmp/train/B_5c3dc13138c7a.json\n",
      "Load .json metadata:  ./tmp/train/G_puerta_bautismo_catedral_sevilla6.json\n",
      "Load .json metadata:  ./tmp/train/B_museo_bellas_artes_sevilla5.json\n",
      "Load .json metadata:  ./tmp/train/B_colegio_bartolome_santiago_granada3.json\n",
      "Load .json metadata:  ./tmp/train/B_san_felipe_neri_baeza8.json\n",
      "Load .json metadata:  ./tmp/train/B_5c2764eb103ed.json\n",
      "Load .json metadata:  ./tmp/train/B_5df7426bc0bff.json\n",
      "Load .json metadata:  ./tmp/train/M_5bbcca84a8516.json\n",
      "Load .json metadata:  ./tmp/train/R_palacio_carlos_v_granada20.json\n",
      "Load .json metadata:  ./tmp/train/B_convento_jesus_nazareno_chiclana2.json\n",
      "Load .json metadata:  ./tmp/train/B_5baff856046e5.json\n",
      "Load .json metadata:  ./tmp/train/G_palacio_jabalquinto_baeza14.json\n",
      "Load .json metadata:  ./tmp/train/M_20181212_115538.json\n",
      "Load .json metadata:  ./tmp/train/R_puerta_puente_cordoba8.json\n",
      "Load .json metadata:  ./tmp/train/B_IMG_0378.json\n",
      "Load .json metadata:  ./tmp/train/G_puerta_bautismo_catedral_sevilla7.json\n",
      "Load .json metadata:  ./tmp/train/G_5c7d00c96fbbb.json\n",
      "Load .json metadata:  ./tmp/train/R_iglesia_san_ildefonso_jaen2.json\n",
      "Load .json metadata:  ./tmp/train/R_5c7d015d64d2e.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_del_vino_granada7.json\n",
      "Load .json metadata:  ./tmp/train/R_5bb90f5617705.json\n",
      "Load .json metadata:  ./tmp/train/B_5bb0a2c4b9b8b.json\n",
      "Load .json metadata:  ./tmp/train/G_puerta_apostoles_catedral_murcia3.json\n",
      "Load .json metadata:  ./tmp/train/G_5d98c684abe28.json\n",
      "Load .json metadata:  ./tmp/train/B_5c484246ab3f1.json\n",
      "Load .json metadata:  ./tmp/train/R_palacio_cadenas_ubeda9.json\n",
      "Load .json metadata:  ./tmp/train/M_patio_doncella_reales_alcazares_sevilla9.json\n",
      "Load .json metadata:  ./tmp/train/M_5bd34f9db3310.json\n",
      "Load .json metadata:  ./tmp/train/B_5c2c947748ce6.json\n",
      "Load .json metadata:  ./tmp/train/B_IMG_1132.json\n",
      "Load .json metadata:  ./tmp/train/B_iglesia_san_anton_granada2.json\n",
      "Load .json metadata:  ./tmp/train/B_casa_calle_san_matias_granada3.json\n",
      "Load .json metadata:  ./tmp/train/G_iglesia_san_pablo_ubeda6.json\n",
      "Load .json metadata:  ./tmp/train/G_5da6fcf439ccd.json\n",
      "Load .json metadata:  ./tmp/train/G_5c0d0d49c0423.json\n",
      "Load .json metadata:  ./tmp/train/B_5c4066fd86767.json\n",
      "Load .json metadata:  ./tmp/train/G_iglesia_san_miguel_cordoba4.json\n",
      "Load .json metadata:  ./tmp/train/R_santa_maria_antequera5.json\n",
      "Load .json metadata:  ./tmp/train/B_5d0e5f2316005.json\n",
      "Load .json metadata:  ./tmp/train/M_5bc745d744106.json\n",
      "Load .json metadata:  ./tmp/train/R_iglesia_san_bartolome.json\n",
      "Load .json metadata:  ./tmp/train/B_5c878f098b516.json\n",
      "Load .json metadata:  ./tmp/train/R_5bd96e97c779b.json\n",
      "Load .json metadata:  ./tmp/train/B_iglesia_san_jeronimo_granada2.json\n",
      "Load .json metadata:  ./tmp/train/R_5bacb84ca1ce0.json\n",
      "Load .json metadata:  ./tmp/train/B_5df95dd4cf94d.json\n",
      "Load .json metadata:  ./tmp/train/R_carcel_martos.json\n",
      "Load .json metadata:  ./tmp/train/G_5d9f61bbc6dc2.json\n",
      "Load .json metadata:  ./tmp/train/G_hospital_san_sebastian_cordoba11.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_del_vino_granada9.json\n",
      "Load .json metadata:  ./tmp/train/M_patio_doncella_reales_alcazares_sevilla11.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_monaita_granada4.json\n",
      "Load .json metadata:  ./tmp/train/R_catedral_puerta_perdon_granada.json\n",
      "Load .json metadata:  ./tmp/train/G_5bb28cf500312.json\n",
      "Load .json metadata:  ./tmp/train/R_5bf7c979ad2be.json\n",
      "Load .json metadata:  ./tmp/train/G_basilica_santa_maria_arcos_frontera2.json\n",
      "Load .json metadata:  ./tmp/train/B_san_felipe_neri_baeza4.json\n",
      "Load .json metadata:  ./tmp/train/R_5bb5f7e3b6c72.json\n",
      "Load .json metadata:  ./tmp/train/R_5d98aefd76ce6.json\n",
      "Load .json metadata:  ./tmp/train/B_IMG_1002.json\n",
      "Load .json metadata:  ./tmp/train/R_palacio_carlos_v_granada17.json\n",
      "Load .json metadata:  ./tmp/train/G_5c0a9e2643692.json\n",
      "Load .json metadata:  ./tmp/train/G_hospital_san_sebastian_cordoba2.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_del_vino_granada10.json\n",
      "Load .json metadata:  ./tmp/train/G_5e5a2e8dc057b.json\n",
      "Load .json metadata:  ./tmp/train/B_hospital_real_granada5.json\n",
      "Load .json metadata:  ./tmp/train/B_chancilleria_granada10.json\n",
      "Load .json metadata:  ./tmp/train/G_catedral_sevilla4.json\n",
      "Load .json metadata:  ./tmp/train/R_5bb0b22d051f2.json\n",
      "Load .json metadata:  ./tmp/train/R_ayuntamiento_sevilla.json\n",
      "Load .json metadata:  ./tmp/train/R_palacio_cadenas_ubeda18.json\n",
      "Load .json metadata:  ./tmp/train/B_5ced7d9be567d.json\n",
      "Load .json metadata:  ./tmp/train/G_pinaculo3.json\n",
      "Load .json metadata:  ./tmp/train/M_medina_azahara30.json\n",
      "Load .json metadata:  ./tmp/train/G_5c877f4185ccc.json\n",
      "Load .json metadata:  ./tmp/train/M_20181212_150121.json\n",
      "Load .json metadata:  ./tmp/train/B_5bae53895ec1c.json\n",
      "Load .json metadata:  ./tmp/train/M_patio_yeso_reales_alcazares_sevilla.json\n",
      "Load .json metadata:  ./tmp/train/M_medina_azahara24.json\n",
      "Load .json metadata:  ./tmp/train/B_iglesia_san_anton_granada3.json\n",
      "Load .json metadata:  ./tmp/train/G_hospital_san_sebastian_cordoba8.json\n",
      "Load .json metadata:  ./tmp/train/G_hospital_san_sebastian_cordoba6.json\n",
      "Load .json metadata:  ./tmp/train/B_5bb1ff537029b.json\n",
      "Load .json metadata:  ./tmp/train/G_5c1799d2dde1a.json\n",
      "Load .json metadata:  ./tmp/train/B_5bdb1d1c42d96.json\n",
      "Load .json metadata:  ./tmp/train/B_catedral_jaen.json\n",
      "Load .json metadata:  ./tmp/train/B_5baf98b804126.json\n",
      "Load .json metadata:  ./tmp/train/R_iglesia_santa_fe_granada.json\n",
      "Load .json metadata:  ./tmp/train/R_5bb0b25a063e4.json\n",
      "Load .json metadata:  ./tmp/train/R_palacio_carlos_v_granada15.json\n",
      "Load .json metadata:  ./tmp/train/B_chancilleria_granada9.json\n",
      "Load .json metadata:  ./tmp/train/R_5c0966aea69f7.json\n",
      "Load .json metadata:  ./tmp/train/B_hospital_rreal_granada2.json\n",
      "Load .json metadata:  ./tmp/train/G_hospital_san_sebastian_cordoba5.json\n",
      "Load .json metadata:  ./tmp/train/R_5bc1abdd2b50a.json\n",
      "Load .json metadata:  ./tmp/train/B_5c12755aad84a.json\n",
      "Load .json metadata:  ./tmp/train/B_5bb7972ad3e16.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc76484d31a1.json\n",
      "Load .json metadata:  ./tmp/train/B_5ddba624afba4.json\n",
      "Load .json metadata:  ./tmp/train/G_5d111a858480b.json\n",
      "Load .json metadata:  ./tmp/train/R_san_pedro_cordoba4.json\n",
      "Load .json metadata:  ./tmp/train/B_san_felipe_neri_baeza3.json\n",
      "Load .json metadata:  ./tmp/train/R_5c48450f3f550.json\n",
      "Load .json metadata:  ./tmp/train/R_5bc76d793e6e7.json\n",
      "Load .json metadata:  ./tmp/train/B_5bba92638b868.json\n",
      "Load .json metadata:  ./tmp/train/G_iglesia_santa_maría_del_pi_barcelona2.json\n",
      "Load .json metadata:  ./tmp/train/B_5bfe9d813c0ca.json\n",
      "Load .json metadata:  ./tmp/train/B_5bb5f69957c0a.json\n",
      "Load .json metadata:  ./tmp/train/M_20181212_150254.json\n",
      "Load .json metadata:  ./tmp/train/R_palacio_carlos_v_granada11.json\n",
      "Load .json metadata:  ./tmp/train/B_5c025913a9ddb.json\n",
      "Load .json metadata:  ./tmp/train/G_5c699dfd45a1a.json\n",
      "Load .json metadata:  ./tmp/train/M_20181212_130014.json\n",
      "Load .json metadata:  ./tmp/train/R_puerta_perdon_catedral_granada4.json\n",
      "Load .json metadata:  ./tmp/train/R_san_pedro_cordoba5.json\n",
      "Load .json metadata:  ./tmp/train/B_iglesia_salvador_sevilla.json\n",
      "Load .json metadata:  ./tmp/train/B_san_felipe_neri_baeza7.json\n",
      "Load .json metadata:  ./tmp/train/M_corral_carbon_granada3.json\n",
      "Load .json metadata:  ./tmp/train/M_5bcc9ce820ba1.json\n",
      "Load .json metadata:  ./tmp/train/G_catedral_leon4.json\n",
      "Load .json metadata:  ./tmp/train/B_5bb1c89ba7002.json\n",
      "Load .json metadata:  ./tmp/train/M_20181212_115637.json\n",
      "Load .json metadata:  ./tmp/train/R_5dfa0add8bffc.json\n",
      "Load .json metadata:  ./tmp/train/R_san_pedro_cordoba3.json\n",
      "Load .json metadata:  ./tmp/train/B_5bd0751729011.json\n",
      "Load .json metadata:  ./tmp/train/G_5bb48060bc6a0.json\n",
      "Load .json metadata:  ./tmp/train/B_facultad_derecho_granada5.json\n",
      "Load .json metadata:  ./tmp/train/G_palacio_jabalquinto_baeza.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_del_vino_granada4.json\n",
      "Load .json metadata:  ./tmp/train/G_5cf2f6096b752.json\n",
      "Load .json metadata:  ./tmp/train/G_5c0d10a4df5cb.json\n",
      "Load .json metadata:  ./tmp/train/B_5cf7e81e4e982.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_del_vino_granada.json\n",
      "Load .json metadata:  ./tmp/train/M_5e4fb8e1009fb.json\n",
      "Load .json metadata:  ./tmp/train/R_5bc6e43c0907f.json\n",
      "Load .json metadata:  ./tmp/train/R_5de0eaa225937.json\n",
      "Load .json metadata:  ./tmp/train/G_catedral_burgos4.json\n",
      "Load .json metadata:  ./tmp/train/R_5bb768f243f4d.json\n",
      "Load .json metadata:  ./tmp/train/M_5d623f48dabcd.json\n",
      "Load .json metadata:  ./tmp/train/B_iglesia_caridad_sevilla3.json\n",
      "Load .json metadata:  ./tmp/train/G_catedral_leon5.json\n",
      "Load .json metadata:  ./tmp/train/R_puerta_perdon_catedral_granada12.json\n",
      "Load .json metadata:  ./tmp/train/M_patio_doncella_reales_alcazares_sevilla8.json\n",
      "Load .json metadata:  ./tmp/train/B_5bec4cccf3ed2.json\n",
      "Load .json metadata:  ./tmp/train/B_5c4841c1ca3e2.json\n",
      "Load .json metadata:  ./tmp/train/G_basilica_santa_maria_arcos_frontera3.json\n",
      "Load .json metadata:  ./tmp/train/G_5d74bc786cba6.json\n",
      "Load .json metadata:  ./tmp/train/G_IMG_1052.json\n",
      "Load .json metadata:  ./tmp/train/G_convento_clarisas_palencia5.json\n",
      "Load .json metadata:  ./tmp/train/G_5c2ca09d347ad.json\n",
      "Load .json metadata:  ./tmp/train/M_5bbcca3f7448f.json\n",
      "Load .json metadata:  ./tmp/train/B_parroquia_mayor_santa_maria_encarnacion_huescar.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_justicia_granada5.json\n",
      "Load .json metadata:  ./tmp/train/M_medina_azahara36.json\n",
      "Load .json metadata:  ./tmp/train/R_iglesia_san_cecilio_granada4.json\n",
      "Load .json metadata:  ./tmp/train/G_palacio_jabalquinto_baeza5.json\n",
      "Load .json metadata:  ./tmp/train/R_5bbe3480002dc.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_san_isidro_mezquita_cordoba3.json\n",
      "Load .json metadata:  ./tmp/train/G_5c0d0de30a8f2.json\n",
      "Load .json metadata:  ./tmp/train/G_casa_abrantes_granada.json\n",
      "Load .json metadata:  ./tmp/train/G_5d98c47b04a88.json\n",
      "Load .json metadata:  ./tmp/train/M_20181212_125945.json\n",
      "Load .json metadata:  ./tmp/train/R_puerta_perdon_catedral_granada2.json\n",
      "Load .json metadata:  ./tmp/train/B_5bae55d7aad09.json\n",
      "Load .json metadata:  ./tmp/train/B_5c80d24a04008.json\n",
      "Load .json metadata:  ./tmp/train/G_5db2a2cad60a2.json\n",
      "Load .json metadata:  ./tmp/train/B_colegio_bartolome_santiago_granada4.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc75f2c9c6a4.json\n",
      "Load .json metadata:  ./tmp/train/R_5bc76d50783ef.json\n",
      "Load .json metadata:  ./tmp/train/M_5bc5c30c3eaf6.json\n",
      "Load .json metadata:  ./tmp/train/B_chancilleria_granada11.json\n",
      "Load .json metadata:  ./tmp/train/G_convento_clarisas_palencia2.json\n",
      "Load .json metadata:  ./tmp/train/R_5bc4d1797c791.json\n",
      "Load .json metadata:  ./tmp/train/B_chancilleria_granada2.json\n",
      "Load .json metadata:  ./tmp/train/R_5d559f8ccff2a.json\n",
      "Load .json metadata:  ./tmp/train/G_5bad41c85ae3d.json\n",
      "Load .json metadata:  ./tmp/train/B_casa_almirante_cadiz.json\n",
      "Load .json metadata:  ./tmp/train/R_puerta_perdon_catedral_granada7.json\n",
      "Load .json metadata:  ./tmp/train/B_basilica_angustias_granada2.json\n",
      "Load .json metadata:  ./tmp/train/R_palacio_cadenas_ubeda10.json\n",
      "Load .json metadata:  ./tmp/train/M_5bd4b5dfc5dd4.json\n",
      "Load .json metadata:  ./tmp/train/M_5c1b60d5c92de.json\n",
      "Load .json metadata:  ./tmp/train/G_palacio_jabalquinto_baeza10.json\n",
      "Load .json metadata:  ./tmp/train/R_san_grabiel_loja3.json\n",
      "Load .json metadata:  ./tmp/train/M_dintel_adovelado6.json\n",
      "Load .json metadata:  ./tmp/train/B_museo_bellas_artes_sevilla3.json\n",
      "Load .json metadata:  ./tmp/train/B_5c0b9bda7349b.json\n",
      "Load .json metadata:  ./tmp/train/B_5c19275826ba9.json\n",
      "Load .json metadata:  ./tmp/train/G_5dac7070aa7e2.json\n",
      "Load .json metadata:  ./tmp/train/G_5bc76e72997a7.json\n",
      "Load .json metadata:  ./tmp/train/G_20181212_105521.json\n",
      "Load .json metadata:  ./tmp/train/B_san_felipe_neri_baeza5.json\n",
      "Load .json metadata:  ./tmp/train/R_ayuntamiento_baeza9.json\n",
      "Load .json metadata:  ./tmp/train/B_5c15224895f85.json\n",
      "Load .json metadata:  ./tmp/train/B_5be5d7c4bb9bb.json\n",
      "Load .json metadata:  ./tmp/train/M_5db2c2e015c8c.json\n",
      "Load .json metadata:  ./tmp/train/R_5bb74d7c3e166.json\n",
      "Load .json metadata:  ./tmp/train/B_5cadabdf51477.json\n",
      "Load .json metadata:  ./tmp/train/G_5c7ba984d24b3.json\n",
      "Load .json metadata:  ./tmp/train/B_5ba898dd6f92c.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_san_isidro_mezquita_cordoba4.json\n",
      "Load .json metadata:  ./tmp/train/M_corral_carbon_granada8.json\n",
      "Load .json metadata:  ./tmp/train/B_chancilleria_granada12.json\n",
      "Load .json metadata:  ./tmp/train/R_5bf437f158eb5.json\n",
      "Load .json metadata:  ./tmp/train/B_iglesia_señora_gracia_estepa3.json\n",
      "Load .json metadata:  ./tmp/train/B_catedral_granada9.json\n",
      "Load .json metadata:  ./tmp/train/R_palacio_carlos_v_granada8.json\n",
      "Load .json metadata:  ./tmp/train/M_20181212_105457.json\n",
      "Load .json metadata:  ./tmp/train/B_casatercia_baena.json\n",
      "Load .json metadata:  ./tmp/train/B_5c17dbfe94db3.json\n",
      "Load .json metadata:  ./tmp/train/B_colegio_san_fernando_granada2.json\n",
      "Load .json metadata:  ./tmp/train/R_ayuntamiento_baeza10.json\n",
      "Load .json metadata:  ./tmp/train/B_casa_conde_gabia_granada.json\n",
      "Load .json metadata:  ./tmp/train/B_colegio_san_telmo_sevilla2.json\n",
      "Load .json metadata:  ./tmp/train/G_5e0b2c3b44d7a.json\n",
      "Load .json metadata:  ./tmp/train/R_palacio_carlos_v_granada16.json\n",
      "Load .json metadata:  ./tmp/train/B_casa_calle_san_matias_granada.json\n",
      "Load .json metadata:  ./tmp/train/R_5c23b9ae08c28.json\n",
      "Load .json metadata:  ./tmp/train/B_5bb8ee994df2a.json\n",
      "Load .json metadata:  ./tmp/train/B_san_juan_dios_antequera2.json\n",
      "Load .json metadata:  ./tmp/train/B_chancilleria_granada15.json\n",
      "Load .json metadata:  ./tmp/train/B_palacio_bibataubin_granada.json\n",
      "Load .json metadata:  ./tmp/train/G_5df0cfe41c9e2.json\n",
      "Load .json metadata:  ./tmp/train/B_hospital_san_juan_de_dios_granada2.json\n",
      "Load .json metadata:  ./tmp/train/M_5bdee0fc89299.json\n",
      "Load .json metadata:  ./tmp/train/R_5bfabb729d3b7.json\n",
      "Load .json metadata:  ./tmp/train/R_5bec3f44c6943.json\n",
      "Load .json metadata:  ./tmp/train/R_5bb602378e74b.json\n",
      "Load .json metadata:  ./tmp/train/R_casa_torres_ubeda5.json\n",
      "Load .json metadata:  ./tmp/train/B_5ced0fbf8575d.json\n",
      "Load .json metadata:  ./tmp/train/B_catedral_granada8.json\n",
      "Load .json metadata:  ./tmp/train/R_palacio_cadenas_ubeda2.json\n",
      "Load .json metadata:  ./tmp/train/R_palacio_carlos_v_granada7.json\n",
      "Load .json metadata:  ./tmp/train/G_puerta_bautismo_catedral_sevilla5.json\n",
      "Load .json metadata:  ./tmp/train/B_convento_jesus_nazareno_chiclana4.json\n",
      "Load .json metadata:  ./tmp/train/R_5c1514396c39f.json\n",
      "Load .json metadata:  ./tmp/train/G_20181212_105032.json\n",
      "Load .json metadata:  ./tmp/train/R_5ce695bde2c12.json\n",
      "Load .json metadata:  ./tmp/train/B_5c4c40ffaee5b.json\n",
      "Load .json metadata:  ./tmp/train/M_5ca46555b8d6f.json\n",
      "Load .json metadata:  ./tmp/train/R_ayuntamiento_baeza12.json\n",
      "Load .json metadata:  ./tmp/train/R_5c0cf59f3c68c.json\n",
      "Load .json metadata:  ./tmp/train/R_5e1b37e6a0cca.json\n",
      "Load .json metadata:  ./tmp/train/M_patio_doncella_reales_alcazares_sevilla4.json\n",
      "Load .json metadata:  ./tmp/train/M_patio_yeso_reales_alcazares_sevilla6.json\n",
      "Load .json metadata:  ./tmp/train/G_puerta_apostoles_catedra_valencia4.json\n",
      "Load .json metadata:  ./tmp/train/G_iglesia_san_miguel_cordoba3.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_visires_mezquita_cordoba.json\n",
      "Load .json metadata:  ./tmp/train/B_5c0d00ee1c0cd.json\n",
      "Load .json metadata:  ./tmp/train/G_iglesia_sabiote3.json\n",
      "Load .json metadata:  ./tmp/train/R_5bfab9bb46da6.json\n",
      "Load .json metadata:  ./tmp/train/M_5bb0a6aa5f6e4.json\n",
      "Load .json metadata:  ./tmp/train/R_san_pedro_cordoba.json\n",
      "Load .json metadata:  ./tmp/train/M_20181212_110915.json\n",
      "Load .json metadata:  ./tmp/train/G_5d9f5b7f5da26.json\n",
      "Load .json metadata:  ./tmp/train/G_5da98678c6c25.json\n",
      "Load .json metadata:  ./tmp/train/R_ayuntamiento_baeza2.json\n",
      "Load .json metadata:  ./tmp/train/B_chancilleria_granada3.json\n",
      "Load .json metadata:  ./tmp/train/B_hospital_rreal_granada.json\n",
      "Load .json metadata:  ./tmp/train/R_5bb79917b8e2f.json\n",
      "Load .json metadata:  ./tmp/train/R_5bc4b222ab8b9.json\n",
      "Load .json metadata:  ./tmp/train/B_5bb727333c120.json\n",
      "Load .json metadata:  ./tmp/train/G_puerta_perdon_catedral_toledo.json\n",
      "Load .json metadata:  ./tmp/train/R_santa_maria_puebla_fadrique.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_justicia_granada4.json\n",
      "Load .json metadata:  ./tmp/train/B_5beff5707aec9.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_atarazanas_malaga.json\n",
      "Load .json metadata:  ./tmp/train/M_aljibe_san_miguel_bajo3.json\n",
      "Load .json metadata:  ./tmp/train/B_casa_almirante_cadiz4.json\n",
      "Load .json metadata:  ./tmp/train/R_iglesia_salvador_ubeda5.json\n",
      "Load .json metadata:  ./tmp/train/B_palacio_ansoti6.json\n",
      "Load .json metadata:  ./tmp/train/G_catedral_sevilla.json\n",
      "Load .json metadata:  ./tmp/train/M_5bccb0f95a19f.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc75ea2043a1.json\n",
      "Load .json metadata:  ./tmp/train/B_5bacbc0c24a80.json\n",
      "Load .json metadata:  ./tmp/train/R_5d559e35666bb.json\n",
      "Load .json metadata:  ./tmp/train/M_5c24c231d82db.json\n",
      "Load .json metadata:  ./tmp/train/R_palacio_carlos_v_granada6.json\n",
      "Load .json metadata:  ./tmp/train/G_5d9dcda7e43c1.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_san_isidro_mezquita_cordoba.json\n",
      "Load .json metadata:  ./tmp/train/R_casa_lonja_sevilla_patio2.json\n",
      "Load .json metadata:  ./tmp/train/G_alcazaba-almeria2.json\n",
      "Load .json metadata:  ./tmp/train/G_5c0d1111d3183.json\n",
      "Load .json metadata:  ./tmp/train/G_5d9f5b784eef2.json\n",
      "Load .json metadata:  ./tmp/train/R_puerta_puente_cordoba2.json\n",
      "Load .json metadata:  ./tmp/train/R_5c23bd0b1c5b3.json\n",
      "Load .json metadata:  ./tmp/train/B_5bfab9d919e44.json\n",
      "Load .json metadata:  ./tmp/train/B_hospital_san_juan_de_dios_granada6.json\n",
      "Load .json metadata:  ./tmp/train/B_5c1913fa4368f.json\n",
      "Load .json metadata:  ./tmp/train/M_5c879cbec00c9.json\n",
      "Load .json metadata:  ./tmp/train/G_puerta_apostoles_catedra_valencia6.json\n",
      "Load .json metadata:  ./tmp/train/B_fabrica_tabaco_sevilla4.json\n",
      "Load .json metadata:  ./tmp/train/R_plaza_santa_teresa_ubeda2.json\n",
      "Load .json metadata:  ./tmp/train/R_palacio_carlos_v_granada13.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc75ddc3d1ba.json\n",
      "Load .json metadata:  ./tmp/train/G_5c2b98e90a715.json\n",
      "Load .json metadata:  ./tmp/train/R_ayuntamiento_sevilla9.json\n",
      "Load .json metadata:  ./tmp/train/M_20181212_112635.json\n",
      "Load .json metadata:  ./tmp/train/B_5bdf15a853ace.json\n",
      "Load .json metadata:  ./tmp/train/M_medina_azahara33.json\n",
      "Load .json metadata:  ./tmp/train/M_20181212_112338.json\n",
      "Load .json metadata:  ./tmp/train/B_5bfabad3ce768.json\n",
      "Load .json metadata:  ./tmp/train/B_5bae53c39b2b7.json\n",
      "Load .json metadata:  ./tmp/train/B_5cd7c70902846.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc75ee5ebe5d.json\n",
      "Load .json metadata:  ./tmp/train/G_santa_maria_del_mar_barcelona2.json\n",
      "Load .json metadata:  ./tmp/train/G_palacio_salcedo2.json\n",
      "Load .json metadata:  ./tmp/train/B_san_felipe_neri_baeza6.json\n",
      "Load .json metadata:  ./tmp/train/B_iglesia_señora_gracia_estepa2.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_mihrab_mezquita_cordoba4.json\n",
      "Load .json metadata:  ./tmp/train/G_5df76902c546e.json\n",
      "Load .json metadata:  ./tmp/train/R_5c261a545bbe2.json\n",
      "Load .json metadata:  ./tmp/train/R_5bcaeef31f64b.json\n",
      "Load .json metadata:  ./tmp/train/B_parroquia_nuestra_señora_de_la_o_chipiona.json\n",
      "Load .json metadata:  ./tmp/train/M_5c700b74d7c96.json\n",
      "Load .json metadata:  ./tmp/train/B_catedral_granada3.json\n",
      "Load .json metadata:  ./tmp/train/M_5c6fda72e1704.json\n",
      "Load .json metadata:  ./tmp/train/G_5c740a02c0dac.json\n",
      "Load .json metadata:  ./tmp/train/R_puerta_puente_cordoba11.json\n",
      "Load .json metadata:  ./tmp/train/B_5cada883c36bc.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_atarazanas_malaga2.json\n",
      "Load .json metadata:  ./tmp/val/M_5db2c3273aa37.json\n",
      "Load .json metadata:  ./tmp/val/B_casa_marqueses_de_cartagena_granada5.json\n",
      "Load .json metadata:  ./tmp/val/G_5df806400189c.json\n",
      "Load .json metadata:  ./tmp/val/B_5bd0a18e3a7cf.json\n",
      "Load .json metadata:  ./tmp/val/B_5c45af8e61851.json\n",
      "Load .json metadata:  ./tmp/val/B_5c68094c5269c.json\n",
      "Load .json metadata:  ./tmp/val/R_casa_cabildo_jerez8.json\n",
      "Load .json metadata:  ./tmp/val/B_5de179ec7b386.json\n",
      "Load .json metadata:  ./tmp/val/M_patio_doncella_reales_alcazares_sevilla12.json\n",
      "Load .json metadata:  ./tmp/val/B_5d2af2ba74f7c.json\n",
      "Load .json metadata:  ./tmp/val/M_puerta_justicia_granada3.json\n",
      "Load .json metadata:  ./tmp/val/R_iglesia_asuncion_jodar2.json\n",
      "Load .json metadata:  ./tmp/val/G_5b8ecbfc3afd4.json\n",
      "Load .json metadata:  ./tmp/val/R_5db7125d0d87f.json\n",
      "Load .json metadata:  ./tmp/val/B_5c8a449b2672b.json\n",
      "Load .json metadata:  ./tmp/val/B_5bae55f40f890.json\n",
      "Load .json metadata:  ./tmp/val/M_5bc3179bc5bd7.json\n",
      "Load .json metadata:  ./tmp/val/M_5bbcca8260a77.json\n",
      "Load .json metadata:  ./tmp/val/B_hospital_san_juan_de_dios_granada.json\n",
      "Load .json metadata:  ./tmp/val/G_5d3603beb29ee.json\n",
      "Load .json metadata:  ./tmp/val/G_5cadb9254e5bb.json\n",
      "Load .json metadata:  ./tmp/val/R_puerta_puente_cordoba7.json\n",
      "Load .json metadata:  ./tmp/val/G_5bc06c895d7f1.json\n",
      "Load .json metadata:  ./tmp/val/M_5bacf44fbf465.json\n",
      "Load .json metadata:  ./tmp/val/B_5bae63c34ffa2.json\n",
      "Load .json metadata:  ./tmp/val/G_5bad24e5bfd54.json\n",
      "Load .json metadata:  ./tmp/val/R_20181212_114849.json\n",
      "Load .json metadata:  ./tmp/val/B_5d9dc590766ab.json\n",
      "Load .json metadata:  ./tmp/val/M_patio_doncella_reales_alcazares_sevilla7.json\n",
      "Load .json metadata:  ./tmp/val/R_casa_arandas.json\n",
      "Load .json metadata:  ./tmp/val/G_casa_abrantes_granada8.json\n",
      "Load .json metadata:  ./tmp/val/B_catedral_jaen5.json\n",
      "Load .json metadata:  ./tmp/val/B_5c876de809b23.json\n",
      "Load .json metadata:  ./tmp/val/R_5bb78ee318b3f.json\n",
      "Load .json metadata:  ./tmp/val/M_20181212_122208.json\n",
      "Load .json metadata:  ./tmp/val/M_5c45b1ab7eacc.json\n",
      "Load .json metadata:  ./tmp/val/G_5bc4b0000a171.json\n",
      "Load .json metadata:  ./tmp/val/M_puerta_atarazanas_malaga7.json\n",
      "Load .json metadata:  ./tmp/val/R_5be6b690211bf.json\n",
      "Load .json metadata:  ./tmp/val/B_5bad4ad9c95b3.json\n",
      "Load .json metadata:  ./tmp/val/G_convento_clarisas_palencia3.json\n",
      "Load .json metadata:  ./tmp/val/M_puerta_de_las_pesas_granada2.json\n",
      "Load .json metadata:  ./tmp/val/G_5c267e2387828.json\n",
      "Load .json metadata:  ./tmp/val/G_5d9f5d4905e1d.json\n",
      "Load .json metadata:  ./tmp/val/B_5cd6a30c8eeae.json\n",
      "Load .json metadata:  ./tmp/val/R_5d208b11429c6.json\n",
      "Load .json metadata:  ./tmp/val/G_catedral_toledo3.json\n",
      "Load .json metadata:  ./tmp/val/R_5bcc411061ead.json\n",
      "Load .json metadata:  ./tmp/val/M_5e5f7d583c41f.json\n",
      "Load .json metadata:  ./tmp/val/B_5bfabb1a9d451.json\n",
      "Load .json metadata:  ./tmp/val/B_iglesia_san_juan_de_dios_granada2.json\n",
      "Load .json metadata:  ./tmp/val/G_casa_abrantes_granada2.json\n",
      "Load .json metadata:  ./tmp/val/M_puerta_del_vino_granada8.json\n",
      "Load .json metadata:  ./tmp/val/B_5cada2796e206.json\n",
      "Load .json metadata:  ./tmp/val/B_chancilleria_granada7.json\n",
      "Load .json metadata:  ./tmp/val/M_5c2ce172117a7.json\n",
      "Load .json metadata:  ./tmp/val/G_5cc0716275b2e.json\n",
      "Load .json metadata:  ./tmp/val/G_5b8a5fbbcc59f.json\n",
      "Load .json metadata:  ./tmp/val/R_convento_santa_clara_ubeda.json\n",
      "Load .json metadata:  ./tmp/val/G_5d09350c0fda2.json\n",
      "Load .json metadata:  ./tmp/val/M_5bd1dff352ca4.json\n",
      "Load .json metadata:  ./tmp/val/M_5c75185ba9a61.json\n",
      "Load .json metadata:  ./tmp/val/B_palacio_ansoti5.json\n",
      "Load .json metadata:  ./tmp/val/M_5bacb65e7ea39.json\n",
      "Load .json metadata:  ./tmp/val/G_hospital_san_sebastian_cordoba.json\n",
      "Load .json metadata:  ./tmp/val/B_casa_cadenas_cadiz.json\n",
      "Load .json metadata:  ./tmp/val/G_capilla_real_granada4.json\n",
      "Load .json metadata:  ./tmp/val/G_20181212_105134.json\n",
      "Load .json metadata:  ./tmp/val/R_5c60427368d45.json\n",
      "Load .json metadata:  ./tmp/val/G_catedral_toledo.json\n",
      "Load .json metadata:  ./tmp/val/B_5bec4cd58ecc0.json\n",
      "Load .json metadata:  ./tmp/val/B_IMG_0329.json\n",
      "Load .json metadata:  ./tmp/val/G_capilla_real_granada2_2.json\n",
      "Load .json metadata:  ./tmp/val/R_plaza_santa_teresa_ubeda.json\n",
      "Load .json metadata:  ./tmp/val/G_iglesia_san_pablo_ubeda9.json\n",
      "Load .json metadata:  ./tmp/val/B_iglesia_san_juan_de_dios_granada3.json\n",
      "Load .json metadata:  ./tmp/val/R_ayuntamiento_baeza7.json\n",
      "Load .json metadata:  ./tmp/val/G_igl_arcos_frontera.json\n",
      "Load .json metadata:  ./tmp/val/B_5c14f985ec8cb.json\n",
      "Load .json metadata:  ./tmp/val/M_20181212_115509.json\n",
      "Load .json metadata:  ./tmp/val/B_5bc75e93a80c2.json\n",
      "Load .json metadata:  ./tmp/val/B_5bc75f886de87.json\n",
      "Load .json metadata:  ./tmp/val/R_5bfdb2389a627.json\n",
      "Load .json metadata:  ./tmp/val/M_medina_azahara9.json\n",
      "Load .json metadata:  ./tmp/val/M_puerta_monaita_granada3.json\n",
      "Load .json metadata:  ./tmp/val/R_palacio_carlos_v_granada.json\n",
      "Load .json metadata:  ./tmp/val/R_san_pedro_cordoba2.json\n",
      "Load .json metadata:  ./tmp/val/B_5c596ad870071.json\n",
      "Load .json metadata:  ./tmp/val/B_5bcdf776e2630.json\n",
      "Load .json metadata:  ./tmp/val/G_5bec3a72c823a.json\n",
      "Load .json metadata:  ./tmp/val/B_palacio_bibataubin_granada4.json\n",
      "Load .json metadata:  ./tmp/val/G_5c877f504a07b.json\n",
      "Load .json metadata:  ./tmp/val/M_puerta_atarazanas_malaga3.json\n",
      "Load .json metadata:  ./tmp/val/G_puerta_bautismo_catedral_sevilla2.json\n",
      "Load .json metadata:  ./tmp/val/R_casa_torres_ubeda4.json\n",
      "Load .json metadata:  ./tmp/val/G_IMG_0369.json\n",
      "Load .json metadata:  ./tmp/val/M_puerta_de_las_pesas_granada6.json\n",
      "Load .json metadata:  ./tmp/val/R_puerta_perdon_catedral_granada5.json\n",
      "Load .json metadata:  ./tmp/val/M_5c85601a50e23.json\n",
      "Load .json metadata:  ./tmp/val/M_5dd41a8a19a4a.json\n",
      "Load .json metadata:  ./tmp/val/M_medina_azahara10.json\n",
      "Load .json metadata:  ./tmp/val/B_convento_santa_ines_granada2.json\n",
      "Load .json metadata:  ./tmp/val/G_basilica_santa_maria_arcos_frontera.json\n",
      "Load .json metadata:  ./tmp/val/B_5be5b0ed738a7.json\n",
      "Load .json metadata:  ./tmp/val/M_5c9620edef2ff.json\n",
      "Load .json metadata:  ./tmp/val/M_5e4fb97a24480.json\n",
      "Load .json metadata:  ./tmp/val/R_puerta_granada_granada.json\n",
      "Load .json metadata:  ./tmp/val/B_facultad_derecho_granada4.json\n",
      "Load .json metadata:  ./tmp/val/R_colegio_niñas_nobles_granada2.json\n",
      "Load .json metadata:  ./tmp/val/R_5bb733b336220.json\n",
      "Load .json metadata:  ./tmp/val/B_fabrica_tabaco_sevilla2.json\n",
      "Load .json metadata:  ./tmp/val/G_pinaculo4.json\n",
      "Load .json metadata:  ./tmp/val/R_capilla_san_francisco_baeza5.json\n",
      "Load .json metadata:  ./tmp/val/M_medina_azahara35.json\n",
      "Load .json metadata:  ./tmp/val/B_IMG_1004.json\n",
      "Load .json metadata:  ./tmp/val/R_5c15277c84aab.json\n",
      "Load .json metadata:  ./tmp/val/G_5cd8200569568.json\n",
      "Load .json metadata:  ./tmp/val/R_5bdef11ecc329.json\n",
      "Load .json metadata:  ./tmp/val/B_catedral_guadix5.json\n",
      "Load .json metadata:  ./tmp/val/B_5c878f865c701.json\n",
      "Load .json metadata:  ./tmp/val/M_20181212_113400.json\n",
      "Load .json metadata:  ./tmp/val/M_5db079dfc13c7.json\n",
      "Load .json metadata:  ./tmp/val/R_5bb4547e1c1e9.json\n",
      "Load .json metadata:  ./tmp/val/R_5cba22808268e.json\n",
      "Load .json metadata:  ./tmp/val/R_5bc0b4b6c8948.json\n",
      "Load .json metadata:  ./tmp/val/B_fabrica_tabaco_sevilla5.json\n",
      "Load .json metadata:  ./tmp/val/B_5ca466a359d1d.json\n",
      "Load .json metadata:  ./tmp/val/R_5bcaf9bf6194d.json\n",
      "Load .json metadata:  ./tmp/val/B_catedral_granada5.json\n",
      "Load .json metadata:  ./tmp/val/B_5cdeec644d080.json\n",
      "Load .json metadata:  ./tmp/val/B_IMG_1055.json\n",
      "Load .json metadata:  ./tmp/val/M_5e5245bcb4ee4.json\n",
      "Load .json metadata:  ./tmp/val/G_iglesia_san_pablo_ubeda3.json\n",
      "Load .json metadata:  ./tmp/val/M_5bccb200d68f2.json\n",
      "Load .json metadata:  ./tmp/val/M_5da4ceed0c3d9.json\n",
      "Load .json metadata:  ./tmp/val/B_IMG_1054.json\n",
      "Load .json metadata:  ./tmp/val/B_5c878f258d48a.json\n",
      "Load .json metadata:  ./tmp/val/B_catedral_granada10.json\n",
      "Load .json metadata:  ./tmp/val/R_iglesia_salvador_granada.json\n",
      "Load .json metadata:  ./tmp/val/B_5bb7b650342fc.json\n",
      "Load .json metadata:  ./tmp/val/G_5d9dcdcba5a00.json\n",
      "Load .json metadata:  ./tmp/val/B_5c0a71fb016ae.json\n",
      "Load .json metadata:  ./tmp/val/B_IMG_0362.json\n",
      "Load .json metadata:  ./tmp/val/B_5bc75e23a2930.json\n",
      "Load .json metadata:  ./tmp/val/G_casa_abrantes_granada5.json\n",
      "Load .json metadata:  ./tmp/val/B_basilica_angustias_granada5.json\n",
      "Load .json metadata:  ./tmp/val/B_5b8ecb06eab42.json\n",
      "Load .json metadata:  ./tmp/val/R_san_grabiel_loja.json\n",
      "Load .json metadata:  ./tmp/val/B_IMG_0359.json\n",
      "Load .json metadata:  ./tmp/val/R_puerta_perdon_catedral_granada8.json\n",
      "Load .json metadata:  ./tmp/val/R_monasterio_cartuja_granada.json\n",
      "Load .json metadata:  ./tmp/val/R_palacio_cadenas_ubeda13.json\n",
      "Load .json metadata:  ./tmp/val/B_IMG_1034.json\n",
      "Load .json metadata:  ./tmp/val/B_5cd3273f34c66.json\n",
      "Load .json metadata:  ./tmp/val/M_puerta_mihrab_mezquita_cordoba2.json\n",
      "Load .json metadata:  ./tmp/val/G_5d98cad22479c.json\n",
      "Load .json metadata:  ./tmp/val/M_patio_yeso_reales_alcazares_sevilla2.json\n",
      "Load .json metadata:  ./tmp/val/B_5bec3a0558cf5.json\n",
      "Load .json metadata:  ./tmp/val/R_casa_cabildo_jerez3.json\n",
      "Load .json metadata:  ./tmp/val/M_5bd577ad73bb0.json\n",
      "Load .json metadata:  ./tmp/val/G_5ced8f6051d21.json\n",
      "Load .json metadata:  ./tmp/val/B_5bfaba8fb40e3.json\n",
      "Load .json metadata:  ./tmp/val/G_puerta_bautismo_catedral_sevilla8.json\n",
      "Load .json metadata:  ./tmp/val/R_5bb78bd53e5ad.json\n",
      "Load .json metadata:  ./tmp/val/B_5c12759d8cc79.json\n",
      "Load .json metadata:  ./tmp/val/G_5bc76dc28fd08.json\n",
      "Load .json metadata:  ./tmp/val/G_5bc9a11663f9b.json\n",
      "Load .json metadata:  ./tmp/val/B_5e4ed1c6cbdec.json\n",
      "Load .json metadata:  ./tmp/val/G_iglesia_san_pablo_ubeda10.json\n",
      "Load .json metadata:  ./tmp/val/G_5de135380f7c3.json\n",
      "Load .json metadata:  ./tmp/val/M_medina_azahara29.json\n",
      "Load .json metadata:  ./tmp/val/M_5baf1a3f2e94b.json\n",
      "Load .json metadata:  ./tmp/val/M_5d623f17ab783.json\n",
      "Load .json metadata:  ./tmp/val/B_basilica_angustias_granada4.json\n",
      "Load .json metadata:  ./tmp/val/B_catedral_guadix7.json\n",
      "Load .json metadata:  ./tmp/val/R_palacio_carlos_v_granada12.json\n",
      "Load .json metadata:  ./tmp/val/B_chancilleria_granada.json\n",
      "Load .json metadata:  ./tmp/val/G_puerta_apostoles_catedral_murcia6.json\n",
      "Load .json metadata:  ./tmp/val/G_iglesia_sabiote4.json\n",
      "Load .json metadata:  ./tmp/val/B_5d9dd3c5b2f16.json\n",
      "Load .json metadata:  ./tmp/val/G_5bc1aaf94ea6d.json\n",
      "Load .json metadata:  ./tmp/val/B_san_juan_dios_antequera.json\n",
      "Load .json metadata:  ./tmp/val/G_5bc9a70361bff.json\n",
      "Load .json metadata:  ./tmp/val/B_5c1cde9e6260a.json\n",
      "Load .json metadata:  ./tmp/val/M_5de6aa806cbef.json\n",
      "Load .json metadata:  ./tmp/val/B_colegio_san_telmo_sevilla.json\n",
      "Load .json metadata:  ./tmp/val/B_IMG_0358.json\n",
      "Load .json metadata:  ./tmp/val/G_palacio_salcedo.json\n",
      "Load .json metadata:  ./tmp/val/R_5d98bfa797969.json\n",
      "Load .json metadata:  ./tmp/val/R_5bc6037474c90.json\n",
      "Load .json metadata:  ./tmp/val/B_5c62af60bdd94.json\n",
      "Load .json metadata:  ./tmp/val/M_5e51856c4c5d0.json\n",
      "Load .json metadata:  ./tmp/val/G_5bb8e97e9badf.json\n",
      "Load .json metadata:  ./tmp/val/B_5babaafb202cf.json\n",
      "Load .json metadata:  ./tmp/val/R_convento_santa_clara_ubeda4.json\n",
      "Load .json metadata:  ./tmp/val/B_5e0354ada9bdf.json\n",
      "Load .json metadata:  ./tmp/val/B_5cf7f3fe6fcc7.json\n",
      "Load .json metadata:  ./tmp/val/M_medina_azahara4.json\n",
      "Load .json metadata:  ./tmp/val/R_5c15348990691.json\n",
      "Load .json metadata:  ./tmp/val/G_palacio_jabalquinto_baeza9.json\n",
      "Load .json metadata:  ./tmp/val/R_5be5e8d4933d2.json\n",
      "Load .json metadata:  ./tmp/val/R_palacio_carlos_v_granada10.json\n",
      "Load .json metadata:  ./tmp/val/R_5c0aaaa13f0d4.json\n",
      "Load .json metadata:  ./tmp/val/G_5c877f35824a9.json\n",
      "Load .json metadata:  ./tmp/val/G_capilla_real_granada5.json\n",
      "Load .json metadata:  ./tmp/val/G_puerta_apostoles_catedral_murcia.json\n",
      "Load .json metadata:  ./tmp/val/R_puerta_perdon_catedral_granada3.json\n",
      "Load .json metadata:  ./tmp/val/M_puerta_elvira_granada.json\n",
      "Load .json metadata:  ./tmp/val/G_5d9c62a9002f9.json\n",
      "Load .json metadata:  ./tmp/val/M_20181212_150308.json\n",
      "Load .json metadata:  ./tmp/val/R_catedral_santa_maria_sevilla2.json\n",
      "Load .json metadata:  ./tmp/val/G_5dd41c407dad2.json\n",
      "Load .json metadata:  ./tmp/val/B_5dfb6b3ec6d75.json\n",
      "Load .json metadata:  ./tmp/val/G_5c6299b35348d.json\n",
      "Load .json metadata:  ./tmp/val/R_ayuntamiento_sevilla8.json\n",
      "Load .json metadata:  ./tmp/val/R_iglesia_san_cecilio_granada.json\n",
      "Load .json metadata:  ./tmp/val/B_museo_bellas_artes_sevilla4.json\n",
      "Load .json metadata:  ./tmp/val/G_5bc4b0208afce.json\n",
      "Load .json metadata:  ./tmp/val/R_5ce91ca209e93.json\n",
      "Load .json metadata:  ./tmp/val/B_IMG_0340.json\n",
      "Load .json metadata:  ./tmp/val/M_5be567087517e.json\n",
      "Load .json metadata:  ./tmp/val/B_facultad_derecho_granada3.json\n",
      "Load .json metadata:  ./tmp/val/B_palacio_ansoti7.json\n",
      "Load .json metadata:  ./tmp/val/B_5c878f1213e55.json\n",
      "Load .json metadata:  ./tmp/val/B_catedral_guadix.json\n",
      "Load .json metadata:  ./tmp/val/B_5d53cdc09e048.json\n",
      "Load .json metadata:  ./tmp/val/B_iglesia_caridad_sevilla4.json\n",
      "Load .json metadata:  ./tmp/val/M_5bae5ed261c0c.json\n",
      "Load .json metadata:  ./tmp/val/M_5c961ed2964b2.json\n",
      "Load .json metadata:  ./tmp/val/B_casa_marqueses_de_cartagena_granada6.json\n",
      "Load .json metadata:  ./tmp/val/R_iglesia_san_cecilio_granada2.json\n",
      "Load .json metadata:  ./tmp/val/B_casa_monte_de_piedad_granada.json\n",
      "Load .json metadata:  ./tmp/val/G_5c82f5c3c0a67.json\n",
      "Load .json metadata:  ./tmp/val/G_puerta_infierno_catedral_toledo2.json\n",
      "Load .json metadata:  ./tmp/val/M_5c38866fefaad.json\n",
      "Load .json metadata:  ./tmp/val/B_5d9dcbbfc416a.json\n",
      "Load .json metadata:  ./tmp/val/B_5be98c369a004.json\n",
      "Load .json metadata:  ./tmp/val/B_5ba899636f449.json\n",
      "Load .json metadata:  ./tmp/val/B_5c8778ca611a2.json\n",
      "Load .json metadata:  ./tmp/val/B_5bc75e6119173.json\n",
      "Load .json metadata:  ./tmp/val/M_20181212_130052.json\n",
      "Load .json metadata:  ./tmp/val/M_5db2e635ab8ed.json\n",
      "Load .json metadata:  ./tmp/val/R_palacio_carlos_v_granada19.json\n",
      "Load .json metadata:  ./tmp/val/M_puerta_de_las_pesas_granada.json\n",
      "Load .json metadata:  ./tmp/val/M_5bcdf82621374.json\n",
      "Load .json metadata:  ./tmp/val/B_compas_convento_santa_isabel_granada.json\n",
      "Load .json metadata:  ./tmp/val/M_5bad4996b3cf4.json\n",
      "Load .json metadata:  ./tmp/val/M_5db2bfe305c0b.json\n",
      "Load .json metadata:  ./tmp/val/B_5bd0a549b5653.json\n",
      "Load .json metadata:  ./tmp/val/G_puerta_bautismo_catedral_sevilla.json\n",
      "Load .json metadata:  ./tmp/val/M_5d0383b7abaf0.json\n",
      "Load .json metadata:  ./tmp/val/R_iglesia_san_cecilio_granada3.json\n",
      "Load .json metadata:  ./tmp/val/M_5baf19070489a.json\n",
      "Load .json metadata:  ./tmp/val/M_corral_carbon_granada9.json\n",
      "Load .json metadata:  ./tmp/val/B_iglesia_san_basilio_granada.json\n",
      "Load .json metadata:  ./tmp/val/B_casa_cadenas_cadiz2.json\n",
      "Load .json metadata:  ./tmp/val/M_corral_carbon_granada.json\n",
      "Load .json metadata:  ./tmp/val/B_5c80d1f310860.json\n",
      "Load .json metadata:  ./tmp/val/G_5c67d9d394832.json\n",
      "Load .json metadata:  ./tmp/val/R_iglesia_anunciacion_sevilla2.json\n",
      "Load .json metadata:  ./tmp/val/B_iglesia_perpetuo_socorro_granada.json\n",
      "Load .json metadata:  ./tmp/val/G_5d98c6d57f872.json\n",
      "Load .json metadata:  ./tmp/val/B_5bed739fdf02e.json\n",
      "Load .json metadata:  ./tmp/val/B_5cf7e7d0e7106.json\n",
      "Load .json metadata:  ./tmp/val/G_5bc4b2d9006fc.json\n",
      "Load .json metadata:  ./tmp/val/R_catedral_puerta_san_jeronimo_granada.json\n",
      "Load .json metadata:  ./tmp/val/R_palacio_cadenas_ubeda4.json\n",
      "Load .json metadata:  ./tmp/val/M_20181212_112853.json\n",
      "Load .json metadata:  ./tmp/val/R_iglesia_santo_domingo_granada.json\n",
      "Load .json metadata:  ./tmp/val/G_5cadb7f561357.json\n",
      "Load .json metadata:  ./tmp/val/G_5cc07140b8e70.json\n",
      "Load .json metadata:  ./tmp/val/B_5bd2cda2a9579.json\n",
      "Load .json metadata:  ./tmp/val/B_convento_carmelitas_descalzas_granada5.json\n",
      "Load .json metadata:  ./tmp/val/B_basilica_angustias_granada.json\n",
      "Load .json metadata:  ./tmp/val/R_5bd33de5f3fa8.json\n",
      "Load .json metadata:  ./tmp/val/G_puerta_apostoles_catedral_murcia4.json\n",
      "Load .json metadata:  ./tmp/val/B_5bdd80e6ea7c8.json\n",
      "Load .json metadata:  ./tmp/val/G_iglesia_nuestra_señora_de_la_o_chipiona.json\n",
      "Load .json metadata:  ./tmp/val/G_iglesia_santa_maría_del_pi_barcelona.json\n",
      "Load .json metadata:  ./tmp/val/R_5db2c3759cdbd.json\n",
      "Load .json metadata:  ./tmp/val/B_palacio_bibataubin_granada3.json\n",
      "Load .json metadata:  ./tmp/val/G_pinaculo2.json\n",
      "Load .json metadata:  ./tmp/val/G_5c138466132c4.json\n",
      "Load .json metadata:  ./tmp/val/M_patio_doncella_reales_alcazares_sevilla.json\n",
      "Load .json metadata:  ./tmp/val/G_catedral_sevilla3.json\n",
      "Load .json metadata:  ./tmp/val/M_patio_doncella_reales_alcazares_sevilla5.json\n",
      "Load .json metadata:  ./tmp/val/B_5bae4188a9817.json\n",
      "Load .json metadata:  ./tmp/val/M_20181212_150258.json\n",
      "Load .json metadata:  ./tmp/val/G_pinaculo5.json\n",
      "Load .json metadata:  ./tmp/val/B_5bd074b099963.json\n",
      "Load .json metadata:  ./tmp/val/R_5bee96a235a67.json\n",
      "Load .json metadata:  ./tmp/val/M_corralcarbon.json\n",
      "Load .json metadata:  ./tmp/val/R_5bb5f65db689e.json\n",
      "Load .json metadata:  ./tmp/val/R_20181212_110256.json\n",
      "Load .json metadata:  ./tmp/val/B_5bc75e9246655.json\n",
      "Load .json metadata:  ./tmp/val/R_puerta_perdon_catedral_granada.json\n",
      "Load .json metadata:  ./tmp/val/R_palacio_carlos_v_granada9.json\n",
      "Load .json metadata:  ./tmp/val/B_IMG_1135.json\n",
      "Load .json metadata:  ./tmp/val/M_alcazaba_malaga.json\n",
      "Load .json metadata:  ./tmp/val/G_iglesia_san_pablo_ubeda2.json\n",
      "Load .json metadata:  ./tmp/val/G_5cb9a35070358.json\n",
      "Load .json metadata:  ./tmp/val/M_ermita_sansebastian3.json\n",
      "Load .json metadata:  ./tmp/val/G_5d4f11234ab2d.json\n",
      "Training del classificatore...\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib/python3.9/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "W0000 00:00:1732051807.268201 1594522 gpu_device.cc:2344] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.2709 - loss: 1.5585\n",
      "Epoch 2/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4868 - loss: 1.1755\n",
      "Epoch 3/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5554 - loss: 0.9720\n",
      "Epoch 4/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6998 - loss: 0.7993\n",
      "Epoch 5/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8147 - loss: 0.6952\n",
      "Epoch 6/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8191 - loss: 0.5832\n",
      "Epoch 7/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8387 - loss: 0.5209\n",
      "Epoch 8/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8599 - loss: 0.4712\n",
      "Epoch 9/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8735 - loss: 0.4332\n",
      "Epoch 10/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8771 - loss: 0.3823\n",
      "Epoch 11/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9047 - loss: 0.3270\n",
      "Epoch 12/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9101 - loss: 0.3336\n",
      "Epoch 13/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9034 - loss: 0.3183\n",
      "Epoch 14/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9314 - loss: 0.2728\n",
      "Epoch 15/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9277 - loss: 0.2470\n",
      "Epoch 16/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9211 - loss: 0.2605\n",
      "Epoch 17/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9308 - loss: 0.2261\n",
      "Epoch 18/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9259 - loss: 0.2514\n",
      "Epoch 19/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9401 - loss: 0.2256\n",
      "Epoch 20/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9199 - loss: 0.2384\n",
      "Epoch 21/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9226 - loss: 0.2374\n",
      "Epoch 22/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9366 - loss: 0.2167\n",
      "Epoch 23/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9191 - loss: 0.2305\n",
      "Epoch 24/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9324 - loss: 0.2190\n",
      "Epoch 25/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9336 - loss: 0.2031\n",
      "Epoch 26/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9387 - loss: 0.2079\n",
      "Epoch 27/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9293 - loss: 0.2028\n",
      "Epoch 28/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9361 - loss: 0.1901\n",
      "Epoch 29/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9420 - loss: 0.1811\n",
      "Epoch 30/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9476 - loss: 0.1845\n",
      "Epoch 31/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9440 - loss: 0.1750\n",
      "Epoch 32/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9497 - loss: 0.1827\n",
      "Epoch 33/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9502 - loss: 0.1744\n",
      "Epoch 34/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9379 - loss: 0.1841\n",
      "Epoch 35/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9393 - loss: 0.1920\n",
      "Epoch 36/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9312 - loss: 0.2043\n",
      "Epoch 37/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9316 - loss: 0.1864\n",
      "Epoch 38/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9438 - loss: 0.1803\n",
      "Epoch 39/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9395 - loss: 0.1689\n",
      "Epoch 40/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9218 - loss: 0.1919\n",
      "Epoch 41/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9492 - loss: 0.1704\n",
      "Epoch 42/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9284 - loss: 0.1983\n",
      "Epoch 43/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9322 - loss: 0.1969\n",
      "Epoch 44/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9316 - loss: 0.1837\n",
      "Epoch 45/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9382 - loss: 0.1749\n",
      "Epoch 46/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9533 - loss: 0.1618\n",
      "Epoch 47/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9400 - loss: 0.1672\n",
      "Epoch 48/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9439 - loss: 0.1506\n",
      "Epoch 49/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9418 - loss: 0.1609\n",
      "Epoch 50/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9344 - loss: 0.1778\n",
      "Epoch 51/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9399 - loss: 0.1639\n",
      "Epoch 52/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9517 - loss: 0.1494\n",
      "Epoch 53/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9415 - loss: 0.1707\n",
      "Epoch 54/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9332 - loss: 0.1765\n",
      "Epoch 55/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9519 - loss: 0.1433\n",
      "Epoch 56/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9517 - loss: 0.1539\n",
      "Epoch 57/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9486 - loss: 0.1465\n",
      "Epoch 58/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9379 - loss: 0.1747\n",
      "Epoch 59/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9426 - loss: 0.1526\n",
      "Epoch 60/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9339 - loss: 0.1786\n",
      "Epoch 61/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9313 - loss: 0.1653\n",
      "Epoch 62/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9499 - loss: 0.1447\n",
      "Epoch 63/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9386 - loss: 0.1655\n",
      "Epoch 64/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9370 - loss: 0.1621\n",
      "Epoch 65/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9442 - loss: 0.1562\n",
      "Epoch 66/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9385 - loss: 0.1565\n",
      "Epoch 67/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9429 - loss: 0.1664\n",
      "Epoch 68/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9402 - loss: 0.1673\n",
      "Epoch 69/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9304 - loss: 0.1649\n",
      "Epoch 70/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9383 - loss: 0.1554\n",
      "Epoch 71/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9382 - loss: 0.1531\n",
      "Epoch 72/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9286 - loss: 0.1881\n",
      "Epoch 73/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9618 - loss: 0.1326\n",
      "Epoch 74/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9305 - loss: 0.1630\n",
      "Epoch 75/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9472 - loss: 0.1579\n",
      "Epoch 76/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9225 - loss: 0.1910\n",
      "Epoch 77/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9445 - loss: 0.1372\n",
      "Epoch 78/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9369 - loss: 0.1798\n",
      "Epoch 79/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9553 - loss: 0.1307\n",
      "Epoch 80/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9536 - loss: 0.1270\n",
      "Epoch 81/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9511 - loss: 0.1395\n",
      "Epoch 82/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9547 - loss: 0.1360\n",
      "Epoch 83/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9425 - loss: 0.1436\n",
      "Epoch 84/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9444 - loss: 0.1416\n",
      "Epoch 85/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9307 - loss: 0.1620\n",
      "Epoch 86/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9606 - loss: 0.1281\n",
      "Epoch 87/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9567 - loss: 0.1276\n",
      "Epoch 88/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9278 - loss: 0.1773\n",
      "Epoch 89/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9387 - loss: 0.1435\n",
      "Epoch 90/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9386 - loss: 0.1336\n",
      "Epoch 91/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9448 - loss: 0.1407\n",
      "Epoch 92/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9435 - loss: 0.1638\n",
      "Epoch 93/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9430 - loss: 0.1474\n",
      "Epoch 94/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9634 - loss: 0.1135\n",
      "Epoch 95/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9401 - loss: 0.1674\n",
      "Epoch 96/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9496 - loss: 0.1522\n",
      "Epoch 97/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9357 - loss: 0.1501\n",
      "Epoch 98/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9581 - loss: 0.1287\n",
      "Epoch 99/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9523 - loss: 0.1389\n",
      "Epoch 100/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9621 - loss: 0.1197\n",
      "Epoch 101/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9581 - loss: 0.1376\n",
      "Epoch 102/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9481 - loss: 0.1353\n",
      "Epoch 103/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9597 - loss: 0.1255\n",
      "Epoch 104/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9449 - loss: 0.1533\n",
      "Epoch 105/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9432 - loss: 0.1414\n",
      "Epoch 106/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9377 - loss: 0.1492\n",
      "Epoch 107/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9591 - loss: 0.1200\n",
      "Epoch 108/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9474 - loss: 0.1559\n",
      "Epoch 109/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9446 - loss: 0.1473\n",
      "Epoch 110/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9475 - loss: 0.1466\n",
      "Epoch 111/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9589 - loss: 0.1267\n",
      "Epoch 112/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9540 - loss: 0.1304\n",
      "Epoch 113/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9495 - loss: 0.1330\n",
      "Epoch 114/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9591 - loss: 0.1344\n",
      "Epoch 115/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9625 - loss: 0.1205\n",
      "Epoch 116/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9417 - loss: 0.1437\n",
      "Epoch 117/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9590 - loss: 0.1209\n",
      "Epoch 118/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9551 - loss: 0.1383\n",
      "Epoch 119/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9584 - loss: 0.1303\n",
      "Epoch 120/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9512 - loss: 0.1316\n",
      "Epoch 121/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9528 - loss: 0.1255\n",
      "Epoch 122/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9524 - loss: 0.1348\n",
      "Epoch 123/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9653 - loss: 0.1094\n",
      "Epoch 124/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9467 - loss: 0.1464\n",
      "Epoch 125/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9643 - loss: 0.1141\n",
      "Epoch 126/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9612 - loss: 0.1121\n",
      "Epoch 127/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9497 - loss: 0.1413\n",
      "Epoch 128/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9555 - loss: 0.1329\n",
      "Epoch 129/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9552 - loss: 0.1362\n",
      "Epoch 130/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9638 - loss: 0.1107\n",
      "Epoch 131/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9485 - loss: 0.1494\n",
      "Epoch 132/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9563 - loss: 0.1298\n",
      "Epoch 133/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9449 - loss: 0.1489\n",
      "Epoch 134/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9391 - loss: 0.1601\n",
      "Epoch 135/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9602 - loss: 0.1211\n",
      "Epoch 136/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9462 - loss: 0.1417\n",
      "Epoch 137/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9453 - loss: 0.1477\n",
      "Epoch 138/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9488 - loss: 0.1406\n",
      "Epoch 139/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9528 - loss: 0.1285\n",
      "Epoch 140/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9462 - loss: 0.1336\n",
      "Epoch 141/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9445 - loss: 0.1487\n",
      "Epoch 142/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9479 - loss: 0.1535\n",
      "Epoch 143/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9527 - loss: 0.1335\n",
      "Epoch 144/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9573 - loss: 0.1119\n",
      "Epoch 145/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9522 - loss: 0.1347\n",
      "Epoch 146/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9481 - loss: 0.1325\n",
      "Epoch 147/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9424 - loss: 0.1497\n",
      "Epoch 148/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9600 - loss: 0.1167\n",
      "Epoch 149/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9397 - loss: 0.1398\n",
      "Epoch 150/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9571 - loss: 0.1125\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8646 - loss: 0.6849 \n",
      "Loss: 0.7021741271018982, Accuracy: 0.8646864891052246\n",
      "Calcolo degli SHAP values...\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 272 background data samples could cause slower run times. Consider using shap.sample(data, K) or shap.kmeans(data, K) to summarize the background as K samples.\n",
      "  0%|                                                                                                        | 0/303 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=8.704e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 6 iterations, alpha=4.125e-03, previous alpha=4.125e-03, with an active set of 5 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=8.457e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.013e-02, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 10 iterations, alpha=1.013e-02, previous alpha=1.007e-02, with an active set of 9 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=1.122e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=3.728e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=2.380e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=2.346e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=2.167e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=5.208e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=4.465e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=1.461e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=1.253e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "  0%|▎                                                                                               | 1/303 [00:00<02:21,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▋                                                                                               | 2/303 [00:00<02:20,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▉                                                                                               | 3/303 [00:01<02:19,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|█▎                                                                                              | 4/303 [00:01<02:19,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▌                                                                                              | 5/303 [00:02<02:19,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▉                                                                                              | 6/303 [00:02<02:18,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|██▏                                                                                             | 7/303 [00:03<02:18,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=1.140e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=7.226e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=2.913e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=2.895e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.185e-03, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=8.433e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=1.062e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=5.312e-03, with an active set of 2 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=2.715e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=2.088e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.317e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.239e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=9.178e-04, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=7.938e-04, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=4.560e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=2.937e-04, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=2.861e-04, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 12 iterations, alpha=7.310e-04, previous alpha=2.012e-04, with an active set of 11 regressors.\n",
      "  warnings.warn(\n",
      "  3%|██▌                                                                                             | 8/303 [00:03<02:17,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.027e-03, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=1.716e-05, with an active set of 16 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "  3%|██▊                                                                                             | 9/303 [00:04<02:16,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|███▏                                                                                           | 10/303 [00:04<02:16,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▍                                                                                           | 11/303 [00:05<02:15,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▊                                                                                           | 12/303 [00:05<02:15,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|████                                                                                           | 13/303 [00:06<02:14,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.850e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 24 iterations, alpha=8.290e-04, previous alpha=3.907e-04, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=1.330e-06, with an active set of 16 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=1.817e-06, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "  5%|████▍                                                                                          | 14/303 [00:06<02:14,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████▋                                                                                          | 15/303 [00:06<02:13,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|█████                                                                                          | 16/303 [00:07<02:13,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 815us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=4.951e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=3.320e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 17 iterations, alpha=1.544e-03, previous alpha=1.543e-03, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=6.167e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=5.183e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=7.260e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 17 iterations, alpha=3.595e-05, previous alpha=3.595e-05, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=8.681e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 16 iterations, alpha=8.681e-05, previous alpha=8.674e-05, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      "  6%|█████▎                                                                                         | 17/303 [00:07<02:12,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|█████▋                                                                                         | 18/303 [00:08<02:12,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|█████▉                                                                                         | 19/303 [00:08<02:12,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=4.500e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 21 iterations, alpha=1.282e-04, previous alpha=1.270e-04, with an active set of 16 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=9.174e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 16 iterations, alpha=6.493e-05, previous alpha=5.510e-05, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=2.196e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=9.497e-06, with an active set of 16 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "  7%|██████▎                                                                                        | 20/303 [00:09<02:11,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 833us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██████▌                                                                                        | 21/303 [00:09<02:11,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██████▉                                                                                        | 22/303 [00:10<02:10,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|███████▏                                                                                       | 23/303 [00:10<02:09,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|███████▌                                                                                       | 24/303 [00:11<02:09,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|███████▊                                                                                       | 25/303 [00:11<02:09,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|████████▏                                                                                      | 26/303 [00:12<02:08,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|████████▍                                                                                      | 27/303 [00:12<02:07,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|████████▊                                                                                      | 28/303 [00:13<02:07,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█████████                                                                                      | 29/303 [00:13<02:07,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█████████▍                                                                                     | 30/303 [00:13<02:06,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=5.437e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=7.223e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=4.982e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 26 iterations, alpha=6.639e-03, previous alpha=4.326e-03, with an active set of 11 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.332e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.240e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 14 iterations, alpha=1.207e-03, previous alpha=1.036e-03, with an active set of 11 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.911e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=8.420e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 17 iterations, alpha=8.420e-05, previous alpha=7.163e-05, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.135e-02, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=4.550e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 18 iterations, alpha=4.550e-04, previous alpha=3.879e-04, with an active set of 11 regressors.\n",
      "  warnings.warn(\n",
      " 10%|█████████▋                                                                                     | 31/303 [00:14<02:06,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|██████████                                                                                     | 32/303 [00:14<02:05,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=7.604e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.779e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 15 iterations, alpha=1.768e-03, previous alpha=1.651e-03, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=7.821e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=4.557e-03, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 23 iterations, alpha=4.557e-03, previous alpha=3.918e-03, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      " 11%|██████████▎                                                                                    | 33/303 [00:15<02:05,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|██████████▋                                                                                    | 34/303 [00:15<02:04,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=2.236e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=8.852e-06, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=2.239e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=8.628e-04, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=8.428e-04, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 9 iterations, alpha=6.956e-04, previous alpha=6.762e-04, with an active set of 8 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=1.027e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=3.304e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=2.845e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 11 iterations, alpha=2.198e-03, previous alpha=1.622e-03, with an active set of 10 regressors.\n",
      "  warnings.warn(\n",
      " 12%|██████████▉                                                                                    | 35/303 [00:16<02:04,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=6.277e-03, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=3.139e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 11 iterations, alpha=1.936e-03, previous alpha=1.696e-03, with an active set of 8 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.650e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=4.623e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 10 iterations, alpha=2.573e-03, previous alpha=2.357e-03, with an active set of 9 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=2.732e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.366e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=2.057e-03, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=5.655e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 12%|███████████▎                                                                                   | 36/303 [00:16<02:03,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=9.723e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=9.238e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=9.238e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 6 iterations, alpha=9.171e-03, previous alpha=7.544e-03, with an active set of 5 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=2.639e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.828e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=7.433e-04, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=3.274e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=1.203e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=8.822e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 12%|███████████▌                                                                                   | 37/303 [00:17<02:03,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|███████████▉                                                                                   | 38/303 [00:17<02:02,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=7.329e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=5.525e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=5.720e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/shap/explainers/_kernel.py:707: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.599e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.253e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.199e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 18 iterations, alpha=8.267e-04, previous alpha=7.047e-04, with an active set of 11 regressors.\n",
      "  warnings.warn(\n",
      " 13%|████████████▏                                                                                  | 39/303 [00:18<02:03,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=9.311e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 22 iterations, alpha=9.034e-05, previous alpha=9.034e-05, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=8.219e-04, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=4.187e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=3.283e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 18 iterations, alpha=2.770e-04, previous alpha=3.776e-05, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      " 13%|████████████▌                                                                                  | 40/303 [00:18<02:02,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|████████████▊                                                                                  | 41/303 [00:19<02:02,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█████████████▏                                                                                 | 42/303 [00:19<02:01,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█████████████▍                                                                                 | 43/303 [00:20<02:02,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█████████████▊                                                                                 | 44/303 [00:20<02:01,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=5.130e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=3.188e-03, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=2.160e-03, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=2.418e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=8.308e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=4.017e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=3.992e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.825e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.670e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.628e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 17 iterations, alpha=2.476e-03, previous alpha=8.493e-04, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      " 15%|██████████████                                                                                 | 45/303 [00:20<02:00,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|██████████████▍                                                                                | 46/303 [00:21<01:59,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|██████████████▋                                                                                | 47/303 [00:21<01:59,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.708e-02, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.443e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=6.648e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 20 iterations, alpha=5.585e-04, previous alpha=5.113e-04, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=6.213e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=3.940e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=2.835e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 16 iterations, alpha=1.842e-04, previous alpha=1.733e-04, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=3.718e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=3.801e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.717e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=6.631e-06, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=3.132e-06, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=2.546e-06, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 16%|███████████████                                                                                | 48/303 [00:22<01:58,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|███████████████▎                                                                               | 49/303 [00:22<01:58,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=2.214e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=2.214e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.517e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=7.431e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=4.250e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.397e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.397e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 15 iterations, alpha=1.649e-04, previous alpha=8.765e-06, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=4.524e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=4.051e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=4.051e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.780e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.660e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 14 iterations, alpha=1.660e-04, previous alpha=1.579e-04, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.216e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.198e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.198e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=5.902e-04, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=5.363e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 19 iterations, alpha=4.909e-04, previous alpha=8.227e-05, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      " 17%|███████████████▋                                                                               | 50/303 [00:23<01:57,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|███████████████▉                                                                               | 51/303 [00:23<01:57,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|████████████████▎                                                                              | 52/303 [00:24<01:56,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|████████████████▌                                                                              | 53/303 [00:24<01:56,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|████████████████▉                                                                              | 54/303 [00:25<01:55,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█████████████████▏                                                                             | 55/303 [00:25<01:55,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=5.430e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=2.461e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 18%|█████████████████▌                                                                             | 56/303 [00:26<01:54,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█████████████████▊                                                                             | 57/303 [00:26<01:54,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=4.870e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=8.493e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=2.878e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=2.166e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.644e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.089e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=7.000e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 15 iterations, alpha=1.092e-04, previous alpha=3.975e-05, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=2.184e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=6.571e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=5.429e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=3.707e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=1.719e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 21 iterations, alpha=1.408e-03, previous alpha=1.289e-03, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=4.186e-04, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=2.803e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=2.757e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 15 iterations, alpha=2.800e-04, previous alpha=1.554e-04, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      " 19%|██████████████████▏                                                                            | 58/303 [00:26<01:54,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|██████████████████▍                                                                            | 59/303 [00:27<01:53,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██████████████████▊                                                                            | 60/303 [00:27<01:52,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████████████████▏                                                                           | 61/303 [00:28<01:52,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████████████████▍                                                                           | 62/303 [00:28<01:51,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|███████████████████▊                                                                           | 63/303 [00:29<01:51,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|████████████████████                                                                           | 64/303 [00:29<01:51,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=3.139e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=2.543e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.160e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=7.876e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 15 iterations, alpha=8.075e-05, previous alpha=6.237e-05, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.233e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=2.671e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 17 iterations, alpha=1.161e-03, previous alpha=1.121e-03, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      " 21%|████████████████████▍                                                                          | 65/303 [00:30<01:50,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.842e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=1.232e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=4.873e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=4.825e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=2.152e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.128e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=9.986e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=6.100e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=3.123e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=2.441e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.805e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.974e-04, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 11 iterations, alpha=1.922e-04, previous alpha=1.799e-04, with an active set of 10 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=3.286e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=3.286e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.402e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.104e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 13 iterations, alpha=1.818e-03, previous alpha=8.395e-04, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      " 22%|████████████████████▋                                                                          | 66/303 [00:30<01:50,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=1.765e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=8.127e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=4.063e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=2.773e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=1.077e-03, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=8.309e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=3.499e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=2.759e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=1.819e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=2.163e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=3.235e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=1.027e-03, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=2.857e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.342e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=6.975e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=5.362e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=3.373e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.111e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=4.758e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=4.758e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=2.209e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=7.735e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=4.297e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=2.701e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 13 iterations, alpha=1.214e-03, previous alpha=2.216e-04, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      " 22%|█████████████████████                                                                          | 67/303 [00:31<01:49,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|█████████████████████▎                                                                         | 68/303 [00:31<01:48,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|█████████████████████▋                                                                         | 69/303 [00:32<01:48,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.403e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=1.445e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=1.119e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 26 iterations, alpha=1.128e-03, previous alpha=5.795e-04, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=3.637e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.074e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.060e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=8.381e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=8.037e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 18 iterations, alpha=8.019e-04, previous alpha=4.260e-04, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=2.177e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.322e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.277e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=2.814e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=2.216e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=6.557e-06, with an active set of 16 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 23%|█████████████████████▉                                                                         | 70/303 [00:32<01:48,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██████████████████████▎                                                                        | 71/303 [00:33<01:47,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██████████████████████▌                                                                        | 72/303 [00:33<01:47,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=7.476e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.170e-02, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=2.304e-03, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=9.132e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=2.576e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=9.439e-06, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=4.350e-04, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=3.903e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 20 iterations, alpha=3.903e-05, previous alpha=3.157e-05, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.857e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=6.022e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=2.511e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 13 iterations, alpha=2.325e-03, previous alpha=1.580e-03, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=2.206e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.614e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.297e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=5.137e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 14 iterations, alpha=1.100e-04, previous alpha=4.128e-05, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      " 24%|██████████████████████▉                                                                        | 73/303 [00:33<01:47,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|███████████████████████▏                                                                       | 74/303 [00:34<01:46,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=7.507e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=8.346e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=7.925e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 19 iterations, alpha=8.346e-05, previous alpha=6.398e-05, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=8.482e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=9.291e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=8.008e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 27 iterations, alpha=5.320e-03, previous alpha=3.975e-03, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=1.337e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 17 iterations, alpha=1.337e-04, previous alpha=1.336e-04, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      " 25%|███████████████████████▌                                                                       | 75/303 [00:34<01:46,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=2.689e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.191e-02, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=4.372e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=1.602e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=7.489e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=8.726e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=6.015e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 29 iterations, i.e. alpha=2.386e-03, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 29 iterations, i.e. alpha=5.289e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=2.477e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=9.197e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=6.843e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=4.666e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.544e-03, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 14 iterations, alpha=4.194e-03, previous alpha=1.276e-03, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=5.502e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.294e-02, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.294e-02, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.209e-02, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 9 iterations, alpha=1.268e-02, previous alpha=1.106e-02, with an active set of 8 regressors.\n",
      "  warnings.warn(\n",
      " 25%|███████████████████████▊                                                                       | 76/303 [00:35<01:45,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|████████████████████████▏                                                                      | 77/303 [00:35<01:45,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|████████████████████████▍                                                                      | 78/303 [00:36<01:44,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|████████████████████████▊                                                                      | 79/303 [00:36<01:44,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 825us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.697e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.038e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=3.815e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.002e-03, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 15 iterations, alpha=8.193e-04, previous alpha=4.434e-04, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=9.480e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=3.522e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 16 iterations, alpha=8.648e-04, previous alpha=6.921e-04, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=4.697e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=4.697e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=2.348e-02, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=5.499e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=2.660e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=2.358e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 22 iterations, alpha=2.518e-03, previous alpha=1.402e-03, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=7.508e-03, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.448e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.086e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 13 iterations, alpha=7.260e-04, previous alpha=7.068e-04, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      " 26%|█████████████████████████                                                                      | 80/303 [00:37<01:43,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|█████████████████████████▍                                                                     | 81/303 [00:37<01:42,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 815us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|█████████████████████████▋                                                                     | 82/303 [00:38<01:42,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██████████████████████████                                                                     | 83/303 [00:38<01:42,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=6.696e-07, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 18 iterations, alpha=4.050e-07, previous alpha=3.104e-07, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      " 28%|██████████████████████████▎                                                                    | 84/303 [00:39<01:41,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██████████████████████████▋                                                                    | 85/303 [00:39<01:41,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██████████████████████████▉                                                                    | 86/303 [00:39<01:40,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|███████████████████████████▎                                                                   | 87/303 [00:40<01:40,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|███████████████████████████▌                                                                   | 88/303 [00:40<01:39,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|███████████████████████████▉                                                                   | 89/303 [00:41<01:39,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████████████████████▏                                                                  | 90/303 [00:41<01:38,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████████████████████▌                                                                  | 91/303 [00:42<01:38,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=5.563e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=2.781e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 21 iterations, alpha=7.090e-04, previous alpha=6.688e-04, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=3.573e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.786e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.425e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 6 iterations, alpha=1.425e-02, previous alpha=1.425e-02, with an active set of 5 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=2.655e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.328e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=7.806e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=6.051e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=4.051e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 12 iterations, alpha=3.843e-03, previous alpha=3.595e-03, with an active set of 11 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=5.527e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=4.265e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=2.752e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=2.104e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.111e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=5.418e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 13 iterations, alpha=1.544e-03, previous alpha=4.525e-04, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      " 30%|████████████████████████████▊                                                                  | 92/303 [00:42<01:37,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|█████████████████████████████▏                                                                 | 93/303 [00:43<01:37,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=4.359e-04, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=2.104e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 15 iterations, alpha=2.254e-04, previous alpha=2.097e-04, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      " 31%|█████████████████████████████▍                                                                 | 94/303 [00:43<01:36,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=2.032e-05, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=1.417e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=1.245e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=3.637e-06, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=3.197e-06, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=2.528e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=6.701e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=6.122e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=2.279e-04, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=2.079e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 15 iterations, alpha=2.079e-04, previous alpha=1.817e-04, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=6.145e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.640e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 25 iterations, alpha=2.976e-04, previous alpha=2.473e-05, with an active set of 16 regressors.\n",
      "  warnings.warn(\n",
      " 31%|█████████████████████████████▊                                                                 | 95/303 [00:44<01:36,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|██████████████████████████████                                                                 | 96/303 [00:44<01:36,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|██████████████████████████████▍                                                                | 97/303 [00:45<01:35,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.128e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=4.916e-05, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=1.662e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=4.088e-06, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 17 iterations, alpha=1.602e-05, previous alpha=3.446e-06, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.037e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=1.784e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=9.035e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=2.799e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=1.476e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 20 iterations, alpha=1.417e-04, previous alpha=1.703e-05, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      " 32%|██████████████████████████████▋                                                                | 98/303 [00:45<01:35,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███████████████████████████████                                                                | 99/303 [00:46<01:35,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███████████████████████████████                                                               | 100/303 [00:46<01:34,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.229e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 25 iterations, alpha=1.169e-03, previous alpha=9.385e-04, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=2.478e-04, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=5.490e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 18 iterations, alpha=5.261e-05, previous alpha=5.166e-05, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=3.160e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.286e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=6.478e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 13 iterations, alpha=1.263e-03, previous alpha=5.584e-04, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=5.374e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=1.985e-06, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 33%|███████████████████████████████▎                                                              | 101/303 [00:46<01:33,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███████████████████████████████▋                                                              | 102/303 [00:47<01:33,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=1.059e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=5.295e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=1.801e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=2.040e-05, with an active set of 16 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=3.525e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=5.379e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 12 iterations, alpha=4.789e-03, previous alpha=4.608e-03, with an active set of 11 regressors.\n",
      "  warnings.warn(\n",
      " 34%|███████████████████████████████▉                                                              | 103/303 [00:47<01:33,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|████████████████████████████████▎                                                             | 104/303 [00:48<01:32,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.228e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=6.091e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=2.170e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 15 iterations, alpha=1.275e-03, previous alpha=1.226e-03, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      " 35%|████████████████████████████████▌                                                             | 105/303 [00:48<01:31,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|████████████████████████████████▉                                                             | 106/303 [00:49<01:31,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=3.442e-04, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=3.416e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 18 iterations, alpha=1.565e-04, previous alpha=1.028e-04, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=4.081e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=2.183e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.276e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 15 iterations, alpha=1.293e-03, previous alpha=3.506e-04, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      " 35%|█████████████████████████████████▏                                                            | 107/303 [00:49<01:30,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|█████████████████████████████████▌                                                            | 108/303 [00:50<01:30,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|█████████████████████████████████▊                                                            | 109/303 [00:50<01:30,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 815us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=5.553e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=8.924e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=8.550e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=3.957e-03, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 16 iterations, alpha=4.536e-03, previous alpha=3.000e-03, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=3.523e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=1.537e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=8.365e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=3.526e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 15 iterations, alpha=3.611e-03, previous alpha=3.713e-04, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=1.149e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.640e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.300e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=6.796e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 17 iterations, alpha=6.788e-04, previous alpha=4.720e-04, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      " 36%|██████████████████████████████████▏                                                           | 110/303 [00:51<01:29,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.634e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.205e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.112e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=5.163e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 15 iterations, alpha=3.373e-03, previous alpha=2.527e-03, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=3.554e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 29 iterations, i.e. alpha=1.010e-03, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 29 iterations, i.e. alpha=6.763e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 37%|██████████████████████████████████▍                                                           | 111/303 [00:51<01:29,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=8.004e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=4.219e-05, with an active set of 16 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=4.404e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.227e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=6.004e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 13 iterations, alpha=4.482e-03, previous alpha=3.394e-03, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      " 37%|██████████████████████████████████▋                                                           | 112/303 [00:52<01:28,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███████████████████████████████████                                                           | 113/303 [00:52<01:28,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=5.745e-04, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=1.113e-05, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 27 iterations, alpha=4.066e-05, previous alpha=4.066e-05, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=2.826e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=9.389e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=7.045e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 38%|███████████████████████████████████▎                                                          | 114/303 [00:53<01:28,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███████████████████████████████████▋                                                          | 115/303 [00:53<01:27,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 820us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███████████████████████████████████▉                                                          | 116/303 [00:53<01:27,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 815us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|████████████████████████████████████▎                                                         | 117/303 [00:54<01:29,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|████████████████████████████████████▌                                                         | 118/303 [00:54<01:28,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|████████████████████████████████████▉                                                         | 119/303 [00:55<01:26,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████████████████████████▏                                                        | 120/303 [00:55<01:25,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████████████████████████▌                                                        | 121/303 [00:56<01:25,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=9.273e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 28 iterations, alpha=3.529e-03, previous alpha=7.860e-04, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=3.448e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.719e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.624e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 15 iterations, alpha=1.115e-03, previous alpha=8.690e-04, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=3.840e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=6.612e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=5.967e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 21 iterations, alpha=5.931e-03, previous alpha=4.157e-03, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      " 40%|█████████████████████████████████████▊                                                        | 122/303 [00:56<01:24,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=3.195e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=2.601e-04, with an active set of 16 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.117e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=2.666e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=5.940e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 17 iterations, alpha=1.558e-04, previous alpha=3.448e-05, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=1.899e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=1.965e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=1.636e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 21 iterations, alpha=1.882e-03, previous alpha=1.628e-03, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      " 41%|██████████████████████████████████████▏                                                       | 123/303 [00:57<01:24,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 823us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|██████████████████████████████████████▍                                                       | 124/303 [00:57<01:23,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|██████████████████████████████████████▊                                                       | 125/303 [00:58<01:22,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|███████████████████████████████████████                                                       | 126/303 [00:58<01:22,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.053e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=1.415e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 20 iterations, alpha=1.174e-04, previous alpha=8.028e-05, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=7.002e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=1.043e-02, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 20 iterations, alpha=1.086e-02, previous alpha=1.037e-02, with an active set of 11 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=9.380e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=5.951e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=4.395e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 11 iterations, alpha=4.540e-03, previous alpha=4.221e-03, with an active set of 10 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=2.957e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.428e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=6.852e-04, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 16 iterations, alpha=4.574e-04, previous alpha=1.590e-04, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      " 42%|███████████████████████████████████████▍                                                      | 127/303 [00:59<01:22,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|███████████████████████████████████████▋                                                      | 128/303 [00:59<01:21,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████████████████████████████████████████                                                      | 129/303 [01:00<01:20,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████████████████████████████████████████▎                                                     | 130/303 [01:00<01:20,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.587e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=1.325e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=8.816e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 21 iterations, alpha=2.018e-05, previous alpha=1.933e-05, with an active set of 16 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.566e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=3.215e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=4.736e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 16 iterations, alpha=2.185e-04, previous alpha=3.594e-05, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=2.332e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 23 iterations, alpha=3.139e-03, previous alpha=2.496e-04, with an active set of 16 regressors.\n",
      "  warnings.warn(\n",
      " 43%|████████████████████████████████████████▋                                                     | 131/303 [01:00<01:20,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=3.255e-05, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=1.118e-06, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=1.065e-06, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 44%|████████████████████████████████████████▉                                                     | 132/303 [01:01<01:19,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|█████████████████████████████████████████▎                                                    | 133/303 [01:01<01:18,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|█████████████████████████████████████████▌                                                    | 134/303 [01:02<01:18,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=6.511e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=2.879e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 13 iterations, alpha=1.622e-03, previous alpha=9.741e-04, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      " 45%|█████████████████████████████████████████▉                                                    | 135/303 [01:02<01:18,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 815us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.243e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=1.984e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=1.602e-03, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=1.388e-03, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=1.145e-03, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=7.779e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=3.910e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=7.726e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 17 iterations, alpha=3.939e-04, previous alpha=3.863e-04, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.297e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=4.036e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=2.127e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=9.711e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=8.753e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=4.179e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=2.732e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.534e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 45%|██████████████████████████████████████████▏                                                   | 136/303 [01:03<01:17,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|██████████████████████████████████████████▌                                                   | 137/303 [01:03<01:17,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|██████████████████████████████████████████▊                                                   | 138/303 [01:04<01:16,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|███████████████████████████████████████████                                                   | 139/303 [01:04<01:16,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|███████████████████████████████████████████▍                                                  | 140/303 [01:05<01:15,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|███████████████████████████████████████████▋                                                  | 141/303 [01:05<01:15,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████████████████████████████████████████████                                                  | 142/303 [01:06<01:14,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████████████████████████████████████████████▎                                                 | 143/303 [01:06<01:14,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=6.569e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.222e-02, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=5.059e-04, with an active set of 16 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=3.243e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.812e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=7.360e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=5.743e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=6.107e-05, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.896e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=8.508e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=7.152e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 48%|████████████████████████████████████████████▋                                                 | 144/303 [01:07<01:13,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████████████████████████████████████████████▉                                                 | 145/303 [01:07<01:13,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|█████████████████████████████████████████████▎                                                | 146/303 [01:07<01:13,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|█████████████████████████████████████████████▌                                                | 147/303 [01:08<01:12,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=6.638e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=6.343e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=4.823e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 49%|█████████████████████████████████████████████▉                                                | 148/303 [01:08<01:12,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=8.657e-04, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=3.377e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=2.893e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=8.681e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=3.147e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=1.181e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=9.686e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=4.460e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=3.863e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=2.996e-06, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=2.595e-06, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=1.824e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=3.958e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 12 iterations, alpha=3.958e-03, previous alpha=3.937e-03, with an active set of 7 regressors.\n",
      "  warnings.warn(\n",
      " 49%|██████████████████████████████████████████████▏                                               | 149/303 [01:09<01:11,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=2.306e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=4.387e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 11 iterations, alpha=4.364e-03, previous alpha=3.848e-03, with an active set of 10 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=5.729e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=1.356e-02, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=8.907e-03, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=5.472e-03, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=1.288e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 18 iterations, alpha=6.859e-06, previous alpha=6.199e-06, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      " 50%|██████████████████████████████████████████████▌                                               | 150/303 [01:09<01:11,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 871us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████████████████████████████▊                                               | 151/303 [01:10<01:10,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.404e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=2.702e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.842e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=4.916e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=2.699e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=7.149e-06, with an active set of 16 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 50%|███████████████████████████████████████████████▏                                              | 152/303 [01:10<01:10,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|███████████████████████████████████████████████▍                                              | 153/303 [01:11<01:09,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=2.143e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=7.988e-05, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=3.266e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=5.671e-06, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=5.671e-06, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=5.237e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.568e-02, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.424e-02, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=7.841e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=6.801e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=3.539e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=3.139e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=7.677e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=7.677e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=4.982e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.284e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=6.422e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=6.422e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=2.545e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=7.133e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=4.981e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=3.337e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=5.860e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=8.841e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=8.841e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=4.421e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 8 iterations, alpha=2.690e-03, previous alpha=2.433e-03, with an active set of 7 regressors.\n",
      "  warnings.warn(\n",
      " 51%|███████████████████████████████████████████████▊                                              | 154/303 [01:11<01:09,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.638e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.638e-04, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.356e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=6.251e-05, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=4.577e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=4.387e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=1.200e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=4.135e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.887e-02, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=6.129e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=4.862e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=2.426e-03, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 19 iterations, alpha=3.252e-03, previous alpha=2.039e-03, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=6.546e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=4.262e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=7.580e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 17 iterations, alpha=1.328e-03, previous alpha=7.305e-04, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=8.539e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=8.481e-04, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=7.495e-04, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 15 iterations, alpha=8.183e-04, previous alpha=7.495e-04, with an active set of 10 regressors.\n",
      "  warnings.warn(\n",
      " 51%|████████████████████████████████████████████████                                              | 155/303 [01:12<01:08,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=4.437e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=4.354e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=3.990e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=6.133e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.142e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 11 iterations, alpha=1.142e-03, previous alpha=1.141e-03, with an active set of 10 regressors.\n",
      "  warnings.warn(\n",
      " 51%|████████████████████████████████████████████████▍                                             | 156/303 [01:12<01:08,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|████████████████████████████████████████████████▋                                             | 157/303 [01:13<01:07,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 832us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████████████████████████████████████████████████                                             | 158/303 [01:13<01:07,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████████████████████████████████████████████████▎                                            | 159/303 [01:14<01:07,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████████████████████████████████████████████████▋                                            | 160/303 [01:14<01:06,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/shap/explainers/_kernel.py:707: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 21 iterations, alpha=7.316e-05, previous alpha=7.316e-05, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/shap/explainers/_kernel.py:707: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 11 iterations, alpha=4.442e-03, previous alpha=3.354e-03, with an active set of 10 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/shap/explainers/_kernel.py:707: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      " 53%|█████████████████████████████████████████████████▉                                            | 161/303 [01:14<01:05,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=3.285e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 18 iterations, alpha=2.386e-05, previous alpha=1.844e-05, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=3.286e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=8.165e-07, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=1.463e-07, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=3.777e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.482e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=7.761e-04, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 16 iterations, alpha=1.254e-03, previous alpha=3.551e-04, with an active set of 11 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.069e-02, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=2.836e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=2.787e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 17 iterations, alpha=2.302e-03, previous alpha=2.123e-03, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      " 53%|██████████████████████████████████████████████████▎                                           | 162/303 [01:15<01:05,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 815us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|██████████████████████████████████████████████████▌                                           | 163/303 [01:15<01:05,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=4.571e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 19 iterations, alpha=4.571e-05, previous alpha=3.538e-05, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=7.152e-04, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=6.173e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 18 iterations, alpha=6.173e-05, previous alpha=4.900e-05, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=1.453e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=3.779e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=2.411e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=2.053e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=8.386e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 14 iterations, alpha=1.305e-03, previous alpha=3.305e-04, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=7.252e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.190e-02, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 11 iterations, alpha=1.078e-02, previous alpha=9.019e-03, with an active set of 10 regressors.\n",
      "  warnings.warn(\n",
      " 54%|██████████████████████████████████████████████████▉                                           | 164/303 [01:16<01:04,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|███████████████████████████████████████████████████▏                                          | 165/303 [01:16<01:04,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|███████████████████████████████████████████████████▍                                          | 166/303 [01:17<01:03,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|███████████████████████████████████████████████████▊                                          | 167/303 [01:17<01:03,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|████████████████████████████████████████████████████                                          | 168/303 [01:18<01:02,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.012e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=5.061e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=5.133e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=3.846e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=2.256e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=1.268e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=4.200e-06, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=2.306e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.294e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=9.311e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=5.172e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=5.095e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 7 iterations, alpha=4.841e-03, previous alpha=4.808e-03, with an active set of 6 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.156e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=8.258e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=8.258e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=3.348e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 17 iterations, alpha=4.764e-04, previous alpha=3.166e-04, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      " 56%|████████████████████████████████████████████████████▍                                         | 169/303 [01:18<01:02,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|████████████████████████████████████████████████████▋                                         | 170/303 [01:19<01:01,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.129e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=5.645e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.091e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=8.624e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=8.131e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=7.287e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=9.608e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=9.556e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=9.556e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=4.039e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=2.019e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=9.345e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 14 iterations, alpha=8.925e-03, previous alpha=8.587e-03, with an active set of 11 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=3.109e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=1.554e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=9.152e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=6.583e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=5.262e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=2.500e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=2.189e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=2.139e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 13 iterations, alpha=1.079e-03, previous alpha=1.079e-03, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/shap/explainers/_kernel.py:707: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=1.395e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=6.625e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 9 iterations, alpha=5.005e-03, previous alpha=4.738e-03, with an active set of 8 regressors.\n",
      "  warnings.warn(\n",
      " 56%|█████████████████████████████████████████████████████                                         | 171/303 [01:19<01:01,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=2.312e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=2.428e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 25 iterations, alpha=1.926e-03, previous alpha=1.486e-03, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=3.435e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=2.514e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=5.323e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 17 iterations, alpha=9.317e-04, previous alpha=2.890e-04, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=5.567e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.310e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=2.960e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=1.021e-04, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.570e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.527e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=6.819e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.558e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=5.324e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=3.000e-06, with an active set of 16 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 57%|█████████████████████████████████████████████████████▎                                        | 172/303 [01:20<01:00,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████████████████████████████████████████████████████▋                                        | 173/303 [01:20<01:01,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████████████████████████████████████████████████████▉                                        | 174/303 [01:20<01:00,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=3.312e-04, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.425e-04, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=8.568e-05, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 17 iterations, alpha=1.098e-04, previous alpha=5.401e-05, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=6.355e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=1.279e-02, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=9.998e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 17 iterations, alpha=1.193e-02, previous alpha=9.003e-03, with an active set of 8 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=3.659e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=2.767e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=5.180e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 14 iterations, alpha=4.347e-04, previous alpha=4.099e-04, with an active set of 11 regressors.\n",
      "  warnings.warn(\n",
      " 58%|██████████████████████████████████████████████████████▎                                       | 175/303 [01:21<00:59,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=4.068e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.161e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=2.505e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=2.277e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 13 iterations, alpha=2.265e-03, previous alpha=1.872e-03, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=2.367e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=4.438e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=2.689e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.926e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=8.077e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=6.179e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 19 iterations, alpha=6.699e-04, previous alpha=3.204e-04, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=8.947e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.352e-02, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.199e-02, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 15 iterations, alpha=1.344e-02, previous alpha=1.160e-02, with an active set of 10 regressors.\n",
      "  warnings.warn(\n",
      " 58%|██████████████████████████████████████████████████████▌                                       | 176/303 [01:21<00:59,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=3.352e-04, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.588e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.099e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=4.473e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=5.173e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=3.703e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=2.917e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 20 iterations, alpha=2.969e-04, previous alpha=1.826e-04, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=9.651e-06, with an active set of 16 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 58%|██████████████████████████████████████████████████████▉                                       | 177/303 [01:22<00:58,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|███████████████████████████████████████████████████████▏                                      | 178/303 [01:22<00:58,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 815us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|███████████████████████████████████████████████████████▌                                      | 179/303 [01:23<00:57,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|███████████████████████████████████████████████████████▊                                      | 180/303 [01:23<00:57,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=3.523e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.194e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=4.412e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 16 iterations, alpha=4.199e-04, previous alpha=1.642e-04, with an active set of 11 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=6.199e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=3.424e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 14 iterations, alpha=3.424e-04, previous alpha=2.903e-04, with an active set of 11 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=4.237e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=2.089e-02, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 11 iterations, alpha=2.089e-02, previous alpha=2.087e-02, with an active set of 8 regressors.\n",
      "  warnings.warn(\n",
      " 60%|████████████████████████████████████████████████████████▏                                     | 181/303 [01:24<00:56,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 820us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|████████████████████████████████████████████████████████▍                                     | 182/303 [01:24<00:56,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|████████████████████████████████████████████████████████▊                                     | 183/303 [01:25<00:55,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=9.237e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=6.413e-04, with an active set of 16 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=2.769e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=4.454e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=3.337e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=3.809e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=2.158e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=4.783e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=4.200e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=1.328e-06, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=4.523e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 61%|█████████████████████████████████████████████████████████                                     | 184/303 [01:25<00:55,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|█████████████████████████████████████████████████████████▍                                    | 185/303 [01:26<00:54,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|█████████████████████████████████████████████████████████▋                                    | 186/303 [01:26<00:54,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████████████████████████████████████████████████████████                                    | 187/303 [01:27<00:53,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████████████████████████████████████████████████████████▎                                   | 188/303 [01:27<00:53,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████████████████████████████████████████████████████████▋                                   | 189/303 [01:27<00:53,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████████████████████████████████████████████████████████▉                                   | 190/303 [01:28<00:52,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.452e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=4.376e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 16 iterations, alpha=2.715e-04, previous alpha=1.614e-04, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=2.210e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=9.070e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 15 iterations, alpha=2.288e-03, previous alpha=1.316e-03, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      " 63%|███████████████████████████████████████████████████████████▎                                  | 191/303 [01:28<00:52,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|███████████████████████████████████████████████████████████▌                                  | 192/303 [01:29<00:51,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|███████████████████████████████████████████████████████████▊                                  | 193/303 [01:29<00:51,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|████████████████████████████████████████████████████████████▏                                 | 194/303 [01:30<00:50,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|████████████████████████████████████████████████████████████▍                                 | 195/303 [01:30<00:50,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|████████████████████████████████████████████████████████████▊                                 | 196/303 [01:31<00:49,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|█████████████████████████████████████████████████████████████                                 | 197/303 [01:31<00:49,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 815us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|█████████████████████████████████████████████████████████████▍                                | 198/303 [01:32<00:48,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 815us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|█████████████████████████████████████████████████████████████▋                                | 199/303 [01:32<00:48,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 815us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=5.408e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=2.704e-02, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=9.774e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=4.676e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 16 iterations, alpha=3.874e-03, previous alpha=2.573e-03, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=3.603e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.251e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=7.652e-04, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=5.352e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=2.995e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.600e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.314e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 15 iterations, alpha=3.735e-04, previous alpha=1.240e-04, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.215e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=3.041e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 11 iterations, alpha=2.712e-03, previous alpha=2.526e-03, with an active set of 10 regressors.\n",
      "  warnings.warn(\n",
      " 66%|██████████████████████████████████████████████████████████████                                | 200/303 [01:33<00:47,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████████████████████████████████████████████████████████████▎                               | 201/303 [01:33<00:47,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 820us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=2.000e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.334e-04, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 11 iterations, alpha=1.334e-04, previous alpha=1.128e-04, with an active set of 10 regressors.\n",
      "  warnings.warn(\n",
      " 67%|██████████████████████████████████████████████████████████████▋                               | 202/303 [01:34<00:46,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████████████████████████████████████████████████████████████▉                               | 203/303 [01:34<00:46,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|███████████████████████████████████████████████████████████████▎                              | 204/303 [01:34<00:46,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|███████████████████████████████████████████████████████████████▌                              | 205/303 [01:35<00:45,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|███████████████████████████████████████████████████████████████▉                              | 206/303 [01:35<00:45,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=2.786e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.213e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=5.757e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=8.825e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=3.343e-05, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 68%|████████████████████████████████████████████████████████████████▏                             | 207/303 [01:36<00:44,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|████████████████████████████████████████████████████████████████▌                             | 208/303 [01:36<00:44,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=1.283e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=2.870e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=7.151e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 20 iterations, alpha=8.483e-04, previous alpha=4.898e-04, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=2.737e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 35 iterations, alpha=7.443e-04, previous alpha=6.015e-04, with an active set of 16 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=8.136e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.711e-02, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=8.323e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=2.055e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 16 iterations, alpha=3.292e-03, previous alpha=1.571e-03, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=3.368e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.351e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=2.890e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=2.306e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.104e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=6.364e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 15 iterations, alpha=2.008e-03, previous alpha=5.354e-04, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      " 69%|████████████████████████████████████████████████████████████████▊                             | 209/303 [01:37<00:43,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=1.370e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=2.666e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=2.357e-03, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=2.222e-03, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=2.312e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=8.949e-06, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=4.474e-06, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 69%|█████████████████████████████████████████████████████████████████▏                            | 210/303 [01:37<00:43,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|█████████████████████████████████████████████████████████████████▍                            | 211/303 [01:38<00:42,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|█████████████████████████████████████████████████████████████████▊                            | 212/303 [01:38<00:42,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████████████████████████████████████████                            | 213/303 [01:39<00:41,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|██████████████████████████████████████████████████████████████████▍                           | 214/303 [01:39<00:41,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|██████████████████████████████████████████████████████████████████▋                           | 215/303 [01:40<00:41,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████████████████████████████████████████████████████████████████                           | 216/303 [01:40<00:40,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████████████████████████████████████████████████████████████████▎                          | 217/303 [01:41<00:40,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████████████████████████████████████████████████████████████████▋                          | 218/303 [01:41<00:39,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=1.117e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=1.274e-05, with an active set of 16 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.864e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.381e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 13 iterations, alpha=1.129e-03, previous alpha=9.848e-04, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=3.200e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=1.331e-03, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=1.178e-03, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 23 iterations, alpha=1.184e-03, previous alpha=8.069e-04, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      " 72%|███████████████████████████████████████████████████████████████████▉                          | 219/303 [01:41<00:39,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 815us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|████████████████████████████████████████████████████████████████████▎                         | 220/303 [01:42<00:38,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|████████████████████████████████████████████████████████████████████▌                         | 221/303 [01:42<00:38,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.839e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=7.861e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.726e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.639e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.264e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 11 iterations, alpha=1.469e-03, previous alpha=4.114e-04, with an active set of 10 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=4.070e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=2.035e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 7 iterations, alpha=1.951e-02, previous alpha=1.939e-02, with an active set of 6 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=1.390e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=6.950e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=5.619e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=3.951e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 12 iterations, alpha=4.468e-03, previous alpha=2.209e-03, with an active set of 11 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=4.541e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=2.271e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=4.982e-03, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=3.677e-03, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 73%|████████████████████████████████████████████████████████████████████▊                         | 222/303 [01:43<00:37,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=9.950e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=3.516e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=3.296e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 14 iterations, alpha=2.216e-03, previous alpha=1.522e-03, with an active set of 11 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=3.250e-02, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 33 iterations, alpha=3.140e-03, previous alpha=2.357e-03, with an active set of 16 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=1.111e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=1.108e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=4.191e-07, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 18 iterations, alpha=1.107e-04, previous alpha=4.180e-07, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      " 74%|█████████████████████████████████████████████████████████████████████▏                        | 223/303 [01:43<00:37,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|█████████████████████████████████████████████████████████████████████▍                        | 224/303 [01:44<00:36,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|█████████████████████████████████████████████████████████████████████▊                        | 225/303 [01:44<00:36,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|██████████████████████████████████████████████████████████████████████                        | 226/303 [01:45<00:35,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|██████████████████████████████████████████████████████████████████████▍                       | 227/303 [01:45<00:35,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|██████████████████████████████████████████████████████████████████████▋                       | 228/303 [01:46<00:34,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████████████████████████████████████████████████████████████████████                       | 229/303 [01:46<00:34,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=4.176e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 14 iterations, alpha=3.984e-04, previous alpha=3.418e-04, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=4.964e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=4.475e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 15 iterations, alpha=1.376e-03, previous alpha=1.230e-03, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/shap/explainers/_kernel.py:707: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      " 76%|███████████████████████████████████████████████████████████████████████▎                      | 230/303 [01:47<00:33,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████████████████████████████████████████████████████████████████████▋                      | 231/303 [01:47<00:33,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████████████████████████████████████████████████████████████████████▉                      | 232/303 [01:47<00:33,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|████████████████████████████████████████████████████████████████████████▎                     | 233/303 [01:48<00:32,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|████████████████████████████████████████████████████████████████████████▌                     | 234/303 [01:48<00:32,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=3.476e-02, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 25 iterations, alpha=9.551e-03, previous alpha=2.645e-03, with an active set of 16 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 17 iterations, alpha=3.396e-04, previous alpha=2.873e-04, with an active set of 16 regressors.\n",
      "  warnings.warn(\n",
      " 78%|████████████████████████████████████████████████████████████████████████▉                     | 235/303 [01:49<00:31,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|█████████████████████████████████████████████████████████████████████████▏                    | 236/303 [01:49<00:31,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|█████████████████████████████████████████████████████████████████████████▌                    | 237/303 [01:50<00:30,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 865us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|█████████████████████████████████████████████████████████████████████████▊                    | 238/303 [01:50<00:30,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|██████████████████████████████████████████████████████████████████████████▏                   | 239/303 [01:51<00:29,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|██████████████████████████████████████████████████████████████████████████▍                   | 240/303 [01:51<00:29,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████████████████████████████████████████████▊                   | 241/303 [01:52<00:28,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████████████████████████████████████████████████████████████████████████                   | 242/303 [01:52<00:28,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████████████████████████████████████████████████████████████████████████▍                  | 243/303 [01:53<00:27,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=2.913e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=1.994e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=9.005e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=8.842e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 21 iterations, alpha=8.389e-05, previous alpha=6.352e-05, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=6.385e-03, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=2.189e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=2.686e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=2.043e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=4.482e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=1.360e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=1.360e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=6.962e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=3.704e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=3.704e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.607e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.409e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 11 iterations, alpha=2.225e-03, previous alpha=9.590e-04, with an active set of 10 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=1.522e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=6.737e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=2.409e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=1.699e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=7.747e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=7.188e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=5.234e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=1.606e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=3.301e-06, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 81%|███████████████████████████████████████████████████████████████████████████▋                  | 244/303 [01:53<00:27,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████████████████████████████████████████████████████████████████████████                  | 245/303 [01:54<00:27,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████████████████████████████████████████████████████████████████████████▎                 | 246/303 [01:54<00:26,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=1.334e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=9.939e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=1.430e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=6.514e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=2.593e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=2.487e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=7.457e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=3.508e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 18 iterations, alpha=5.092e-04, previous alpha=2.876e-04, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=2.771e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=2.611e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=3.749e-06, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 82%|████████████████████████████████████████████████████████████████████████████▋                 | 247/303 [01:54<00:26,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████████████████████████████████████████████████████████████████████████▉                 | 248/303 [01:55<00:25,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|█████████████████████████████████████████████████████████████████████████████▏                | 249/303 [01:55<00:25,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|█████████████████████████████████████████████████████████████████████████████▌                | 250/303 [01:56<00:24,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|█████████████████████████████████████████████████████████████████████████████▊                | 251/303 [01:56<00:24,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|██████████████████████████████████████████████████████████████████████████████▏               | 252/303 [01:57<00:23,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|██████████████████████████████████████████████████████████████████████████████▍               | 253/303 [01:57<00:23,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.197e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 12 iterations, alpha=1.090e-04, previous alpha=9.712e-05, with an active set of 11 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=7.666e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.459e-02, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 14 iterations, alpha=1.339e-02, previous alpha=1.300e-02, with an active set of 9 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=9.683e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=2.812e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=2.710e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=2.429e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.989e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.158e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=9.710e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=8.181e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=7.981e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=7.981e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=3.395e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=6.683e-06, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=6.683e-06, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 84%|██████████████████████████████████████████████████████████████████████████████▊               | 254/303 [01:58<00:22,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 835us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=5.975e-03, with an active set of 1 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.757e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=9.164e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=7.978e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=1.741e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=1.017e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=5.083e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=9.547e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=8.895e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=8.893e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=2.439e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.218e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=1.512e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=7.562e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=3.923e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=2.512e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.141e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=9.903e-04, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 9 iterations, alpha=6.293e-03, previous alpha=9.609e-04, with an active set of 8 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=2.658e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=1.570e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.184e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.275e-03, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=4.264e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=1.724e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 84%|███████████████████████████████████████████████████████████████████████████████               | 255/303 [01:58<00:22,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|███████████████████████████████████████████████████████████████████████████████▍              | 256/303 [01:59<00:22,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|███████████████████████████████████████████████████████████████████████████████▋              | 257/303 [01:59<00:22,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████████████████████████████████████████████████████████████████████████████              | 258/303 [02:00<00:21,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████████████████████████████████████████████████████████████████████████████▎             | 259/303 [02:00<00:20,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████████████████████████████████████████████████████████████████████████████▋             | 260/303 [02:01<00:20,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████████████████████████████████████████████████████████████████████████████▉             | 261/303 [02:01<00:19,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|█████████████████████████████████████████████████████████████████████████████████▎            | 262/303 [02:02<00:19,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=3.198e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.148e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=5.234e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.687e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=3.990e-05, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=6.040e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=5.701e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=4.255e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=3.503e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 16 iterations, alpha=4.220e-03, previous alpha=8.310e-04, with an active set of 11 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=2.966e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=2.158e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=9.733e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=1.357e-04, with an active set of 16 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 87%|█████████████████████████████████████████████████████████████████████████████████▌            | 263/303 [02:02<00:18,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=6.854e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=6.784e-04, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=2.368e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=2.332e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=9.038e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=6.783e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=2.204e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=2.194e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 87%|█████████████████████████████████████████████████████████████████████████████████▉            | 264/303 [02:02<00:18,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=5.167e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.368e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.284e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 15 iterations, alpha=6.397e-04, previous alpha=6.385e-04, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=8.398e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.405e-02, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=2.419e-03, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=1.861e-03, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=2.113e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 18 iterations, alpha=2.113e-05, previous alpha=1.881e-05, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=6.069e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.143e-02, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 13 iterations, alpha=1.143e-02, previous alpha=1.139e-02, with an active set of 10 regressors.\n",
      "  warnings.warn(\n",
      " 87%|██████████████████████████████████████████████████████████████████████████████████▏           | 265/303 [02:03<00:17,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|██████████████████████████████████████████████████████████████████████████████████▌           | 266/303 [02:03<00:17,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|██████████████████████████████████████████████████████████████████████████████████▊           | 267/303 [02:04<00:16,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=5.499e-04, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=3.746e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=8.025e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=3.539e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 88%|███████████████████████████████████████████████████████████████████████████████████▏          | 268/303 [02:04<00:16,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|███████████████████████████████████████████████████████████████████████████████████▍          | 269/303 [02:05<00:15,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.736e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 17 iterations, alpha=2.790e-03, previous alpha=2.790e-03, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.824e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=8.570e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=8.483e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=4.285e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 13 iterations, alpha=4.159e-03, previous alpha=2.743e-03, with an active set of 8 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=1.531e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=1.456e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=6.810e-06, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 89%|███████████████████████████████████████████████████████████████████████████████████▊          | 270/303 [02:05<00:15,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=9.172e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.683e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=6.908e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.252e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=6.090e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 15 iterations, alpha=6.090e-05, previous alpha=5.972e-05, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=1.196e-01, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=5.333e-03, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.339e-03, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=5.901e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 20 iterations, alpha=1.003e-03, previous alpha=3.092e-04, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      " 89%|████████████████████████████████████████████████████████████████████████████████████          | 271/303 [02:06<00:14,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████████████████████████████████████████████████████████████████████████████████▍         | 272/303 [02:06<00:14,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 825us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████████████████████████████████████████████████████████████████████████████████▋         | 273/303 [02:07<00:13,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=7.629e-03, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=3.006e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=2.521e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=5.666e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=2.942e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 15 iterations, alpha=1.537e-02, previous alpha=5.577e-03, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=1.855e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=1.392e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=5.148e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=4.110e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=3.862e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=3.597e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 10 iterations, alpha=2.979e-03, previous alpha=1.666e-03, with an active set of 9 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=4.670e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.153e-02, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.153e-02, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 11 iterations, alpha=1.064e-02, previous alpha=1.046e-02, with an active set of 10 regressors.\n",
      "  warnings.warn(\n",
      " 90%|█████████████████████████████████████████████████████████████████████████████████████         | 274/303 [02:07<00:13,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 19 iterations, alpha=5.263e-04, previous alpha=4.619e-04, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      " 91%|█████████████████████████████████████████████████████████████████████████████████████▎        | 275/303 [02:08<00:13,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████████████████████████████████████████████████████████████████████████████████▌        | 276/303 [02:08<00:12,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████████████████████████████████████████████████████████████████████████████████▉        | 277/303 [02:08<00:12,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|██████████████████████████████████████████████████████████████████████████████████████▏       | 278/303 [02:09<00:11,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 820us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=6.480e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=2.349e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=9.719e-06, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=9.669e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=1.952e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=9.610e-06, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=7.255e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 16 iterations, alpha=6.897e-04, previous alpha=4.130e-04, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      " 92%|██████████████████████████████████████████████████████████████████████████████████████▌       | 279/303 [02:09<00:11,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|██████████████████████████████████████████████████████████████████████████████████████▊       | 280/303 [02:10<00:10,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|███████████████████████████████████████████████████████████████████████████████████████▏      | 281/303 [02:10<00:10,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=2.206e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 22 iterations, alpha=2.346e-04, previous alpha=2.307e-04, with an active set of 11 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=4.045e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=2.278e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=2.320e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=2.450e-06, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=4.924e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=2.462e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=6.684e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=6.205e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 93%|███████████████████████████████████████████████████████████████████████████████████████▍      | 282/303 [02:11<00:09,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|███████████████████████████████████████████████████████████████████████████████████████▊      | 283/303 [02:11<00:09,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|████████████████████████████████████████████████████████████████████████████████████████      | 284/303 [02:12<00:08,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=6.026e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.267e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.258e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=4.858e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=4.219e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=2.039e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=6.280e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 13 iterations, alpha=3.157e-04, previous alpha=3.140e-04, with an active set of 10 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/shap/explainers/_kernel.py:707: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=8.579e-04, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=1.815e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=1.168e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=3.962e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=3.028e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 19 iterations, alpha=2.677e-04, previous alpha=2.378e-04, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      " 94%|████████████████████████████████████████████████████████████████████████████████████████▍     | 285/303 [02:12<00:08,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|████████████████████████████████████████████████████████████████████████████████████████▋     | 286/303 [02:13<00:07,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=6.505e-06, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 95%|█████████████████████████████████████████████████████████████████████████████████████████     | 287/303 [02:13<00:07,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=2.172e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.086e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=2.753e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 15 iterations, alpha=3.031e-03, previous alpha=1.620e-03, with an active set of 10 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=2.691e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.345e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=6.873e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=6.722e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=3.290e-03, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=2.297e-03, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=1.115e-03, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.292e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=7.687e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=5.975e-04, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=2.411e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=2.003e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.134e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=4.584e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=2.755e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.378e-02, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 12 iterations, alpha=1.032e-02, previous alpha=1.032e-02, with an active set of 9 regressors.\n",
      "  warnings.warn(\n",
      " 95%|█████████████████████████████████████████████████████████████████████████████████████████▎    | 288/303 [02:14<00:06,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 815us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████████████████████████████████████████████████████████████████████████████████████▋    | 289/303 [02:14<00:06,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████████████████████████████████████████████████████████████████████████████████████▉    | 290/303 [02:15<00:06,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/shap/explainers/_kernel.py:707: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=9.995e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=8.272e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=1.917e-03, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=2.759e-04, with an active set of 16 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/shap/explainers/_kernel.py:707: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=8.138e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=4.006e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=2.066e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.101e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/shap/explainers/_kernel.py:707: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      " 96%|██████████████████████████████████████████████████████████████████████████████████████████▎   | 291/303 [02:15<00:06,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|██████████████████████████████████████████████████████████████████████████████████████████▌   | 292/303 [02:16<00:05,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=2.973e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.684e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=5.020e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=3.282e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 15 iterations, alpha=5.020e-05, previous alpha=1.122e-05, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=9.511e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=2.748e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 16 iterations, alpha=2.550e-03, previous alpha=2.299e-03, with an active set of 11 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=5.851e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=1.235e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=4.297e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=1.382e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=9.814e-06, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=4.343e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=4.043e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=4.018e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 20 iterations, alpha=3.049e-05, previous alpha=2.780e-05, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      " 97%|██████████████████████████████████████████████████████████████████████████████████████████▉   | 293/303 [02:16<00:05,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=4.255e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=2.071e-02, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 16 iterations, alpha=6.547e-03, previous alpha=5.599e-03, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=1.567e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=5.788e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 97%|███████████████████████████████████████████████████████████████████████████████████████████▏  | 294/303 [02:17<00:04,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.590e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=2.268e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=1.379e-03, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 24 iterations, alpha=1.348e-03, previous alpha=7.039e-04, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=2.228e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=1.845e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 19 iterations, alpha=1.701e-04, previous alpha=1.327e-04, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=2.400e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=3.645e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=2.636e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 97%|███████████████████████████████████████████████████████████████████████████████████████████▌  | 295/303 [02:17<00:03,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|███████████████████████████████████████████████████████████████████████████████████████████▊  | 296/303 [02:18<00:03,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=3.761e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.343e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.330e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=3.916e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 17 iterations, alpha=1.620e-04, previous alpha=2.589e-05, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      " 98%|████████████████████████████████████████████████████████████████████████████████████████████▏ | 297/303 [02:18<00:02,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|████████████████████████████████████████████████████████████████████████████████████████████▍ | 298/303 [02:19<00:02,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.158e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=5.777e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=1.059e-03, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=8.719e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 23 iterations, alpha=6.506e-04, previous alpha=4.334e-04, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=7.107e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=2.986e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 25 iterations, alpha=6.109e-04, previous alpha=4.694e-04, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=1.872e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=1.867e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 99%|████████████████████████████████████████████████████████████████████████████████████████████▊ | 299/303 [02:19<00:01,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.822e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=5.894e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.601e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 13 iterations, alpha=2.219e-03, previous alpha=1.292e-03, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=7.257e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 21 iterations, alpha=1.027e-02, previous alpha=9.422e-03, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      " 99%|█████████████████████████████████████████████████████████████████████████████████████████████ | 300/303 [02:20<00:01,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=7.864e-07, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 19 iterations, alpha=7.864e-07, previous alpha=7.830e-07, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=3.884e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=2.029e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.139e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.082e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=3.866e-04, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 16 iterations, alpha=4.489e-04, previous alpha=1.475e-04, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=2.645e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=3.298e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 99%|█████████████████████████████████████████████████████████████████████████████████████████████▍| 301/303 [02:20<00:00,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.714e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=8.569e-04, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=7.319e-04, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=6.511e-04, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=2.204e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=2.080e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.071e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=4.639e-05, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=4.011e-05, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=8.368e-06, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.926e-06, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=5.814e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=2.907e-02, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.413e-02, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 14 iterations, alpha=6.915e-03, previous alpha=6.307e-03, with an active set of 11 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=2.693e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.347e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.233e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=7.392e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=5.388e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=4.970e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=2.119e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 12 iterations, alpha=4.324e-03, previous alpha=1.979e-03, with an active set of 11 regressors.\n",
      "  warnings.warn(\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████▋| 302/303 [02:20<00:00,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████| 303/303 [02:21<00:00,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAP values calcolati.\n",
      "SHAP values per classe 0: [[-0.14073796  0.14184601  0.          0.        ]\n",
      " [-0.01695277  0.01295775  0.          0.        ]\n",
      " [-0.05862586  0.11556503 -0.07248438  0.        ]\n",
      " [ 0.          0.29998397 -0.21191421 -0.0461809 ]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 1: [[-0.08962471  0.03267856  0.          0.04684827]\n",
      " [ 0.          0.          0.          0.01979314]\n",
      " [-0.01986257  0.          0.          0.01276034]\n",
      " [ 0.         -0.06565083  0.          0.05294637]\n",
      " [ 0.         -0.030665    0.          0.03915612]]\n",
      "SHAP values per classe 2: [[-0.07912267  0.          0.          0.05597414]\n",
      " [-0.0061264   0.          0.          0.00764504]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.00622298 -0.04330766  0.          0.0286063 ]\n",
      " [ 0.         -0.01514996  0.          0.        ]]\n",
      "SHAP values per classe 3: [[-0.00142911  0.          0.          0.        ]\n",
      " [ 0.         -0.01531261  0.          0.022191  ]\n",
      " [-0.03827351  0.          0.          0.05469642]\n",
      " [ 0.         -0.01169143  0.          0.        ]\n",
      " [-0.05366987 -0.01475903  0.13089892  0.        ]]\n",
      "SHAP values per classe 4: [[-0.1376577   0.          0.          0.        ]\n",
      " [-0.02558683  0.          0.02750747  0.        ]\n",
      " [-0.02000599 -0.04598048  0.00777898  0.        ]\n",
      " [-0.01805195  0.07734881 -0.056105    0.        ]\n",
      " [-0.01649784  0.          0.0696113   0.04900502]]\n",
      "SHAP values per classe 5: [[-0.14045232  0.07144474  0.05086922  0.01405272]\n",
      " [-0.0157307   0.01961535  0.          0.        ]\n",
      " [-0.02018107  0.          0.          0.        ]\n",
      " [-0.03204374  0.40221782 -0.24052112 -0.15061568]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 6: [[-0.09896592  0.          0.          0.06634142]\n",
      " [-0.00997503  0.          0.          0.        ]\n",
      " [-0.00570439  0.          0.          0.        ]\n",
      " [-0.0062702  -0.05036196  0.          0.        ]\n",
      " [ 0.         -0.0332533   0.02713537  0.        ]]\n",
      "SHAP values per classe 7: [[-0.10167451  0.          0.          0.04103684]\n",
      " [-0.0064399   0.          0.02057005  0.00680797]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.0755492  -0.14040229 -0.35364126  0.63546715]\n",
      " [-0.00459116 -0.04356774  0.          0.        ]]\n",
      "SHAP values per classe 8: [[-0.00694102  0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.05516622  0.00820888  0.        ]\n",
      " [ 0.         -0.02544666  0.          0.        ]]\n",
      "SHAP values per classe 9: [[-0.06575454  0.          0.02789447  0.        ]\n",
      " [-0.0104673   0.          0.          0.0311939 ]\n",
      " [-0.00690487  0.          0.          0.01664429]\n",
      " [ 0.          0.05514494 -0.04359748  0.        ]\n",
      " [-0.01739079  0.03273344  0.          0.        ]]\n",
      "SHAP values per classe 10: [[-0.10363813  0.02163046  0.04812222  0.04045181]\n",
      " [ 0.          0.          0.          0.01954919]\n",
      " [-0.01386821  0.          0.          0.        ]\n",
      " [-0.01579829 -0.0420997   0.          0.02244811]\n",
      " [-0.0112809  -0.02262909  0.          0.00727771]]\n",
      "SHAP values per classe 11: [[-0.14935106 -0.09038881  0.23208472  0.        ]\n",
      " [-0.01435101 -0.00716532  0.01097416  0.        ]\n",
      " [-0.00654829  0.05853926 -0.01186001  0.        ]\n",
      " [ 0.         -0.07847777  0.07497294  0.        ]\n",
      " [ 0.         -0.03205167  0.05092131  0.        ]]\n",
      "SHAP values per classe 12: [[-0.13239629  0.06022626  0.          0.        ]\n",
      " [-0.00584937  0.14845195 -0.06551304  0.00713127]\n",
      " [-0.00446458  0.00636936  0.          0.        ]\n",
      " [-0.02793774  0.05162336 -0.00715884 -0.02127445]\n",
      " [-0.05084574  0.33042311 -0.08738826 -0.16744189]]\n",
      "SHAP values per classe 13: [[-0.10264547  0.          0.09694654  0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.01836176 -0.01927179]\n",
      " [ 0.         -0.04766564  0.05814989  0.        ]\n",
      " [-0.00835351  0.          0.          0.        ]]\n",
      "SHAP values per classe 14: [[-0.07038012  0.03067949  0.         -0.02310582]\n",
      " [ 0.          0.04526086  0.          0.        ]\n",
      " [-0.00732119  0.          0.          0.        ]\n",
      " [-0.11125708  0.59651158 -0.33753583 -0.14197649]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 15: [[-0.07771537  0.          0.0061273   0.02069851]\n",
      " [-0.02326645  0.          0.01275749  0.02244976]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.00115931 -0.07653398  0.0226476   0.03321206]\n",
      " [-0.00223595 -0.03348978  0.          0.01560167]]\n",
      "SHAP values per classe 16: [[ 0.43881852 -0.25736219 -0.11244146 -0.03423733]\n",
      " [ 0.          0.         -0.11489307  0.        ]\n",
      " [-0.019317    0.          0.          0.        ]\n",
      " [ 0.06999526 -0.08805184  0.00274336 -0.02580687]\n",
      " [ 0.0487139   0.          0.01819171 -0.00919843]]\n",
      "SHAP values per classe 17: [[ 0.51480728 -0.13773077 -0.31030909 -0.06475474]\n",
      " [ 0.02496754  0.02679464  0.00742659 -0.05353107]\n",
      " [ 0.0157426  -0.03813136  0.          0.        ]\n",
      " [ 0.06104732 -0.12370459  0.03924361  0.01598435]\n",
      " [ 0.04219787 -0.02302549  0.          0.        ]]\n",
      "SHAP values per classe 18: [[-0.09991908  0.03586742  0.08039573  0.        ]\n",
      " [ 0.         -0.00755122  0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.03968994  0.          0.        ]\n",
      " [ 0.         -0.02870422  0.02496925  0.        ]]\n",
      "SHAP values per classe 19: [[-0.00100567  0.          0.          0.        ]\n",
      " [ 0.          0.         -0.01561226  0.01422172]\n",
      " [ 0.          0.         -0.02670107  0.02272214]\n",
      " [ 0.         -0.04803286  0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 20: [[-0.12383382  0.01535545  0.0824084   0.00883626]\n",
      " [-0.00875348  0.          0.24744447 -0.25109479]\n",
      " [-0.02763495  0.02869214  0.06017418  0.        ]\n",
      " [ 0.         -0.11642083  0.05820065  0.04624245]\n",
      " [ 0.         -0.06252086  0.11470218  0.        ]]\n",
      "SHAP values per classe 21: [[-0.08649848  0.          0.03303836  0.02850719]\n",
      " [ 0.          0.          0.11043935 -0.1066961 ]\n",
      " [-0.00993053  0.          0.          0.        ]\n",
      " [ 0.         -0.08616524  0.09936772  0.        ]\n",
      " [ 0.         -0.031428    0.          0.        ]]\n",
      "SHAP values per classe 22: [[ 0.          0.         -0.00269168  0.        ]\n",
      " [ 0.          0.          0.         -0.07178233]\n",
      " [ 0.          0.01087547  0.          0.        ]\n",
      " [-0.38314442  0.56338352 -0.02762915 -0.08022512]\n",
      " [ 0.          0.         -0.01243944  0.        ]]\n",
      "SHAP values per classe 23: [[-0.06049187  0.04385091  0.          0.        ]\n",
      " [ 0.34758122 -0.1437377  -0.05640643 -0.17857338]\n",
      " [ 0.          0.00349404  0.          0.        ]\n",
      " [ 0.          0.          0.         -0.01399393]\n",
      " [ 0.02567023 -0.08172411  0.          0.        ]]\n",
      "SHAP values per classe 24: [[-0.15039473  0.11473638  0.02711827  0.        ]\n",
      " [-0.01905852  0.          0.          0.        ]\n",
      " [-0.03395311  0.          0.03280666  0.        ]\n",
      " [-0.00117046 -0.18567928  0.          0.02435693]\n",
      " [-0.0182923   0.45906711 -0.37131453  0.        ]]\n",
      "SHAP values per classe 25: [[-0.07254972  0.05179184  0.          0.06593693]\n",
      " [ 0.          0.         -0.02125903  0.02747201]\n",
      " [ 0.          0.         -0.04111728  0.0440659 ]\n",
      " [ 0.         -0.06641509  0.03040358  0.00493202]\n",
      " [-0.00298199  0.          0.00922449  0.0095467 ]]\n",
      "SHAP values per classe 26: [[-0.12291528  0.07447773  0.03992691  0.        ]\n",
      " [-0.01476727  0.01057424  0.          0.        ]\n",
      " [-0.03325841  0.          0.          0.        ]\n",
      " [ 0.         -0.04811514  0.03796045  0.        ]\n",
      " [-0.06043149  0.57828298 -0.40004179 -0.10600292]]\n",
      "SHAP values per classe 27: [[-0.11558142 -0.00236845  0.15361297  0.        ]\n",
      " [-0.00744128  0.          0.06242193 -0.07950756]\n",
      " [ 0.06482028 -0.00432231 -0.06969384  0.        ]\n",
      " [ 0.00262046 -0.05606656  0.05035689  0.        ]\n",
      " [ 0.         -0.03704169  0.          0.        ]]\n",
      "SHAP values per classe 28: [[ 0.36120866 -0.12060823 -0.13613943 -0.1032181 ]\n",
      " [ 0.          0.01639648  0.          0.        ]\n",
      " [ 0.05707244 -0.03188348 -0.01658339  0.        ]\n",
      " [ 0.01821891 -0.06200699  0.04083945  0.        ]\n",
      " [ 0.01289696 -0.01938981  0.          0.        ]]\n",
      "SHAP values per classe 29: [[ 0.2800931  -0.0798924  -0.15647868 -0.01188696]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.09059601 -0.14422454  0.03954802  0.        ]\n",
      " [ 0.04686285 -0.0717358   0.01781645  0.        ]]\n",
      "SHAP values per classe 30: [[ 0.52475612 -0.26635049 -0.19033564 -0.06354769]\n",
      " [ 0.02123856  0.07033263 -0.03652159  0.        ]\n",
      " [-0.00762163  0.          0.          0.        ]\n",
      " [ 0.05834197 -0.09418195  0.03549413  0.        ]\n",
      " [ 0.         -0.03166246  0.          0.        ]]\n",
      "SHAP values per classe 31: [[-0.04395207  0.          0.02214475  0.        ]\n",
      " [ 0.          0.          0.04263044 -0.02918232]\n",
      " [-0.06388554  0.          0.07036027  0.        ]\n",
      " [ 0.02613718 -0.02442614  0.00236853  0.        ]\n",
      " [ 0.          0.          0.0199777   0.03715616]]\n",
      "SHAP values per classe 32: [[-0.08029401  0.02320864  0.          0.        ]\n",
      " [ 0.         -0.01190165 -0.08189118  0.        ]\n",
      " [-0.01515488 -0.04309521  0.25082429 -0.00751271]\n",
      " [ 0.         -0.12555286  0.          0.        ]\n",
      " [ 0.         -0.03410828  0.03508322  0.        ]]\n",
      "SHAP values per classe 33: [[-0.14439732  0.04046365  0.          0.05352699]\n",
      " [-0.01279953 -0.02164104  0.          0.        ]\n",
      " [ 0.          0.          0.04391471  0.        ]\n",
      " [ 0.         -0.03923551  0.          0.        ]\n",
      " [ 0.         -0.01294113  0.05681094  0.        ]]\n",
      "SHAP values per classe 34: [[ 0.53748378 -0.09959017 -0.29464807 -0.12392446]\n",
      " [ 0.          0.          0.          0.0019975 ]\n",
      " [ 0.          0.         -0.01071486  0.03381176]\n",
      " [ 0.03390845 -0.07618134  0.04315891  0.        ]\n",
      " [ 0.0807511  -0.05177783  0.1423985  -0.16888819]]\n",
      "SHAP values per classe 35: [[-0.16191264  0.03322947  0.02927722  0.03347875]\n",
      " [-0.04499789 -0.06343079  0.          0.28650843]\n",
      " [ 0.          0.          0.04671843  0.        ]\n",
      " [-0.00344847 -0.10001689  0.          0.        ]\n",
      " [ 0.         -0.07000748  0.03255775  0.04356177]]\n",
      "SHAP values per classe 36: [[-0.05788833  0.          0.          0.01814134]\n",
      " [ 0.          0.          0.          0.11393766]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.04130731  0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 37: [[-0.17169254  0.07368513  0.09349962  0.01942454]\n",
      " [ 0.          0.01283158  0.          0.01053253]\n",
      " [-0.02680256  0.09908811  0.         -0.02710844]\n",
      " [ 0.          0.14178221 -0.14238538  0.        ]\n",
      " [ 0.          0.          0.00167591  0.        ]]\n",
      "SHAP values per classe 38: [[-0.12009215  0.01994124  0.          0.        ]\n",
      " [ 0.          0.01801473  0.         -0.01149904]\n",
      " [-0.01307582  0.01846018 -0.01449816  0.        ]\n",
      " [-0.06096767  0.29693404 -0.13962109 -0.07544251]\n",
      " [-0.02900067  0.32406697 -0.13526634 -0.0685449 ]]\n",
      "SHAP values per classe 39: [[-0.10750231  0.          0.0570273   0.0378383 ]\n",
      " [-0.01124146  0.          0.          0.01726648]\n",
      " [-0.0185642   0.          0.          0.        ]\n",
      " [ 0.         -0.04962886  0.03106354  0.02029697]\n",
      " [ 0.         -0.05037423  0.03660547  0.01478063]]\n",
      "SHAP values per classe 40: [[ 0.66039748 -0.10965395 -0.33362588 -0.15141024]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.01577775 -0.08978608  0.          0.        ]\n",
      " [ 0.01353598 -0.04937997  0.          0.        ]]\n",
      "SHAP values per classe 41: [[ 0.4774265  -0.18440448 -0.15557604 -0.13133987]\n",
      " [ 0.         -0.01787927  0.          0.        ]\n",
      " [ 0.          0.10788086  0.          0.        ]\n",
      " [ 0.04078191 -0.08660265  0.          0.        ]\n",
      " [ 0.05272703 -0.06762942  0.02220117  0.        ]]\n",
      "SHAP values per classe 42: [[-0.15384215  0.04665945  0.06221871  0.03905507]\n",
      " [-0.01642774  0.00125958  0.          0.03458586]\n",
      " [-0.00579164  0.00150034  0.          0.        ]\n",
      " [ 0.         -0.07643029  0.          0.02401712]\n",
      " [ 0.         -0.02687226  0.01223969  0.        ]]\n",
      "SHAP values per classe 43: [[-0.00509895 -0.06790457  0.08179437  0.        ]\n",
      " [-0.01004343  0.          0.03618938  0.        ]\n",
      " [-0.02498277  0.          0.          0.        ]\n",
      " [ 0.         -0.03560391  0.          0.        ]\n",
      " [ 0.         -0.01469861  0.          0.        ]]\n",
      "SHAP values per classe 44: [[ 0.31398004 -0.08178292 -0.08648318 -0.10423116]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.11046841 -0.05991233 -0.02194783  0.        ]\n",
      " [ 0.         -0.06406722  0.040522    0.        ]\n",
      " [ 0.         -0.0254504   0.03195002  0.        ]]\n",
      "SHAP values per classe 45: [[-0.16401569 -0.06936858  0.08437272  0.1003604 ]\n",
      " [-0.0137533   0.00139038  0.          0.01685953]\n",
      " [-0.00204401  0.          0.          0.        ]\n",
      " [ 0.         -0.07875105  0.03212178  0.03869004]\n",
      " [ 0.         -0.0340524   0.03015795  0.0160101 ]]\n",
      "SHAP values per classe 46: [[ 0.1527334  -0.07769008 -0.04325722  0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.         -0.01379832]\n",
      " [ 0.13565664  0.12640527 -0.204908   -0.03719112]\n",
      " [ 0.          0.         -0.01905874  0.        ]]\n",
      "SHAP values per classe 47: [[-0.10228288  0.32758168 -0.17258894 -0.01166557]\n",
      " [-0.01320757  0.05181162  0.09780636 -0.1415805 ]\n",
      " [-0.00756214  0.          0.          0.        ]\n",
      " [-0.01970247  0.04139746 -0.0127821  -0.0089129 ]\n",
      " [-0.03403971  0.14207823 -0.07878096 -0.01537624]]\n",
      "SHAP values per classe 48: [[ 0.          0.          0.          0.        ]\n",
      " [-0.11800934  0.11313594  0.         -0.02645425]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.01231921 -0.01895199  0.0007319   0.01537263]\n",
      " [ 0.16840633 -0.19770163  0.06144356 -0.00904641]]\n",
      "SHAP values per classe 49: [[-0.04856425 -0.02019045  0.09813264 -0.0197399 ]\n",
      " [-0.01936044  0.          0.11259804 -0.09290354]\n",
      " [-0.03310057  0.          0.03456632  0.        ]\n",
      " [ 0.         -0.05427184  0.05443193  0.        ]\n",
      " [ 0.         -0.09091522  0.08177198  0.        ]]\n",
      "SHAP values per classe 50: [[-0.16207946  0.03222526  0.0343967   0.06320032]\n",
      " [-0.01727921  0.0021247   0.          0.03026808]\n",
      " [-0.02304363  0.0068477   0.         -0.01027903]\n",
      " [ 0.00509911 -0.11566401  0.          0.04461228]\n",
      " [ 0.00596445 -0.05806036  0.05196555  0.07294202]]\n",
      "SHAP values per classe 51: [[-0.14698372  0.          0.0399506   0.09565052]\n",
      " [ 0.         -0.02172643  0.03623737  0.        ]\n",
      " [-0.05284382  0.04649844  0.          0.        ]\n",
      " [ 0.         -0.06833867  0.05664774  0.        ]\n",
      " [ 0.         -0.07251285  0.06489842  0.00667742]]\n",
      "SHAP values per classe 52: [[-0.16339652  0.02712009  0.09430688  0.03039587]\n",
      " [-0.01572206  0.          0.08421142  0.        ]\n",
      " [-0.02979347  0.          0.          0.04354977]\n",
      " [-0.0013876  -0.12651795  0.05437549  0.04301059]\n",
      " [ 0.         -0.07503164  0.06146945  0.01296256]]\n",
      "SHAP values per classe 53: [[-0.09394831  0.02442665  0.          0.        ]\n",
      " [-0.00594512 -0.02895237  0.          0.05135542]\n",
      " [ 0.          0.0089497  -0.05298126  0.        ]\n",
      " [-0.00035138 -0.11152429  0.          0.01743481]\n",
      " [ 0.         -0.03943987  0.          0.        ]]\n",
      "SHAP values per classe 54: [[-0.04202976  0.          0.          0.02595153]\n",
      " [ 0.          0.         -0.01546973  0.02821641]\n",
      " [-0.0227649   0.          0.06272837  0.        ]\n",
      " [ 0.         -0.03330797  0.          0.        ]\n",
      " [ 0.         -0.03836317  0.          0.        ]]\n",
      "SHAP values per classe 55: [[-0.15464948  0.08789554  0.04724121  0.        ]\n",
      " [-0.02922266  0.          0.18336865  0.        ]\n",
      " [-0.01810618  0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.01743755  0.36432475 -0.37731284  0.        ]]\n",
      "SHAP values per classe 56: [[ 0.20018143 -0.07194739 -0.02491464 -0.05383265]\n",
      " [ 0.          0.          0.          0.03419106]\n",
      " [-0.02315362  0.00278046  0.          0.        ]\n",
      " [-0.09069312  0.25451543 -0.04945924 -0.04475008]\n",
      " [ 0.          0.          0.0417167   0.        ]]\n",
      "SHAP values per classe 57: [[ 0.36932614 -0.06480908 -0.10225028 -0.14441751]\n",
      " [ 0.07116887  0.          0.          0.        ]\n",
      " [ 0.05772459 -0.0287352   0.01156821 -0.03905258]\n",
      " [ 0.         -0.09549216  0.          0.0245332 ]\n",
      " [-0.02580244 -0.0420414   0.04756123  0.        ]]\n",
      "SHAP values per classe 58: [[-0.11752769  0.01839567  0.12035138 -0.00358522]\n",
      " [-0.02243637  0.          0.          0.00024848]\n",
      " [-0.03301976  0.00960791  0.          0.        ]\n",
      " [ 0.         -0.08937526  0.06837469  0.        ]\n",
      " [ 0.         -0.10621279  0.09882458  0.        ]]\n",
      "SHAP values per classe 59: [[-0.12093377  0.          0.07622018  0.        ]\n",
      " [-0.02439772 -0.01628727  0.          0.06108329]\n",
      " [-0.01316014  0.          0.0204702   0.        ]\n",
      " [ 0.         -0.07452258  0.03681252  0.0214331 ]\n",
      " [ 0.          0.          0.          0.02111343]]\n",
      "SHAP values per classe 60: [[-0.06992732  0.          0.          0.        ]\n",
      " [-0.005915    0.         -0.03756233  0.01908795]\n",
      " [-0.00439566 -0.0008315   0.          0.        ]\n",
      " [ 0.         -0.0311447   0.          0.        ]\n",
      " [ 0.         -0.02638645  0.          0.00938003]]\n",
      "SHAP values per classe 61: [[-0.15404372  0.02369582  0.06737276  0.06297513]\n",
      " [-0.02275799  0.          0.03826473  0.        ]\n",
      " [ 0.         -0.01471199  0.         -0.01619219]\n",
      " [-0.0265264  -0.1375019   0.03821903  0.08634327]\n",
      " [-0.01110585 -0.05684699  0.04170119  0.03846849]]\n",
      "SHAP values per classe 62: [[ 0.58393976 -0.17624884 -0.26880043 -0.13127985]\n",
      " [ 0.          0.0191158  -0.01828163  0.        ]\n",
      " [ 0.00537108  0.          0.          0.        ]\n",
      " [ 0.02343362 -0.08888028  0.01693388  0.        ]\n",
      " [ 0.         -0.05387883  0.          0.03272139]]\n",
      "SHAP values per classe 63: [[ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.06213307 -0.10750385]\n",
      " [ 0.         -0.04308901  0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.00924287 -0.01349012  0.00888203  0.        ]]\n",
      "SHAP values per classe 64: [[-0.09210833  0.03459811  0.046506    0.        ]\n",
      " [ 0.          0.          0.          0.00660001]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.0796165   0.54911218 -0.2859538  -0.18215035]\n",
      " [ 0.          0.          0.         -0.00328345]]\n",
      "SHAP values per classe 65: [[ 0.          0.          0.          0.        ]\n",
      " [-0.0075048   0.          0.          0.        ]\n",
      " [ 0.08138287 -0.01132121  0.          0.        ]\n",
      " [-0.09111682 -0.10175551  0.2923     -0.20667996]\n",
      " [-0.00354828  0.          0.          0.02803885]]\n",
      "SHAP values per classe 66: [[-0.1633803   0.          0.04650658  0.02249905]\n",
      " [-0.01143177 -0.00104242  0.          0.05557082]\n",
      " [ 0.          0.          0.          0.02014069]\n",
      " [-0.03288837 -0.1550171   0.          0.26862829]\n",
      " [ 0.         -0.04149573  0.          0.        ]]\n",
      "SHAP values per classe 67: [[-0.1602224   0.          0.11306238  0.05225036]\n",
      " [-0.01767077  0.          0.          0.01212452]\n",
      " [-0.03750698  0.          0.03669746  0.00784641]\n",
      " [ 0.         -0.0870973   0.10187449  0.        ]\n",
      " [ 0.          0.          0.035135    0.        ]]\n",
      "SHAP values per classe 68: [[-0.07196852  0.02882873  0.00673294  0.        ]\n",
      " [-0.01325877  0.          0.          0.02788408]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.02304659  0.02524595  0.        ]\n",
      " [-0.00159927  0.          0.          0.        ]]\n",
      "SHAP values per classe 69: [[-0.07254651  0.01901086  0.08282962 -0.03066381]\n",
      " [ 0.         -0.02043156  0.11827652 -0.0940098 ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.00702795 -0.0629027   0.06268768  0.        ]\n",
      " [ 0.         -0.03042264  0.03291562 -0.00760658]]\n",
      "SHAP values per classe 70: [[-0.10224961  0.          0.          0.07832246]\n",
      " [-0.00843118  0.          0.          0.05447021]\n",
      " [-0.01288536  0.          0.          0.        ]\n",
      " [ 0.         -0.0648372   0.          0.0652413 ]\n",
      " [ 0.         -0.02485291  0.          0.        ]]\n",
      "SHAP values per classe 71: [[ 0.13461674 -0.01828617  0.          0.        ]\n",
      " [ 0.         -0.00853956  0.          0.        ]\n",
      " [ 0.          0.          0.0216941   0.        ]\n",
      " [ 0.         -0.05639811  0.01824586  0.01475749]\n",
      " [ 0.         -0.01822702  0.          0.        ]]\n",
      "SHAP values per classe 72: [[ 0.43193583 -0.03414265 -0.18566915  0.        ]\n",
      " [-0.02753369  0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.05840238 -0.13097114  0.03109215  0.02577345]\n",
      " [ 0.         -0.06723613  0.          0.        ]]\n",
      "SHAP values per classe 73: [[-0.00321551  0.          0.          0.        ]\n",
      " [-0.00925899 -0.00404042  0.24939657 -0.23474133]\n",
      " [-0.01061464 -0.0053563   0.          0.        ]\n",
      " [-0.03970924 -0.07743172  0.17522064 -0.09882033]\n",
      " [-0.03118236 -0.02736003  0.0758527   0.        ]]\n",
      "SHAP values per classe 74: [[-0.12208241  0.01907421  0.07520159  0.0240891 ]\n",
      " [-0.01187467  0.00922807  0.0061921   0.        ]\n",
      " [-0.00928661  0.          0.04524044  0.01040774]\n",
      " [ 0.         -0.09718641  0.          0.02471434]\n",
      " [ 0.         -0.0419496   0.02892489  0.01506334]]\n",
      "SHAP values per classe 75: [[-0.086656    0.          0.05306685  0.        ]\n",
      " [ 0.         -0.04812088  0.07005613 -0.00665095]\n",
      " [ 0.          0.06305552 -0.02684539  0.        ]\n",
      " [-0.06463406  0.27518133 -0.0312372  -0.17698084]\n",
      " [ 0.          0.05431243 -0.03512658  0.        ]]\n",
      "SHAP values per classe 76: [[-6.23807247e-02 -1.85701733e-02  5.60909679e-02 -4.29682430e-02]\n",
      " [ 0.00000000e+00 -7.91266308e-02  1.15261343e-02  0.00000000e+00]\n",
      " [ 0.00000000e+00  1.30583883e-05  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00 -6.71870513e-02  5.73232672e-02  9.87420401e-03]\n",
      " [ 0.00000000e+00 -3.21358766e-02  0.00000000e+00  2.27209486e-02]]\n",
      "SHAP values per classe 77: [[-0.11647574 -0.01735844  0.          0.14009427]\n",
      " [ 0.          0.          0.01186934 -0.00532577]\n",
      " [ 0.          0.         -0.00267855  0.00243563]\n",
      " [ 0.         -0.06508465  0.03803731  0.01836165]\n",
      " [ 0.         -0.03394483  0.          0.00871397]]\n",
      "SHAP values per classe 78: [[-0.07939049  0.          0.02904989  0.02779235]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.01889282  0.          0.          0.        ]\n",
      " [ 0.         -0.04099833  0.          0.        ]\n",
      " [ 0.         -0.01087592  0.02201899  0.        ]]\n",
      "SHAP values per classe 79: [[-0.12708383  0.02312643  0.          0.        ]\n",
      " [-0.01546265  0.          0.          0.        ]\n",
      " [ 0.          0.         -0.02901562  0.        ]\n",
      " [ 0.         -0.11576657  0.10243802  0.        ]\n",
      " [ 0.00219991 -0.06679374  0.06251615  0.        ]]\n",
      "SHAP values per classe 80: [[ 0.04188093  0.         -0.00885899  0.        ]\n",
      " [-0.00558352  0.         -0.03109387  0.03177374]\n",
      " [ 0.          0.          0.01199989  0.        ]\n",
      " [ 0.         -0.07040467  0.10942072  0.        ]\n",
      " [ 0.         -0.03800763  0.          0.05632889]]\n",
      "SHAP values per classe 81: [[-0.09023099 -0.00662363  0.          0.03732997]\n",
      " [-0.00533298  0.          0.          0.012624  ]\n",
      " [-0.00521555  0.          0.          0.        ]\n",
      " [ 0.         -0.06609471  0.          0.        ]\n",
      " [-0.01495938 -0.04480315  0.04579009  0.        ]]\n",
      "SHAP values per classe 82: [[-0.18305995  0.02415191  0.15538291  0.02308245]\n",
      " [-0.02181905  0.          0.05168246 -0.0055342 ]\n",
      " [-0.01763127 -0.00646439  0.03118255  0.        ]\n",
      " [ 0.         -0.14313115  0.07958912  0.07654139]\n",
      " [ 0.         -0.06728819  0.          0.01982952]]\n",
      "SHAP values per classe 83: [[-0.08077948 -0.01481993  0.03638152  0.01015101]\n",
      " [ 0.          0.         -0.00134154  0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.05135287  0.03171252  0.        ]\n",
      " [ 0.         -0.01847666  0.00555435  0.        ]]\n",
      "SHAP values per classe 84: [[ 0.          0.          0.          0.01328295]\n",
      " [ 0.00973643  0.         -0.03284869  0.03467944]\n",
      " [ 0.16836997 -0.03538238 -0.138693    0.        ]\n",
      " [ 0.         -0.15014721  0.13357582  0.        ]\n",
      " [-0.00244052 -0.02849669  0.          0.        ]]\n",
      "SHAP values per classe 85: [[ 0.22515412  0.         -0.12073882 -0.03539102]\n",
      " [ 0.         -0.02354331  0.          0.        ]\n",
      " [ 0.1195225  -0.01763354 -0.03171297  0.        ]\n",
      " [ 0.         -0.01109379  0.09355469  0.        ]\n",
      " [ 0.06016408 -0.08902961  0.         -0.0528751 ]]\n",
      "SHAP values per classe 86: [[-0.1836907   0.06894964  0.06211237  0.        ]\n",
      " [-0.01017582  0.          0.          0.01044372]\n",
      " [-0.03599504  0.          0.0096707  -0.01535206]\n",
      " [ 0.          0.          0.07774823  0.        ]\n",
      " [ 0.         -0.07390762  0.04904264  0.0193043 ]]\n",
      "SHAP values per classe 87: [[ 0.51863866 -0.10351858 -0.26805887 -0.09129794]\n",
      " [ 0.          0.         -0.00075621  0.        ]\n",
      " [ 0.13681942 -0.08765972 -0.02067193 -0.03451061]\n",
      " [ 0.0195966  -0.05731412  0.03641339  0.        ]\n",
      " [ 0.04618656 -0.02933534 -0.00172315 -0.02245506]]\n",
      "SHAP values per classe 88: [[-0.08618845  0.02831273  0.02214918  0.        ]\n",
      " [ 0.          0.         -0.02460522  0.        ]\n",
      " [-0.01076343  0.          0.          0.        ]\n",
      " [ 0.         -0.06635482  0.          0.02880729]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 89: [[-0.10126901  0.10917526  0.0435702   0.        ]\n",
      " [-0.00559832  0.06351747  0.         -0.02675931]\n",
      " [ 0.          0.         -0.04870614  0.        ]\n",
      " [-0.1161797   0.44716397 -0.20491095 -0.08162649]\n",
      " [ 0.         -0.02920886  0.06930835  0.        ]]\n",
      "SHAP values per classe 90: [[-0.07354016  0.         -0.05514137  0.10500253]\n",
      " [ 0.          0.          0.06275553  0.01203978]\n",
      " [-0.00799234  0.          0.          0.06606501]\n",
      " [-0.00477136  0.          0.02903708  0.00615527]\n",
      " [ 0.          0.00220911 -0.08690002  0.18672881]]\n",
      "SHAP values per classe 91: [[-0.07609667  0.         -0.03346706  0.09004568]\n",
      " [-0.00817457  0.         -0.00024896  0.01567788]\n",
      " [ 0.         -0.11908802  0.19595304 -0.02475906]\n",
      " [-0.05122687  0.          0.          0.        ]\n",
      " [-0.0309757  -0.05914913  0.          0.        ]]\n",
      "SHAP values per classe 92: [[-0.1069397   0.          0.07019263  0.01518274]\n",
      " [-0.02920867 -0.00594104  0.          0.04614683]\n",
      " [ 0.00170942  0.          0.0166325   0.        ]\n",
      " [ 0.         -0.0899763   0.0435989   0.03413793]\n",
      " [ 0.         -0.00932603  0.          0.00818439]]\n",
      "SHAP values per classe 93: [[ 0.63146457 -0.32061757 -0.21642498 -0.11611501]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.01481516  0.          0.          0.        ]\n",
      " [ 0.03403181 -0.10569475  0.08563737  0.        ]\n",
      " [ 0.01888952  0.         -0.00890199  0.        ]]\n",
      "SHAP values per classe 94: [[-0.09036867  0.03266636  0.          0.        ]\n",
      " [-0.01217938  0.          0.          0.03113257]\n",
      " [-0.01764211  0.01747978  0.         -0.00281191]\n",
      " [-0.12279366  0.52104552 -0.25490254 -0.1061681 ]\n",
      " [ 0.01036708  0.          0.          0.        ]]\n",
      "SHAP values per classe 95: [[ 0.60054692 -0.14593093 -0.23653666 -0.17007968]\n",
      " [ 0.          0.          0.          0.00836177]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.04007333 -0.08324706  0.0322074   0.00607304]\n",
      " [ 0.01900955 -0.03166329  0.          0.        ]]\n",
      "SHAP values per classe 96: [[ 0.60405377 -0.13148052 -0.31144496 -0.14110369]\n",
      " [ 0.          0.          0.          0.0014747 ]\n",
      " [ 0.01139461  0.          0.          0.        ]\n",
      " [ 0.03089041 -0.0870477   0.07091896  0.        ]\n",
      " [ 0.01063393 -0.03954122  0.          0.        ]]\n",
      "SHAP values per classe 97: [[-0.17851742  0.07648837  0.10160749  0.        ]\n",
      " [-0.01639759  0.          0.          0.0141183 ]\n",
      " [-0.03021309  0.          0.01267935  0.        ]\n",
      " [ 0.         -0.10196655  0.08378947  0.        ]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 98: [[-0.08015697  0.          0.07758002  0.        ]\n",
      " [ 0.          0.01300278  0.          0.        ]\n",
      " [ 0.          0.          0.01239075  0.        ]\n",
      " [-0.10939363  0.71368707 -0.46393744 -0.14709749]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 99: [[-0.17450509  0.          0.132567    0.02771442]\n",
      " [-0.02370488 -0.00942258  0.03791392  0.        ]\n",
      " [-0.03067318  0.          0.0415849  -0.01281275]\n",
      " [ 0.         -0.09678491  0.0819989   0.        ]\n",
      " [-0.00155914  0.          0.0512659   0.        ]]\n",
      "SHAP values per classe 100: [[-0.13793967  0.          0.07713945  0.03496843]\n",
      " [-0.01245205  0.00247584  0.          0.03041925]\n",
      " [ 0.          0.07370932  0.          0.02662503]\n",
      " [-0.03106997 -0.19316832  0.08261873  0.06050095]\n",
      " [ 0.         -0.04160902  0.03868351  0.        ]]\n",
      "SHAP values per classe 101: [[-0.12948285  0.084153    0.03481838  0.        ]\n",
      " [-0.0138586   0.0086165   0.         -0.00762523]\n",
      " [-0.01683868  0.          0.          0.        ]\n",
      " [-0.03131762  0.31070833 -0.16857641 -0.07126909]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 102: [[ 0.14802961 -0.02268762 -0.0843768  -0.04096516]\n",
      " [ 0.          0.00439222  0.          0.        ]\n",
      " [ 0.09891582 -0.10015426  0.02750832 -0.00859362]\n",
      " [ 0.04990773  0.          0.          0.        ]\n",
      " [ 0.         -0.00860866  0.          0.        ]]\n",
      "SHAP values per classe 103: [[ 0.          0.          0.         -0.1535106 ]\n",
      " [ 0.14211186  0.          0.         -0.00474365]\n",
      " [ 0.          0.         -0.00606999  0.        ]\n",
      " [-0.30790117  0.52204054 -0.17539352 -0.0450253 ]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 104: [[-0.04726802  0.          0.          0.03085784]\n",
      " [-0.01063439  0.          0.          0.        ]\n",
      " [-0.02163989  0.          0.          0.        ]\n",
      " [-0.04224601  0.28949264 -0.10175259 -0.12852176]\n",
      " [ 0.          0.          0.01586514  0.03225734]]\n",
      "SHAP values per classe 105: [[-0.06650537  0.01883636  0.03205253  0.        ]\n",
      " [-0.00928728  0.          0.          0.        ]\n",
      " [-0.0085244   0.          0.          0.        ]\n",
      " [-0.12636272  0.69678984 -0.38486827 -0.18351778]\n",
      " [-0.00759545  0.          0.02044382  0.        ]]\n",
      "SHAP values per classe 106: [[-0.07904496  0.01562548  0.03487088  0.02233914]\n",
      " [-0.00932085  0.          0.          0.        ]\n",
      " [-0.03630183  0.02144582  0.          0.02250225]\n",
      " [-0.00884822 -0.09188701  0.02034904  0.08168733]\n",
      " [ 0.         -0.06039795  0.05169179  0.        ]]\n",
      "SHAP values per classe 107: [[-0.09165154  0.          0.          0.0419717 ]\n",
      " [-0.01077806  0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.04269908]\n",
      " [ 0.         -0.05885065  0.06284669  0.        ]\n",
      " [ 0.         -0.02568859  0.          0.00240116]]\n",
      "SHAP values per classe 108: [[-0.14093654  0.14700538  0.04506068  0.        ]\n",
      " [-0.00807005 -0.11526461 -0.01197466  0.        ]\n",
      " [-0.00903434  0.          0.          0.        ]\n",
      " [-0.03795895  0.39103675 -0.13283926 -0.0506065 ]\n",
      " [-0.02395278  0.16408533 -0.12836095  0.        ]]\n",
      "SHAP values per classe 109: [[ 0.52419051 -0.22794279 -0.19264819  0.        ]\n",
      " [ 0.0218021   0.          0.0020173   0.        ]\n",
      " [ 0.          0.          0.         -0.06710204]\n",
      " [ 0.06196354 -0.06023043  0.          0.        ]\n",
      " [ 0.03803766 -0.06848322  0.04222368  0.        ]]\n",
      "SHAP values per classe 110: [[-0.12296965  0.          0.07457623  0.04396052]\n",
      " [-0.02679221 -0.01384223  0.         -0.05175709]\n",
      " [ 0.          0.          0.04718278  0.        ]\n",
      " [-0.02022638  0.05548113 -0.101396    0.06033496]\n",
      " [ 0.         -0.11367036  0.          0.04452545]]\n",
      "SHAP values per classe 111: [[-0.04095407  0.          0.          0.        ]\n",
      " [ 0.          0.04186947  0.          0.        ]\n",
      " [ 0.          0.          0.          0.03599327]\n",
      " [-0.01913487  0.          0.          0.        ]\n",
      " [-0.00327663  0.          0.          0.        ]]\n",
      "SHAP values per classe 112: [[ 0.45057209 -0.03712689 -0.3388324  -0.04739569]\n",
      " [ 0.          0.          0.          0.16999202]\n",
      " [ 0.         -0.00709468  0.         -0.02830544]\n",
      " [ 0.04698725 -0.03405846  0.         -0.02125276]\n",
      " [ 0.02341671 -0.02130355  0.          0.        ]]\n",
      "SHAP values per classe 113: [[-0.12026919  0.02147763  0.0348768   0.0528158 ]\n",
      " [-0.0306407  -0.04427591  0.          0.0687322 ]\n",
      " [ 0.          0.         -0.03648733  0.02439349]\n",
      " [ 0.         -0.06798135  0.06431388  0.        ]\n",
      " [ 0.         -0.02605811  0.          0.        ]]\n",
      "SHAP values per classe 114: [[-0.11453331  0.          0.02564821  0.02877678]\n",
      " [-0.00785341  0.          0.          0.        ]\n",
      " [-0.02635365  0.05636493  0.02236588  0.        ]\n",
      " [ 0.         -0.02768881  0.          0.02109698]\n",
      " [ 0.          0.          0.03073832  0.        ]]\n",
      "SHAP values per classe 115: [[-0.16325284  0.          0.          0.        ]\n",
      " [-0.01528562  0.          0.          0.        ]\n",
      " [-0.00692614  0.          0.          0.        ]\n",
      " [ 0.         -0.06047451  0.06606208  0.        ]\n",
      " [ 0.          0.          0.03011657  0.        ]]\n",
      "SHAP values per classe 116: [[ 0.55835206 -0.10389165 -0.26333274 -0.1251842 ]\n",
      " [ 0.          0.          0.02027856  0.        ]\n",
      " [ 0.0259785  -0.01713678  0.         -0.01880066]\n",
      " [ 0.01333989 -0.05694722  0.          0.        ]\n",
      " [ 0.         -0.03477772  0.          0.        ]]\n",
      "SHAP values per classe 117: [[-0.01615818  0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.01329397 -0.10565548  0.0438335 ]\n",
      " [-0.00812568 -0.00616828  0.          0.06382271]]\n",
      "SHAP values per classe 118: [[-0.126629    0.          0.          0.03762183]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.05169464  0.03235274  0.        ]\n",
      " [-0.00128673 -0.04005795  0.          0.        ]]\n",
      "SHAP values per classe 119: [[-0.16393987  0.0211412   0.04373264  0.04731213]\n",
      " [ 0.          0.          0.02642391  0.00480481]\n",
      " [ 0.          0.          0.01377291  0.        ]\n",
      " [-0.01157889 -0.03601992  0.00308941  0.06651883]\n",
      " [ 0.         -0.07801668  0.10306946  0.072103  ]]\n",
      "SHAP values per classe 120: [[-0.1663716   0.          0.12626074  0.        ]\n",
      " [-0.01878243  0.          0.          0.        ]\n",
      " [-0.0089003   0.01954426  0.          0.        ]\n",
      " [ 0.         -0.07131675  0.03271809  0.03043362]\n",
      " [ 0.         -0.06095015  0.          0.        ]]\n",
      "SHAP values per classe 121: [[-0.1393996  -0.06132536 -0.10285498  0.23414035]\n",
      " [-0.01460905  0.          0.         -0.07620285]\n",
      " [-0.0048334   0.         -0.02529189  0.05702895]\n",
      " [ 0.         -0.06295499  0.02794152  0.04074988]\n",
      " [ 0.         -0.04154324  0.02954053  0.        ]]\n",
      "SHAP values per classe 122: [[ 0.34450497 -0.0913293  -0.17858068 -0.02688822]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.10838662 -0.15163376  0.03803471  0.        ]\n",
      " [ 0.         -0.06330729  0.03260635 -0.00873022]]\n",
      "SHAP values per classe 123: [[-0.07302371  0.          0.09072988  0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.01608523  0.          0.          0.        ]\n",
      " [ 0.         -0.0278589   0.03566041  0.        ]\n",
      " [ 0.         -0.02491321  0.          0.        ]]\n",
      "SHAP values per classe 124: [[ 0.21370593 -0.03271767 -0.11263511 -0.01519022]\n",
      " [ 0.01285145  0.          0.         -0.01022898]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.09862421 -0.15505651  0.04371666  0.02340598]\n",
      " [ 0.         -0.01857399  0.          0.        ]]\n",
      "SHAP values per classe 125: [[ 0.39458818 -0.07517155 -0.21840416 -0.11187516]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.04574482 -0.05354779  0.         -0.01238453]\n",
      " [ 0.01503196 -0.09278832  0.03568289  0.        ]\n",
      " [ 0.         -0.02530638  0.          0.        ]]\n",
      "SHAP values per classe 126: [[-0.13450316  0.10651229  0.          0.        ]\n",
      " [ 0.         -0.03636525  0.          0.        ]\n",
      " [-0.01041088  0.          0.0392168   0.02496031]\n",
      " [-0.03971942  0.2214513  -0.07017325 -0.06050613]\n",
      " [-0.00502709  0.16815412 -0.07379964 -0.02484093]]\n",
      "SHAP values per classe 127: [[-0.09716457 -0.02391957  0.10505015  0.        ]\n",
      " [-0.0211258   0.         -0.08002228  0.08866006]\n",
      " [ 0.         -0.00290313  0.          0.        ]\n",
      " [ 0.         -0.03613666  0.00588067  0.        ]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 128: [[ 0.35004713 -0.09272718 -0.13677733 -0.16909869]\n",
      " [-0.00558351  0.          0.          0.        ]\n",
      " [ 0.04078169 -0.03304252  0.          0.        ]\n",
      " [ 0.01857841 -0.06689056  0.          0.        ]\n",
      " [ 0.0747648  -0.02034652 -0.02593531  0.        ]]\n",
      "SHAP values per classe 129: [[ 0.66448666 -0.33292927 -0.19614405 -0.13693125]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.05524584 -0.01841017 -0.02781928]\n",
      " [ 0.01368298  0.          0.         -0.0091588 ]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 130: [[ 0.35356512 -0.07289227 -0.16294779 -0.0813152 ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.02966931 -0.01997056  0.         -0.00837725]\n",
      " [ 0.2527986  -0.18287171 -0.02007283  0.        ]\n",
      " [ 0.0105356   0.          0.03816115 -0.01889137]]\n",
      "SHAP values per classe 131: [[-0.12423285  0.11173187  0.         -0.01076887]\n",
      " [-0.01645969  0.01339128  0.         -0.00620582]\n",
      " [-0.00740338  0.          0.          0.        ]\n",
      " [-0.02384967  0.06868741 -0.01758153 -0.01833399]\n",
      " [-0.02386947  0.08705475 -0.05480602  0.        ]]\n",
      "SHAP values per classe 132: [[-0.04683404 -0.00833837  0.          0.        ]\n",
      " [-0.01272031  0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.00741429 -0.0284532   0.          0.        ]\n",
      " [ 0.         -0.02063517  0.03375972  0.        ]]\n",
      "SHAP values per classe 133: [[-0.15158237 -0.00239345  0.15489842  0.        ]\n",
      " [-0.01206836  0.          0.          0.04998112]\n",
      " [ 0.          0.          0.00538068  0.        ]\n",
      " [ 0.         -0.07199102  0.05717408  0.        ]\n",
      " [ 0.         -0.03790718  0.04009252  0.        ]]\n",
      "SHAP values per classe 134: [[-0.12451698  0.02465334  0.07126908  0.        ]\n",
      " [-0.07173205  0.          0.          0.05493512]\n",
      " [ 0.01099803  0.          0.          0.        ]\n",
      " [ 0.04159037 -0.04950303  0.          0.        ]\n",
      " [ 0.         -0.07777862  0.0434892   0.        ]]\n",
      "SHAP values per classe 135: [[-0.11422628  0.          0.03132525  0.        ]\n",
      " [ 0.          0.          0.03296032  0.        ]\n",
      " [-0.01870597  0.          0.         -0.01140241]\n",
      " [-0.0302092   0.09156998 -0.03594234 -0.02541842]\n",
      " [-0.02729022  0.21307293 -0.08314969 -0.03918915]]\n",
      "SHAP values per classe 136: [[-0.03302455  0.01572586 -0.02622569  0.        ]\n",
      " [-0.04946401  0.          0.          0.        ]\n",
      " [ 0.03553311  0.02724574  0.          0.        ]\n",
      " [-0.09545598  0.54003776 -0.21327623 -0.23769646]\n",
      " [ 0.04581384  0.          0.0203001   0.        ]]\n",
      "SHAP values per classe 137: [[ 0.32903373  0.         -0.08045871  0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.         -0.02089017]\n",
      " [-0.01198203 -0.14127801  0.          0.        ]\n",
      " [ 0.0786002   0.          0.          0.        ]]\n",
      "SHAP values per classe 138: [[-0.12746397  0.02096361  0.09899168  0.        ]\n",
      " [-0.02467531  0.05434335  0.          0.        ]\n",
      " [-0.01408374  0.01048888  0.01833465 -0.02013038]\n",
      " [ 0.         -0.07387626  0.04116334 -0.00094448]\n",
      " [ 0.02425684 -0.03622795  0.04505167 -0.01657428]]\n",
      "SHAP values per classe 139: [[ 0.38497241 -0.24163424 -0.13119464 -0.02553673]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.02156931  0.          0.        ]\n",
      " [ 0.07619615 -0.13775033  0.05953898  0.        ]\n",
      " [ 0.02675562 -0.04502176  0.          0.        ]]\n",
      "SHAP values per classe 140: [[ 0.40888582 -0.30194225 -0.10632107 -0.02724748]\n",
      " [ 0.          0.01518472  0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.09182434 -0.06480851  0.          0.07014625]\n",
      " [ 0.04531461  0.          0.          0.        ]]\n",
      "SHAP values per classe 141: [[ 0.26842216 -0.08086091 -0.1508844  -0.01983479]\n",
      " [ 0.0250613  -0.00434581  0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.09822805 -0.13850836  0.05045787  0.01061058]\n",
      " [ 0.01856305 -0.04814383  0.          0.        ]]\n",
      "SHAP values per classe 142: [[-0.14448511  0.02398144  0.13082142  0.02731557]\n",
      " [-0.01811869  0.          0.02461795 -0.04511047]\n",
      " [-0.00688598  0.          0.00480943  0.        ]\n",
      " [ 0.         -0.05856316  0.04849177  0.        ]\n",
      " [-0.00530515  0.          0.04854509 -0.03887342]]\n",
      "SHAP values per classe 143: [[ 0.06325284  0.01587068 -0.07581021 -0.02318448]\n",
      " [ 0.         -0.02389454  0.          0.        ]\n",
      " [-0.02085659  0.00525789  0.          0.        ]\n",
      " [ 0.10857979 -0.18017642  0.          0.        ]\n",
      " [ 0.         -0.00873882  0.11700645  0.        ]]\n",
      "SHAP values per classe 144: [[ 0.4005866  -0.07320139 -0.27046466 -0.05418389]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.01014509  0.         -0.01514578]\n",
      " [ 0.01122496  0.          0.          0.        ]\n",
      " [ 0.00749563 -0.01851942  0.          0.        ]]\n",
      "SHAP values per classe 145: [[-0.16398574  0.          0.17548125  0.        ]\n",
      " [-0.00278376  0.          0.          0.        ]\n",
      " [ 0.         -0.02857976  0.0122602   0.        ]\n",
      " [ 0.         -0.04876745  0.02955632  0.        ]\n",
      " [ 0.         -0.01945895  0.05658268 -0.016166  ]]\n",
      "SHAP values per classe 146: [[ 0.29592892 -0.0209859  -0.17504358 -0.04416246]\n",
      " [ 0.          0.         -0.04061095  0.01752841]\n",
      " [ 0.08489197 -0.07810519  0.         -0.03862091]\n",
      " [ 0.06534829 -0.11359456  0.042444    0.        ]\n",
      " [ 0.06194056 -0.08486237  0.         -0.0197647 ]]\n",
      "SHAP values per classe 147: [[-0.15325925  0.          0.06801443  0.04335086]\n",
      " [-0.01577398  0.          0.          0.        ]\n",
      " [-0.01490788  0.01779327  0.          0.00777913]\n",
      " [ 0.         -0.07541725  0.05301834  0.02564608]\n",
      " [-0.00701429 -0.05694887  0.05537282  0.01202356]]\n",
      "SHAP values per classe 148: [[ 0.18021772 -0.12968266 -0.12541535  0.        ]\n",
      " [ 0.05253005  0.          0.          0.03730122]\n",
      " [ 0.          0.          0.         -0.05734007]\n",
      " [ 0.09704541 -0.08641903  0.         -0.01438085]\n",
      " [ 0.          0.0672407   0.          0.        ]]\n",
      "SHAP values per classe 149: [[-0.10958157  0.          0.04451945  0.        ]\n",
      " [-0.03550345 -0.03128251  0.35237948 -0.24561427]\n",
      " [-0.00389415 -0.00176572  0.          0.        ]\n",
      " [ 0.         -0.10651688  0.11915325  0.01821523]\n",
      " [ 0.         -0.03178435  0.          0.        ]]\n",
      "SHAP values per classe 150: [[-0.16121689  0.37265701  0.          0.02528309]\n",
      " [-0.0111969   0.33584827 -0.11106365  0.        ]\n",
      " [-0.03471283  0.03100929  0.         -0.01159144]\n",
      " [-0.03207854  0.1723267  -0.12418617 -0.03657181]\n",
      " [ 0.01274974 -0.03003209  0.          0.01192149]]\n",
      "SHAP values per classe 151: [[-0.07332486  0.          0.04241386  0.02691971]\n",
      " [ 0.          0.          0.01511179  0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.04887071  0.          0.02627361]\n",
      " [-0.00774599 -0.02396432  0.          0.00662943]]\n",
      "SHAP values per classe 152: [[-0.13897569  0.03327084  0.04479582  0.06371026]\n",
      " [-0.01175701  0.         -0.0015165   0.        ]\n",
      " [-0.00631851  0.02490138 -0.02165565  0.01491982]\n",
      " [ 0.         -0.06969103  0.07759724  0.        ]\n",
      " [ 0.         -0.07711381  0.04464562  0.03219174]]\n",
      "SHAP values per classe 153: [[-0.12893508  0.08532847  0.03840974  0.        ]\n",
      " [-0.01452189  0.00401756  0.          0.00880058]\n",
      " [-0.01526382  0.05887717  0.          0.        ]\n",
      " [-0.02146633  0.10377532 -0.03833076  0.01328567]\n",
      " [-0.04812178  0.38946321 -0.09083141 -0.24206899]]\n",
      "SHAP values per classe 154: [[-0.15074545  0.16037592  0.          0.        ]\n",
      " [-0.04173361  0.          0.          0.        ]\n",
      " [-0.00545237  0.          0.          0.        ]\n",
      " [-0.02875771  0.30677175 -0.21262021 -0.07396582]\n",
      " [ 0.          0.03485971  0.          0.        ]]\n",
      "SHAP values per classe 155: [[ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [-1.43504498e-03  2.57694848e-02 -1.51971499e-02  0.00000000e+00]\n",
      " [-3.17986469e-02  3.04609969e-02  4.20662732e-03 -1.40742343e-04]\n",
      " [-3.16303695e-01  3.04699329e-01  8.68523506e-03 -2.27965015e-02]\n",
      " [ 0.00000000e+00  0.00000000e+00 -2.70389560e-02  0.00000000e+00]]\n",
      "SHAP values per classe 156: [[ 0.48678016 -0.26037517 -0.12005795 -0.04415057]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.03759771  0.         -0.0614011 ]\n",
      " [ 0.03991679 -0.05073172  0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 157: [[-0.08519869  0.          0.03492346  0.01516137]\n",
      " [-0.02289016  0.01823063  0.          0.        ]\n",
      " [-0.01237703 -0.04565365  0.          0.02174138]\n",
      " [ 0.         -0.06099011  0.05809666  0.01491503]\n",
      " [ 0.         -0.04735173  0.02116994  0.        ]]\n",
      "SHAP values per classe 158: [[ 0.3890464  -0.05058341 -0.27819638 -0.03343231]\n",
      " [ 0.          0.          0.05971281 -0.11098307]\n",
      " [ 0.02083041 -0.00486917  0.          0.        ]\n",
      " [ 0.06856427 -0.12065267  0.          0.02963142]\n",
      " [ 0.04356491 -0.06413708  0.01462049  0.        ]]\n",
      "SHAP values per classe 159: [[-0.10745582  0.07542339  0.03937451  0.        ]\n",
      " [-0.01271342  0.          0.05576543 -0.02806992]\n",
      " [-0.01596362  0.01145762  0.          0.        ]\n",
      " [-0.08805585  0.42102036 -0.27615089 -0.05465645]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 160: [[ 0.04441695 -0.01389552 -0.04133917  0.04468917]\n",
      " [-0.00347366  0.          0.22568054 -0.23928711]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.03787165  0.          0.0360665 ]\n",
      " [ 0.         -0.05166299  0.         -0.00200207]]\n",
      "SHAP values per classe 161: [[-0.11557854  0.02060839  0.          0.06242826]\n",
      " [-0.02270046  0.          0.          0.00613371]\n",
      " [-0.00701885  0.          0.          0.02612208]\n",
      " [ 0.01488382 -0.02003337 -0.0350099   0.03316376]\n",
      " [ 0.         -0.04253734  0.          0.01662048]]\n",
      "SHAP values per classe 162: [[-0.13453079  0.02544415  0.          0.09162199]\n",
      " [-0.01179154 -0.01189757 -0.06042932  0.08185069]\n",
      " [-0.03464633  0.          0.          0.04449278]\n",
      " [-0.00020251 -0.10663181  0.08289171  0.01229132]\n",
      " [ 0.         -0.0348757   0.          0.01913428]]\n",
      "SHAP values per classe 163: [[-0.09681738  0.02834095  0.06756721  0.        ]\n",
      " [-0.0079358   0.          0.          0.01687518]\n",
      " [ 0.          0.         -0.00560779  0.0624982 ]\n",
      " [ 0.         -0.07323569  0.06251179 -0.0027827 ]\n",
      " [ 0.         -0.03161862  0.          0.07024088]]\n",
      "SHAP values per classe 164: [[-0.05151144  0.02419039  0.          0.        ]\n",
      " [-0.01031369  0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.04515152 -0.00490883  0.          0.        ]\n",
      " [ 0.         -0.04189714  0.          0.03308557]]\n",
      "SHAP values per classe 165: [[-0.13187869  0.13625991  0.          0.        ]\n",
      " [-0.0077726   0.01998317 -0.00901825  0.        ]\n",
      " [ 0.          0.         -0.00905927  0.        ]\n",
      " [ 0.          0.0119693   0.          0.        ]\n",
      " [-0.08526142  0.49562122 -0.22339256 -0.16131387]]\n",
      "SHAP values per classe 166: [[-0.15891625  0.16020575  0.          0.        ]\n",
      " [-0.01302371  0.01305818 -0.01975985  0.0148979 ]\n",
      " [-0.01823876  0.          0.          0.01175515]\n",
      " [-0.02764993  0.19354763 -0.15624158 -0.01591614]\n",
      " [ 0.         -0.05447852  0.06211511  0.        ]]\n",
      "SHAP values per classe 167: [[-0.17621198  0.01828015  0.14311167  0.        ]\n",
      " [ 0.          0.00551804 -0.06826561  0.03798033]\n",
      " [-0.02388153  0.          0.          0.        ]\n",
      " [ 0.          0.          0.03646631  0.        ]\n",
      " [-0.01870633  0.43124311 -0.36491129 -0.03432377]]\n",
      "SHAP values per classe 168: [[-0.08870745  0.          0.04322824  0.02500135]\n",
      " [ 0.          0.          0.          0.00877414]\n",
      " [-0.02553167 -0.06812692  0.          0.        ]\n",
      " [ 0.          0.          0.          0.02555951]\n",
      " [-0.00847386 -0.03160545  0.          0.        ]]\n",
      "SHAP values per classe 169: [[-0.12094172  0.02190614  0.08577715  0.03074357]\n",
      " [ 0.          0.          0.          0.02051171]\n",
      " [ 0.          0.          0.          0.00091747]\n",
      " [ 0.         -0.09477827  0.          0.03620464]\n",
      " [ 0.         -0.02391979  0.          0.00594569]]\n",
      "SHAP values per classe 170: [[-0.0811468   0.05305902  0.          0.        ]\n",
      " [-0.01272834  0.          0.05087922  0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.         -0.02831235]\n",
      " [-0.03391512  0.58913102 -0.16104143 -0.30568889]]\n",
      "SHAP values per classe 171: [[ 0.5896321  -0.30286571 -0.18834622 -0.08839539]\n",
      " [ 0.          0.          0.09281355 -0.11115243]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.0597713  -0.15113844  0.08045674  0.        ]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 172: [[ 0.1406451  -0.0611484  -0.0485258  -0.02475663]\n",
      " [ 0.03135595  0.         -0.01279395  0.        ]\n",
      " [ 0.          0.00417786  0.          0.        ]\n",
      " [-0.08298204  0.24931558 -0.06005904 -0.01474915]\n",
      " [ 0.         -0.08815996  0.         -0.03773995]]\n",
      "SHAP values per classe 173: [[-0.06378594  0.04892802  0.          0.02386943]\n",
      " [ 0.         -0.00305687  0.04125704 -0.0259395 ]\n",
      " [-0.00590484  0.          0.          0.        ]\n",
      " [ 0.         -0.0149079   0.03053008  0.        ]\n",
      " [ 0.         -0.01574436  0.          0.        ]]\n",
      "SHAP values per classe 174: [[-0.16461499  0.0147788   0.11612488  0.0117576 ]\n",
      " [-0.01703757  0.          0.          0.00256227]\n",
      " [-0.0222694   0.         -0.05765944  0.00888429]\n",
      " [ 0.         -0.14078153  0.08395299  0.06221663]\n",
      " [ 0.         -0.06633107  0.0628318   0.00287211]]\n",
      "SHAP values per classe 175: [[ 0.         -0.01855803  0.          0.04535042]\n",
      " [-0.02016695  0.01516778  0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.08592709  0.          0.05058242]\n",
      " [ 0.          0.         -0.01863834  0.03676079]]\n",
      "SHAP values per classe 176: [[-0.1544408   0.01963487  0.01621311  0.        ]\n",
      " [-0.0181226   0.          0.          0.        ]\n",
      " [-0.01992222  0.          0.          0.        ]\n",
      " [ 0.         -0.10372209  0.13752735 -0.02694617]\n",
      " [ 0.         -0.04390854  0.          0.        ]]\n",
      "SHAP values per classe 177: [[ 0.55843959 -0.09066557 -0.27230995 -0.17178745]\n",
      " [ 0.          0.          0.          0.02224237]\n",
      " [ 0.10843804 -0.02853285 -0.0325487  -0.02665681]\n",
      " [ 0.013472   -0.06883153  0.04810081  0.        ]\n",
      " [ 0.00393108 -0.02959917  0.          0.        ]]\n",
      "SHAP values per classe 178: [[ 0.2013646  -0.00911037 -0.10543466 -0.06201676]\n",
      " [ 0.01374784  0.00093885  0.01899231  0.        ]\n",
      " [ 0.04648099 -0.01064732  0.         -0.0257464 ]\n",
      " [ 0.06652727 -0.09061342  0.          0.01837935]\n",
      " [ 0.          0.          0.07911723  0.        ]]\n",
      "SHAP values per classe 179: [[-0.09274349  0.          0.11953323 -0.07441385]\n",
      " [-0.00531714  0.          0.00078146  0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.04472828  0.          0.        ]\n",
      " [ 0.         -0.0283554   0.02578195  0.        ]]\n",
      "SHAP values per classe 180: [[ 0.06046237  0.         -0.03597423  0.        ]\n",
      " [ 0.          0.          0.06549257 -0.05296641]\n",
      " [ 0.          0.01316283 -0.13923233  0.        ]\n",
      " [-0.42466634  0.61734957 -0.06824161 -0.07674306]\n",
      " [ 0.13283153  0.         -0.0628004  -0.00300883]]\n",
      "SHAP values per classe 181: [[ 0.          0.          0.          0.        ]\n",
      " [ 0.11257735  0.          0.         -0.14162993]\n",
      " [ 0.          0.03098891  0.          0.        ]\n",
      " [-0.44727367  0.66527199 -0.08284194 -0.07860142]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 182: [[-0.12865004  0.          0.08895481  0.0592883 ]\n",
      " [-0.01454397  0.06783946  0.          0.        ]\n",
      " [-0.03945871  0.05093733 -0.00138518 -0.05808576]\n",
      " [-0.03540041  0.29391459 -0.20663945 -0.06653902]\n",
      " [-0.0097726   0.10477625 -0.0305906   0.        ]]\n",
      "SHAP values per classe 183: [[ 0.19544051 -0.04237746 -0.15781118  0.        ]\n",
      " [ 0.          0.0249361   0.          0.        ]\n",
      " [ 0.02842582 -0.08528396  0.         -0.00974117]\n",
      " [ 0.07126148 -0.13402858  0.05113423  0.        ]\n",
      " [ 0.         -0.07425423  0.          0.        ]]\n",
      "SHAP values per classe 184: [[-0.15791924  0.03882724  0.04315093  0.        ]\n",
      " [-0.02020435  0.02651472  0.          0.        ]\n",
      " [-0.02818336  0.          0.          0.        ]\n",
      " [ 0.          0.          0.05441789  0.        ]\n",
      " [-0.02531582  0.40557328 -0.32028226 -0.0476478 ]]\n",
      "SHAP values per classe 185: [[-0.02010224  0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.05234241]\n",
      " [ 0.         -0.03574828  0.          0.01534965]\n",
      " [ 0.         -0.00582611  0.          0.        ]]\n",
      "SHAP values per classe 186: [[-0.1120636   0.          0.06330711  0.0434671 ]\n",
      " [-0.01078688  0.          0.          0.02420836]\n",
      " [-0.02932299  0.          0.          0.        ]\n",
      " [ 0.         -0.09751222  0.          0.06581838]\n",
      " [-0.02285161 -0.04463054  0.          0.03766522]]\n",
      "SHAP values per classe 187: [[ 0.25292051 -0.13174206 -0.13938245 -0.03037866]\n",
      " [ 0.          0.          0.00898559  0.        ]\n",
      " [ 0.04041014  0.          0.         -0.01581667]\n",
      " [ 0.         -0.04522773  0.07906642  0.        ]\n",
      " [ 0.03834718 -0.06349279  0.          0.00248358]]\n",
      "SHAP values per classe 188: [[-0.08658683  0.          0.03507463  0.04297039]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.02838623  0.          0.          0.        ]\n",
      " [ 0.         -0.05435464  0.          0.01594617]\n",
      " [ 0.          0.          0.          0.00973327]]\n",
      "SHAP values per classe 189: [[-0.17903825  0.04753181  0.0884332   0.03866694]\n",
      " [-0.01574096  0.         -0.0039582   0.02941442]\n",
      " [-0.02107658  0.0163718   0.01087418  0.        ]\n",
      " [ 0.         -0.07658762  0.0526393   0.        ]\n",
      " [-0.00614733  0.02626277 -0.13316441  0.10791751]]\n",
      "SHAP values per classe 190: [[-0.13595542 -0.0443853   0.13302541  0.        ]\n",
      " [-0.00654529  0.          0.          0.        ]\n",
      " [ 0.          0.          0.02459382 -0.04333628]\n",
      " [ 0.         -0.07492404  0.00566406  0.0196174 ]\n",
      " [ 0.         -0.04332232  0.          0.        ]]\n",
      "SHAP values per classe 191: [[-0.11770051  0.05049707  0.03036941  0.        ]\n",
      " [-0.01266012  0.0103098   0.          0.        ]\n",
      " [-0.01134585  0.          0.          0.        ]\n",
      " [-0.05003961  0.41693589 -0.25698143 -0.10476463]\n",
      " [ 0.          0.          0.02813274  0.        ]]\n",
      "SHAP values per classe 192: [[ 0.35792339 -0.12266072 -0.2155084  -0.01743169]\n",
      " [ 0.          0.01879527  0.          0.01147836]\n",
      " [ 0.         -0.01952315  0.         -0.00077309]\n",
      " [ 0.07972488 -0.13458016  0.          0.04832758]\n",
      " [ 0.05757323 -0.06644567  0.02375772  0.        ]]\n",
      "SHAP values per classe 193: [[-0.09855146  0.09249209  0.          0.        ]\n",
      " [ 0.          0.02144545  0.          0.        ]\n",
      " [-0.05983522  0.0668948   0.         -0.02258749]\n",
      " [ 0.04126064  0.          0.          0.        ]\n",
      " [-0.04916404  0.28252586 -0.16055996 -0.03423087]]\n",
      "SHAP values per classe 194: [[-0.07249182  0.          0.05880786 -0.07985854]\n",
      " [-0.00507811  0.          0.02439273 -0.01440445]\n",
      " [-0.01436781  0.          0.          0.        ]\n",
      " [ 0.         -0.03573749  0.08324716 -0.0278014 ]\n",
      " [ 0.          0.          0.          0.01298953]]\n",
      "SHAP values per classe 195: [[-0.10902682  0.          0.          0.        ]\n",
      " [-0.02812178 -0.02900535  0.          0.10756196]\n",
      " [ 0.         -0.02062922  0.          0.        ]\n",
      " [ 0.         -0.06754177  0.          0.        ]\n",
      " [ 0.         -0.04527639  0.          0.        ]]\n",
      "SHAP values per classe 196: [[-0.12271466  0.013849    0.12658319 -0.01705237]\n",
      " [ 0.          0.          0.25004947 -0.24305603]\n",
      " [-0.05379876 -0.00924628  0.09005543  0.        ]\n",
      " [ 0.         -0.10231607  0.15305473  0.        ]\n",
      " [ 0.02622325 -0.04706128  0.          0.        ]]\n",
      "SHAP values per classe 197: [[ 0.          0.          0.          0.        ]\n",
      " [ 0.23053711  0.         -0.10462182 -0.09426673]\n",
      " [-0.08142373  0.04383472  0.          0.        ]\n",
      " [-0.3074306   0.5330652  -0.10586542 -0.10046246]\n",
      " [ 0.          0.03077086 -0.00645328  0.        ]]\n",
      "SHAP values per classe 198: [[-0.15853333  0.27349188 -0.04421294 -0.06535551]\n",
      " [-0.01787549  0.          0.          0.        ]\n",
      " [-0.01103278  0.          0.          0.        ]\n",
      " [-0.02297594  0.06995945 -0.02531652 -0.01716422]\n",
      " [-0.02223738  0.08608563 -0.05434358  0.        ]]\n",
      "SHAP values per classe 199: [[ 0.23045391 -0.03835868 -0.21570036 -0.04766492]\n",
      " [-0.00476117  0.          0.          0.        ]\n",
      " [ 0.2908389  -0.1444556   0.         -0.05089303]\n",
      " [ 0.         -0.07922537  0.          0.00794305]\n",
      " [ 0.          0.         -0.03289682  0.        ]]\n",
      "SHAP values per classe 200: [[-0.07279779  0.          0.07350582  0.        ]\n",
      " [-0.01314619 -0.00967943  0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.06044952  0.          0.        ]\n",
      " [ 0.         -0.02272257  0.          0.        ]]\n",
      "SHAP values per classe 201: [[-0.11560997  0.04456427  0.06794913  0.        ]\n",
      " [-0.01631122  0.         -0.01100506  0.02592692]\n",
      " [-0.06408835  0.          0.          0.07981692]\n",
      " [ 0.         -0.10923695  0.02189991  0.06574162]\n",
      " [ 0.         -0.04388483  0.01729031  0.02850111]]\n",
      "SHAP values per classe 202: [[-0.12404272  0.02156084  0.1016775   0.01162962]\n",
      " [ 0.          0.01693649  0.01284783  0.        ]\n",
      " [-0.01219982  0.          0.          0.        ]\n",
      " [ 0.         -0.12629727  0.0580906   0.03067193]\n",
      " [ 0.01130412 -0.03215372  0.          0.        ]]\n",
      "SHAP values per classe 203: [[-0.09103176  0.          0.          0.04912388]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.0170695   0.          0.          0.0148877 ]\n",
      " [-0.00686246 -0.0558725   0.          0.        ]\n",
      " [ 0.         -0.03672569  0.          0.00503093]]\n",
      "SHAP values per classe 204: [[-0.14457134  0.05157937  0.04126604  0.05500325]\n",
      " [-0.01366063  0.          0.03901928 -0.03200016]\n",
      " [-0.01618993  0.          0.03747554  0.        ]\n",
      " [ 0.         -0.0243068   0.          0.01680931]\n",
      " [ 0.         -0.03205921  0.          0.03180066]]\n",
      "SHAP values per classe 205: [[-1.43309363e-01  0.00000000e+00  9.75019837e-02  1.18295031e-02]\n",
      " [-1.38530000e-02  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [-4.45812177e-03  0.00000000e+00  1.44490644e-02  0.00000000e+00]\n",
      " [-3.51198940e-02  0.00000000e+00 -1.28462190e-04  0.00000000e+00]\n",
      " [-5.38033265e-03  0.00000000e+00  3.84376333e-02  0.00000000e+00]]\n",
      "SHAP values per classe 206: [[-0.0710946   0.04166549  0.03892979  0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.03333133  0.          0.          0.        ]\n",
      " [-0.07687349  0.3569829  -0.0582288  -0.13811512]\n",
      " [-0.02566435  0.15288606 -0.04629767 -0.03237933]]\n",
      "SHAP values per classe 207: [[-0.07383897  0.01989535  0.05447009  0.        ]\n",
      " [ 0.          0.          0.39597612 -0.33108939]\n",
      " [-0.03238831  0.          0.          0.        ]\n",
      " [ 0.         -0.06857344  0.08533331  0.        ]\n",
      " [ 0.         -0.03036821  0.          0.        ]]\n",
      "SHAP values per classe 208: [[-0.01339836  0.          0.          0.        ]\n",
      " [ 0.          0.         -0.00119718  0.00882528]\n",
      " [ 0.          0.05809959  0.          0.        ]\n",
      " [-0.06199434 -0.0406135   0.31376717 -0.14635462]\n",
      " [ 0.          0.          0.08526846 -0.06617105]]\n",
      "SHAP values per classe 209: [[-0.10637351  0.          0.          0.00518021]\n",
      " [-0.01117667  0.          0.          0.03007801]\n",
      " [-0.01714061  0.01223561  0.03081265  0.        ]\n",
      " [ 0.         -0.10196227  0.06335481  0.02601896]\n",
      " [ 0.         -0.05457773  0.0619829   0.        ]]\n",
      "SHAP values per classe 210: [[-0.08244455 -0.01613975 -0.01250269  0.11726845]\n",
      " [ 0.          0.         -0.02804338  0.05327933]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.05169378  0.03653217  0.        ]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 211: [[-0.13141369  0.14718132  0.          0.        ]\n",
      " [-0.01453364  0.01334766  0.          0.021912  ]\n",
      " [-0.03230634  0.03482204  0.          0.        ]\n",
      " [-0.04182037  0.35331915 -0.25051468 -0.05516533]\n",
      " [ 0.          0.          0.          0.01092262]]\n",
      "SHAP values per classe 212: [[-0.10684128  0.0201066   0.02881983  0.05367756]\n",
      " [-0.01460926  0.          0.          0.02087996]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.00296177 -0.06065026  0.03811977  0.02111827]\n",
      " [ 0.         -0.10826218  0.01162356  0.07101768]]\n",
      "SHAP values per classe 213: [[-0.16372903  0.02306919  0.07940931  0.04723985]\n",
      " [-0.01802293 -0.00270553  0.00644108  0.01971959]\n",
      " [-0.01519194 -0.03063402  0.          0.        ]\n",
      " [ 0.         -0.15567994  0.12766088  0.06808068]\n",
      " [ 0.         -0.04819887  0.          0.02362476]]\n",
      "SHAP values per classe 214: [[-0.11458232  0.06271411  0.01894641  0.        ]\n",
      " [ 0.         -0.00211177  0.00607158  0.        ]\n",
      " [-0.03551234  0.          0.         -0.05642021]\n",
      " [-0.04931946  0.36220368 -0.24844301 -0.07234658]\n",
      " [ 0.         -0.02111004  0.02478927  0.        ]]\n",
      "SHAP values per classe 215: [[ 1.16841893e-01 -3.17037259e-02  0.00000000e+00 -4.37027290e-02]\n",
      " [ 0.00000000e+00  2.61520329e-03  0.00000000e+00  0.00000000e+00]\n",
      " [-5.75003103e-02  1.15943340e-02  3.64283601e-02  0.00000000e+00]\n",
      " [ 0.00000000e+00 -1.64054611e-01  1.04344800e-01  7.42111092e-02]\n",
      " [ 5.61080114e-05 -3.60371162e-02  4.17064665e-02  0.00000000e+00]]\n",
      "SHAP values per classe 216: [[-0.12282667  0.          0.          0.        ]\n",
      " [-0.00984146  0.          0.          0.        ]\n",
      " [-0.0040323   0.          0.          0.        ]\n",
      " [ 0.         -0.10543629  0.09324721  0.        ]\n",
      " [ 0.         -0.02964707  0.          0.169874  ]]\n",
      "SHAP values per classe 217: [[-0.12358658  0.02823318  0.03793804  0.04216164]\n",
      " [ 0.00608933  0.         -0.03844974  0.01957311]\n",
      " [-0.00620956  0.          0.0020324   0.        ]\n",
      " [ 0.         -0.04198135  0.          0.03090178]\n",
      " [ 0.          0.          0.00701428  0.        ]]\n",
      "SHAP values per classe 218: [[ 3.05222536e-01 -6.24082293e-02 -1.92157522e-01 -4.11227083e-02]\n",
      " [ 5.77629503e-06  0.00000000e+00  0.00000000e+00 -7.58157472e-03]\n",
      " [ 6.36608190e-02 -6.32157254e-02  0.00000000e+00  0.00000000e+00]\n",
      " [ 5.97181333e-02 -1.15744540e-01  6.31271609e-02  0.00000000e+00]\n",
      " [ 2.48091982e-02 -5.38579210e-02  6.47610907e-03  0.00000000e+00]]\n",
      "SHAP values per classe 219: [[-0.07486438  0.          0.02058166  0.        ]\n",
      " [-0.00730248  0.          0.          0.        ]\n",
      " [-0.01960153  0.          0.03268678  0.        ]\n",
      " [ 0.         -0.04160808  0.          0.0270688 ]\n",
      " [ 0.         -0.0188151   0.          0.        ]]\n",
      "SHAP values per classe 220: [[-0.05569499  0.02289374  0.03606732  0.        ]\n",
      " [ 0.          0.         -0.02936604  0.03469687]\n",
      " [-0.03716346 -0.02038047  0.          0.03190873]\n",
      " [ 0.         -0.06362445  0.04384373  0.01968224]\n",
      " [ 0.         -0.0361881   0.04532823  0.00694561]]\n",
      "SHAP values per classe 221: [[-0.10638012  0.08144739  0.          0.        ]\n",
      " [ 0.         -0.06046219  0.          0.        ]\n",
      " [-0.0078651   0.          0.          0.        ]\n",
      " [-0.06177528  0.5796954  -0.24117758 -0.18424037]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 222: [[-0.14044856  0.02011096  0.10480472  0.01221127]\n",
      " [-0.00662996 -0.00267626  0.         -0.00394441]\n",
      " [-0.01908204  0.         -0.00435362  0.        ]\n",
      " [ 0.         -0.16737975  0.1499375   0.02093357]\n",
      " [ 0.00540039 -0.03251548  0.02853149  0.        ]]\n",
      "SHAP values per classe 223: [[-0.18780343  0.          0.17097882  0.        ]\n",
      " [-0.01433651  0.          0.00548925  0.01322081]\n",
      " [-0.02767174  0.          0.04268113  0.        ]\n",
      " [-0.01518316  0.03114449 -0.05646945  0.04172201]\n",
      " [ 0.         -0.03237171  0.          0.02699146]]\n",
      "SHAP values per classe 224: [[ 0.49420149 -0.25828135 -0.14963873 -0.06675835]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.07020471 -0.11949918  0.03713343  0.        ]\n",
      " [ 0.01482373  0.          0.          0.        ]]\n",
      "SHAP values per classe 225: [[-0.1510152   0.07000229  0.06387995  0.07413935]\n",
      " [-0.01181493  0.          0.          0.        ]\n",
      " [-0.04090434  0.          0.          0.00132774]\n",
      " [-0.02039622  0.28523865 -0.20152995 -0.08319889]\n",
      " [-0.00230706  0.          0.          0.        ]]\n",
      "SHAP values per classe 226: [[-0.0651149   0.          0.11271953  0.        ]\n",
      " [-0.00712185  0.         -0.05301598  0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.08017498 -0.05573173 -0.01631018]\n",
      " [ 0.         -0.02242801  0.         -0.14265479]]\n",
      "SHAP values per classe 227: [[-0.04108237 -0.004973    0.06231817  0.        ]\n",
      " [ 0.          0.          0.02466816  0.        ]\n",
      " [-0.01620415  0.          0.02188135  0.        ]\n",
      " [ 0.         -0.14505784  0.0246759   0.        ]\n",
      " [ 0.         -0.03416526  0.06241633  0.        ]]\n",
      "SHAP values per classe 228: [[-0.1363981   0.1960563   0.          0.        ]\n",
      " [-0.01729047  0.00711249  0.          0.        ]\n",
      " [-0.02732346 -0.10920256  0.          0.        ]\n",
      " [-0.03944368  0.1923913  -0.1512082  -0.05560308]\n",
      " [-0.00948539  0.         -0.00175326  0.        ]]\n",
      "SHAP values per classe 229: [[-0.07920575  0.          0.14116566  0.        ]\n",
      " [-0.01505241  0.          0.          0.        ]\n",
      " [-0.02272787  0.00596991  0.02533848  0.        ]\n",
      " [-0.09082091  0.43324322 -0.19086879 -0.1376545 ]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 230: [[-0.15392082  0.          0.11915147  0.        ]\n",
      " [ 0.         -0.02543736  0.02466714  0.01229315]\n",
      " [-0.01686768  0.          0.01656723  0.        ]\n",
      " [ 0.00617845 -0.07330788  0.0869724   0.        ]\n",
      " [-0.00739686 -0.04609124  0.0653982   0.00314345]]\n",
      "SHAP values per classe 231: [[-0.10999025  0.02375207  0.04688973  0.04238226]\n",
      " [-0.0705957   0.02162594  0.          0.01980066]\n",
      " [ 0.          0.          0.          0.00898683]\n",
      " [ 0.         -0.04765461  0.          0.02029296]\n",
      " [ 0.         -0.03613012  0.          0.        ]]\n",
      "SHAP values per classe 232: [[-0.08036142  0.          0.05579571  0.0203021 ]\n",
      " [-0.01681084 -0.00345705  0.          0.02463116]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.01113249 -0.05844057  0.0333589   0.00640256]\n",
      " [ 0.         -0.03307367  0.          0.        ]]\n",
      "SHAP values per classe 233: [[ 0.29124203 -0.02711497 -0.19457137 -0.00577368]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.01125101 -0.01360531  0.01751459 -0.015013  ]\n",
      " [ 0.14695928 -0.15502441  0.          0.        ]\n",
      " [ 0.02396841 -0.04417831  0.020399    0.        ]]\n",
      "SHAP values per classe 234: [[ 0.4026042  -0.1251855  -0.19915395 -0.04750862]\n",
      " [ 0.          0.          0.         -0.00114272]\n",
      " [ 0.02751817  0.          0.         -0.00156581]\n",
      " [ 0.         -0.12475292  0.          0.        ]\n",
      " [ 0.05472604  0.          0.          0.        ]]\n",
      "SHAP values per classe 235: [[-0.12621469  0.          0.07770989  0.03386979]\n",
      " [-0.01555678  0.          0.          0.        ]\n",
      " [-0.02904126  0.          0.          0.        ]\n",
      " [-0.01104273 -0.10064558  0.08011888  0.        ]\n",
      " [ 0.01887027 -0.004072    0.          0.02886987]]\n",
      "SHAP values per classe 236: [[ 0.38970776 -0.08337165 -0.15900843 -0.1076503 ]\n",
      " [-0.13725969  0.          0.08689731  0.        ]\n",
      " [ 0.16537161 -0.07544833 -0.03635608  0.        ]\n",
      " [ 0.         -0.05755072  0.04071079  0.        ]\n",
      " [ 0.         -0.01557658  0.01701776  0.        ]]\n",
      "SHAP values per classe 237: [[ 0.68690381 -0.23329657 -0.27691465 -0.16009737]\n",
      " [-0.00530168 -0.00270219  0.          0.        ]\n",
      " [ 0.          0.          0.         -0.03694732]\n",
      " [ 0.02040348 -0.08158321  0.04591435  0.        ]\n",
      " [ 0.00723333 -0.01524724  0.00714076  0.        ]]\n",
      "SHAP values per classe 238: [[ 0.          0.14416837  0.          0.        ]\n",
      " [ 0.          0.         -0.03408088 -0.01192734]\n",
      " [-0.01496346  0.          0.          0.        ]\n",
      " [-0.21521743  0.39995922 -0.09221356 -0.03623261]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 239: [[ 0.11610679  0.         -0.04054691 -0.03177915]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.28917406  0.48456363 -0.10032854 -0.07064828]\n",
      " [ 0.          0.          0.0183349   0.        ]]\n",
      "SHAP values per classe 240: [[-0.085196    0.          0.04289197  0.0312024 ]\n",
      " [ 0.         -0.0049715   0.          0.0049692 ]\n",
      " [ 0.          0.          0.          0.01498372]\n",
      " [ 0.         -0.06793406  0.04394525  0.01531454]\n",
      " [ 0.         -0.02823737  0.01467782  0.00925416]]\n",
      "SHAP values per classe 241: [[-0.0964687   0.05782918  0.02318908  0.        ]\n",
      " [-0.01760101  0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.0800334   0.64666893 -0.40205623 -0.17179988]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 242: [[ 0.32544642 -0.05081476 -0.20816431  0.        ]\n",
      " [ 0.          0.          0.          0.02680042]\n",
      " [ 0.01636379  0.          0.          0.        ]\n",
      " [ 0.00169366 -0.08372962  0.06329012  0.        ]\n",
      " [ 0.05700157 -0.07330839  0.          0.03008562]]\n",
      "SHAP values per classe 243: [[ 0.65862867 -0.18231343 -0.24536641  0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.01554427]\n",
      " [ 0.02770153 -0.07997817  0.          0.        ]\n",
      " [ 0.01143971  0.          0.         -0.02636453]]\n",
      "SHAP values per classe 244: [[-0.15622322  0.          0.04538219  0.01039667]\n",
      " [-0.01795873  0.01428853  0.          0.        ]\n",
      " [-0.02581575  0.0239797   0.          0.        ]\n",
      " [ 0.         -0.05362269  0.          0.01805351]\n",
      " [-0.04672751  0.28132318 -0.1829215  -0.02047   ]]\n",
      "SHAP values per classe 245: [[-0.15334763  0.          0.13689814  0.02545782]\n",
      " [ 0.          0.01870257  0.          0.01597714]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.02902617  0.          0.00430682]\n",
      " [-0.02546639 -0.1798494   0.1911844   0.00849652]]\n",
      "SHAP values per classe 246: [[-0.07796576  0.          0.08456738  0.        ]\n",
      " [ 0.         -0.001866    0.          0.03249905]\n",
      " [-0.10964411 -0.05642698  0.          0.        ]\n",
      " [ 0.         -0.07987765  0.          0.05106993]\n",
      " [-0.01580354 -0.02675378  0.05847947  0.        ]]\n",
      "SHAP values per classe 247: [[-0.14986641  0.02688964  0.11108251 -0.01510187]\n",
      " [-0.01245715  0.01856655  0.         -0.00528277]\n",
      " [-0.02786015  0.          0.          0.        ]\n",
      " [-0.03428593  0.4270928  -0.32691549 -0.05452208]\n",
      " [ 0.          0.          0.         -0.01249187]]\n",
      "SHAP values per classe 248: [[-0.06944284  0.         -0.03731533  0.11888061]\n",
      " [-0.00393512  0.         -0.05415237  0.04980886]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.0339436   0.01592614  0.        ]\n",
      " [ 0.         -0.02041679  0.01704386  0.        ]]\n",
      "SHAP values per classe 249: [[-0.10203412  0.          0.06140307  0.02663701]\n",
      " [-0.0200953   0.          0.          0.        ]\n",
      " [-0.01807017  0.          0.01482188  0.        ]\n",
      " [ 0.         -0.04105259  0.02918219  0.        ]\n",
      " [ 0.         -0.02031851  0.          0.        ]]\n",
      "SHAP values per classe 250: [[-1.18102608e-01  6.63766488e-02  3.49149825e-02  0.00000000e+00]\n",
      " [-3.74387424e-02  2.57689281e-01 -9.04994027e-02 -1.16503888e-03]\n",
      " [-2.16780323e-04  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [-5.81011936e-02  1.97611506e-01 -4.38435080e-02 -1.32801688e-01]\n",
      " [-2.55373755e-02  1.03216528e-01 -6.24223422e-02 -2.01838871e-02]]\n",
      "SHAP values per classe 251: [[-0.15124088  0.          0.05453941  0.        ]\n",
      " [-0.02127875  0.01384627  0.          0.        ]\n",
      " [-0.03738024  0.049948    0.          0.        ]\n",
      " [ 0.          0.          0.03960011  0.        ]\n",
      " [-0.02145382  0.29809308 -0.20582825  0.        ]]\n",
      "SHAP values per classe 252: [[-0.16343127  0.0403486   0.11092093  0.        ]\n",
      " [-0.01656572  0.          0.          0.        ]\n",
      " [-0.03138221  0.          0.          0.04995292]\n",
      " [ 0.         -0.08505659  0.          0.        ]\n",
      " [ 0.00162089 -0.05897001  0.0617594   0.        ]]\n",
      "SHAP values per classe 253: [[-0.11583587  0.          0.10712224  0.        ]\n",
      " [-0.01560348  0.          0.          0.        ]\n",
      " [-0.01195815  0.01627858  0.          0.        ]\n",
      " [-0.1092844   0.46216945 -0.14511127 -0.16654647]\n",
      " [-0.02662839  0.13465756 -0.08486078 -0.00595758]]\n",
      "SHAP values per classe 254: [[-0.20829681  0.         -0.23108914  0.54882228]\n",
      " [ 0.          0.00995784  0.00172397  0.        ]\n",
      " [ 0.         -0.10049622  0.          0.        ]\n",
      " [-0.0089579  -0.10235306  0.06052512  0.04462186]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 255: [[ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.         -0.01185868  0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.01539175 -0.03538511  0.03173472  0.08196998]\n",
      " [ 0.         -0.03271039  0.0332233   0.        ]]\n",
      "SHAP values per classe 256: [[-0.09390783  0.          0.05232695  0.        ]\n",
      " [-0.0109146  -0.02137343  0.          0.05299894]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.06768756  0.04119115  0.02295148]\n",
      " [-0.0054454   0.         -0.01080268  0.00604783]]\n",
      "SHAP values per classe 257: [[ 0.          0.          0.          0.        ]\n",
      " [-0.01891877  0.          0.          0.        ]\n",
      " [-0.01339493 -0.01547461  0.05305772  0.        ]\n",
      " [ 0.         -0.03850652  0.          0.        ]\n",
      " [ 0.         -0.03946499  0.          0.        ]]\n",
      "SHAP values per classe 258: [[-0.08679449  0.06707187  0.          0.        ]\n",
      " [ 0.          0.          0.05292836 -0.04375229]\n",
      " [-0.02721254  0.01182667  0.          0.        ]\n",
      " [-0.10449341  0.25911597 -0.06913299 -0.09288794]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 259: [[-0.07971208  0.          0.          0.04839784]\n",
      " [-0.01476555  0.          0.03355363  0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.06423177  0.0303657   0.02959597]]\n",
      "SHAP values per classe 260: [[-0.12585108  0.03635472  0.08786838  0.05582202]\n",
      " [-0.01288187  0.          0.          0.        ]\n",
      " [-0.00555047  0.00891236  0.          0.        ]\n",
      " [ 0.         -0.10127581  0.03864694  0.0522078 ]\n",
      " [ 0.         -0.11874585  0.          0.02381716]]\n",
      "SHAP values per classe 261: [[-0.06881079  0.          0.11350125  0.        ]\n",
      " [ 0.          0.         -0.0161209   0.02031012]\n",
      " [-0.00596899  0.          0.          0.        ]\n",
      " [ 0.         -0.08000557  0.08289042  0.0213347 ]\n",
      " [ 0.         -0.00828675  0.         -0.04569936]]\n",
      "SHAP values per classe 262: [[-0.11547232  0.          0.06300359  0.        ]\n",
      " [ 0.         -0.10009164  0.25410776 -0.08511126]\n",
      " [-0.00515737  0.10710155 -0.03654008  0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.06611719  0.          0.        ]]\n",
      "SHAP values per classe 263: [[-0.14807596  0.05379395  0.08337628  0.        ]\n",
      " [-0.01361222  0.01139283  0.          0.        ]\n",
      " [-0.03631514  0.11427229 -0.05731117  0.        ]\n",
      " [-0.0213067   0.08114253 -0.04998593 -0.01237996]\n",
      " [ 0.          0.01503691 -0.02667521  0.        ]]\n",
      "SHAP values per classe 264: [[-0.02181233 -0.02576481  0.         -0.06823414]\n",
      " [-0.01447814  0.04883073  0.03288206 -0.03230448]\n",
      " [-0.00738487 -0.01004692  0.01945672  0.        ]\n",
      " [-0.05357926  0.14892852 -0.06955417  0.        ]\n",
      " [-0.10933281  0.28960213 -0.09834229  0.        ]]\n",
      "SHAP values per classe 265: [[ 0.          0.          0.          0.06596606]\n",
      " [ 0.03576689  0.          0.          0.        ]\n",
      " [-0.13735377  0.          0.00951115  0.        ]\n",
      " [ 0.05044243 -0.06570726  0.          0.        ]\n",
      " [-0.03671578 -0.03285791  0.          0.        ]]\n",
      "SHAP values per classe 266: [[ 5.02981387e-01 -2.18308690e-01 -1.60192308e-01 -6.31143724e-02]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  2.42420712e-05  0.00000000e+00]\n",
      " [ 6.84290773e-02 -1.24705021e-01  3.98279088e-02  0.00000000e+00]\n",
      " [ 3.42728339e-02 -4.27969444e-02  3.41451056e-02  2.44887160e-02]]\n",
      "SHAP values per classe 267: [[-0.04683376  0.          0.07002995 -0.0187183 ]\n",
      " [ 0.          0.          0.          0.01828711]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.02024098  0.04371342  0.        ]]\n",
      "SHAP values per classe 268: [[-0.08716944  0.02320879  0.03371079  0.01488194]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.0055337 ]\n",
      " [ 0.         -0.10749442  0.          0.01126798]\n",
      " [ 0.          0.          0.06159861  0.        ]]\n",
      "SHAP values per classe 269: [[-0.07058628  0.06806824  0.13482487 -0.13874898]\n",
      " [-0.03504143  0.          0.05245156 -0.04592852]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.09283445  0.59916    -0.38845223 -0.09482505]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 270: [[-0.12319273  0.          0.17900758  0.        ]\n",
      " [-0.01527757  0.         -0.00883464  0.        ]\n",
      " [-0.00849891  0.          0.          0.00132179]\n",
      " [ 0.00211125 -0.09061734  0.15848203  0.00981015]\n",
      " [ 0.         -0.05926389  0.          0.        ]]\n",
      "SHAP values per classe 271: [[ 0.38916793 -0.20981187 -0.11052294 -0.03380703]\n",
      " [ 0.          0.          0.01432935  0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.05924543 -0.06118052  0.          0.00728972]]\n",
      "SHAP values per classe 272: [[-0.08632041  0.          0.          0.        ]\n",
      " [ 0.          0.         -0.06897588  0.        ]\n",
      " [ 0.         -0.03361971  0.          0.04766473]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.03714984  0.09192584 -0.03688335]]\n",
      "SHAP values per classe 273: [[-0.12471804  0.0947295   0.         -0.00149913]\n",
      " [ 0.          0.03672423  0.         -0.04261469]\n",
      " [ 0.          0.          0.          0.01469756]\n",
      " [-0.08713954  0.49633046 -0.28184791 -0.0683399 ]\n",
      " [ 0.00179195  0.08184778 -0.02385785 -0.0367911 ]]\n",
      "SHAP values per classe 274: [[ 0.27195634 -0.03908711 -0.09404654  0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.09418593  0.         -0.03503777  0.        ]\n",
      " [ 0.0771816  -0.10766466  0.02612886  0.        ]\n",
      " [ 0.04112807 -0.06973954  0.00740436  0.        ]]\n",
      "SHAP values per classe 275: [[-0.14139051  0.02347875  0.05191805  0.07022447]\n",
      " [ 0.         -0.01608555  0.          0.04743066]\n",
      " [ 0.          0.          0.          0.00529922]\n",
      " [ 0.         -0.06521648  0.05042178  0.02824481]\n",
      " [ 0.         -0.03844469  0.          0.01604499]]\n",
      "SHAP values per classe 276: [[-0.14744583  0.02245334  0.10555853  0.0276763 ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.05324229 -0.01043497  0.01966392  0.03836536]\n",
      " [ 0.01165761 -0.10657013  0.05970679  0.00893912]\n",
      " [ 0.00208112 -0.03712164  0.05079177  0.00113618]]\n",
      "SHAP values per classe 277: [[ 0.23475242 -0.05089023 -0.12549687 -0.05501445]\n",
      " [ 0.09737655 -0.02965609  0.15349957 -0.22768882]\n",
      " [ 0.02494664 -0.01972083  0.          0.        ]\n",
      " [ 0.0497071  -0.02424176  0.          0.        ]\n",
      " [ 0.05636926 -0.08053445  0.          0.01415379]]\n",
      "SHAP values per classe 278: [[ 0.26837007 -0.02450001 -0.08695742 -0.15177706]\n",
      " [ 0.          0.          0.          0.03016223]\n",
      " [ 0.          0.          0.          0.026588  ]\n",
      " [ 0.05073001 -0.13234019  0.04007753  0.02257764]\n",
      " [ 0.01103747 -0.06111576  0.          0.02206618]]\n",
      "SHAP values per classe 279: [[-0.15526868  0.04138676  0.10167757  0.        ]\n",
      " [-0.0255873   0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.10486618  0.07343726  0.02722519]\n",
      " [ 0.          0.          0.          0.01586724]]\n",
      "SHAP values per classe 280: [[-0.00917994  0.          0.          0.        ]\n",
      " [-0.00388661  0.          0.          0.        ]\n",
      " [-0.01599204  0.          0.          0.        ]\n",
      " [ 0.         -0.06367787  0.04242295  0.        ]\n",
      " [ 0.         -0.02386244  0.          0.        ]]\n",
      "SHAP values per classe 281: [[-0.175163   -0.04901727  0.20675123  0.0223682 ]\n",
      " [ 0.          0.00548962  0.         -0.03327417]\n",
      " [ 0.         -0.03671414  0.          0.02473181]\n",
      " [ 0.         -0.09150967  0.08231117  0.01075762]\n",
      " [ 0.         -0.12198781  0.1014738   0.00978641]]\n",
      "SHAP values per classe 282: [[-0.06119425  0.          0.          0.        ]\n",
      " [-0.00566889  0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.02414894  0.04014542  0.        ]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 283: [[ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.09131944 -0.04707717]\n",
      " [ 0.         -0.03155381  0.          0.        ]\n",
      " [ 0.         -0.06899406  0.04654052  0.        ]\n",
      " [ 0.         -0.01739042  0.          0.00795444]]\n",
      "SHAP values per classe 284: [[ 0.65590378 -0.23462162 -0.17695466 -0.21363646]\n",
      " [ 0.          0.          0.00831178  0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.0290447  -0.06808685  0.03449994  0.        ]\n",
      " [ 0.         -0.02757836  0.00487165  0.        ]]\n",
      "SHAP values per classe 285: [[-0.07514155  0.          0.          0.00847085]\n",
      " [-0.01054444  0.          0.          0.        ]\n",
      " [ 0.          0.03557071  0.01576227  0.        ]\n",
      " [ 0.         -0.04855086  0.04326435  0.03198926]\n",
      " [ 0.         -0.044321    0.          0.        ]]\n",
      "SHAP values per classe 286: [[-0.13949077  0.14285568  0.          0.        ]\n",
      " [-0.00948968  0.00319635  0.          0.        ]\n",
      " [-0.02158908  0.01094826  0.          0.        ]\n",
      " [-0.04869203  0.29954478 -0.23760067 -0.04302751]\n",
      " [ 0.          0.10536487 -0.11253283 -0.00664396]]\n",
      "SHAP values per classe 287: [[-0.13859542  0.          0.11727811  0.04358523]\n",
      " [-0.01198826  0.02080248 -0.04276871  0.03193535]\n",
      " [-0.00112042  0.          0.          0.        ]\n",
      " [ 0.         -0.0687993   0.03157567  0.        ]\n",
      " [ 0.         -0.02765033  0.0170874   0.        ]]\n",
      "SHAP values per classe 288: [[ 0.26004498 -0.25502863 -0.02377632 -0.01502812]\n",
      " [ 0.017431   -0.00958432  0.          0.        ]\n",
      " [ 0.          0.01081835  0.0557531   0.        ]\n",
      " [ 0.10712269 -0.14854623  0.03540276  0.        ]\n",
      " [ 0.03599469  0.          0.          0.        ]]\n",
      "SHAP values per classe 289: [[-0.09825516  0.0252449   0.03093012  0.07025266]\n",
      " [ 0.          0.          0.         -0.01098657]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.07821691  0.05475141  0.03481877]\n",
      " [ 0.         -0.03546229  0.02984562  0.01381882]]\n",
      "SHAP values per classe 290: [[-0.13642632  0.          0.0450859   0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.00655289  0.          0.         -0.01406313]\n",
      " [ 0.00015259  0.          0.04643741  0.        ]\n",
      " [ 0.          0.          0.         -0.08546358]]\n",
      "SHAP values per classe 291: [[ 0.3035087  -0.05720995 -0.07079013 -0.09922307]\n",
      " [ 0.23083155 -0.06820478  0.         -0.13048042]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.01885481 -0.07835181  0.05350784  0.        ]\n",
      " [ 0.03210827 -0.04470651 -0.02554377  0.        ]]\n",
      "SHAP values per classe 292: [[-7.68310967e-02  1.45602792e-02  4.65191387e-02  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  9.29385445e-05  0.00000000e+00]\n",
      " [-9.07066074e-03  5.45867623e-03  0.00000000e+00  0.00000000e+00]\n",
      " [-1.27248937e-01  7.11340792e-01 -3.76724928e-01 -1.64527402e-01]\n",
      " [ 0.00000000e+00 -1.84271902e-02  1.71887130e-02  0.00000000e+00]]\n",
      "SHAP values per classe 293: [[-0.11613555 -0.00469038  0.          0.01076821]\n",
      " [-0.04536375  0.13931429  0.00116708 -0.00331343]\n",
      " [-0.01775847  0.          0.          0.        ]\n",
      " [-0.00852144  0.02023399  0.         -0.03833453]\n",
      " [-0.03446077  0.1672673  -0.06535268  0.        ]]\n",
      "SHAP values per classe 294: [[-0.14577005  0.01781352  0.09583654  0.05649562]\n",
      " [-0.01548841  0.00139169  0.          0.        ]\n",
      " [ 0.          0.00024786  0.          0.        ]\n",
      " [-0.00104564 -0.11719359  0.04430001  0.03495035]\n",
      " [ 0.         -0.05371611  0.          0.01794839]]\n",
      "SHAP values per classe 295: [[-0.1307879   0.07523559  0.03726732  0.        ]\n",
      " [-0.01790132  0.          0.          0.        ]\n",
      " [-0.01790537  0.          0.          0.        ]\n",
      " [-0.03481488  0.35324241 -0.27113208 -0.01504426]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 296: [[-0.06421768  0.          0.          0.08668095]\n",
      " [ 0.          0.          0.          0.00933564]\n",
      " [ 0.         -0.02462048  0.          0.        ]\n",
      " [ 0.         -0.06288736  0.05115565  0.        ]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 297: [[-1.14950183e-01  8.27750701e-02  4.49060259e-02  0.00000000e+00]\n",
      " [-3.64041817e-02  4.01947135e-02  0.00000000e+00  0.00000000e+00]\n",
      " [ 3.36471385e-04  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [-8.49403219e-02  4.83939859e-01 -2.64225261e-01 -1.27620567e-01]\n",
      " [ 0.00000000e+00 -1.90414304e-02  2.13383767e-02  0.00000000e+00]]\n",
      "SHAP values per classe 298: [[-0.13850376  0.03225188  0.06992692  0.02547591]\n",
      " [-0.02159308  0.          0.01185482  0.        ]\n",
      " [ 0.          0.          0.          0.02978731]\n",
      " [-0.03428113  0.29215663 -0.19978979 -0.05458188]\n",
      " [-0.00661866  0.02389106  0.          0.        ]]\n",
      "SHAP values per classe 299: [[-0.17855581  0.03054638  0.1453145   0.01430868]\n",
      " [-0.02123425  0.          0.          0.        ]\n",
      " [-0.02612298  0.          0.          0.00325963]\n",
      " [ 0.         -0.12131857  0.          0.        ]\n",
      " [ 0.         -0.06798578  0.07125321  0.        ]]\n",
      "SHAP values per classe 300: [[-0.08602573  0.02596785  0.04288547  0.00951434]\n",
      " [-0.01426695  0.          0.          0.01669806]\n",
      " [ 0.         -0.036333    0.02948748  0.        ]\n",
      " [ 0.         -0.07110021  0.04021109  0.03283739]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 301: [[-0.14506424  0.10141098  0.03912726  0.        ]\n",
      " [-0.01523871  0.02179349 -0.01401094  0.        ]\n",
      " [-0.03625953  0.04219203  0.          0.        ]\n",
      " [-0.02580575  0.10535446 -0.06883147 -0.00650217]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 302: [[ 0.3288132  -0.15520757 -0.1935296  -0.02953466]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.00109128  0.          0.          0.        ]\n",
      " [ 0.1094977  -0.12999746  0.          0.00688291]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP GED: 11.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training del detector...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib/python3.9/site-packages/albumentations/core/bbox_utils.py:476: RuntimeWarning: invalid value encountered in divide\n",
      "  & (clipped_box_areas / denormalized_box_areas >= min_visibility - epsilon)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint salvato per l'epoca 9.\n",
      "------------------\n",
      "Epoch 11/150\n",
      "Inference completata\n",
      "Load .json metadata:  ./tmp/train/B_20181212_110313.json\n",
      "Load .json metadata:  ./tmp/train/B_5bed71eae40c4.json\n",
      "Load .json metadata:  ./tmp/train/B_20181212_110321.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_mihrab_mezquita_cordoba.json\n",
      "Load .json metadata:  ./tmp/train/B_5bad4cbc18c44.json\n",
      "Load .json metadata:  ./tmp/train/R_5c1f82413637d.json\n",
      "Load .json metadata:  ./tmp/train/G_5c67d991a4cf7.json\n",
      "Load .json metadata:  ./tmp/train/B_5dd7d6e26f601.json\n",
      "Load .json metadata:  ./tmp/train/M_alcazaba_malaga3.json\n",
      "Load .json metadata:  ./tmp/train/G_casa_bailio_cordoba.json\n",
      "Load .json metadata:  ./tmp/train/G_5babc82fc022f.json\n",
      "Load .json metadata:  ./tmp/train/M_5e4fb912bf15b.json\n",
      "Load .json metadata:  ./tmp/train/R_5c75195fbb8f2.json\n",
      "Load .json metadata:  ./tmp/train/G_5bb8f33edfa1f.json\n",
      "Load .json metadata:  ./tmp/train/M_5bb0d93bcd653.json\n",
      "Load .json metadata:  ./tmp/train/B_5c15322219e6f.json\n",
      "Load .json metadata:  ./tmp/train/B_facultad_derecho_granada2.json\n",
      "Load .json metadata:  ./tmp/train/M_patio_yeso_reales_alcazares_sevilla3.json\n",
      "Load .json metadata:  ./tmp/train/B_iglesia_caridad_sevilla2.json\n",
      "Load .json metadata:  ./tmp/train/M_20181212_112649.json\n",
      "Load .json metadata:  ./tmp/train/R_ayuntamiento_baeza3.json\n",
      "Load .json metadata:  ./tmp/train/R_5bc0b3ee639ce.json\n",
      "Load .json metadata:  ./tmp/train/B_convento_siervas_de_maria_granada.json\n",
      "Load .json metadata:  ./tmp/train/B_casa_almirante_cadiz2.json\n",
      "Load .json metadata:  ./tmp/train/G_20181212_105119.json\n",
      "Load .json metadata:  ./tmp/train/G_catedral_leon12.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc76ea8caf7b.json\n",
      "Load .json metadata:  ./tmp/train/M_medina_azahara3.json\n",
      "Load .json metadata:  ./tmp/train/G_5baeaa86ac71e.json\n",
      "Load .json metadata:  ./tmp/train/B_catedral_granada4.json\n",
      "Load .json metadata:  ./tmp/train/M_5bae5bf050e24.json\n",
      "Load .json metadata:  ./tmp/train/M_5baf14eb92e6d.json\n",
      "Load .json metadata:  ./tmp/train/B_5c80ebc6ddf27.json\n",
      "Load .json metadata:  ./tmp/train/B_iglesia_gracia_granada.json\n",
      "Load .json metadata:  ./tmp/train/G_iglesia_san_nicolas_ubeda4.json\n",
      "Load .json metadata:  ./tmp/train/R_5bf7c972311d4.json\n",
      "Load .json metadata:  ./tmp/train/M_5bec1e4b72f12.json\n",
      "Load .json metadata:  ./tmp/train/B_iglesia_caridad_sevilla5.json\n",
      "Load .json metadata:  ./tmp/train/M_5bd579c5023a7.json\n",
      "Load .json metadata:  ./tmp/train/R_5bb5f3109fda8.json\n",
      "Load .json metadata:  ./tmp/train/B_santos_justo_pastor_granada8.json\n",
      "Load .json metadata:  ./tmp/train/G_casa_bailio_cordoba2.json\n",
      "Load .json metadata:  ./tmp/train/B_iglesia_san_jeronimo_granada3.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_del_vino_granada6.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_de_las_pesas_granada4.json\n",
      "Load .json metadata:  ./tmp/train/M_5bec1e6a04058.json\n",
      "Load .json metadata:  ./tmp/train/M_5de6b189c985e.json\n",
      "Load .json metadata:  ./tmp/train/B_museo_bellas_artes_sevilla6.json\n",
      "Load .json metadata:  ./tmp/train/M_5bae5eef7467f.json\n",
      "Load .json metadata:  ./tmp/train/M_20181212_115504.json\n",
      "Load .json metadata:  ./tmp/train/R_puerta_puente_cordoba15.json\n",
      "Load .json metadata:  ./tmp/train/B_5baff8c138f48.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc0ca38b7006.json\n",
      "Load .json metadata:  ./tmp/train/G_5cadb7eb3a84a.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_monaita_granada6.json\n",
      "Load .json metadata:  ./tmp/train/B_5bdb2454edef4.json\n",
      "Load .json metadata:  ./tmp/train/G_catedral_leon10.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_san_isidro_mezquita_cordoba5.json\n",
      "Load .json metadata:  ./tmp/train/B_5bebfefce3f27.json\n",
      "Load .json metadata:  ./tmp/train/G_5b8ecc4c3cde4.json\n",
      "Load .json metadata:  ./tmp/train/G_5baf18213b6f1.json\n",
      "Load .json metadata:  ./tmp/train/G_iglesia_santa_maría_del_pi_barcelona3.json\n",
      "Load .json metadata:  ./tmp/train/R_casa_cabildo_jerez6.json\n",
      "Load .json metadata:  ./tmp/train/B_5c48452e4af47.json\n",
      "Load .json metadata:  ./tmp/train/M_5d99bad3a10f2.json\n",
      "Load .json metadata:  ./tmp/train/R_puerta_puente_cordoba4.json\n",
      "Load .json metadata:  ./tmp/train/R_plaza_santa_teresa_ubeda3.json\n",
      "Load .json metadata:  ./tmp/train/B_casa_marqueses_de_cartagena_granada4.json\n",
      "Load .json metadata:  ./tmp/train/B_colegio_bartolome_santiago_granada.json\n",
      "Load .json metadata:  ./tmp/train/G_5b8d77afb94e9.json\n",
      "Load .json metadata:  ./tmp/train/R_5bd6baf8e455c.json\n",
      "Load .json metadata:  ./tmp/train/B_basilica_angustias_granada3.json\n",
      "Load .json metadata:  ./tmp/train/B_5bacbbeed360e.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_monaita_granada5.json\n",
      "Load .json metadata:  ./tmp/train/B_casa-mariana_pineda_granada.json\n",
      "Load .json metadata:  ./tmp/train/R_5bdefaf7351c6.json\n",
      "Load .json metadata:  ./tmp/train/R_palacio_cadenas_ubeda.json\n",
      "Load .json metadata:  ./tmp/train/G_hospital_san_sebastian_cordoba9.json\n",
      "Load .json metadata:  ./tmp/train/G_torre_fadrique2.json\n",
      "Load .json metadata:  ./tmp/train/G_convento_clarisas_palencia4.json\n",
      "Load .json metadata:  ./tmp/train/M_medina_azahara23.json\n",
      "Load .json metadata:  ./tmp/train/G_casa_abrantes_granada6.json\n",
      "Load .json metadata:  ./tmp/train/B_catedral_guadix2.json\n",
      "Load .json metadata:  ./tmp/train/B_5c878e7d3d3f0.json\n",
      "Load .json metadata:  ./tmp/train/G_5de139e53bea1.json\n",
      "Load .json metadata:  ./tmp/train/M_dintel_adovelado5.json\n",
      "Load .json metadata:  ./tmp/train/B_san_felipe_neri_baeza.json\n",
      "Load .json metadata:  ./tmp/train/M_5bafb615991d4.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc765746e381.json\n",
      "Load .json metadata:  ./tmp/train/B_5c14f6b287d17.json\n",
      "Load .json metadata:  ./tmp/train/G_5c62923184bbc.json\n",
      "Load .json metadata:  ./tmp/train/B_casa_cadenas_cadiz3.json\n",
      "Load .json metadata:  ./tmp/train/G_casa_zafra_granada.json\n",
      "Load .json metadata:  ./tmp/train/B_iglesia_caridad_sevilla6.json\n",
      "Load .json metadata:  ./tmp/train/B_5bb0aaee9afc9.json\n",
      "Load .json metadata:  ./tmp/train/B_5dd8f69aee967.json\n",
      "Load .json metadata:  ./tmp/train/M_5c38860a8e338.json\n",
      "Load .json metadata:  ./tmp/train/R_5bb35143c8292.json\n",
      "Load .json metadata:  ./tmp/train/R_20181212_110343.json\n",
      "Load .json metadata:  ./tmp/train/M_5bbe3f16a2771.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc7645ea64dc.json\n",
      "Load .json metadata:  ./tmp/train/G_puerta_apostoles_catedra_valencia3.json\n",
      "Load .json metadata:  ./tmp/train/M_20181212_115516.json\n",
      "Load .json metadata:  ./tmp/train/B_casa_museo_sefardi_granada2.json\n",
      "Load .json metadata:  ./tmp/train/M_5defb57b27d8b.json\n",
      "Load .json metadata:  ./tmp/train/R_5c07fc9b36ec9.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_monaita_granada2.json\n",
      "Load .json metadata:  ./tmp/train/B_palacio_quemadas_cordoba2.json\n",
      "Load .json metadata:  ./tmp/train/R_iglesia_guadahortuna3.json\n",
      "Load .json metadata:  ./tmp/train/M_5e4fb8674b6b0.json\n",
      "Load .json metadata:  ./tmp/train/M_corral_carbon_granada4.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_del_vino_granada12.json\n",
      "Load .json metadata:  ./tmp/train/R_casa_lonja_sevilla_patio.json\n",
      "Load .json metadata:  ./tmp/train/G_puerta_apostoles_catedra_valencia5.json\n",
      "Load .json metadata:  ./tmp/train/G_iglesia_san_nicolas_ubeda2.json\n",
      "Load .json metadata:  ./tmp/train/B_5ce90d44c81b5.json\n",
      "Load .json metadata:  ./tmp/train/M_medina_azahara16.json\n",
      "Load .json metadata:  ./tmp/train/M_5db2c2a620a94.json\n",
      "Load .json metadata:  ./tmp/train/R_san_pedro_cordoba6.json\n",
      "Load .json metadata:  ./tmp/train/R_5bc601592c5ae.json\n",
      "Load .json metadata:  ./tmp/train/B_iglesia_san_juan_de_dios_granada.json\n",
      "Load .json metadata:  ./tmp/train/B_5c4c5d588f969.json\n",
      "Load .json metadata:  ./tmp/train/G_catedral_burgos11.json\n",
      "Load .json metadata:  ./tmp/train/R_5bae51ba6d784.json\n",
      "Load .json metadata:  ./tmp/train/M_5bd35122f11d2.json\n",
      "Load .json metadata:  ./tmp/train/B_5d9e1bfaeb1b0.json\n",
      "Load .json metadata:  ./tmp/train/M_5db2e7f92118d.json\n",
      "Load .json metadata:  ./tmp/train/G_puerta_apostoles_catedra_valencia7.json\n",
      "Load .json metadata:  ./tmp/train/R_5bc2c464cce14.json\n",
      "Load .json metadata:  ./tmp/train/R_iglesia_salvador_ubeda3.json\n",
      "Load .json metadata:  ./tmp/train/M_5bdec6139317d.json\n",
      "Load .json metadata:  ./tmp/train/B_5bbb3a49e5e1d.json\n",
      "Load .json metadata:  ./tmp/train/B_5d98e54e59775.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_elvira_granada3.json\n",
      "Load .json metadata:  ./tmp/train/G_puerta_apostoles_catedral_valencia.json\n",
      "Load .json metadata:  ./tmp/train/B_5c7be6a013c47.json\n",
      "Load .json metadata:  ./tmp/train/M_5bba4d3b86c50.json\n",
      "Load .json metadata:  ./tmp/train/R_5bc4cf3b20c2e.json\n",
      "Load .json metadata:  ./tmp/train/G_iglesia_san_pablo_ubeda5.json\n",
      "Load .json metadata:  ./tmp/train/B_convento_esclavas_puerto_santa_maria.json\n",
      "Load .json metadata:  ./tmp/train/B_5da39ec706056.json\n",
      "Load .json metadata:  ./tmp/train/M_medina_azahara5.json\n",
      "Load .json metadata:  ./tmp/train/G_catedral_burgos9.json\n",
      "Load .json metadata:  ./tmp/train/G_iglesia_san_pablo_ubeda8.json\n",
      "Load .json metadata:  ./tmp/train/R_carcel_martos5.json\n",
      "Load .json metadata:  ./tmp/train/M_5e4fb7d4eb466.json\n",
      "Load .json metadata:  ./tmp/train/G_5cb4506788a6c.json\n",
      "Load .json metadata:  ./tmp/train/G_casa_inquisicion_alhama.json\n",
      "Load .json metadata:  ./tmp/train/B_chancilleria_granada5.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc4cdf0585e4.json\n",
      "Load .json metadata:  ./tmp/train/M_20181212_145543.json\n",
      "Load .json metadata:  ./tmp/train/G_alcazaba-almeria.json\n",
      "Load .json metadata:  ./tmp/train/R_casa_cabildo_jerez5.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc76500a43e5.json\n",
      "Load .json metadata:  ./tmp/train/R_5bcaed60a57a5.json\n",
      "Load .json metadata:  ./tmp/train/M_dintel_adovelado4.json\n",
      "Load .json metadata:  ./tmp/train/B_5bae520c3096f.json\n",
      "Load .json metadata:  ./tmp/train/M_patio_yeso_reales_alcazares_sevilla4.json\n",
      "Load .json metadata:  ./tmp/train/G_monasterio_concepcion_granada4.json\n",
      "Load .json metadata:  ./tmp/train/G_catedral_leon8.json\n",
      "Load .json metadata:  ./tmp/train/R_5bae6379a7219.json\n",
      "Load .json metadata:  ./tmp/train/B_5d90ba3786f84.json\n",
      "Load .json metadata:  ./tmp/train/B_5bacbc2c46129.json\n",
      "Load .json metadata:  ./tmp/train/G_5d853bf14c54f.json\n",
      "Load .json metadata:  ./tmp/train/M_aljibe_san_miguel_bajo.json\n",
      "Load .json metadata:  ./tmp/train/M_5bb0a6a0a9219.json\n",
      "Load .json metadata:  ./tmp/train/M_alcazaba_malaga2.json\n",
      "Load .json metadata:  ./tmp/train/R_5da5cd3e7a1ca.json\n",
      "Load .json metadata:  ./tmp/train/B_5baff87c5d061.json\n",
      "Load .json metadata:  ./tmp/train/B_5bd34562c7157.json\n",
      "Load .json metadata:  ./tmp/train/G_palacio_jabalquinto_baeza13.json\n",
      "Load .json metadata:  ./tmp/train/G_5bac8c5becc42.json\n",
      "Load .json metadata:  ./tmp/train/B_5c191ae226d3d.json\n",
      "Load .json metadata:  ./tmp/train/B_palacio_quemadas_cordoba3.json\n",
      "Load .json metadata:  ./tmp/train/G_5cf2f7b8bb83b.json\n",
      "Load .json metadata:  ./tmp/train/M_5e4fd06f4005c.json\n",
      "Load .json metadata:  ./tmp/train/G_hospital_san_sebastian_cordoba4.json\n",
      "Load .json metadata:  ./tmp/train/M_medina_azahara22.json\n",
      "Load .json metadata:  ./tmp/train/R_puerta_puente_cordoba16.json\n",
      "Load .json metadata:  ./tmp/train/R_5bb897329f5cd.json\n",
      "Load .json metadata:  ./tmp/train/R_5bb90da49c913.json\n",
      "Load .json metadata:  ./tmp/train/B_5c13837ca48df.json\n",
      "Load .json metadata:  ./tmp/train/G_catedral_sevilla6.json\n",
      "Load .json metadata:  ./tmp/train/M_5bf678c169e06.json\n",
      "Load .json metadata:  ./tmp/train/B_5cadbcbc0e666.json\n",
      "Load .json metadata:  ./tmp/train/M_5bcaecccd162f.json\n",
      "Load .json metadata:  ./tmp/train/G_catedral_leon2.json\n",
      "Load .json metadata:  ./tmp/train/B_5df7681a6a1d3.json\n",
      "Load .json metadata:  ./tmp/train/M_alminar_san_jose_granada6.json\n",
      "Load .json metadata:  ./tmp/train/M_20181212_115543.json\n",
      "Load .json metadata:  ./tmp/train/B_santos_justo_pastor_granada3.json\n",
      "Load .json metadata:  ./tmp/train/R_5c1914b7dafda.json\n",
      "Load .json metadata:  ./tmp/train/M_5dd41d557867b.json\n",
      "Load .json metadata:  ./tmp/train/M_5c879cd0ed2cc.json\n",
      "Load .json metadata:  ./tmp/train/R_puerta_puente_cordoba10.json\n",
      "Load .json metadata:  ./tmp/train/G_puerta_bautismo_catedral_sevilla9.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_justicia_granada2.json\n",
      "Load .json metadata:  ./tmp/train/M_5bdedf6d54d29.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_justicia_granada.json\n",
      "Load .json metadata:  ./tmp/train/R_carcel_martos3.json\n",
      "Load .json metadata:  ./tmp/train/R_5c1903a4925ea.json\n",
      "Load .json metadata:  ./tmp/train/B_colegio_san_telmo_sevilla6.json\n",
      "Load .json metadata:  ./tmp/train/G_5d3da546e111e.json\n",
      "Load .json metadata:  ./tmp/train/G_casa_zafra_granada5.json\n",
      "Load .json metadata:  ./tmp/train/G_catedral_toledo2.json\n",
      "Load .json metadata:  ./tmp/train/R_5df9f2036b740.json\n",
      "Load .json metadata:  ./tmp/train/G_5de134de77277.json\n",
      "Load .json metadata:  ./tmp/train/B_convento_magdalena_granada.json\n",
      "Load .json metadata:  ./tmp/train/G_5cc07126bd06d.json\n",
      "Load .json metadata:  ./tmp/train/R_5bb350a2e289a.json\n",
      "Load .json metadata:  ./tmp/train/B_5c4065a551b5d.json\n",
      "Load .json metadata:  ./tmp/train/B_5bd07567077f8.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_elvira_granada2.json\n",
      "Load .json metadata:  ./tmp/train/R_casa_torres_ubeda3.json\n",
      "Load .json metadata:  ./tmp/train/G_catedral_burgos.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc0c8c89fd21.json\n",
      "Load .json metadata:  ./tmp/train/G_casa_abrantes_granada4.json\n",
      "Load .json metadata:  ./tmp/train/M_5db2c2d58820d.json\n",
      "Load .json metadata:  ./tmp/train/B_5ce8393752ba0.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc7645dbbec1.json\n",
      "Load .json metadata:  ./tmp/train/R_iglesia_san_andres.json\n",
      "Load .json metadata:  ./tmp/train/B_chancilleria_granada14.json\n",
      "Load .json metadata:  ./tmp/train/G_palacio_jabalquinto_baeza11.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_monaita_granada.json\n",
      "Load .json metadata:  ./tmp/train/G_5bc1d52645376.json\n",
      "Load .json metadata:  ./tmp/train/R_5c9d17dc28b0e.json\n",
      "Load .json metadata:  ./tmp/train/M_alminar_san_jose_granada4.json\n",
      "Load .json metadata:  ./tmp/train/M_corral_carbon_granada2.json\n",
      "Load .json metadata:  ./tmp/train/G_puerta_apostoles_catedra_valencia2.json\n",
      "Load .json metadata:  ./tmp/train/R_puerta_puente_cordoba5.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc765017d63d.json\n",
      "Load .json metadata:  ./tmp/train/G_casa_abrantes_granada7.json\n",
      "Load .json metadata:  ./tmp/train/R_5bf67925573b1.json\n",
      "Load .json metadata:  ./tmp/train/B_casa_almirante_cadiz5.json\n",
      "Load .json metadata:  ./tmp/train/B_palacio_quemadas_cordoba.json\n",
      "Load .json metadata:  ./tmp/train/G_palacio_jabalquinto_baeza2.json\n",
      "Load .json metadata:  ./tmp/train/B_5bb0b452a19f9.json\n",
      "Load .json metadata:  ./tmp/train/G_catedral_leon6.json\n",
      "Load .json metadata:  ./tmp/train/R_ayuntamiento_baeza13.json\n",
      "Load .json metadata:  ./tmp/train/B_palacio_ansoti_granada9.json\n",
      "Load .json metadata:  ./tmp/train/B_5b8a5bebf2b05.json\n",
      "Load .json metadata:  ./tmp/train/M_20181212_145535.json\n",
      "Load .json metadata:  ./tmp/train/R_palacio_cadenas_ubeda6.json\n",
      "Load .json metadata:  ./tmp/train/G_5d9f62eb395ce.json\n",
      "Load .json metadata:  ./tmp/train/M_5c879cb97a78b.json\n",
      "Load .json metadata:  ./tmp/train/G_hospital_san_sebastian_cordoba3.json\n",
      "Load .json metadata:  ./tmp/train/G_torre_fadrique.json\n",
      "Load .json metadata:  ./tmp/train/G_5cc07109e57de.json\n",
      "Load .json metadata:  ./tmp/train/G_5c4838d6e0fd8.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc8b5000bde2.json\n",
      "Load .json metadata:  ./tmp/train/B_iglesia_angustias_granada2.json\n",
      "Load .json metadata:  ./tmp/train/M_medina_azahara32.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc765338c390.json\n",
      "Load .json metadata:  ./tmp/train/M_5cad9cd45d2e9.json\n",
      "Load .json metadata:  ./tmp/train/G_5bb28d496a53a.json\n",
      "Load .json metadata:  ./tmp/train/M_medina_azahara28.json\n",
      "Load .json metadata:  ./tmp/train/B_5baf982ee2bfd.json\n",
      "Load .json metadata:  ./tmp/train/M_5d31db347e7fe.json\n",
      "Load .json metadata:  ./tmp/train/B_5e3ec0560f9a0.json\n",
      "Load .json metadata:  ./tmp/train/G_5c13847fdc587.json\n",
      "Load .json metadata:  ./tmp/train/B_casa_almirante_cadiz3.json\n",
      "Load .json metadata:  ./tmp/train/G_iglesia_san_pablo_ubeda7.json\n",
      "Load .json metadata:  ./tmp/train/R_5bb78e09c8a9a.json\n",
      "Load .json metadata:  ./tmp/train/B_IMG_0357.json\n",
      "Load .json metadata:  ./tmp/train/R_5c7134cd2811e.json\n",
      "Load .json metadata:  ./tmp/train/M_5d9dcd1b591de.json\n",
      "Load .json metadata:  ./tmp/train/B_catedral_jaen3.json\n",
      "Load .json metadata:  ./tmp/train/R_iglesia_san_cecilio_granada5.json\n",
      "Load .json metadata:  ./tmp/train/R_palacio_carlos_v_granada18.json\n",
      "Load .json metadata:  ./tmp/train/B_compas_convento_santa_isabel_granada3.json\n",
      "Load .json metadata:  ./tmp/train/G_casa_abrantes_granada3.json\n",
      "Load .json metadata:  ./tmp/train/B_casa_museo_sefardi_granada.json\n",
      "Load .json metadata:  ./tmp/train/B_5df11afa505fc.json\n",
      "Load .json metadata:  ./tmp/train/G_iglesia_sabiote.json\n",
      "Load .json metadata:  ./tmp/train/M_5dd41b35bc692.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc75ff931f5d.json\n",
      "Load .json metadata:  ./tmp/train/B_iglesia_san_pedro_pablo_granada3.json\n",
      "Load .json metadata:  ./tmp/train/M_5bbcca54787e1.json\n",
      "Load .json metadata:  ./tmp/train/M_5bec3b41cead0.json\n",
      "Load .json metadata:  ./tmp/train/B_convento_carmelitas_descalzas_granada4.json\n",
      "Load .json metadata:  ./tmp/train/R_iglesia_asuncion_jodar.json\n",
      "Load .json metadata:  ./tmp/train/G_monasterio_concepcion_granada3.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc75fefdc08e.json\n",
      "Load .json metadata:  ./tmp/train/B_5baf578813fe8.json\n",
      "Load .json metadata:  ./tmp/train/B_5be5b11d168b4.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc75e0d6a8e0.json\n",
      "Load .json metadata:  ./tmp/train/G_iglesia_sabiote5.json\n",
      "Load .json metadata:  ./tmp/train/B_5bacb65418a73.json\n",
      "Load .json metadata:  ./tmp/train/B_casa_marqueses_caicedo_granada.json\n",
      "Load .json metadata:  ./tmp/train/R_iglesia_anunciacion_sevilla.json\n",
      "Load .json metadata:  ./tmp/train/B_5bb0a2afa286c.json\n",
      "Load .json metadata:  ./tmp/train/M_20181212_113410.json\n",
      "Load .json metadata:  ./tmp/train/G_catedral_burgos10.json\n",
      "Load .json metadata:  ./tmp/train/G_catedral_leon3.json\n",
      "Load .json metadata:  ./tmp/train/M_5bec3b6fce57a.json\n",
      "Load .json metadata:  ./tmp/train/R_iglesia_guadahortuna2.json\n",
      "Load .json metadata:  ./tmp/train/M_5d99bc04097a3.json\n",
      "Load .json metadata:  ./tmp/train/B_catedral_granada6.json\n",
      "Load .json metadata:  ./tmp/train/G_5bdf14be71c61.json\n",
      "Load .json metadata:  ./tmp/train/B_IMG_0330.json\n",
      "Load .json metadata:  ./tmp/train/M_5baf1bc3da161.json\n",
      "Load .json metadata:  ./tmp/train/R_iglesia_del_sagrario_jaen2.json\n",
      "Load .json metadata:  ./tmp/train/M_alminar_san_jose_granada3.json\n",
      "Load .json metadata:  ./tmp/train/G_iglesia_san_pablo_ubeda4.json\n",
      "Load .json metadata:  ./tmp/train/M_5c7bc23b3c8df.json\n",
      "Load .json metadata:  ./tmp/train/R_5bf817556125f.json\n",
      "Load .json metadata:  ./tmp/train/R_palacio_carlos_v_granada2.json\n",
      "Load .json metadata:  ./tmp/train/B_5ddba404ec262.json\n",
      "Load .json metadata:  ./tmp/train/B_5bd33eb67044c.json\n",
      "Load .json metadata:  ./tmp/train/B_5bb5f3dfac1c3.json\n",
      "Load .json metadata:  ./tmp/train/G_casa_zafra_granada3.json\n",
      "Load .json metadata:  ./tmp/train/M_medina_azahara34.json\n",
      "Load .json metadata:  ./tmp/train/G_capilla_real_granada3.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_de_las_pesas_granada5.json\n",
      "Load .json metadata:  ./tmp/train/G_5bcaece80705a.json\n",
      "Load .json metadata:  ./tmp/train/R_iglesia_san_jeronimo_granada.json\n",
      "Load .json metadata:  ./tmp/train/B_5bad4af6cbe6a.json\n",
      "Load .json metadata:  ./tmp/train/G_5da5cf2a09f80.json\n",
      "Load .json metadata:  ./tmp/train/R_5bf817543af18.json\n",
      "Load .json metadata:  ./tmp/train/B_palacio_ansoti2.json\n",
      "Load .json metadata:  ./tmp/train/B_casa_marqueses_caicedo_granada2.json\n",
      "Load .json metadata:  ./tmp/train/R_5bd575da84afe.json\n",
      "Load .json metadata:  ./tmp/train/R_iglesia_del_sagrario_jaen.json\n",
      "Load .json metadata:  ./tmp/train/B_convento_carmelitas_descalzas_granada6.json\n",
      "Load .json metadata:  ./tmp/train/G_5da6fe91a1b08.json\n",
      "Load .json metadata:  ./tmp/train/M_5c82f4cdc538e.json\n",
      "Load .json metadata:  ./tmp/train/R_puerta_puente_cordoba13.json\n",
      "Load .json metadata:  ./tmp/train/M_5bdee1652730b.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc7649e7f853.json\n",
      "Load .json metadata:  ./tmp/train/M_5db444d933327.json\n",
      "Load .json metadata:  ./tmp/train/G_catedral_burgos8.json\n",
      "Load .json metadata:  ./tmp/train/M_medina_azahara8.json\n",
      "Load .json metadata:  ./tmp/train/B_san_felipe_neri_baeza2.json\n",
      "Load .json metadata:  ./tmp/train/M_5c45b1d2472c7.json\n",
      "Load .json metadata:  ./tmp/train/M_5b8eceba8b412.json\n",
      "Load .json metadata:  ./tmp/train/G_5db2fc59d9b68.json\n",
      "Load .json metadata:  ./tmp/train/R_5bded6103ee40.json\n",
      "Load .json metadata:  ./tmp/train/B_5bb71c65a6474.json\n",
      "Load .json metadata:  ./tmp/train/B_5cb9a29a5424f.json\n",
      "Load .json metadata:  ./tmp/train/R_5bc9b16bd7277.json\n",
      "Load .json metadata:  ./tmp/train/R_palacio_cadenas_ubeda16.json\n",
      "Load .json metadata:  ./tmp/train/M_medina_azahara6.json\n",
      "Load .json metadata:  ./tmp/train/B_iglesia_caridad_sevilla9.json\n",
      "Load .json metadata:  ./tmp/train/G_5ced8dfa04cf1.json\n",
      "Load .json metadata:  ./tmp/train/R_5bcdbfa0a31fb.json\n",
      "Load .json metadata:  ./tmp/train/R_san_grabiel_loja2.json\n",
      "Load .json metadata:  ./tmp/train/B_iglesia_caridad_sevilla8.json\n",
      "Load .json metadata:  ./tmp/train/B_iglesia_san_francisco_cordoba.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc764f8d06ab.json\n",
      "Load .json metadata:  ./tmp/train/R_colegio_niñas_nobles_granada3.json\n",
      "Load .json metadata:  ./tmp/train/B_5bd354095e856.json\n",
      "Load .json metadata:  ./tmp/train/B_5bdb228d13793.json\n",
      "Load .json metadata:  ./tmp/train/G_5dd41b5a94b5e.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc75e652da1b.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc4d231daaf1.json\n",
      "Load .json metadata:  ./tmp/train/B_5c14f51720f9a.json\n",
      "Load .json metadata:  ./tmp/train/G_5c010d67518b6.json\n",
      "Load .json metadata:  ./tmp/train/M_5bd753b475e1b.json\n",
      "Load .json metadata:  ./tmp/train/G_5bc8af93c364c.json\n",
      "Load .json metadata:  ./tmp/train/B_iglesia_señora_gracia_estepa.json\n",
      "Load .json metadata:  ./tmp/train/G_monasterio_concepcion_granada.json\n",
      "Load .json metadata:  ./tmp/train/B_5c2ba60f43651.json\n",
      "Load .json metadata:  ./tmp/train/B_5bb0b4dfa6fc4.json\n",
      "Load .json metadata:  ./tmp/train/M_5bd3504ad94ce.json\n",
      "Load .json metadata:  ./tmp/train/B_5bccafb89cf2f.json\n",
      "Load .json metadata:  ./tmp/train/M_aljibe_san_miguel_bajo4.json\n",
      "Load .json metadata:  ./tmp/train/G_catedral_leon9.json\n",
      "Load .json metadata:  ./tmp/train/R_convento_santa_clara_ubeda2.json\n",
      "Load .json metadata:  ./tmp/train/G_5b8ecc074657b.json\n",
      "Load .json metadata:  ./tmp/train/R_iglesia_del_sagrario_jaen5.json\n",
      "Load .json metadata:  ./tmp/train/B_5bec3a03c184c.json\n",
      "Load .json metadata:  ./tmp/train/G_5c82f51ed64ae.json\n",
      "Load .json metadata:  ./tmp/train/M_20181212_122859.json\n",
      "Load .json metadata:  ./tmp/train/G_torre_fadrique4.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc764753c2e3.json\n",
      "Load .json metadata:  ./tmp/train/G_5bad4abe0539c.json\n",
      "Load .json metadata:  ./tmp/train/G_puerta_bautismo_catedral_sevilla3.json\n",
      "Load .json metadata:  ./tmp/train/B_5e53b78a07e5e.json\n",
      "Load .json metadata:  ./tmp/train/M_5bacb800b40e1.json\n",
      "Load .json metadata:  ./tmp/train/R_ayuntamiento_baeza5.json\n",
      "Load .json metadata:  ./tmp/train/R_5bd19e2979917.json\n",
      "Load .json metadata:  ./tmp/train/M_5c9d17c407acd.json\n",
      "Load .json metadata:  ./tmp/train/R_ayuntamiento_baeza8.json\n",
      "Load .json metadata:  ./tmp/train/M_5e4fbfcdcf33a.json\n",
      "Load .json metadata:  ./tmp/train/B_chancilleria_granada13.json\n",
      "Load .json metadata:  ./tmp/train/G_iglesia_san_miguel_cordoba2.json\n",
      "Load .json metadata:  ./tmp/train/R_5bb8b808d52c6.json\n",
      "Load .json metadata:  ./tmp/train/R_5bb28db47335d.json\n",
      "Load .json metadata:  ./tmp/train/B_fabrica_tabaco_sevilla8.json\n",
      "Load .json metadata:  ./tmp/train/G_catedral_burgos3.json\n",
      "Load .json metadata:  ./tmp/train/B_5bcdf5e2a5c10.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc306e82d209.json\n",
      "Load .json metadata:  ./tmp/train/G_puerta_bautismo_catedral_sevilla11.json\n",
      "Load .json metadata:  ./tmp/train/G_puerta_bautismo_catedral_sevilla12.json\n",
      "Load .json metadata:  ./tmp/train/B_5cf8001418164.json\n",
      "Load .json metadata:  ./tmp/train/G_5bdf0bf35d6ef.json\n",
      "Load .json metadata:  ./tmp/train/M_20181212_113415.json\n",
      "Load .json metadata:  ./tmp/train/M_5c7026209438f.json\n",
      "Load .json metadata:  ./tmp/train/B_santos_justo_pastor_granada7.json\n",
      "Load .json metadata:  ./tmp/train/M_patio_doncella_reales_alcazares_sevilla13.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc9a5fe2bed8.json\n",
      "Load .json metadata:  ./tmp/train/R_palacio_carlos_v_granada14.json\n",
      "Load .json metadata:  ./tmp/train/M_5bae64dc35949.json\n",
      "Load .json metadata:  ./tmp/train/M_corral_carbon_granada11.json\n",
      "Load .json metadata:  ./tmp/train/B_casa_marqueses_de_cartagena_granada3.json\n",
      "Load .json metadata:  ./tmp/train/B_IMG_0339.json\n",
      "Load .json metadata:  ./tmp/train/B_5b8ecb55cc725.json\n",
      "Load .json metadata:  ./tmp/train/R_5c024c2323973.json\n",
      "Load .json metadata:  ./tmp/train/B_5bf6cf1b04611.json\n",
      "Load .json metadata:  ./tmp/train/B_5c8cdc1b5564c.json\n",
      "Load .json metadata:  ./tmp/train/G_5b8eccf9cacde.json\n",
      "Load .json metadata:  ./tmp/train/B_carmelitas_calzadas_granada.json\n",
      "Load .json metadata:  ./tmp/train/G_5d98cc88e4a26.json\n",
      "Load .json metadata:  ./tmp/train/G_5ccefd1dbdf9e.json\n",
      "Load .json metadata:  ./tmp/train/R_20181212_110248.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc75e8d06c33.json\n",
      "Load .json metadata:  ./tmp/train/B_5be6b71806804.json\n",
      "Load .json metadata:  ./tmp/train/G_hospital_san_sebastian_cordoba7.json\n",
      "Load .json metadata:  ./tmp/train/R_ayuntamiento_sevilla3.json\n",
      "Load .json metadata:  ./tmp/train/B_iglesia_san_pedro_pablo_granada2.json\n",
      "Load .json metadata:  ./tmp/train/B_iglesia_angustias_granada3.json\n",
      "Load .json metadata:  ./tmp/train/R_5bd3450596f60.json\n",
      "Load .json metadata:  ./tmp/train/B_5bae52157ff90.json\n",
      "Load .json metadata:  ./tmp/train/B_5bb4ea3b75f38.json\n",
      "Load .json metadata:  ./tmp/train/R_5c09688c5bd6d.json\n",
      "Load .json metadata:  ./tmp/train/M_5c0bb6ad8a829.json\n",
      "Load .json metadata:  ./tmp/train/R_iglesia_santa_ana_granada.json\n",
      "Load .json metadata:  ./tmp/train/G_5ddab25a85cf9.json\n",
      "Load .json metadata:  ./tmp/train/R_puerta_compas_cartuja_granada.json\n",
      "Load .json metadata:  ./tmp/train/M_medina_azahara27.json\n",
      "Load .json metadata:  ./tmp/train/R_palacio_carlos_v_granada4.json\n",
      "Load .json metadata:  ./tmp/train/M_dintel_adovelado7.json\n",
      "Load .json metadata:  ./tmp/train/R_5de6b1e7a7256.json\n",
      "Load .json metadata:  ./tmp/train/B_5c0a71a53b060.json\n",
      "Load .json metadata:  ./tmp/train/B_catedral_granada7.json\n",
      "Load .json metadata:  ./tmp/train/B_5bddc20b3a228.json\n",
      "Load .json metadata:  ./tmp/train/B_convento_carmelitas_descalzas_granada3.json\n",
      "Load .json metadata:  ./tmp/train/R_5bdd586f9ce77.json\n",
      "Load .json metadata:  ./tmp/train/B_convento_carmelitas_descalzas_granada.json\n",
      "Load .json metadata:  ./tmp/train/R_puerta_perdon_catedral_granada6.json\n",
      "Load .json metadata:  ./tmp/train/B_5bec3a053928b.json\n",
      "Load .json metadata:  ./tmp/train/R_curia_granada.json\n",
      "Load .json metadata:  ./tmp/train/G_5bb2417649091.json\n",
      "Load .json metadata:  ./tmp/train/B_5cadbc893b98b.json\n",
      "Load .json metadata:  ./tmp/train/B_casa_cadenas_cadiz4.json\n",
      "Load .json metadata:  ./tmp/train/B_5da8720703692.json\n",
      "Load .json metadata:  ./tmp/train/M_5bd34f039bd23.json\n",
      "Load .json metadata:  ./tmp/train/B_palacio_mendoza_granada.json\n",
      "Load .json metadata:  ./tmp/train/G_5dd2b36c2d262.json\n",
      "Load .json metadata:  ./tmp/train/G_cathedral.json\n",
      "Load .json metadata:  ./tmp/train/G_puerta_infierno_catedral_toledo3.json\n",
      "Load .json metadata:  ./tmp/train/M_5bec3b4e60282.json\n",
      "Load .json metadata:  ./tmp/train/G_5bc06c2a9953c.json\n",
      "Load .json metadata:  ./tmp/train/R_catedral_santa_maria_sevilla.json\n",
      "Load .json metadata:  ./tmp/train/M_medina_azahara.json\n",
      "Load .json metadata:  ./tmp/train/G_basilica_santa_maria_arcos_frontera4.json\n",
      "Load .json metadata:  ./tmp/train/B_hospital_real_granada.json\n",
      "Load .json metadata:  ./tmp/train/G_hospital_san_sebastian_cordoba10.json\n",
      "Load .json metadata:  ./tmp/train/B_5cb31f11d9127.json\n",
      "Load .json metadata:  ./tmp/train/B_iglesia_san_francisco_cordoba2.json\n",
      "Load .json metadata:  ./tmp/train/G_5c0d0f01f22fb.json\n",
      "Load .json metadata:  ./tmp/train/B_5ddd37fa3005f.json\n",
      "Load .json metadata:  ./tmp/train/M_corral_carbon_granada10.json\n",
      "Load .json metadata:  ./tmp/train/B_5c2c923e98eb3.json\n",
      "Load .json metadata:  ./tmp/train/G_convento_clarisas_palencia.json\n",
      "Load .json metadata:  ./tmp/train/B_facultad_derecho_granada6.json\n",
      "Load .json metadata:  ./tmp/train/M_5bd34e85bb4d0.json\n",
      "Load .json metadata:  ./tmp/train/B_5d90d036cd46d.json\n",
      "Load .json metadata:  ./tmp/train/B_5cadb8073058a.json\n",
      "Load .json metadata:  ./tmp/train/R_5c0a52d721023.json\n",
      "Load .json metadata:  ./tmp/train/G_catedral_sevilla2.json\n",
      "Load .json metadata:  ./tmp/train/R_puerta_puente_cordoba.json\n",
      "Load .json metadata:  ./tmp/train/B_colegio_san_telmo_sevilla4.json\n",
      "Load .json metadata:  ./tmp/train/M_alhambra2.json\n",
      "Load .json metadata:  ./tmp/train/B_hospital_san_juan_de_dios_granada3.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc76e871b47e.json\n",
      "Load .json metadata:  ./tmp/train/B_colegio_san_telmo_sevilla5.json\n",
      "Load .json metadata:  ./tmp/train/G_5cd4510ecd2a1.json\n",
      "Load .json metadata:  ./tmp/train/G_5d98cbcf8b124.json\n",
      "Load .json metadata:  ./tmp/train/G_5d07bb5a78cf0.json\n",
      "Load .json metadata:  ./tmp/train/B_5b8ecac4ebfae.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc4cdce3fab8.json\n",
      "Load .json metadata:  ./tmp/train/G_5bc743ec098e2.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_atarazanas_malaga8.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_atarazanas_malaga4.json\n",
      "Load .json metadata:  ./tmp/train/B_5bacb69c505b0.json\n",
      "Load .json metadata:  ./tmp/train/M_5e4fb9bc9e1ae.json\n",
      "Load .json metadata:  ./tmp/train/G_iglesia_sabiote6.json\n",
      "Load .json metadata:  ./tmp/train/G_5bc76dba8ef2f.json\n",
      "Load .json metadata:  ./tmp/train/R_iglesia_salvador_ubeda4.json\n",
      "Load .json metadata:  ./tmp/train/B_5cf7f31d58a0d.json\n",
      "Load .json metadata:  ./tmp/train/M_medina_azahara19.json\n",
      "Load .json metadata:  ./tmp/train/G_5cb6fbc6f2a4a.json\n",
      "Load .json metadata:  ./tmp/train/G_5bec3a78bce6d.json\n",
      "Load .json metadata:  ./tmp/train/G_5c62926eae2a5.json\n",
      "Load .json metadata:  ./tmp/train/B_5cada1e3cfdea.json\n",
      "Load .json metadata:  ./tmp/train/G_iglesia_nuestra_señora_de_la_o_chipiona2.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc765452f841.json\n",
      "Load .json metadata:  ./tmp/train/R_5bd5a68809887.json\n",
      "Load .json metadata:  ./tmp/train/G_5bec50ea6cb7f.json\n",
      "Load .json metadata:  ./tmp/train/M_medina_azahara18.json\n",
      "Load .json metadata:  ./tmp/train/M_5c879cb402953.json\n",
      "Load .json metadata:  ./tmp/train/G_5d62cfd4039d2.json\n",
      "Load .json metadata:  ./tmp/train/M_medina_azahara20.json\n",
      "Load .json metadata:  ./tmp/train/B_5d6648730c69e.json\n",
      "Load .json metadata:  ./tmp/train/G_20181212_105125.json\n",
      "Load .json metadata:  ./tmp/train/R_iglesia_del_sagrario_jaen3.json\n",
      "Load .json metadata:  ./tmp/train/R_iglesia_salvador_ubeda2.json\n",
      "Load .json metadata:  ./tmp/train/B_20181212_105924.json\n",
      "Load .json metadata:  ./tmp/train/B_santos_justo_pastor_granada6.json\n",
      "Load .json metadata:  ./tmp/train/B_5bb5f605c1f88.json\n",
      "Load .json metadata:  ./tmp/train/M_ermita_sansebastian.json\n",
      "Load .json metadata:  ./tmp/train/M_5be5e804a3167.json\n",
      "Load .json metadata:  ./tmp/train/G_5c877f6795355.json\n",
      "Load .json metadata:  ./tmp/train/G_5cadb87f04f94.json\n",
      "Load .json metadata:  ./tmp/train/G_puerta_bautismo_catedral_sevilla10.json\n",
      "Load .json metadata:  ./tmp/train/B_san_juan_cordoba.json\n",
      "Load .json metadata:  ./tmp/train/B_5d9dcbaf77eae.json\n",
      "Load .json metadata:  ./tmp/train/B_catedral_granada.json\n",
      "Load .json metadata:  ./tmp/train/B_5da5d013f0299.json\n",
      "Load .json metadata:  ./tmp/train/M_5db2e772b2a7e.json\n",
      "Load .json metadata:  ./tmp/train/M_5ced1021171f9.json\n",
      "Load .json metadata:  ./tmp/train/R_santa_maria_antequera4.json\n",
      "Load .json metadata:  ./tmp/train/G_iglesia_san_nicolas_ubeda5.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_elvira_granada4.json\n",
      "Load .json metadata:  ./tmp/train/G_5bdf0bbee1eb6.json\n",
      "Load .json metadata:  ./tmp/train/B_convento_merced_granada.json\n",
      "Load .json metadata:  ./tmp/train/R_5c191267b06b1.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_san_isidro_mezquita_cordoba7.json\n",
      "Load .json metadata:  ./tmp/train/B_20181212_105011.json\n",
      "Load .json metadata:  ./tmp/train/M_20181212_115640.json\n",
      "Load .json metadata:  ./tmp/train/B_5bcaedfc23bdb.json\n",
      "Load .json metadata:  ./tmp/train/M_dintel_adovelado2.json\n",
      "Load .json metadata:  ./tmp/train/G_5bdf0b71aba0a.json\n",
      "Load .json metadata:  ./tmp/train/G_5b8ecbee59495.json\n",
      "Load .json metadata:  ./tmp/train/R_5c4066194de97.json\n",
      "Load .json metadata:  ./tmp/train/M_medina_azahara26.json\n",
      "Load .json metadata:  ./tmp/train/R_5db1cfe3aed90.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_elvira_granada6.json\n",
      "Load .json metadata:  ./tmp/train/B_5d66482a8551f.json\n",
      "Load .json metadata:  ./tmp/train/B_5bb4e71f205dd.json\n",
      "Load .json metadata:  ./tmp/train/R_5bb8b7efe4c9c.json\n",
      "Load .json metadata:  ./tmp/train/B_5bd5754e6f78b.json\n",
      "Load .json metadata:  ./tmp/train/G_5c2f2f40203c3.json\n",
      "Load .json metadata:  ./tmp/train/G_5da4ce32a9cbf.json\n",
      "Load .json metadata:  ./tmp/train/R_ayuntamiento_sevilla6.json\n",
      "Load .json metadata:  ./tmp/train/G_5ddc200ecb1a5.json\n",
      "Load .json metadata:  ./tmp/train/G_catedral_toledo4.json\n",
      "Load .json metadata:  ./tmp/train/G_5bb24276e44cc.json\n",
      "Load .json metadata:  ./tmp/train/B_5bb78d37dd05b.json\n",
      "Load .json metadata:  ./tmp/train/M_patio_doncella_reales_alcazares_sevilla6.json\n",
      "Load .json metadata:  ./tmp/train/G_iglesia_san_miguel_cordoba.json\n",
      "Load .json metadata:  ./tmp/train/R_santa_maria_antequera.json\n",
      "Load .json metadata:  ./tmp/train/M_5bad538f2022e.json\n",
      "Load .json metadata:  ./tmp/train/B_5bded5483c8c8.json\n",
      "Load .json metadata:  ./tmp/train/B_5ce83a2b2d61c.json\n",
      "Load .json metadata:  ./tmp/train/B_5def64aa85fc0.json\n",
      "Load .json metadata:  ./tmp/train/R_ayuntamiento_baeza6.json\n",
      "Load .json metadata:  ./tmp/train/B_5c096afcab1bf.json\n",
      "Load .json metadata:  ./tmp/train/G_san_bartolome_andujar2.json\n",
      "Load .json metadata:  ./tmp/train/M_dintel_adovelado.json\n",
      "Load .json metadata:  ./tmp/train/M_5cad9d871f944.json\n",
      "Load .json metadata:  ./tmp/train/M_5baf14b3d8aec.json\n",
      "Load .json metadata:  ./tmp/train/M_5c1385195448d.json\n",
      "Load .json metadata:  ./tmp/train/G_monasterio_concepcion_granada2.json\n",
      "Load .json metadata:  ./tmp/train/R_5be9a1419232a.json\n",
      "Load .json metadata:  ./tmp/train/G_basilica_santa_maria_arcos_frontera7.json\n",
      "Load .json metadata:  ./tmp/train/B_5c0acbbb675b5.json\n",
      "Load .json metadata:  ./tmp/train/M_corral_carbon_granada6.json\n",
      "Load .json metadata:  ./tmp/train/G_5bc76b1661432.json\n",
      "Load .json metadata:  ./tmp/train/M_corral_carbon_granada7.json\n",
      "Load .json metadata:  ./tmp/train/B_palacio_ansoti4.json\n",
      "Load .json metadata:  ./tmp/train/M_medina_azahara11.json\n",
      "Load .json metadata:  ./tmp/train/R_palacio_carlos_v_granada3.json\n",
      "Load .json metadata:  ./tmp/train/G_5bd3513c8e708.json\n",
      "Load .json metadata:  ./tmp/train/B_colegio_san_fernando_granada.json\n",
      "Load .json metadata:  ./tmp/train/M_5e4fb99bb2bc3.json\n",
      "Load .json metadata:  ./tmp/train/B_IMG_1131.json\n",
      "Load .json metadata:  ./tmp/train/B_5c794e4eb432a.json\n",
      "Load .json metadata:  ./tmp/train/M_5e4fb8cac7644.json\n",
      "Load .json metadata:  ./tmp/train/M_ermita_sansebastian2.json\n",
      "Load .json metadata:  ./tmp/train/B_hospital_real_granada2.json\n",
      "Load .json metadata:  ./tmp/train/B_casa_calle_san_matias_granada2.json\n",
      "Load .json metadata:  ./tmp/train/G_5c67dcd823270.json\n",
      "Load .json metadata:  ./tmp/train/R_5bde0353e3682.json\n",
      "Load .json metadata:  ./tmp/train/R_5bb5f42a2c989.json\n",
      "Load .json metadata:  ./tmp/train/R_5bdef0fa697b6.json\n",
      "Load .json metadata:  ./tmp/train/B_5c3dc13138c7a.json\n",
      "Load .json metadata:  ./tmp/train/G_puerta_bautismo_catedral_sevilla6.json\n",
      "Load .json metadata:  ./tmp/train/B_museo_bellas_artes_sevilla5.json\n",
      "Load .json metadata:  ./tmp/train/B_colegio_bartolome_santiago_granada3.json\n",
      "Load .json metadata:  ./tmp/train/B_san_felipe_neri_baeza8.json\n",
      "Load .json metadata:  ./tmp/train/B_5c2764eb103ed.json\n",
      "Load .json metadata:  ./tmp/train/B_5df7426bc0bff.json\n",
      "Load .json metadata:  ./tmp/train/M_5bbcca84a8516.json\n",
      "Load .json metadata:  ./tmp/train/R_palacio_carlos_v_granada20.json\n",
      "Load .json metadata:  ./tmp/train/B_convento_jesus_nazareno_chiclana2.json\n",
      "Load .json metadata:  ./tmp/train/B_5baff856046e5.json\n",
      "Load .json metadata:  ./tmp/train/G_palacio_jabalquinto_baeza14.json\n",
      "Load .json metadata:  ./tmp/train/M_20181212_115538.json\n",
      "Load .json metadata:  ./tmp/train/R_puerta_puente_cordoba8.json\n",
      "Load .json metadata:  ./tmp/train/B_IMG_0378.json\n",
      "Load .json metadata:  ./tmp/train/G_puerta_bautismo_catedral_sevilla7.json\n",
      "Load .json metadata:  ./tmp/train/G_5c7d00c96fbbb.json\n",
      "Load .json metadata:  ./tmp/train/R_iglesia_san_ildefonso_jaen2.json\n",
      "Load .json metadata:  ./tmp/train/R_5c7d015d64d2e.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_del_vino_granada7.json\n",
      "Load .json metadata:  ./tmp/train/R_5bb90f5617705.json\n",
      "Load .json metadata:  ./tmp/train/B_5bb0a2c4b9b8b.json\n",
      "Load .json metadata:  ./tmp/train/G_puerta_apostoles_catedral_murcia3.json\n",
      "Load .json metadata:  ./tmp/train/G_5d98c684abe28.json\n",
      "Load .json metadata:  ./tmp/train/B_5c484246ab3f1.json\n",
      "Load .json metadata:  ./tmp/train/R_palacio_cadenas_ubeda9.json\n",
      "Load .json metadata:  ./tmp/train/M_patio_doncella_reales_alcazares_sevilla9.json\n",
      "Load .json metadata:  ./tmp/train/M_5bd34f9db3310.json\n",
      "Load .json metadata:  ./tmp/train/B_5c2c947748ce6.json\n",
      "Load .json metadata:  ./tmp/train/B_IMG_1132.json\n",
      "Load .json metadata:  ./tmp/train/B_iglesia_san_anton_granada2.json\n",
      "Load .json metadata:  ./tmp/train/B_casa_calle_san_matias_granada3.json\n",
      "Load .json metadata:  ./tmp/train/G_iglesia_san_pablo_ubeda6.json\n",
      "Load .json metadata:  ./tmp/train/G_5da6fcf439ccd.json\n",
      "Load .json metadata:  ./tmp/train/G_5c0d0d49c0423.json\n",
      "Load .json metadata:  ./tmp/train/B_5c4066fd86767.json\n",
      "Load .json metadata:  ./tmp/train/G_iglesia_san_miguel_cordoba4.json\n",
      "Load .json metadata:  ./tmp/train/R_santa_maria_antequera5.json\n",
      "Load .json metadata:  ./tmp/train/B_5d0e5f2316005.json\n",
      "Load .json metadata:  ./tmp/train/M_5bc745d744106.json\n",
      "Load .json metadata:  ./tmp/train/R_iglesia_san_bartolome.json\n",
      "Load .json metadata:  ./tmp/train/B_5c878f098b516.json\n",
      "Load .json metadata:  ./tmp/train/R_5bd96e97c779b.json\n",
      "Load .json metadata:  ./tmp/train/B_iglesia_san_jeronimo_granada2.json\n",
      "Load .json metadata:  ./tmp/train/R_5bacb84ca1ce0.json\n",
      "Load .json metadata:  ./tmp/train/B_5df95dd4cf94d.json\n",
      "Load .json metadata:  ./tmp/train/R_carcel_martos.json\n",
      "Load .json metadata:  ./tmp/train/G_5d9f61bbc6dc2.json\n",
      "Load .json metadata:  ./tmp/train/G_hospital_san_sebastian_cordoba11.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_del_vino_granada9.json\n",
      "Load .json metadata:  ./tmp/train/M_patio_doncella_reales_alcazares_sevilla11.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_monaita_granada4.json\n",
      "Load .json metadata:  ./tmp/train/R_catedral_puerta_perdon_granada.json\n",
      "Load .json metadata:  ./tmp/train/G_5bb28cf500312.json\n",
      "Load .json metadata:  ./tmp/train/R_5bf7c979ad2be.json\n",
      "Load .json metadata:  ./tmp/train/G_basilica_santa_maria_arcos_frontera2.json\n",
      "Load .json metadata:  ./tmp/train/B_san_felipe_neri_baeza4.json\n",
      "Load .json metadata:  ./tmp/train/R_5bb5f7e3b6c72.json\n",
      "Load .json metadata:  ./tmp/train/R_5d98aefd76ce6.json\n",
      "Load .json metadata:  ./tmp/train/B_IMG_1002.json\n",
      "Load .json metadata:  ./tmp/train/R_palacio_carlos_v_granada17.json\n",
      "Load .json metadata:  ./tmp/train/G_5c0a9e2643692.json\n",
      "Load .json metadata:  ./tmp/train/G_hospital_san_sebastian_cordoba2.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_del_vino_granada10.json\n",
      "Load .json metadata:  ./tmp/train/G_5e5a2e8dc057b.json\n",
      "Load .json metadata:  ./tmp/train/B_hospital_real_granada5.json\n",
      "Load .json metadata:  ./tmp/train/B_chancilleria_granada10.json\n",
      "Load .json metadata:  ./tmp/train/G_catedral_sevilla4.json\n",
      "Load .json metadata:  ./tmp/train/R_5bb0b22d051f2.json\n",
      "Load .json metadata:  ./tmp/train/R_ayuntamiento_sevilla.json\n",
      "Load .json metadata:  ./tmp/train/R_palacio_cadenas_ubeda18.json\n",
      "Load .json metadata:  ./tmp/train/B_5ced7d9be567d.json\n",
      "Load .json metadata:  ./tmp/train/G_pinaculo3.json\n",
      "Load .json metadata:  ./tmp/train/M_medina_azahara30.json\n",
      "Load .json metadata:  ./tmp/train/G_5c877f4185ccc.json\n",
      "Load .json metadata:  ./tmp/train/M_20181212_150121.json\n",
      "Load .json metadata:  ./tmp/train/B_5bae53895ec1c.json\n",
      "Load .json metadata:  ./tmp/train/M_patio_yeso_reales_alcazares_sevilla.json\n",
      "Load .json metadata:  ./tmp/train/M_medina_azahara24.json\n",
      "Load .json metadata:  ./tmp/train/B_iglesia_san_anton_granada3.json\n",
      "Load .json metadata:  ./tmp/train/G_hospital_san_sebastian_cordoba8.json\n",
      "Load .json metadata:  ./tmp/train/G_hospital_san_sebastian_cordoba6.json\n",
      "Load .json metadata:  ./tmp/train/B_5bb1ff537029b.json\n",
      "Load .json metadata:  ./tmp/train/G_5c1799d2dde1a.json\n",
      "Load .json metadata:  ./tmp/train/B_5bdb1d1c42d96.json\n",
      "Load .json metadata:  ./tmp/train/B_catedral_jaen.json\n",
      "Load .json metadata:  ./tmp/train/B_5baf98b804126.json\n",
      "Load .json metadata:  ./tmp/train/R_iglesia_santa_fe_granada.json\n",
      "Load .json metadata:  ./tmp/train/R_5bb0b25a063e4.json\n",
      "Load .json metadata:  ./tmp/train/R_palacio_carlos_v_granada15.json\n",
      "Load .json metadata:  ./tmp/train/B_chancilleria_granada9.json\n",
      "Load .json metadata:  ./tmp/train/R_5c0966aea69f7.json\n",
      "Load .json metadata:  ./tmp/train/B_hospital_rreal_granada2.json\n",
      "Load .json metadata:  ./tmp/train/G_hospital_san_sebastian_cordoba5.json\n",
      "Load .json metadata:  ./tmp/train/R_5bc1abdd2b50a.json\n",
      "Load .json metadata:  ./tmp/train/B_5c12755aad84a.json\n",
      "Load .json metadata:  ./tmp/train/B_5bb7972ad3e16.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc76484d31a1.json\n",
      "Load .json metadata:  ./tmp/train/B_5ddba624afba4.json\n",
      "Load .json metadata:  ./tmp/train/G_5d111a858480b.json\n",
      "Load .json metadata:  ./tmp/train/R_san_pedro_cordoba4.json\n",
      "Load .json metadata:  ./tmp/train/B_san_felipe_neri_baeza3.json\n",
      "Load .json metadata:  ./tmp/train/R_5c48450f3f550.json\n",
      "Load .json metadata:  ./tmp/train/R_5bc76d793e6e7.json\n",
      "Load .json metadata:  ./tmp/train/B_5bba92638b868.json\n",
      "Load .json metadata:  ./tmp/train/G_iglesia_santa_maría_del_pi_barcelona2.json\n",
      "Load .json metadata:  ./tmp/train/B_5bfe9d813c0ca.json\n",
      "Load .json metadata:  ./tmp/train/B_5bb5f69957c0a.json\n",
      "Load .json metadata:  ./tmp/train/M_20181212_150254.json\n",
      "Load .json metadata:  ./tmp/train/R_palacio_carlos_v_granada11.json\n",
      "Load .json metadata:  ./tmp/train/B_5c025913a9ddb.json\n",
      "Load .json metadata:  ./tmp/train/G_5c699dfd45a1a.json\n",
      "Load .json metadata:  ./tmp/train/M_20181212_130014.json\n",
      "Load .json metadata:  ./tmp/train/R_puerta_perdon_catedral_granada4.json\n",
      "Load .json metadata:  ./tmp/train/R_san_pedro_cordoba5.json\n",
      "Load .json metadata:  ./tmp/train/B_iglesia_salvador_sevilla.json\n",
      "Load .json metadata:  ./tmp/train/B_san_felipe_neri_baeza7.json\n",
      "Load .json metadata:  ./tmp/train/M_corral_carbon_granada3.json\n",
      "Load .json metadata:  ./tmp/train/M_5bcc9ce820ba1.json\n",
      "Load .json metadata:  ./tmp/train/G_catedral_leon4.json\n",
      "Load .json metadata:  ./tmp/train/B_5bb1c89ba7002.json\n",
      "Load .json metadata:  ./tmp/train/M_20181212_115637.json\n",
      "Load .json metadata:  ./tmp/train/R_5dfa0add8bffc.json\n",
      "Load .json metadata:  ./tmp/train/R_san_pedro_cordoba3.json\n",
      "Load .json metadata:  ./tmp/train/B_5bd0751729011.json\n",
      "Load .json metadata:  ./tmp/train/G_5bb48060bc6a0.json\n",
      "Load .json metadata:  ./tmp/train/B_facultad_derecho_granada5.json\n",
      "Load .json metadata:  ./tmp/train/G_palacio_jabalquinto_baeza.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_del_vino_granada4.json\n",
      "Load .json metadata:  ./tmp/train/G_5cf2f6096b752.json\n",
      "Load .json metadata:  ./tmp/train/G_5c0d10a4df5cb.json\n",
      "Load .json metadata:  ./tmp/train/B_5cf7e81e4e982.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_del_vino_granada.json\n",
      "Load .json metadata:  ./tmp/train/M_5e4fb8e1009fb.json\n",
      "Load .json metadata:  ./tmp/train/R_5bc6e43c0907f.json\n",
      "Load .json metadata:  ./tmp/train/R_5de0eaa225937.json\n",
      "Load .json metadata:  ./tmp/train/G_catedral_burgos4.json\n",
      "Load .json metadata:  ./tmp/train/R_5bb768f243f4d.json\n",
      "Load .json metadata:  ./tmp/train/M_5d623f48dabcd.json\n",
      "Load .json metadata:  ./tmp/train/B_iglesia_caridad_sevilla3.json\n",
      "Load .json metadata:  ./tmp/train/G_catedral_leon5.json\n",
      "Load .json metadata:  ./tmp/train/R_puerta_perdon_catedral_granada12.json\n",
      "Load .json metadata:  ./tmp/train/M_patio_doncella_reales_alcazares_sevilla8.json\n",
      "Load .json metadata:  ./tmp/train/B_5bec4cccf3ed2.json\n",
      "Load .json metadata:  ./tmp/train/B_5c4841c1ca3e2.json\n",
      "Load .json metadata:  ./tmp/train/G_basilica_santa_maria_arcos_frontera3.json\n",
      "Load .json metadata:  ./tmp/train/G_5d74bc786cba6.json\n",
      "Load .json metadata:  ./tmp/train/G_IMG_1052.json\n",
      "Load .json metadata:  ./tmp/train/G_convento_clarisas_palencia5.json\n",
      "Load .json metadata:  ./tmp/train/G_5c2ca09d347ad.json\n",
      "Load .json metadata:  ./tmp/train/M_5bbcca3f7448f.json\n",
      "Load .json metadata:  ./tmp/train/B_parroquia_mayor_santa_maria_encarnacion_huescar.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_justicia_granada5.json\n",
      "Load .json metadata:  ./tmp/train/M_medina_azahara36.json\n",
      "Load .json metadata:  ./tmp/train/R_iglesia_san_cecilio_granada4.json\n",
      "Load .json metadata:  ./tmp/train/G_palacio_jabalquinto_baeza5.json\n",
      "Load .json metadata:  ./tmp/train/R_5bbe3480002dc.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_san_isidro_mezquita_cordoba3.json\n",
      "Load .json metadata:  ./tmp/train/G_5c0d0de30a8f2.json\n",
      "Load .json metadata:  ./tmp/train/G_casa_abrantes_granada.json\n",
      "Load .json metadata:  ./tmp/train/G_5d98c47b04a88.json\n",
      "Load .json metadata:  ./tmp/train/M_20181212_125945.json\n",
      "Load .json metadata:  ./tmp/train/R_puerta_perdon_catedral_granada2.json\n",
      "Load .json metadata:  ./tmp/train/B_5bae55d7aad09.json\n",
      "Load .json metadata:  ./tmp/train/B_5c80d24a04008.json\n",
      "Load .json metadata:  ./tmp/train/G_5db2a2cad60a2.json\n",
      "Load .json metadata:  ./tmp/train/B_colegio_bartolome_santiago_granada4.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc75f2c9c6a4.json\n",
      "Load .json metadata:  ./tmp/train/R_5bc76d50783ef.json\n",
      "Load .json metadata:  ./tmp/train/M_5bc5c30c3eaf6.json\n",
      "Load .json metadata:  ./tmp/train/B_chancilleria_granada11.json\n",
      "Load .json metadata:  ./tmp/train/G_convento_clarisas_palencia2.json\n",
      "Load .json metadata:  ./tmp/train/R_5bc4d1797c791.json\n",
      "Load .json metadata:  ./tmp/train/B_chancilleria_granada2.json\n",
      "Load .json metadata:  ./tmp/train/R_5d559f8ccff2a.json\n",
      "Load .json metadata:  ./tmp/train/G_5bad41c85ae3d.json\n",
      "Load .json metadata:  ./tmp/train/B_casa_almirante_cadiz.json\n",
      "Load .json metadata:  ./tmp/train/R_puerta_perdon_catedral_granada7.json\n",
      "Load .json metadata:  ./tmp/train/B_basilica_angustias_granada2.json\n",
      "Load .json metadata:  ./tmp/train/R_palacio_cadenas_ubeda10.json\n",
      "Load .json metadata:  ./tmp/train/M_5bd4b5dfc5dd4.json\n",
      "Load .json metadata:  ./tmp/train/M_5c1b60d5c92de.json\n",
      "Load .json metadata:  ./tmp/train/G_palacio_jabalquinto_baeza10.json\n",
      "Load .json metadata:  ./tmp/train/R_san_grabiel_loja3.json\n",
      "Load .json metadata:  ./tmp/train/M_dintel_adovelado6.json\n",
      "Load .json metadata:  ./tmp/train/B_museo_bellas_artes_sevilla3.json\n",
      "Load .json metadata:  ./tmp/train/B_5c0b9bda7349b.json\n",
      "Load .json metadata:  ./tmp/train/B_5c19275826ba9.json\n",
      "Load .json metadata:  ./tmp/train/G_5dac7070aa7e2.json\n",
      "Load .json metadata:  ./tmp/train/G_5bc76e72997a7.json\n",
      "Load .json metadata:  ./tmp/train/G_20181212_105521.json\n",
      "Load .json metadata:  ./tmp/train/B_san_felipe_neri_baeza5.json\n",
      "Load .json metadata:  ./tmp/train/R_ayuntamiento_baeza9.json\n",
      "Load .json metadata:  ./tmp/train/B_5c15224895f85.json\n",
      "Load .json metadata:  ./tmp/train/B_5be5d7c4bb9bb.json\n",
      "Load .json metadata:  ./tmp/train/M_5db2c2e015c8c.json\n",
      "Load .json metadata:  ./tmp/train/R_5bb74d7c3e166.json\n",
      "Load .json metadata:  ./tmp/train/B_5cadabdf51477.json\n",
      "Load .json metadata:  ./tmp/train/G_5c7ba984d24b3.json\n",
      "Load .json metadata:  ./tmp/train/B_5ba898dd6f92c.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_san_isidro_mezquita_cordoba4.json\n",
      "Load .json metadata:  ./tmp/train/M_corral_carbon_granada8.json\n",
      "Load .json metadata:  ./tmp/train/B_chancilleria_granada12.json\n",
      "Load .json metadata:  ./tmp/train/R_5bf437f158eb5.json\n",
      "Load .json metadata:  ./tmp/train/B_iglesia_señora_gracia_estepa3.json\n",
      "Load .json metadata:  ./tmp/train/B_catedral_granada9.json\n",
      "Load .json metadata:  ./tmp/train/R_palacio_carlos_v_granada8.json\n",
      "Load .json metadata:  ./tmp/train/M_20181212_105457.json\n",
      "Load .json metadata:  ./tmp/train/B_casatercia_baena.json\n",
      "Load .json metadata:  ./tmp/train/B_5c17dbfe94db3.json\n",
      "Load .json metadata:  ./tmp/train/B_colegio_san_fernando_granada2.json\n",
      "Load .json metadata:  ./tmp/train/R_ayuntamiento_baeza10.json\n",
      "Load .json metadata:  ./tmp/train/B_casa_conde_gabia_granada.json\n",
      "Load .json metadata:  ./tmp/train/B_colegio_san_telmo_sevilla2.json\n",
      "Load .json metadata:  ./tmp/train/G_5e0b2c3b44d7a.json\n",
      "Load .json metadata:  ./tmp/train/R_palacio_carlos_v_granada16.json\n",
      "Load .json metadata:  ./tmp/train/B_casa_calle_san_matias_granada.json\n",
      "Load .json metadata:  ./tmp/train/R_5c23b9ae08c28.json\n",
      "Load .json metadata:  ./tmp/train/B_5bb8ee994df2a.json\n",
      "Load .json metadata:  ./tmp/train/B_san_juan_dios_antequera2.json\n",
      "Load .json metadata:  ./tmp/train/B_chancilleria_granada15.json\n",
      "Load .json metadata:  ./tmp/train/B_palacio_bibataubin_granada.json\n",
      "Load .json metadata:  ./tmp/train/G_5df0cfe41c9e2.json\n",
      "Load .json metadata:  ./tmp/train/B_hospital_san_juan_de_dios_granada2.json\n",
      "Load .json metadata:  ./tmp/train/M_5bdee0fc89299.json\n",
      "Load .json metadata:  ./tmp/train/R_5bfabb729d3b7.json\n",
      "Load .json metadata:  ./tmp/train/R_5bec3f44c6943.json\n",
      "Load .json metadata:  ./tmp/train/R_5bb602378e74b.json\n",
      "Load .json metadata:  ./tmp/train/R_casa_torres_ubeda5.json\n",
      "Load .json metadata:  ./tmp/train/B_5ced0fbf8575d.json\n",
      "Load .json metadata:  ./tmp/train/B_catedral_granada8.json\n",
      "Load .json metadata:  ./tmp/train/R_palacio_cadenas_ubeda2.json\n",
      "Load .json metadata:  ./tmp/train/R_palacio_carlos_v_granada7.json\n",
      "Load .json metadata:  ./tmp/train/G_puerta_bautismo_catedral_sevilla5.json\n",
      "Load .json metadata:  ./tmp/train/B_convento_jesus_nazareno_chiclana4.json\n",
      "Load .json metadata:  ./tmp/train/R_5c1514396c39f.json\n",
      "Load .json metadata:  ./tmp/train/G_20181212_105032.json\n",
      "Load .json metadata:  ./tmp/train/R_5ce695bde2c12.json\n",
      "Load .json metadata:  ./tmp/train/B_5c4c40ffaee5b.json\n",
      "Load .json metadata:  ./tmp/train/M_5ca46555b8d6f.json\n",
      "Load .json metadata:  ./tmp/train/R_ayuntamiento_baeza12.json\n",
      "Load .json metadata:  ./tmp/train/R_5c0cf59f3c68c.json\n",
      "Load .json metadata:  ./tmp/train/R_5e1b37e6a0cca.json\n",
      "Load .json metadata:  ./tmp/train/M_patio_doncella_reales_alcazares_sevilla4.json\n",
      "Load .json metadata:  ./tmp/train/M_patio_yeso_reales_alcazares_sevilla6.json\n",
      "Load .json metadata:  ./tmp/train/G_puerta_apostoles_catedra_valencia4.json\n",
      "Load .json metadata:  ./tmp/train/G_iglesia_san_miguel_cordoba3.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_visires_mezquita_cordoba.json\n",
      "Load .json metadata:  ./tmp/train/B_5c0d00ee1c0cd.json\n",
      "Load .json metadata:  ./tmp/train/G_iglesia_sabiote3.json\n",
      "Load .json metadata:  ./tmp/train/R_5bfab9bb46da6.json\n",
      "Load .json metadata:  ./tmp/train/M_5bb0a6aa5f6e4.json\n",
      "Load .json metadata:  ./tmp/train/R_san_pedro_cordoba.json\n",
      "Load .json metadata:  ./tmp/train/M_20181212_110915.json\n",
      "Load .json metadata:  ./tmp/train/G_5d9f5b7f5da26.json\n",
      "Load .json metadata:  ./tmp/train/G_5da98678c6c25.json\n",
      "Load .json metadata:  ./tmp/train/R_ayuntamiento_baeza2.json\n",
      "Load .json metadata:  ./tmp/train/B_chancilleria_granada3.json\n",
      "Load .json metadata:  ./tmp/train/B_hospital_rreal_granada.json\n",
      "Load .json metadata:  ./tmp/train/R_5bb79917b8e2f.json\n",
      "Load .json metadata:  ./tmp/train/R_5bc4b222ab8b9.json\n",
      "Load .json metadata:  ./tmp/train/B_5bb727333c120.json\n",
      "Load .json metadata:  ./tmp/train/G_puerta_perdon_catedral_toledo.json\n",
      "Load .json metadata:  ./tmp/train/R_santa_maria_puebla_fadrique.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_justicia_granada4.json\n",
      "Load .json metadata:  ./tmp/train/B_5beff5707aec9.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_atarazanas_malaga.json\n",
      "Load .json metadata:  ./tmp/train/M_aljibe_san_miguel_bajo3.json\n",
      "Load .json metadata:  ./tmp/train/B_casa_almirante_cadiz4.json\n",
      "Load .json metadata:  ./tmp/train/R_iglesia_salvador_ubeda5.json\n",
      "Load .json metadata:  ./tmp/train/B_palacio_ansoti6.json\n",
      "Load .json metadata:  ./tmp/train/G_catedral_sevilla.json\n",
      "Load .json metadata:  ./tmp/train/M_5bccb0f95a19f.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc75ea2043a1.json\n",
      "Load .json metadata:  ./tmp/train/B_5bacbc0c24a80.json\n",
      "Load .json metadata:  ./tmp/train/R_5d559e35666bb.json\n",
      "Load .json metadata:  ./tmp/train/M_5c24c231d82db.json\n",
      "Load .json metadata:  ./tmp/train/R_palacio_carlos_v_granada6.json\n",
      "Load .json metadata:  ./tmp/train/G_5d9dcda7e43c1.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_san_isidro_mezquita_cordoba.json\n",
      "Load .json metadata:  ./tmp/train/R_casa_lonja_sevilla_patio2.json\n",
      "Load .json metadata:  ./tmp/train/G_alcazaba-almeria2.json\n",
      "Load .json metadata:  ./tmp/train/G_5c0d1111d3183.json\n",
      "Load .json metadata:  ./tmp/train/G_5d9f5b784eef2.json\n",
      "Load .json metadata:  ./tmp/train/R_puerta_puente_cordoba2.json\n",
      "Load .json metadata:  ./tmp/train/R_5c23bd0b1c5b3.json\n",
      "Load .json metadata:  ./tmp/train/B_5bfab9d919e44.json\n",
      "Load .json metadata:  ./tmp/train/B_hospital_san_juan_de_dios_granada6.json\n",
      "Load .json metadata:  ./tmp/train/B_5c1913fa4368f.json\n",
      "Load .json metadata:  ./tmp/train/M_5c879cbec00c9.json\n",
      "Load .json metadata:  ./tmp/train/G_puerta_apostoles_catedra_valencia6.json\n",
      "Load .json metadata:  ./tmp/train/B_fabrica_tabaco_sevilla4.json\n",
      "Load .json metadata:  ./tmp/train/R_plaza_santa_teresa_ubeda2.json\n",
      "Load .json metadata:  ./tmp/train/R_palacio_carlos_v_granada13.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc75ddc3d1ba.json\n",
      "Load .json metadata:  ./tmp/train/G_5c2b98e90a715.json\n",
      "Load .json metadata:  ./tmp/train/R_ayuntamiento_sevilla9.json\n",
      "Load .json metadata:  ./tmp/train/M_20181212_112635.json\n",
      "Load .json metadata:  ./tmp/train/B_5bdf15a853ace.json\n",
      "Load .json metadata:  ./tmp/train/M_medina_azahara33.json\n",
      "Load .json metadata:  ./tmp/train/M_20181212_112338.json\n",
      "Load .json metadata:  ./tmp/train/B_5bfabad3ce768.json\n",
      "Load .json metadata:  ./tmp/train/B_5bae53c39b2b7.json\n",
      "Load .json metadata:  ./tmp/train/B_5cd7c70902846.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc75ee5ebe5d.json\n",
      "Load .json metadata:  ./tmp/train/G_santa_maria_del_mar_barcelona2.json\n",
      "Load .json metadata:  ./tmp/train/G_palacio_salcedo2.json\n",
      "Load .json metadata:  ./tmp/train/B_san_felipe_neri_baeza6.json\n",
      "Load .json metadata:  ./tmp/train/B_iglesia_señora_gracia_estepa2.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_mihrab_mezquita_cordoba4.json\n",
      "Load .json metadata:  ./tmp/train/G_5df76902c546e.json\n",
      "Load .json metadata:  ./tmp/train/R_5c261a545bbe2.json\n",
      "Load .json metadata:  ./tmp/train/R_5bcaeef31f64b.json\n",
      "Load .json metadata:  ./tmp/train/B_parroquia_nuestra_señora_de_la_o_chipiona.json\n",
      "Load .json metadata:  ./tmp/train/M_5c700b74d7c96.json\n",
      "Load .json metadata:  ./tmp/train/B_catedral_granada3.json\n",
      "Load .json metadata:  ./tmp/train/M_5c6fda72e1704.json\n",
      "Load .json metadata:  ./tmp/train/G_5c740a02c0dac.json\n",
      "Load .json metadata:  ./tmp/train/R_puerta_puente_cordoba11.json\n",
      "Load .json metadata:  ./tmp/train/B_5cada883c36bc.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_atarazanas_malaga2.json\n",
      "Load .json metadata:  ./tmp/val/M_5db2c3273aa37.json\n",
      "Load .json metadata:  ./tmp/val/B_casa_marqueses_de_cartagena_granada5.json\n",
      "Load .json metadata:  ./tmp/val/G_5df806400189c.json\n",
      "Load .json metadata:  ./tmp/val/B_5bd0a18e3a7cf.json\n",
      "Load .json metadata:  ./tmp/val/B_5c45af8e61851.json\n",
      "Load .json metadata:  ./tmp/val/B_5c68094c5269c.json\n",
      "Load .json metadata:  ./tmp/val/R_casa_cabildo_jerez8.json\n",
      "Load .json metadata:  ./tmp/val/B_5de179ec7b386.json\n",
      "Load .json metadata:  ./tmp/val/M_patio_doncella_reales_alcazares_sevilla12.json\n",
      "Load .json metadata:  ./tmp/val/B_5d2af2ba74f7c.json\n",
      "Load .json metadata:  ./tmp/val/M_puerta_justicia_granada3.json\n",
      "Load .json metadata:  ./tmp/val/R_iglesia_asuncion_jodar2.json\n",
      "Load .json metadata:  ./tmp/val/G_5b8ecbfc3afd4.json\n",
      "Load .json metadata:  ./tmp/val/R_5db7125d0d87f.json\n",
      "Load .json metadata:  ./tmp/val/B_5c8a449b2672b.json\n",
      "Load .json metadata:  ./tmp/val/B_5bae55f40f890.json\n",
      "Load .json metadata:  ./tmp/val/M_5bc3179bc5bd7.json\n",
      "Load .json metadata:  ./tmp/val/M_5bbcca8260a77.json\n",
      "Load .json metadata:  ./tmp/val/B_hospital_san_juan_de_dios_granada.json\n",
      "Load .json metadata:  ./tmp/val/G_5d3603beb29ee.json\n",
      "Load .json metadata:  ./tmp/val/G_5cadb9254e5bb.json\n",
      "Load .json metadata:  ./tmp/val/R_puerta_puente_cordoba7.json\n",
      "Load .json metadata:  ./tmp/val/G_5bc06c895d7f1.json\n",
      "Load .json metadata:  ./tmp/val/M_5bacf44fbf465.json\n",
      "Load .json metadata:  ./tmp/val/B_5bae63c34ffa2.json\n",
      "Load .json metadata:  ./tmp/val/G_5bad24e5bfd54.json\n",
      "Load .json metadata:  ./tmp/val/R_20181212_114849.json\n",
      "Load .json metadata:  ./tmp/val/B_5d9dc590766ab.json\n",
      "Load .json metadata:  ./tmp/val/M_patio_doncella_reales_alcazares_sevilla7.json\n",
      "Load .json metadata:  ./tmp/val/R_casa_arandas.json\n",
      "Load .json metadata:  ./tmp/val/G_casa_abrantes_granada8.json\n",
      "Load .json metadata:  ./tmp/val/B_catedral_jaen5.json\n",
      "Load .json metadata:  ./tmp/val/B_5c876de809b23.json\n",
      "Load .json metadata:  ./tmp/val/R_5bb78ee318b3f.json\n",
      "Load .json metadata:  ./tmp/val/M_20181212_122208.json\n",
      "Load .json metadata:  ./tmp/val/M_5c45b1ab7eacc.json\n",
      "Load .json metadata:  ./tmp/val/G_5bc4b0000a171.json\n",
      "Load .json metadata:  ./tmp/val/M_puerta_atarazanas_malaga7.json\n",
      "Load .json metadata:  ./tmp/val/R_5be6b690211bf.json\n",
      "Load .json metadata:  ./tmp/val/B_5bad4ad9c95b3.json\n",
      "Load .json metadata:  ./tmp/val/G_convento_clarisas_palencia3.json\n",
      "Load .json metadata:  ./tmp/val/M_puerta_de_las_pesas_granada2.json\n",
      "Load .json metadata:  ./tmp/val/G_5c267e2387828.json\n",
      "Load .json metadata:  ./tmp/val/G_5d9f5d4905e1d.json\n",
      "Load .json metadata:  ./tmp/val/B_5cd6a30c8eeae.json\n",
      "Load .json metadata:  ./tmp/val/R_5d208b11429c6.json\n",
      "Load .json metadata:  ./tmp/val/G_catedral_toledo3.json\n",
      "Load .json metadata:  ./tmp/val/R_5bcc411061ead.json\n",
      "Load .json metadata:  ./tmp/val/M_5e5f7d583c41f.json\n",
      "Load .json metadata:  ./tmp/val/B_5bfabb1a9d451.json\n",
      "Load .json metadata:  ./tmp/val/B_iglesia_san_juan_de_dios_granada2.json\n",
      "Load .json metadata:  ./tmp/val/G_casa_abrantes_granada2.json\n",
      "Load .json metadata:  ./tmp/val/M_puerta_del_vino_granada8.json\n",
      "Load .json metadata:  ./tmp/val/B_5cada2796e206.json\n",
      "Load .json metadata:  ./tmp/val/B_chancilleria_granada7.json\n",
      "Load .json metadata:  ./tmp/val/M_5c2ce172117a7.json\n",
      "Load .json metadata:  ./tmp/val/G_5cc0716275b2e.json\n",
      "Load .json metadata:  ./tmp/val/G_5b8a5fbbcc59f.json\n",
      "Load .json metadata:  ./tmp/val/R_convento_santa_clara_ubeda.json\n",
      "Load .json metadata:  ./tmp/val/G_5d09350c0fda2.json\n",
      "Load .json metadata:  ./tmp/val/M_5bd1dff352ca4.json\n",
      "Load .json metadata:  ./tmp/val/M_5c75185ba9a61.json\n",
      "Load .json metadata:  ./tmp/val/B_palacio_ansoti5.json\n",
      "Load .json metadata:  ./tmp/val/M_5bacb65e7ea39.json\n",
      "Load .json metadata:  ./tmp/val/G_hospital_san_sebastian_cordoba.json\n",
      "Load .json metadata:  ./tmp/val/B_casa_cadenas_cadiz.json\n",
      "Load .json metadata:  ./tmp/val/G_capilla_real_granada4.json\n",
      "Load .json metadata:  ./tmp/val/G_20181212_105134.json\n",
      "Load .json metadata:  ./tmp/val/R_5c60427368d45.json\n",
      "Load .json metadata:  ./tmp/val/G_catedral_toledo.json\n",
      "Load .json metadata:  ./tmp/val/B_5bec4cd58ecc0.json\n",
      "Load .json metadata:  ./tmp/val/B_IMG_0329.json\n",
      "Load .json metadata:  ./tmp/val/G_capilla_real_granada2_2.json\n",
      "Load .json metadata:  ./tmp/val/R_plaza_santa_teresa_ubeda.json\n",
      "Load .json metadata:  ./tmp/val/G_iglesia_san_pablo_ubeda9.json\n",
      "Load .json metadata:  ./tmp/val/B_iglesia_san_juan_de_dios_granada3.json\n",
      "Load .json metadata:  ./tmp/val/R_ayuntamiento_baeza7.json\n",
      "Load .json metadata:  ./tmp/val/G_igl_arcos_frontera.json\n",
      "Load .json metadata:  ./tmp/val/B_5c14f985ec8cb.json\n",
      "Load .json metadata:  ./tmp/val/M_20181212_115509.json\n",
      "Load .json metadata:  ./tmp/val/B_5bc75e93a80c2.json\n",
      "Load .json metadata:  ./tmp/val/B_5bc75f886de87.json\n",
      "Load .json metadata:  ./tmp/val/R_5bfdb2389a627.json\n",
      "Load .json metadata:  ./tmp/val/M_medina_azahara9.json\n",
      "Load .json metadata:  ./tmp/val/M_puerta_monaita_granada3.json\n",
      "Load .json metadata:  ./tmp/val/R_palacio_carlos_v_granada.json\n",
      "Load .json metadata:  ./tmp/val/R_san_pedro_cordoba2.json\n",
      "Load .json metadata:  ./tmp/val/B_5c596ad870071.json\n",
      "Load .json metadata:  ./tmp/val/B_5bcdf776e2630.json\n",
      "Load .json metadata:  ./tmp/val/G_5bec3a72c823a.json\n",
      "Load .json metadata:  ./tmp/val/B_palacio_bibataubin_granada4.json\n",
      "Load .json metadata:  ./tmp/val/G_5c877f504a07b.json\n",
      "Load .json metadata:  ./tmp/val/M_puerta_atarazanas_malaga3.json\n",
      "Load .json metadata:  ./tmp/val/G_puerta_bautismo_catedral_sevilla2.json\n",
      "Load .json metadata:  ./tmp/val/R_casa_torres_ubeda4.json\n",
      "Load .json metadata:  ./tmp/val/G_IMG_0369.json\n",
      "Load .json metadata:  ./tmp/val/M_puerta_de_las_pesas_granada6.json\n",
      "Load .json metadata:  ./tmp/val/R_puerta_perdon_catedral_granada5.json\n",
      "Load .json metadata:  ./tmp/val/M_5c85601a50e23.json\n",
      "Load .json metadata:  ./tmp/val/M_5dd41a8a19a4a.json\n",
      "Load .json metadata:  ./tmp/val/M_medina_azahara10.json\n",
      "Load .json metadata:  ./tmp/val/B_convento_santa_ines_granada2.json\n",
      "Load .json metadata:  ./tmp/val/G_basilica_santa_maria_arcos_frontera.json\n",
      "Load .json metadata:  ./tmp/val/B_5be5b0ed738a7.json\n",
      "Load .json metadata:  ./tmp/val/M_5c9620edef2ff.json\n",
      "Load .json metadata:  ./tmp/val/M_5e4fb97a24480.json\n",
      "Load .json metadata:  ./tmp/val/R_puerta_granada_granada.json\n",
      "Load .json metadata:  ./tmp/val/B_facultad_derecho_granada4.json\n",
      "Load .json metadata:  ./tmp/val/R_colegio_niñas_nobles_granada2.json\n",
      "Load .json metadata:  ./tmp/val/R_5bb733b336220.json\n",
      "Load .json metadata:  ./tmp/val/B_fabrica_tabaco_sevilla2.json\n",
      "Load .json metadata:  ./tmp/val/G_pinaculo4.json\n",
      "Load .json metadata:  ./tmp/val/R_capilla_san_francisco_baeza5.json\n",
      "Load .json metadata:  ./tmp/val/M_medina_azahara35.json\n",
      "Load .json metadata:  ./tmp/val/B_IMG_1004.json\n",
      "Load .json metadata:  ./tmp/val/R_5c15277c84aab.json\n",
      "Load .json metadata:  ./tmp/val/G_5cd8200569568.json\n",
      "Load .json metadata:  ./tmp/val/R_5bdef11ecc329.json\n",
      "Load .json metadata:  ./tmp/val/B_catedral_guadix5.json\n",
      "Load .json metadata:  ./tmp/val/B_5c878f865c701.json\n",
      "Load .json metadata:  ./tmp/val/M_20181212_113400.json\n",
      "Load .json metadata:  ./tmp/val/M_5db079dfc13c7.json\n",
      "Load .json metadata:  ./tmp/val/R_5bb4547e1c1e9.json\n",
      "Load .json metadata:  ./tmp/val/R_5cba22808268e.json\n",
      "Load .json metadata:  ./tmp/val/R_5bc0b4b6c8948.json\n",
      "Load .json metadata:  ./tmp/val/B_fabrica_tabaco_sevilla5.json\n",
      "Load .json metadata:  ./tmp/val/B_5ca466a359d1d.json\n",
      "Load .json metadata:  ./tmp/val/R_5bcaf9bf6194d.json\n",
      "Load .json metadata:  ./tmp/val/B_catedral_granada5.json\n",
      "Load .json metadata:  ./tmp/val/B_5cdeec644d080.json\n",
      "Load .json metadata:  ./tmp/val/B_IMG_1055.json\n",
      "Load .json metadata:  ./tmp/val/M_5e5245bcb4ee4.json\n",
      "Load .json metadata:  ./tmp/val/G_iglesia_san_pablo_ubeda3.json\n",
      "Load .json metadata:  ./tmp/val/M_5bccb200d68f2.json\n",
      "Load .json metadata:  ./tmp/val/M_5da4ceed0c3d9.json\n",
      "Load .json metadata:  ./tmp/val/B_IMG_1054.json\n",
      "Load .json metadata:  ./tmp/val/B_5c878f258d48a.json\n",
      "Load .json metadata:  ./tmp/val/B_catedral_granada10.json\n",
      "Load .json metadata:  ./tmp/val/R_iglesia_salvador_granada.json\n",
      "Load .json metadata:  ./tmp/val/B_5bb7b650342fc.json\n",
      "Load .json metadata:  ./tmp/val/G_5d9dcdcba5a00.json\n",
      "Load .json metadata:  ./tmp/val/B_5c0a71fb016ae.json\n",
      "Load .json metadata:  ./tmp/val/B_IMG_0362.json\n",
      "Load .json metadata:  ./tmp/val/B_5bc75e23a2930.json\n",
      "Load .json metadata:  ./tmp/val/G_casa_abrantes_granada5.json\n",
      "Load .json metadata:  ./tmp/val/B_basilica_angustias_granada5.json\n",
      "Load .json metadata:  ./tmp/val/B_5b8ecb06eab42.json\n",
      "Load .json metadata:  ./tmp/val/R_san_grabiel_loja.json\n",
      "Load .json metadata:  ./tmp/val/B_IMG_0359.json\n",
      "Load .json metadata:  ./tmp/val/R_puerta_perdon_catedral_granada8.json\n",
      "Load .json metadata:  ./tmp/val/R_monasterio_cartuja_granada.json\n",
      "Load .json metadata:  ./tmp/val/R_palacio_cadenas_ubeda13.json\n",
      "Load .json metadata:  ./tmp/val/B_IMG_1034.json\n",
      "Load .json metadata:  ./tmp/val/B_5cd3273f34c66.json\n",
      "Load .json metadata:  ./tmp/val/M_puerta_mihrab_mezquita_cordoba2.json\n",
      "Load .json metadata:  ./tmp/val/G_5d98cad22479c.json\n",
      "Load .json metadata:  ./tmp/val/M_patio_yeso_reales_alcazares_sevilla2.json\n",
      "Load .json metadata:  ./tmp/val/B_5bec3a0558cf5.json\n",
      "Load .json metadata:  ./tmp/val/R_casa_cabildo_jerez3.json\n",
      "Load .json metadata:  ./tmp/val/M_5bd577ad73bb0.json\n",
      "Load .json metadata:  ./tmp/val/G_5ced8f6051d21.json\n",
      "Load .json metadata:  ./tmp/val/B_5bfaba8fb40e3.json\n",
      "Load .json metadata:  ./tmp/val/G_puerta_bautismo_catedral_sevilla8.json\n",
      "Load .json metadata:  ./tmp/val/R_5bb78bd53e5ad.json\n",
      "Load .json metadata:  ./tmp/val/B_5c12759d8cc79.json\n",
      "Load .json metadata:  ./tmp/val/G_5bc76dc28fd08.json\n",
      "Load .json metadata:  ./tmp/val/G_5bc9a11663f9b.json\n",
      "Load .json metadata:  ./tmp/val/B_5e4ed1c6cbdec.json\n",
      "Load .json metadata:  ./tmp/val/G_iglesia_san_pablo_ubeda10.json\n",
      "Load .json metadata:  ./tmp/val/G_5de135380f7c3.json\n",
      "Load .json metadata:  ./tmp/val/M_medina_azahara29.json\n",
      "Load .json metadata:  ./tmp/val/M_5baf1a3f2e94b.json\n",
      "Load .json metadata:  ./tmp/val/M_5d623f17ab783.json\n",
      "Load .json metadata:  ./tmp/val/B_basilica_angustias_granada4.json\n",
      "Load .json metadata:  ./tmp/val/B_catedral_guadix7.json\n",
      "Load .json metadata:  ./tmp/val/R_palacio_carlos_v_granada12.json\n",
      "Load .json metadata:  ./tmp/val/B_chancilleria_granada.json\n",
      "Load .json metadata:  ./tmp/val/G_puerta_apostoles_catedral_murcia6.json\n",
      "Load .json metadata:  ./tmp/val/G_iglesia_sabiote4.json\n",
      "Load .json metadata:  ./tmp/val/B_5d9dd3c5b2f16.json\n",
      "Load .json metadata:  ./tmp/val/G_5bc1aaf94ea6d.json\n",
      "Load .json metadata:  ./tmp/val/B_san_juan_dios_antequera.json\n",
      "Load .json metadata:  ./tmp/val/G_5bc9a70361bff.json\n",
      "Load .json metadata:  ./tmp/val/B_5c1cde9e6260a.json\n",
      "Load .json metadata:  ./tmp/val/M_5de6aa806cbef.json\n",
      "Load .json metadata:  ./tmp/val/B_colegio_san_telmo_sevilla.json\n",
      "Load .json metadata:  ./tmp/val/B_IMG_0358.json\n",
      "Load .json metadata:  ./tmp/val/G_palacio_salcedo.json\n",
      "Load .json metadata:  ./tmp/val/R_5d98bfa797969.json\n",
      "Load .json metadata:  ./tmp/val/R_5bc6037474c90.json\n",
      "Load .json metadata:  ./tmp/val/B_5c62af60bdd94.json\n",
      "Load .json metadata:  ./tmp/val/M_5e51856c4c5d0.json\n",
      "Load .json metadata:  ./tmp/val/G_5bb8e97e9badf.json\n",
      "Load .json metadata:  ./tmp/val/B_5babaafb202cf.json\n",
      "Load .json metadata:  ./tmp/val/R_convento_santa_clara_ubeda4.json\n",
      "Load .json metadata:  ./tmp/val/B_5e0354ada9bdf.json\n",
      "Load .json metadata:  ./tmp/val/B_5cf7f3fe6fcc7.json\n",
      "Load .json metadata:  ./tmp/val/M_medina_azahara4.json\n",
      "Load .json metadata:  ./tmp/val/R_5c15348990691.json\n",
      "Load .json metadata:  ./tmp/val/G_palacio_jabalquinto_baeza9.json\n",
      "Load .json metadata:  ./tmp/val/R_5be5e8d4933d2.json\n",
      "Load .json metadata:  ./tmp/val/R_palacio_carlos_v_granada10.json\n",
      "Load .json metadata:  ./tmp/val/R_5c0aaaa13f0d4.json\n",
      "Load .json metadata:  ./tmp/val/G_5c877f35824a9.json\n",
      "Load .json metadata:  ./tmp/val/G_capilla_real_granada5.json\n",
      "Load .json metadata:  ./tmp/val/G_puerta_apostoles_catedral_murcia.json\n",
      "Load .json metadata:  ./tmp/val/R_puerta_perdon_catedral_granada3.json\n",
      "Load .json metadata:  ./tmp/val/M_puerta_elvira_granada.json\n",
      "Load .json metadata:  ./tmp/val/G_5d9c62a9002f9.json\n",
      "Load .json metadata:  ./tmp/val/M_20181212_150308.json\n",
      "Load .json metadata:  ./tmp/val/R_catedral_santa_maria_sevilla2.json\n",
      "Load .json metadata:  ./tmp/val/G_5dd41c407dad2.json\n",
      "Load .json metadata:  ./tmp/val/B_5dfb6b3ec6d75.json\n",
      "Load .json metadata:  ./tmp/val/G_5c6299b35348d.json\n",
      "Load .json metadata:  ./tmp/val/R_ayuntamiento_sevilla8.json\n",
      "Load .json metadata:  ./tmp/val/R_iglesia_san_cecilio_granada.json\n",
      "Load .json metadata:  ./tmp/val/B_museo_bellas_artes_sevilla4.json\n",
      "Load .json metadata:  ./tmp/val/G_5bc4b0208afce.json\n",
      "Load .json metadata:  ./tmp/val/R_5ce91ca209e93.json\n",
      "Load .json metadata:  ./tmp/val/B_IMG_0340.json\n",
      "Load .json metadata:  ./tmp/val/M_5be567087517e.json\n",
      "Load .json metadata:  ./tmp/val/B_facultad_derecho_granada3.json\n",
      "Load .json metadata:  ./tmp/val/B_palacio_ansoti7.json\n",
      "Load .json metadata:  ./tmp/val/B_5c878f1213e55.json\n",
      "Load .json metadata:  ./tmp/val/B_catedral_guadix.json\n",
      "Load .json metadata:  ./tmp/val/B_5d53cdc09e048.json\n",
      "Load .json metadata:  ./tmp/val/B_iglesia_caridad_sevilla4.json\n",
      "Load .json metadata:  ./tmp/val/M_5bae5ed261c0c.json\n",
      "Load .json metadata:  ./tmp/val/M_5c961ed2964b2.json\n",
      "Load .json metadata:  ./tmp/val/B_casa_marqueses_de_cartagena_granada6.json\n",
      "Load .json metadata:  ./tmp/val/R_iglesia_san_cecilio_granada2.json\n",
      "Load .json metadata:  ./tmp/val/B_casa_monte_de_piedad_granada.json\n",
      "Load .json metadata:  ./tmp/val/G_5c82f5c3c0a67.json\n",
      "Load .json metadata:  ./tmp/val/G_puerta_infierno_catedral_toledo2.json\n",
      "Load .json metadata:  ./tmp/val/M_5c38866fefaad.json\n",
      "Load .json metadata:  ./tmp/val/B_5d9dcbbfc416a.json\n",
      "Load .json metadata:  ./tmp/val/B_5be98c369a004.json\n",
      "Load .json metadata:  ./tmp/val/B_5ba899636f449.json\n",
      "Load .json metadata:  ./tmp/val/B_5c8778ca611a2.json\n",
      "Load .json metadata:  ./tmp/val/B_5bc75e6119173.json\n",
      "Load .json metadata:  ./tmp/val/M_20181212_130052.json\n",
      "Load .json metadata:  ./tmp/val/M_5db2e635ab8ed.json\n",
      "Load .json metadata:  ./tmp/val/R_palacio_carlos_v_granada19.json\n",
      "Load .json metadata:  ./tmp/val/M_puerta_de_las_pesas_granada.json\n",
      "Load .json metadata:  ./tmp/val/M_5bcdf82621374.json\n",
      "Load .json metadata:  ./tmp/val/B_compas_convento_santa_isabel_granada.json\n",
      "Load .json metadata:  ./tmp/val/M_5bad4996b3cf4.json\n",
      "Load .json metadata:  ./tmp/val/M_5db2bfe305c0b.json\n",
      "Load .json metadata:  ./tmp/val/B_5bd0a549b5653.json\n",
      "Load .json metadata:  ./tmp/val/G_puerta_bautismo_catedral_sevilla.json\n",
      "Load .json metadata:  ./tmp/val/M_5d0383b7abaf0.json\n",
      "Load .json metadata:  ./tmp/val/R_iglesia_san_cecilio_granada3.json\n",
      "Load .json metadata:  ./tmp/val/M_5baf19070489a.json\n",
      "Load .json metadata:  ./tmp/val/M_corral_carbon_granada9.json\n",
      "Load .json metadata:  ./tmp/val/B_iglesia_san_basilio_granada.json\n",
      "Load .json metadata:  ./tmp/val/B_casa_cadenas_cadiz2.json\n",
      "Load .json metadata:  ./tmp/val/M_corral_carbon_granada.json\n",
      "Load .json metadata:  ./tmp/val/B_5c80d1f310860.json\n",
      "Load .json metadata:  ./tmp/val/G_5c67d9d394832.json\n",
      "Load .json metadata:  ./tmp/val/R_iglesia_anunciacion_sevilla2.json\n",
      "Load .json metadata:  ./tmp/val/B_iglesia_perpetuo_socorro_granada.json\n",
      "Load .json metadata:  ./tmp/val/G_5d98c6d57f872.json\n",
      "Load .json metadata:  ./tmp/val/B_5bed739fdf02e.json\n",
      "Load .json metadata:  ./tmp/val/B_5cf7e7d0e7106.json\n",
      "Load .json metadata:  ./tmp/val/G_5bc4b2d9006fc.json\n",
      "Load .json metadata:  ./tmp/val/R_catedral_puerta_san_jeronimo_granada.json\n",
      "Load .json metadata:  ./tmp/val/R_palacio_cadenas_ubeda4.json\n",
      "Load .json metadata:  ./tmp/val/M_20181212_112853.json\n",
      "Load .json metadata:  ./tmp/val/R_iglesia_santo_domingo_granada.json\n",
      "Load .json metadata:  ./tmp/val/G_5cadb7f561357.json\n",
      "Load .json metadata:  ./tmp/val/G_5cc07140b8e70.json\n",
      "Load .json metadata:  ./tmp/val/B_5bd2cda2a9579.json\n",
      "Load .json metadata:  ./tmp/val/B_convento_carmelitas_descalzas_granada5.json\n",
      "Load .json metadata:  ./tmp/val/B_basilica_angustias_granada.json\n",
      "Load .json metadata:  ./tmp/val/R_5bd33de5f3fa8.json\n",
      "Load .json metadata:  ./tmp/val/G_puerta_apostoles_catedral_murcia4.json\n",
      "Load .json metadata:  ./tmp/val/B_5bdd80e6ea7c8.json\n",
      "Load .json metadata:  ./tmp/val/G_iglesia_nuestra_señora_de_la_o_chipiona.json\n",
      "Load .json metadata:  ./tmp/val/G_iglesia_santa_maría_del_pi_barcelona.json\n",
      "Load .json metadata:  ./tmp/val/R_5db2c3759cdbd.json\n",
      "Load .json metadata:  ./tmp/val/B_palacio_bibataubin_granada3.json\n",
      "Load .json metadata:  ./tmp/val/G_pinaculo2.json\n",
      "Load .json metadata:  ./tmp/val/G_5c138466132c4.json\n",
      "Load .json metadata:  ./tmp/val/M_patio_doncella_reales_alcazares_sevilla.json\n",
      "Load .json metadata:  ./tmp/val/G_catedral_sevilla3.json\n",
      "Load .json metadata:  ./tmp/val/M_patio_doncella_reales_alcazares_sevilla5.json\n",
      "Load .json metadata:  ./tmp/val/B_5bae4188a9817.json\n",
      "Load .json metadata:  ./tmp/val/M_20181212_150258.json\n",
      "Load .json metadata:  ./tmp/val/G_pinaculo5.json\n",
      "Load .json metadata:  ./tmp/val/B_5bd074b099963.json\n",
      "Load .json metadata:  ./tmp/val/R_5bee96a235a67.json\n",
      "Load .json metadata:  ./tmp/val/M_corralcarbon.json\n",
      "Load .json metadata:  ./tmp/val/R_5bb5f65db689e.json\n",
      "Load .json metadata:  ./tmp/val/R_20181212_110256.json\n",
      "Load .json metadata:  ./tmp/val/B_5bc75e9246655.json\n",
      "Load .json metadata:  ./tmp/val/R_puerta_perdon_catedral_granada.json\n",
      "Load .json metadata:  ./tmp/val/R_palacio_carlos_v_granada9.json\n",
      "Load .json metadata:  ./tmp/val/B_IMG_1135.json\n",
      "Load .json metadata:  ./tmp/val/M_alcazaba_malaga.json\n",
      "Load .json metadata:  ./tmp/val/G_iglesia_san_pablo_ubeda2.json\n",
      "Load .json metadata:  ./tmp/val/G_5cb9a35070358.json\n",
      "Load .json metadata:  ./tmp/val/M_ermita_sansebastian3.json\n",
      "Load .json metadata:  ./tmp/val/G_5d4f11234ab2d.json\n",
      "Training del classificatore...\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib/python3.9/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.2508 - loss: 1.6366   \n",
      "Epoch 2/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6635 - loss: 1.0539\n",
      "Epoch 3/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7494 - loss: 0.7907\n",
      "Epoch 4/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8301 - loss: 0.6036\n",
      "Epoch 5/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8279 - loss: 0.5540\n",
      "Epoch 6/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8529 - loss: 0.4629\n",
      "Epoch 7/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8745 - loss: 0.3994\n",
      "Epoch 8/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8986 - loss: 0.3577\n",
      "Epoch 9/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8870 - loss: 0.3364\n",
      "Epoch 10/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9183 - loss: 0.3083\n",
      "Epoch 11/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9191 - loss: 0.2759\n",
      "Epoch 12/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9253 - loss: 0.2549\n",
      "Epoch 13/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9202 - loss: 0.2371\n",
      "Epoch 14/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9168 - loss: 0.2468\n",
      "Epoch 15/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9251 - loss: 0.2212\n",
      "Epoch 16/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9290 - loss: 0.2255\n",
      "Epoch 17/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9270 - loss: 0.2065\n",
      "Epoch 18/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9275 - loss: 0.2031\n",
      "Epoch 19/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9295 - loss: 0.1850\n",
      "Epoch 20/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9347 - loss: 0.1892\n",
      "Epoch 21/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9194 - loss: 0.2074\n",
      "Epoch 22/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9373 - loss: 0.1669\n",
      "Epoch 23/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9279 - loss: 0.1974\n",
      "Epoch 24/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9319 - loss: 0.1840\n",
      "Epoch 25/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9433 - loss: 0.1627\n",
      "Epoch 26/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9386 - loss: 0.1673\n",
      "Epoch 27/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9279 - loss: 0.2047\n",
      "Epoch 28/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9485 - loss: 0.1534\n",
      "Epoch 29/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9312 - loss: 0.1790\n",
      "Epoch 30/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9372 - loss: 0.1617\n",
      "Epoch 31/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9434 - loss: 0.1523\n",
      "Epoch 32/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9361 - loss: 0.1701\n",
      "Epoch 33/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9450 - loss: 0.1455\n",
      "Epoch 34/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9449 - loss: 0.1469\n",
      "Epoch 35/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9447 - loss: 0.1486\n",
      "Epoch 36/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9420 - loss: 0.1569\n",
      "Epoch 37/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9416 - loss: 0.1427\n",
      "Epoch 38/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9441 - loss: 0.1484\n",
      "Epoch 39/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9497 - loss: 0.1399\n",
      "Epoch 40/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9420 - loss: 0.1483\n",
      "Epoch 41/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9399 - loss: 0.1559\n",
      "Epoch 42/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9467 - loss: 0.1465\n",
      "Epoch 43/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9350 - loss: 0.1527\n",
      "Epoch 44/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9400 - loss: 0.1530\n",
      "Epoch 45/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9479 - loss: 0.1436\n",
      "Epoch 46/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9347 - loss: 0.1864\n",
      "Epoch 47/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9497 - loss: 0.1395\n",
      "Epoch 48/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9476 - loss: 0.1389\n",
      "Epoch 49/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9504 - loss: 0.1270\n",
      "Epoch 50/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9437 - loss: 0.1485\n",
      "Epoch 51/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9508 - loss: 0.1451\n",
      "Epoch 52/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9503 - loss: 0.1468\n",
      "Epoch 53/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9499 - loss: 0.1420\n",
      "Epoch 54/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9457 - loss: 0.1383\n",
      "Epoch 55/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9488 - loss: 0.1354\n",
      "Epoch 56/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9489 - loss: 0.1461\n",
      "Epoch 57/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9383 - loss: 0.1625\n",
      "Epoch 58/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9461 - loss: 0.1375\n",
      "Epoch 59/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9429 - loss: 0.1423\n",
      "Epoch 60/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9551 - loss: 0.1331\n",
      "Epoch 61/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9540 - loss: 0.1329\n",
      "Epoch 62/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9578 - loss: 0.1190\n",
      "Epoch 63/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9584 - loss: 0.1240\n",
      "Epoch 64/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9379 - loss: 0.1465\n",
      "Epoch 65/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9427 - loss: 0.1329\n",
      "Epoch 66/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9517 - loss: 0.1322\n",
      "Epoch 67/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9340 - loss: 0.1663\n",
      "Epoch 68/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9528 - loss: 0.1361\n",
      "Epoch 69/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9627 - loss: 0.1236\n",
      "Epoch 70/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9447 - loss: 0.1309\n",
      "Epoch 71/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9471 - loss: 0.1499\n",
      "Epoch 72/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9496 - loss: 0.1464\n",
      "Epoch 73/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9528 - loss: 0.1249\n",
      "Epoch 74/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9375 - loss: 0.1735\n",
      "Epoch 75/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9454 - loss: 0.1241\n",
      "Epoch 76/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9581 - loss: 0.1207\n",
      "Epoch 77/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9617 - loss: 0.1286\n",
      "Epoch 78/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9631 - loss: 0.1151\n",
      "Epoch 79/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9515 - loss: 0.1380\n",
      "Epoch 80/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9511 - loss: 0.1278\n",
      "Epoch 81/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9462 - loss: 0.1377\n",
      "Epoch 82/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9437 - loss: 0.1365\n",
      "Epoch 83/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9427 - loss: 0.1370\n",
      "Epoch 84/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9604 - loss: 0.1154\n",
      "Epoch 85/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9361 - loss: 0.1593\n",
      "Epoch 86/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9481 - loss: 0.1434\n",
      "Epoch 87/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9440 - loss: 0.1376\n",
      "Epoch 88/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9458 - loss: 0.1429\n",
      "Epoch 89/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9541 - loss: 0.1368\n",
      "Epoch 90/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9559 - loss: 0.1140\n",
      "Epoch 91/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9416 - loss: 0.1349\n",
      "Epoch 92/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9506 - loss: 0.1193\n",
      "Epoch 93/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9435 - loss: 0.1682\n",
      "Epoch 94/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9443 - loss: 0.1478\n",
      "Epoch 95/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9612 - loss: 0.1044\n",
      "Epoch 96/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9420 - loss: 0.1462\n",
      "Epoch 97/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9508 - loss: 0.1259\n",
      "Epoch 98/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9430 - loss: 0.1319\n",
      "Epoch 99/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9443 - loss: 0.1545\n",
      "Epoch 100/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9453 - loss: 0.1426\n",
      "Epoch 101/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9508 - loss: 0.1330\n",
      "Epoch 102/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9550 - loss: 0.1213\n",
      "Epoch 103/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9328 - loss: 0.1770\n",
      "Epoch 104/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9544 - loss: 0.1198\n",
      "Epoch 105/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9541 - loss: 0.1251\n",
      "Epoch 106/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9402 - loss: 0.1416\n",
      "Epoch 107/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9430 - loss: 0.1288\n",
      "Epoch 108/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9569 - loss: 0.1211\n",
      "Epoch 109/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9582 - loss: 0.1117\n",
      "Epoch 110/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9492 - loss: 0.1228\n",
      "Epoch 111/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9398 - loss: 0.1366\n",
      "Epoch 112/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9485 - loss: 0.1278\n",
      "Epoch 113/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9384 - loss: 0.1426\n",
      "Epoch 114/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9461 - loss: 0.1332\n",
      "Epoch 115/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9586 - loss: 0.1118\n",
      "Epoch 116/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9465 - loss: 0.1291\n",
      "Epoch 117/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9529 - loss: 0.1304\n",
      "Epoch 118/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9449 - loss: 0.1355\n",
      "Epoch 119/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9336 - loss: 0.1531\n",
      "Epoch 120/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9537 - loss: 0.1179\n",
      "Epoch 121/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9505 - loss: 0.1127\n",
      "Epoch 122/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9455 - loss: 0.1263\n",
      "Epoch 123/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9525 - loss: 0.1209\n",
      "Epoch 124/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9495 - loss: 0.1207\n",
      "Epoch 125/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9451 - loss: 0.1174\n",
      "Epoch 126/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9449 - loss: 0.1271\n",
      "Epoch 127/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9432 - loss: 0.1417\n",
      "Epoch 128/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9483 - loss: 0.1229\n",
      "Epoch 129/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9474 - loss: 0.1202\n",
      "Epoch 130/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9614 - loss: 0.0981\n",
      "Epoch 131/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9533 - loss: 0.1069\n",
      "Epoch 132/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9612 - loss: 0.1001\n",
      "Epoch 133/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9505 - loss: 0.1237\n",
      "Epoch 134/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9462 - loss: 0.1235\n",
      "Epoch 135/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9462 - loss: 0.1402\n",
      "Epoch 136/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9537 - loss: 0.1056\n",
      "Epoch 137/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9467 - loss: 0.1333\n",
      "Epoch 138/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9507 - loss: 0.1117\n",
      "Epoch 139/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9614 - loss: 0.1201\n",
      "Epoch 140/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9556 - loss: 0.1042\n",
      "Epoch 141/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9488 - loss: 0.1127\n",
      "Epoch 142/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9521 - loss: 0.1203\n",
      "Epoch 143/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9541 - loss: 0.1045\n",
      "Epoch 144/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9401 - loss: 0.1447\n",
      "Epoch 145/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9465 - loss: 0.1184\n",
      "Epoch 146/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9528 - loss: 0.1075\n",
      "Epoch 147/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9432 - loss: 0.1230\n",
      "Epoch 148/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9594 - loss: 0.1049\n",
      "Epoch 149/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9472 - loss: 0.1370\n",
      "Epoch 150/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9495 - loss: 0.1081\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8615 - loss: 0.6907 \n",
      "Loss: 0.6366373300552368, Accuracy: 0.8613861203193665\n",
      "Calcolo degli SHAP values...\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 272 background data samples could cause slower run times. Consider using shap.sample(data, K) or shap.kmeans(data, K) to summarize the background as K samples.\n",
      "  0%|                                                                                                        | 0/303 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▎                                                                                               | 1/303 [00:00<02:19,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▋                                                                                               | 2/303 [00:00<02:18,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▉                                                                                               | 3/303 [00:01<02:18,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|█▎                                                                                              | 4/303 [00:01<02:18,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▌                                                                                              | 5/303 [00:02<02:18,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▉                                                                                              | 6/303 [00:02<02:17,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|██▏                                                                                             | 7/303 [00:03<02:17,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=9.054e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 19 iterations, alpha=2.672e-04, previous alpha=1.045e-04, with an active set of 16 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=2.412e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.206e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.134e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.057e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=5.193e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=5.158e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=2.579e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=2.568e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=2.161e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=2.100e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.796e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 15 iterations, alpha=2.158e-03, previous alpha=2.483e-04, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=2.148e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.074e-02, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=6.462e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=4.608e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=4.059e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=3.889e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 13 iterations, alpha=2.735e-03, previous alpha=2.241e-03, with an active set of 8 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=8.731e-03, with an active set of 1 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=4.365e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=3.969e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=2.048e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=2.023e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=8.558e-04, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=5.268e-04, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 13 iterations, alpha=6.913e-04, previous alpha=3.563e-04, with an active set of 10 regressors.\n",
      "  warnings.warn(\n",
      "  3%|██▌                                                                                             | 8/303 [00:03<02:17,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██▊                                                                                             | 9/303 [00:04<02:16,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|███▏                                                                                           | 10/303 [00:04<02:16,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▍                                                                                           | 11/303 [00:05<02:15,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▊                                                                                           | 12/303 [00:05<02:15,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=9.694e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 29 iterations, i.e. alpha=4.483e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 29 iterations, i.e. alpha=3.504e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "  4%|████                                                                                           | 13/303 [00:06<02:15,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=2.923e-02, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=5.283e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=5.055e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 18 iterations, alpha=5.283e-03, previous alpha=5.022e-03, with an active set of 11 regressors.\n",
      "  warnings.warn(\n",
      "  5%|████▍                                                                                          | 14/303 [00:06<02:14,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=6.822e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=3.411e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 9 iterations, alpha=2.228e-03, previous alpha=2.218e-03, with an active set of 8 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=1.048e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=5.242e-03, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=3.304e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.560e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.281e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 9 iterations, alpha=1.236e-03, previous alpha=7.965e-04, with an active set of 8 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.514e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 15 iterations, alpha=1.267e-04, previous alpha=8.027e-05, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=5.574e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=2.787e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 6 iterations, alpha=1.769e-02, previous alpha=1.582e-02, with an active set of 5 regressors.\n",
      "  warnings.warn(\n",
      "  5%|████▋                                                                                          | 15/303 [00:06<02:13,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|█████                                                                                          | 16/303 [00:07<02:13,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|█████▎                                                                                         | 17/303 [00:07<02:12,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|█████▋                                                                                         | 18/303 [00:08<02:12,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|█████▉                                                                                         | 19/303 [00:08<02:11,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██████▎                                                                                        | 20/303 [00:09<02:11,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██████▌                                                                                        | 21/303 [00:09<02:10,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██████▉                                                                                        | 22/303 [00:10<02:10,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|███████▏                                                                                       | 23/303 [00:10<02:09,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=6.385e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=9.965e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=8.104e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 21 iterations, alpha=9.432e-04, previous alpha=7.590e-04, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=3.690e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=5.021e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=3.000e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.263e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 16 iterations, alpha=3.594e-04, previous alpha=6.449e-05, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=1.529e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=2.162e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 13 iterations, alpha=7.243e-04, previous alpha=5.908e-04, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      "  8%|███████▌                                                                                       | 24/303 [00:11<02:09,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|███████▊                                                                                       | 25/303 [00:11<02:08,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|████████▏                                                                                      | 26/303 [00:12<02:08,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=3.111e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=2.506e-04, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "  9%|████████▍                                                                                      | 27/303 [00:12<02:07,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|████████▊                                                                                      | 28/303 [00:12<02:07,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█████████                                                                                      | 29/303 [00:13<02:06,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█████████▍                                                                                     | 30/303 [00:13<02:06,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█████████▋                                                                                     | 31/303 [00:14<02:06,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|██████████                                                                                     | 32/303 [00:14<02:05,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|██████████▎                                                                                    | 33/303 [00:15<02:05,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|██████████▋                                                                                    | 34/303 [00:15<02:04,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|██████████▉                                                                                    | 35/303 [00:16<02:04,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 815us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|███████████▎                                                                                   | 36/303 [00:16<02:04,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|███████████▌                                                                                   | 37/303 [00:17<02:03,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=5.953e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=6.978e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=6.978e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=6.878e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=1.060e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=1.060e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=2.398e-06, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=2.398e-06, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=6.584e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=3.195e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.066e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=9.387e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=4.599e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=2.012e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 14 iterations, alpha=2.020e-03, previous alpha=1.351e-04, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=7.198e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 20 iterations, alpha=3.885e-05, previous alpha=3.268e-05, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      " 13%|███████████▉                                                                                   | 38/303 [00:17<02:03,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=2.532e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=1.266e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=8.910e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=1.553e-05, with an active set of 16 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=7.623e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=7.988e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=7.278e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=5.246e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=2.855e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=1.229e-03, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=2.830e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=1.246e-04, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=2.840e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=4.230e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=2.427e-06, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 13%|████████████▏                                                                                  | 39/303 [00:18<02:02,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 840us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.477e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=1.130e-03, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=2.430e-05, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=7.464e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=3.661e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=5.860e-05, with an active set of 16 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 9 iterations, alpha=5.084e-04, previous alpha=4.832e-04, with an active set of 10 regressors.\n",
      "  warnings.warn(\n",
      " 13%|████████████▌                                                                                  | 40/303 [00:18<02:02,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 829us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|████████████▊                                                                                  | 41/303 [00:19<02:02,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█████████████▏                                                                                 | 42/303 [00:19<02:06,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█████████████▍                                                                                 | 43/303 [00:20<02:04,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█████████████▊                                                                                 | 44/303 [00:20<02:03,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|██████████████                                                                                 | 45/303 [00:20<02:01,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|██████████████▍                                                                                | 46/303 [00:21<02:00,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|██████████████▋                                                                                | 47/303 [00:21<01:59,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=3.072e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.140e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.135e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 13 iterations, alpha=1.140e-03, previous alpha=9.908e-04, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=3.603e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=2.863e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=6.535e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 13 iterations, alpha=3.562e-03, previous alpha=2.968e-03, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      " 16%|███████████████                                                                                | 48/303 [00:22<01:59,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|███████████████▎                                                                               | 49/303 [00:22<01:58,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|███████████████▋                                                                               | 50/303 [00:23<01:57,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|███████████████▉                                                                               | 51/303 [00:23<01:57,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 815us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=3.419e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 19 iterations, alpha=3.419e-05, previous alpha=3.404e-05, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=3.123e-02, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=2.394e-03, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=2.147e-03, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 23 iterations, alpha=2.147e-03, previous alpha=1.415e-03, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=8.814e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=7.697e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 17%|████████████████▎                                                                              | 52/303 [00:24<01:56,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|████████████████▌                                                                              | 53/303 [00:24<01:56,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|████████████████▉                                                                              | 54/303 [00:25<01:55,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=2.569e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=3.828e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 15 iterations, alpha=3.364e-03, previous alpha=3.089e-03, with an active set of 10 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.437e-02, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 32 iterations, i.e. alpha=1.579e-04, with an active set of 16 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.191e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=4.248e-05, with an active set of 16 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 18%|█████████████████▏                                                                             | 55/303 [00:25<01:55,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█████████████████▌                                                                             | 56/303 [00:26<01:54,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█████████████████▊                                                                             | 57/303 [00:26<01:54,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=2.997e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.040e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 16 iterations, alpha=5.292e-04, previous alpha=4.967e-04, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=4.050e-04, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=2.173e-04, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.491e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=6.171e-05, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=2.088e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=9.938e-06, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=3.575e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=1.679e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=8.133e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=4.339e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=5.040e-07, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=2.698e-07, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 19%|██████████████████▏                                                                            | 58/303 [00:27<01:53,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 815us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=3.828e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.494e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=4.469e-05, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=2.165e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 19%|██████████████████▍                                                                            | 59/303 [00:27<01:53,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██████████████████▊                                                                            | 60/303 [00:27<01:53,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=4.189e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=4.850e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.782e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.684e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 15 iterations, alpha=3.592e-03, previous alpha=1.300e-03, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.022e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=2.769e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 14 iterations, alpha=1.022e-04, previous alpha=1.142e-05, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=4.485e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=3.949e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 14 iterations, alpha=2.566e-03, previous alpha=1.777e-03, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      " 20%|███████████████████▏                                                                           | 61/303 [00:28<01:52,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████████████████▍                                                                           | 62/303 [00:28<01:51,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|███████████████████▊                                                                           | 63/303 [00:29<01:51,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|████████████████████                                                                           | 64/303 [00:29<01:51,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|████████████████████▍                                                                          | 65/303 [00:30<01:50,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|████████████████████▋                                                                          | 66/303 [00:30<01:49,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|█████████████████████                                                                          | 67/303 [00:31<01:49,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.746e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=7.422e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 14 iterations, alpha=7.422e-05, previous alpha=5.934e-05, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=2.695e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.008e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=7.009e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=3.642e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.919e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 12 iterations, alpha=3.302e-03, previous alpha=8.172e-04, with an active set of 11 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=3.884e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 10 iterations, alpha=2.649e-03, previous alpha=2.396e-03, with an active set of 9 regressors.\n",
      "  warnings.warn(\n",
      " 22%|█████████████████████▎                                                                         | 68/303 [00:31<01:49,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=4.298e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.250e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 11 iterations, alpha=9.413e-04, previous alpha=9.383e-04, with an active set of 10 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.307e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=7.908e-04, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=3.003e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=2.251e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=6.700e-05, with an active set of 16 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=1.860e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=6.556e-05, with an active set of 16 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 23%|█████████████████████▋                                                                         | 69/303 [00:32<01:48,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|█████████████████████▉                                                                         | 70/303 [00:32<01:48,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██████████████████████▎                                                                        | 71/303 [00:33<01:47,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██████████████████████▌                                                                        | 72/303 [00:33<01:47,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██████████████████████▉                                                                        | 73/303 [00:33<01:46,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=6.889e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=5.425e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=3.192e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=3.160e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.128e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 12 iterations, alpha=1.787e-03, previous alpha=1.048e-03, with an active set of 11 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=3.534e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.140e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=2.362e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 16 iterations, alpha=2.075e-04, previous alpha=1.091e-06, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=9.552e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=3.105e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 16 iterations, alpha=2.395e-04, previous alpha=1.659e-04, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      " 24%|███████████████████████▏                                                                       | 74/303 [00:34<01:46,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|███████████████████████▌                                                                       | 75/303 [00:34<01:45,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|███████████████████████▊                                                                       | 76/303 [00:35<01:45,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.434e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=6.159e-04, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=2.990e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 16 iterations, alpha=1.992e-04, previous alpha=4.724e-05, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.068e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=3.193e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 21 iterations, alpha=2.958e-04, previous alpha=6.305e-05, with an active set of 16 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=2.353e-02, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=9.561e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=6.450e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 13 iterations, alpha=9.427e-03, previous alpha=5.712e-03, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=3.453e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=1.093e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=8.402e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 19 iterations, alpha=8.829e-04, previous alpha=3.454e-04, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      " 25%|████████████████████████▏                                                                      | 77/303 [00:35<01:44,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|████████████████████████▍                                                                      | 78/303 [00:36<01:44,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|████████████████████████▊                                                                      | 79/303 [00:36<01:44,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=1.150e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 20 iterations, alpha=1.150e-05, previous alpha=1.103e-05, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.044e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=4.382e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=4.318e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 12 iterations, alpha=4.382e-04, previous alpha=4.202e-04, with an active set of 11 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=2.369e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 13 iterations, alpha=2.369e-03, previous alpha=2.369e-03, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      " 26%|█████████████████████████                                                                      | 80/303 [00:37<01:43,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|█████████████████████████▍                                                                     | 81/303 [00:37<01:43,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.164e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=8.862e-05, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=3.262e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=1.762e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=5.006e-06, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/shap/explainers/_kernel.py:707: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.011e-02, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 10 iterations, alpha=3.713e-03, previous alpha=3.713e-03, with an active set of 9 regressors.\n",
      "  warnings.warn(\n",
      " 27%|█████████████████████████▋                                                                     | 82/303 [00:38<01:42,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██████████████████████████                                                                     | 83/303 [00:38<01:42,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=3.722e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=7.138e-03, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=5.929e-03, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=2.060e-05, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=8.152e-06, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=8.152e-06, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 14 iterations, alpha=8.152e-06, previous alpha=8.134e-06, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=3.265e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=2.985e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=2.325e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=3.807e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.108e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=4.454e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=4.229e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=9.516e-06, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 28%|██████████████████████████▎                                                                    | 84/303 [00:39<01:41,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=1.273e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=5.833e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=5.833e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=4.304e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=2.595e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.256e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.256e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=6.465e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 13 iterations, alpha=1.236e-03, previous alpha=4.761e-04, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=2.855e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=1.428e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.081e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.062e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=5.278e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=3.587e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=3.038e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=2.263e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.481e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.254e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=7.952e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=2.635e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=1.680e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=6.373e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=5.327e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=2.664e-02, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.169e-02, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=5.514e-03, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=3.602e-03, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=5.970e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=3.219e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.610e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=8.048e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=8.007e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 13 iterations, alpha=4.901e-03, previous alpha=4.461e-03, with an active set of 10 regressors.\n",
      "  warnings.warn(\n",
      " 28%|██████████████████████████▋                                                                    | 85/303 [00:39<01:41,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██████████████████████████▉                                                                    | 86/303 [00:40<01:40,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|███████████████████████████▎                                                                   | 87/303 [00:40<01:40,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 815us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|███████████████████████████▌                                                                   | 88/303 [00:40<01:40,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|███████████████████████████▉                                                                   | 89/303 [00:41<01:39,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=2.408e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=1.032e-04, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=2.880e-02, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=3.104e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=3.101e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=1.149e-03, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 26 iterations, alpha=1.956e-03, previous alpha=1.147e-03, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=3.395e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.632e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 17 iterations, alpha=1.196e-04, previous alpha=4.366e-05, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=4.307e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.148e-02, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 10 iterations, alpha=1.122e-02, previous alpha=1.009e-02, with an active set of 9 regressors.\n",
      "  warnings.warn(\n",
      " 30%|████████████████████████████▏                                                                  | 90/303 [00:41<01:39,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=3.402e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.140e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=8.754e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=4.782e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 14 iterations, alpha=5.070e-03, previous alpha=3.843e-03, with an active set of 11 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=6.626e-04, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.430e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=3.446e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=1.529e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=3.188e-06, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=9.242e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=2.374e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.164e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 9 iterations, alpha=1.044e-03, previous alpha=9.872e-04, with an active set of 8 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.433e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=2.116e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 30%|████████████████████████████▌                                                                  | 91/303 [00:42<01:38,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████████████████████▊                                                                  | 92/303 [00:42<01:37,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|█████████████████████████████▏                                                                 | 93/303 [00:43<01:37,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|█████████████████████████████▍                                                                 | 94/303 [00:43<01:36,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|█████████████████████████████▊                                                                 | 95/303 [00:44<01:36,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|██████████████████████████████                                                                 | 96/303 [00:44<01:36,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|██████████████████████████████▍                                                                | 97/303 [00:45<01:35,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=1.131e-06, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=9.375e-07, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=6.700e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 13 iterations, alpha=6.700e-04, previous alpha=5.837e-04, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=7.070e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.261e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 13 iterations, alpha=1.261e-03, previous alpha=1.253e-03, with an active set of 10 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=3.766e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=9.497e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 13 iterations, alpha=9.497e-04, previous alpha=9.441e-04, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      " 32%|██████████████████████████████▋                                                                | 98/303 [00:45<01:35,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=2.100e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=6.343e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 15 iterations, alpha=5.957e-04, previous alpha=5.084e-04, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=4.940e-04, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=2.715e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=2.047e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 13 iterations, alpha=2.715e-04, previous alpha=1.860e-04, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=3.085e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=1.167e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=6.699e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=5.996e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 18 iterations, alpha=9.711e-05, previous alpha=3.639e-05, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      " 33%|███████████████████████████████                                                                | 99/303 [00:46<01:34,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=1.243e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=6.214e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=6.214e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=3.107e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=3.015e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.881e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.180e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=8.941e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=7.086e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=4.441e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 14 iterations, alpha=1.121e-03, previous alpha=4.211e-04, with an active set of 11 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=7.124e-04, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=5.622e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=3.079e-04, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=2.247e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=9.082e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=6.705e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=5.206e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.479e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=4.146e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.614e-03, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=6.959e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 14 iterations, alpha=1.577e-03, previous alpha=6.357e-04, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=1.106e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=9.331e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=6.321e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=6.321e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=3.538e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=2.823e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 10 iterations, alpha=2.656e-03, previous alpha=2.012e-03, with an active set of 9 regressors.\n",
      "  warnings.warn(\n",
      " 33%|███████████████████████████████                                                               | 100/303 [00:46<01:34,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 824us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███████████████████████████████▎                                                              | 101/303 [00:46<01:33,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███████████████████████████████▋                                                              | 102/303 [00:47<01:33,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███████████████████████████████▉                                                              | 103/303 [00:47<01:32,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=6.035e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=3.740e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=2.091e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.998e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=9.259e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=2.912e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.714e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=6.392e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.740e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=8.177e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=6.455e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=5.197e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 15 iterations, alpha=4.906e-03, previous alpha=3.076e-03, with an active set of 10 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=6.277e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=5.344e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=4.374e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 34%|████████████████████████████████▎                                                             | 104/303 [00:48<01:32,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.065e-02, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=9.789e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=5.230e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 7 iterations, alpha=5.185e-03, previous alpha=5.116e-03, with an active set of 6 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.318e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=1.301e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=6.696e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 18 iterations, alpha=6.696e-05, previous alpha=2.469e-06, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      " 35%|████████████████████████████████▌                                                             | 105/303 [00:48<01:31,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=4.215e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=8.006e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 14 iterations, alpha=5.301e-03, previous alpha=5.292e-03, with an active set of 9 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.471e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=4.446e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 19 iterations, alpha=1.592e-03, previous alpha=1.592e-03, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=9.185e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=5.633e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.455e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 14 iterations, alpha=2.836e-03, previous alpha=8.069e-04, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      " 35%|████████████████████████████████▉                                                             | 106/303 [00:49<01:31,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|█████████████████████████████████▏                                                            | 107/303 [00:49<01:31,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 20 iterations, alpha=7.399e-05, previous alpha=7.365e-05, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=3.640e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=2.570e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.432e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=6.841e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=3.498e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=8.763e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=3.677e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.677e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=4.496e-07, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 36%|█████████████████████████████████▌                                                            | 108/303 [00:50<01:30,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|█████████████████████████████████▊                                                            | 109/303 [00:50<01:30,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|██████████████████████████████████▏                                                           | 110/303 [00:51<01:29,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|██████████████████████████████████▍                                                           | 111/303 [00:51<01:29,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=2.601e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=2.237e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 22 iterations, alpha=5.626e-03, previous alpha=2.648e-03, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=3.305e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.652e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=3.317e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.356e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=1.206e-03, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=6.671e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=6.069e-07, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=4.017e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=2.009e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.322e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=6.591e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=3.268e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=1.080e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.259e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=6.297e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=5.360e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=4.415e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=4.115e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 12 iterations, alpha=2.426e-03, previous alpha=1.747e-03, with an active set of 11 regressors.\n",
      "  warnings.warn(\n",
      " 37%|██████████████████████████████████▋                                                           | 112/303 [00:52<01:28,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███████████████████████████████████                                                           | 113/303 [00:52<01:28,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███████████████████████████████████▎                                                          | 114/303 [00:53<01:28,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███████████████████████████████████▋                                                          | 115/303 [00:53<01:27,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=1.345e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=3.008e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=2.639e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=2.225e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=4.753e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=1.804e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=4.536e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=1.115e-05, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=2.856e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 14 iterations, alpha=7.595e-03, previous alpha=7.585e-03, with an active set of 7 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=1.207e-01, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 15 iterations, alpha=3.206e-02, previous alpha=3.199e-02, with an active set of 8 regressors.\n",
      "  warnings.warn(\n",
      " 38%|███████████████████████████████████▉                                                          | 116/303 [00:53<01:26,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=4.968e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=4.537e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 19 iterations, alpha=1.756e-03, previous alpha=1.106e-03, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=2.682e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=1.452e-03, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=1.214e-03, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=3.941e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=1.730e-04, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.461e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.319e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=3.166e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=9.066e-06, with an active set of 16 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 39%|████████████████████████████████████▎                                                         | 117/303 [00:54<01:26,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|████████████████████████████████████▌                                                         | 118/303 [00:54<01:26,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|████████████████████████████████████▉                                                         | 119/303 [00:55<01:25,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████████████████████████▏                                                        | 120/303 [00:55<01:25,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████████████████████████▌                                                        | 121/303 [00:56<01:24,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████████████████████████▊                                                        | 122/303 [00:56<01:24,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|██████████████████████████████████████▏                                                       | 123/303 [00:57<01:23,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|██████████████████████████████████████▍                                                       | 124/303 [00:57<01:23,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|██████████████████████████████████████▊                                                       | 125/303 [00:58<01:22,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|███████████████████████████████████████                                                       | 126/303 [00:58<01:22,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|███████████████████████████████████████▍                                                      | 127/303 [00:59<01:21,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|███████████████████████████████████████▋                                                      | 128/303 [00:59<01:21,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.852e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=3.369e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=2.162e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=5.213e-04, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=8.008e-05, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=7.564e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 24 iterations, alpha=6.641e-05, previous alpha=3.461e-05, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.217e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=3.138e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 13 iterations, alpha=2.436e-03, previous alpha=2.206e-03, with an active set of 10 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.322e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.183e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=1.491e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=8.777e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 43%|████████████████████████████████████████                                                      | 129/303 [00:59<01:20,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████████████████████████████████████████▎                                                     | 130/303 [01:00<01:20,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████████████████████████████████████████▋                                                     | 131/303 [01:00<01:19,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=2.889e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.445e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 13 iterations, alpha=2.549e-04, previous alpha=1.432e-04, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=1.188e-01, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=5.940e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 11 iterations, alpha=2.620e-02, previous alpha=2.513e-02, with an active set of 8 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.697e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=4.377e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=3.094e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=5.346e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.205e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=4.451e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=2.226e-02, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=2.389e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=9.540e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.454e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.547e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 44%|████████████████████████████████████████▉                                                     | 132/303 [01:01<01:19,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=8.022e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 15 iterations, alpha=5.771e-05, previous alpha=2.081e-05, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      " 44%|█████████████████████████████████████████▎                                                    | 133/303 [01:01<01:18,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=4.971e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=1.551e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=1.321e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=5.883e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 19 iterations, alpha=1.497e-04, previous alpha=5.026e-05, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=6.290e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=1.097e-02, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=1.000e-02, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=6.846e-03, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.834e-03, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.209e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=3.973e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=2.744e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=4.642e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=2.266e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 17 iterations, alpha=2.387e-04, previous alpha=2.043e-04, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      " 44%|█████████████████████████████████████████▌                                                    | 134/303 [01:02<01:18,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|█████████████████████████████████████████▉                                                    | 135/303 [01:02<01:17,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|██████████████████████████████████████████▏                                                   | 136/303 [01:03<01:17,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|██████████████████████████████████████████▌                                                   | 137/303 [01:03<01:17,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|██████████████████████████████████████████▊                                                   | 138/303 [01:04<01:16,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|███████████████████████████████████████████                                                   | 139/303 [01:04<01:16,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|███████████████████████████████████████████▍                                                  | 140/303 [01:05<01:15,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=3.959e-04, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=3.478e-04, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.527e-04, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=9.484e-05, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 12 iterations, alpha=9.484e-05, previous alpha=9.055e-05, with an active set of 11 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=2.095e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=6.120e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 22 iterations, alpha=6.120e-05, previous alpha=5.851e-05, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      " 47%|███████████████████████████████████████████▋                                                  | 141/303 [01:05<01:15,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████████████████████████████████████████████                                                  | 142/303 [01:06<01:15,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████████████████████████████████████████████▎                                                 | 143/303 [01:06<01:14,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████████████████████████████████████████████▋                                                 | 144/303 [01:06<01:13,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 822us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=6.643e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=3.313e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=8.771e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=5.609e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=1.192e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 23 iterations, alpha=7.729e-05, previous alpha=5.711e-05, with an active set of 16 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=7.557e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=5.518e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=2.589e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=7.113e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 15 iterations, alpha=1.580e-03, previous alpha=5.679e-04, with an active set of 10 regressors.\n",
      "  warnings.warn(\n",
      " 48%|████████████████████████████████████████████▉                                                 | 145/303 [01:07<01:13,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|█████████████████████████████████████████████▎                                                | 146/303 [01:07<01:12,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|█████████████████████████████████████████████▌                                                | 147/303 [01:08<01:12,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|█████████████████████████████████████████████▉                                                | 148/303 [01:08<01:11,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=6.927e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=3.464e-02, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 14 iterations, alpha=1.431e-02, previous alpha=1.416e-02, with an active set of 11 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=2.611e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=2.065e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=6.365e-06, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 49%|██████████████████████████████████████████████▏                                               | 149/303 [01:09<01:11,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████████████████████████████▌                                               | 150/303 [01:09<01:10,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=5.059e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=5.516e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=3.578e-03, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=1.864e-03, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=1.488e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.054e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 19 iterations, alpha=5.272e-06, previous alpha=5.272e-06, with an active set of 16 regressors.\n",
      "  warnings.warn(\n",
      " 50%|██████████████████████████████████████████████▊                                               | 151/303 [01:10<01:10,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.860e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=9.300e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=4.530e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=4.329e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 13 iterations, alpha=4.461e-03, previous alpha=3.565e-03, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=3.203e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.601e-02, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=6.061e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=1.370e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 21 iterations, alpha=1.656e-03, previous alpha=1.143e-03, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      " 50%|███████████████████████████████████████████████▏                                              | 152/303 [01:10<01:09,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|███████████████████████████████████████████████▍                                              | 153/303 [01:11<01:09,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|███████████████████████████████████████████████▊                                              | 154/303 [01:11<01:09,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|████████████████████████████████████████████████                                              | 155/303 [01:12<01:08,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|████████████████████████████████████████████████▍                                             | 156/303 [01:12<01:08,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 815us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|████████████████████████████████████████████████▋                                             | 157/303 [01:12<01:07,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████████████████████████████████████████████████                                             | 158/303 [01:13<01:07,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████████████████████████████████████████████████▎                                            | 159/303 [01:13<01:06,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████████████████████████████████████████████████▋                                            | 160/303 [01:14<01:06,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████████████████████████████████████████████████▉                                            | 161/303 [01:14<01:06,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|██████████████████████████████████████████████████▎                                           | 162/303 [01:15<01:05,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|██████████████████████████████████████████████████▌                                           | 163/303 [01:15<01:05,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|██████████████████████████████████████████████████▉                                           | 164/303 [01:16<01:04,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|███████████████████████████████████████████████████▏                                          | 165/303 [01:16<01:04,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=2.947e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=2.418e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=2.272e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 18 iterations, alpha=2.002e-03, previous alpha=1.823e-03, with an active set of 11 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=1.818e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 17 iterations, alpha=1.818e-05, previous alpha=2.274e-06, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=3.590e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=3.863e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=2.305e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 19 iterations, alpha=3.863e-04, previous alpha=4.832e-05, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      " 55%|███████████████████████████████████████████████████▍                                          | 166/303 [01:17<01:03,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=1.584e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 55%|███████████████████████████████████████████████████▊                                          | 167/303 [01:17<01:03,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|████████████████████████████████████████████████████                                          | 168/303 [01:18<01:02,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=2.062e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=1.183e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=9.707e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=2.309e-04, with an active set of 16 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.059e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=2.035e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 10 iterations, alpha=2.035e-03, previous alpha=2.026e-03, with an active set of 9 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=9.464e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=3.231e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 19 iterations, alpha=3.231e-05, previous alpha=3.216e-05, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=9.955e-04, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=2.575e-07, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 26 iterations, alpha=2.575e-07, previous alpha=2.138e-07, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      " 56%|████████████████████████████████████████████████████▍                                         | 169/303 [01:18<01:02,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|████████████████████████████████████████████████████▋                                         | 170/303 [01:19<01:01,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████████████████████████████████████████████████████                                         | 171/303 [01:19<01:01,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.978e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=2.794e-05, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 57%|█████████████████████████████████████████████████████▎                                        | 172/303 [01:19<01:00,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=7.768e-04, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=3.976e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=1.954e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=1.359e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.146e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=4.126e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 12 iterations, alpha=2.060e-03, previous alpha=2.028e-03, with an active set of 11 regressors.\n",
      "  warnings.warn(\n",
      " 57%|█████████████████████████████████████████████████████▋                                        | 173/303 [01:20<01:00,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████████████████████████████████████████████████████▉                                        | 174/303 [01:20<01:00,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=5.985e-03, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=9.283e-04, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=5.321e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=2.661e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 14 iterations, alpha=4.651e-04, previous alpha=2.631e-04, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=5.222e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=2.827e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=2.186e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 7 iterations, alpha=1.575e-03, previous alpha=1.432e-03, with an active set of 6 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.151e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=2.470e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=2.080e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=3.125e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=5.898e-07, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.080e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=5.399e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=5.399e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=2.490e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=1.922e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 17 iterations, alpha=2.713e-04, previous alpha=1.656e-04, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      " 58%|██████████████████████████████████████████████████████▎                                       | 175/303 [01:21<00:59,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=5.654e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=3.883e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 19 iterations, alpha=8.056e-04, previous alpha=7.398e-04, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      " 58%|██████████████████████████████████████████████████████▌                                       | 176/303 [01:21<00:58,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|██████████████████████████████████████████████████████▉                                       | 177/303 [01:22<00:58,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|███████████████████████████████████████████████████████▏                                      | 178/303 [01:22<00:58,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|███████████████████████████████████████████████████████▌                                      | 179/303 [01:23<00:57,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|███████████████████████████████████████████████████████▊                                      | 180/303 [01:23<00:57,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|████████████████████████████████████████████████████████▏                                     | 181/303 [01:24<00:56,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|████████████████████████████████████████████████████████▍                                     | 182/303 [01:24<00:56,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|████████████████████████████████████████████████████████▊                                     | 183/303 [01:25<00:55,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|█████████████████████████████████████████████████████████                                     | 184/303 [01:25<00:55,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|█████████████████████████████████████████████████████████▍                                    | 185/303 [01:26<00:54,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|█████████████████████████████████████████████████████████▋                                    | 186/303 [01:26<00:54,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████████████████████████████████████████████████████████                                    | 187/303 [01:26<00:53,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████████████████████████████████████████████████████████▎                                   | 188/303 [01:27<00:53,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=2.833e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 14 iterations, alpha=4.785e-03, previous alpha=4.708e-03, with an active set of 11 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=3.676e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.233e-02, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 12 iterations, alpha=1.220e-02, previous alpha=1.086e-02, with an active set of 9 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=2.135e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.209e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=7.922e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 11 iterations, alpha=7.319e-04, previous alpha=4.542e-04, with an active set of 10 regressors.\n",
      "  warnings.warn(\n",
      " 62%|██████████████████████████████████████████████████████████▋                                   | 189/303 [01:27<00:52,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████████████████████████████████████████████████████████▉                                   | 190/303 [01:28<00:52,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=2.611e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=5.397e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 12 iterations, alpha=5.397e-04, previous alpha=5.386e-04, with an active set of 9 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=2.184e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.092e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=5.327e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 8 iterations, alpha=5.327e-03, previous alpha=5.263e-03, with an active set of 7 regressors.\n",
      "  warnings.warn(\n",
      " 63%|███████████████████████████████████████████████████████████▎                                  | 191/303 [01:28<00:51,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=4.929e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=6.110e-04, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=7.624e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=4.539e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=4.333e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=9.182e-06, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=8.766e-06, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.571e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.286e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.233e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=7.151e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 17 iterations, alpha=1.129e-03, previous alpha=1.463e-04, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      " 63%|███████████████████████████████████████████████████████████▌                                  | 192/303 [01:29<00:51,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|███████████████████████████████████████████████████████████▊                                  | 193/303 [01:29<00:51,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=2.513e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=4.568e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 12 iterations, alpha=4.568e-03, previous alpha=4.559e-03, with an active set of 9 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=7.338e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=9.746e-06, with an active set of 16 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=2.565e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=2.026e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.983e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 64%|████████████████████████████████████████████████████████████▏                                 | 194/303 [01:30<00:50,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=6.611e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=3.138e-02, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 11 iterations, alpha=2.454e-02, previous alpha=2.167e-02, with an active set of 10 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=8.799e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=4.385e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.294e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=5.154e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 16 iterations, alpha=1.982e-03, previous alpha=3.848e-04, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      " 64%|████████████████████████████████████████████████████████████▍                                 | 195/303 [01:30<00:50,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|████████████████████████████████████████████████████████████▊                                 | 196/303 [01:31<00:49,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|█████████████████████████████████████████████████████████████                                 | 197/303 [01:31<00:49,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.043e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=2.503e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.252e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=7.738e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=7.718e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=3.381e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=2.761e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=2.091e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=1.410e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=1.234e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 10 iterations, alpha=4.831e-03, previous alpha=4.436e-03, with an active set of 9 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=2.894e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.206e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 18 iterations, alpha=3.325e-03, previous alpha=3.281e-03, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      " 65%|█████████████████████████████████████████████████████████████▍                                | 198/303 [01:32<00:48,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|█████████████████████████████████████████████████████████████▋                                | 199/303 [01:32<00:48,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=4.210e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=1.430e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.146e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 7 iterations, alpha=9.451e-03, previous alpha=9.146e-03, with an active set of 6 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=6.858e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=3.873e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=2.423e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 10 iterations, alpha=3.261e-03, previous alpha=1.380e-03, with an active set of 9 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=3.395e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=7.557e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=7.557e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=6.871e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=3.778e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=3.778e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=1.378e-03, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 17 iterations, alpha=1.032e-03, previous alpha=3.463e-04, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      " 66%|██████████████████████████████████████████████████████████████                                | 200/303 [01:32<00:47,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=2.814e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.669e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=3.397e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 19 iterations, alpha=3.395e-05, previous alpha=9.390e-06, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      " 66%|██████████████████████████████████████████████████████████████▎                               | 201/303 [01:33<00:47,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████████████████████████████████████████████████████████████▋                               | 202/303 [01:33<00:46,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████████████████████████████████████████████████████████████▉                               | 203/303 [01:34<00:46,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|███████████████████████████████████████████████████████████████▎                              | 204/303 [01:34<00:45,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|███████████████████████████████████████████████████████████████▌                              | 205/303 [01:35<00:45,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|███████████████████████████████████████████████████████████████▉                              | 206/303 [01:35<00:44,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=4.400e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=2.200e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.063e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=4.455e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 8 iterations, alpha=3.774e-03, previous alpha=2.146e-03, with an active set of 7 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=8.283e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.214e-02, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 10 iterations, alpha=1.204e-02, previous alpha=6.904e-03, with an active set of 7 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=7.268e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=9.123e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=8.351e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=3.730e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=3.337e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.500e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 18 iterations, alpha=2.230e-04, previous alpha=1.322e-04, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      " 68%|████████████████████████████████████████████████████████████████▏                             | 207/303 [01:36<00:44,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|████████████████████████████████████████████████████████████████▌                             | 208/303 [01:36<00:44,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|████████████████████████████████████████████████████████████████▊                             | 209/303 [01:37<00:43,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=6.168e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=1.392e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.034e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=9.138e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=5.946e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 17 iterations, alpha=2.554e-03, previous alpha=1.436e-03, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=3.625e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=2.490e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=2.079e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=1.027e-03, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=3.489e-04, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 69%|█████████████████████████████████████████████████████████████████▏                            | 210/303 [01:37<00:43,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=3.460e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.281e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=4.890e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=2.654e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 12 iterations, alpha=2.103e-03, previous alpha=2.031e-03, with an active set of 11 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.061e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.211e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=4.467e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=3.629e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=2.333e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 19 iterations, alpha=2.320e-04, previous alpha=2.066e-04, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=1.490e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=7.770e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=3.221e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.750e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=7.299e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=2.268e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.820e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.226e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 15 iterations, alpha=1.464e-03, previous alpha=3.027e-05, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=9.616e-03, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=7.672e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=8.138e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 17 iterations, alpha=7.491e-04, previous alpha=6.080e-04, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      " 70%|█████████████████████████████████████████████████████████████████▍                            | 211/303 [01:38<00:42,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|█████████████████████████████████████████████████████████████████▊                            | 212/303 [01:38<00:42,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=1.626e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.180e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=9.865e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=4.371e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 14 iterations, alpha=4.754e-03, previous alpha=1.968e-03, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=4.727e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=2.334e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 15 iterations, alpha=7.985e-03, previous alpha=7.393e-03, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      " 70%|██████████████████████████████████████████████████████████████████                            | 213/303 [01:39<00:41,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|██████████████████████████████████████████████████████████████████▍                           | 214/303 [01:39<00:41,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=3.010e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=1.505e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=1.398e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=6.860e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=3.430e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 15 iterations, alpha=4.222e-03, previous alpha=2.766e-03, with an active set of 10 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=1.517e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=7.407e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=1.761e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 22 iterations, alpha=1.676e-05, previous alpha=7.799e-06, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=2.660e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=2.538e-04, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 18 iterations, alpha=2.248e-04, previous alpha=2.108e-04, with an active set of 11 regressors.\n",
      "  warnings.warn(\n",
      " 71%|██████████████████████████████████████████████████████████████████▋                           | 215/303 [01:39<00:40,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=2.233e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.117e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=3.650e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 18 iterations, alpha=2.394e-03, previous alpha=2.020e-03, with an active set of 11 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=6.919e-04, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=6.633e-04, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=2.875e-04, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=2.421e-04, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.156e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=4.333e-05, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=2.501e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.547e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=8.879e-06, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=2.190e-06, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=9.069e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=4.535e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=3.734e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.841e-02, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.207e-02, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.203e-02, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 9 iterations, alpha=1.370e-02, previous alpha=1.161e-02, with an active set of 8 regressors.\n",
      "  warnings.warn(\n",
      " 71%|███████████████████████████████████████████████████████████████████                           | 216/303 [01:40<00:40,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████████████████████████████████████████████████████████████████▎                          | 217/303 [01:40<00:39,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████████████████████████████████████████████████████████████████▋                          | 218/303 [01:41<00:39,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████████████████████████████████████████████████████████████████▉                          | 219/303 [01:41<00:39,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|████████████████████████████████████████████████████████████████████▎                         | 220/303 [01:42<00:38,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|████████████████████████████████████████████████████████████████████▌                         | 221/303 [01:42<00:38,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=8.995e-04, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=5.792e-04, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.767e-04, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 13 iterations, alpha=1.236e-04, previous alpha=1.147e-04, with an active set of 10 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=4.001e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.248e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 18 iterations, alpha=1.248e-04, previous alpha=3.704e-05, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=4.392e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=4.110e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=2.035e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=1.648e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 16 iterations, alpha=4.073e-04, previous alpha=2.779e-05, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=1.373e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 16 iterations, alpha=1.373e-04, previous alpha=1.094e-04, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      " 73%|████████████████████████████████████████████████████████████████████▊                         | 222/303 [01:43<00:37,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/shap/explainers/_kernel.py:707: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=4.160e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=4.004e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=2.498e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=2.437e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.442e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.408e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 14 iterations, alpha=1.533e-03, previous alpha=1.135e-03, with an active set of 9 regressors.\n",
      "  warnings.warn(\n",
      " 74%|█████████████████████████████████████████████████████████████████████▏                        | 223/303 [01:43<00:37,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 14 iterations, alpha=5.678e-03, previous alpha=4.385e-03, with an active set of 9 regressors.\n",
      "  warnings.warn(\n",
      " 74%|█████████████████████████████████████████████████████████████████████▍                        | 224/303 [01:44<00:36,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|█████████████████████████████████████████████████████████████████████▊                        | 225/303 [01:44<00:36,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|██████████████████████████████████████████████████████████████████████                        | 226/303 [01:45<00:35,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=2.737e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=9.315e-05, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 75%|██████████████████████████████████████████████████████████████████████▍                       | 227/303 [01:45<00:35,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|██████████████████████████████████████████████████████████████████████▋                       | 228/303 [01:46<00:34,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████████████████████████████████████████████████████████████████████                       | 229/303 [01:46<00:34,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████████████████████████████████████████████████████████████████████▎                      | 230/303 [01:46<00:34,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=7.429e-06, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=1.525e-06, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=4.859e-07, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=3.794e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=3.308e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 14 iterations, alpha=3.327e-04, previous alpha=3.058e-04, with an active set of 11 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=1.090e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=8.405e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=6.593e-06, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 76%|███████████████████████████████████████████████████████████████████████▋                      | 231/303 [01:47<00:33,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=2.110e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=3.795e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=1.444e-03, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=4.017e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 26 iterations, alpha=1.342e-03, previous alpha=2.108e-04, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=2.891e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=2.507e-03, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=8.290e-05, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 77%|███████████████████████████████████████████████████████████████████████▉                      | 232/303 [01:47<00:33,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=3.174e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=4.786e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 20 iterations, alpha=3.409e-03, previous alpha=3.171e-03, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=1.797e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.413e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=6.993e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=6.048e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=3.229e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=2.214e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=2.157e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.066e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=8.053e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=6.030e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=6.275e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=2.623e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.834e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=8.729e-04, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=4.284e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=4.030e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 14 iterations, alpha=2.763e-04, previous alpha=2.430e-04, with an active set of 11 regressors.\n",
      "  warnings.warn(\n",
      " 77%|████████████████████████████████████████████████████████████████████████▎                     | 233/303 [01:48<00:32,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.183e-02, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 21 iterations, alpha=6.785e-04, previous alpha=6.785e-04, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=6.350e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=2.010e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.475e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.174e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 19 iterations, alpha=1.261e-03, previous alpha=5.921e-04, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      " 77%|████████████████████████████████████████████████████████████████████████▌                     | 234/303 [01:48<00:32,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|████████████████████████████████████████████████████████████████████████▉                     | 235/303 [01:49<00:31,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=2.646e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.323e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=5.877e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 7 iterations, alpha=5.877e-03, previous alpha=5.853e-03, with an active set of 6 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/shap/explainers/_kernel.py:707: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.038e-04, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=9.675e-05, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=9.675e-05, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=8.309e-05, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 15 iterations, alpha=9.058e-05, previous alpha=7.580e-05, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=4.547e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=2.273e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 5 iterations, alpha=2.273e-02, previous alpha=2.271e-02, with an active set of 4 regressors.\n",
      "  warnings.warn(\n",
      " 78%|█████████████████████████████████████████████████████████████████████████▏                    | 236/303 [01:49<00:31,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=2.487e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=4.398e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=3.643e-05, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=1.544e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=7.177e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=3.571e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=2.925e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=6.897e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=2.484e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=1.535e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=2.784e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=2.256e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 14 iterations, alpha=1.436e-03, previous alpha=8.537e-04, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      " 78%|█████████████████████████████████████████████████████████████████████████▌                    | 237/303 [01:50<00:30,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=2.950e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.188e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 12 iterations, alpha=1.188e-04, previous alpha=1.175e-04, with an active set of 11 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.281e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=1.044e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 17 iterations, alpha=1.044e-05, previous alpha=1.033e-05, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.813e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=1.467e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 18 iterations, alpha=1.538e-04, previous alpha=6.833e-06, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.034e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 12 iterations, alpha=1.034e-04, previous alpha=1.023e-04, with an active set of 11 regressors.\n",
      "  warnings.warn(\n",
      " 79%|█████████████████████████████████████████████████████████████████████████▊                    | 238/303 [01:50<00:30,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|██████████████████████████████████████████████████████████████████████████▏                   | 239/303 [01:51<00:29,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|██████████████████████████████████████████████████████████████████████████▍                   | 240/303 [01:51<00:29,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.285e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.158e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 15 iterations, alpha=1.089e-03, previous alpha=8.479e-04, with an active set of 10 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=8.683e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.779e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=1.428e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=2.394e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=1.229e-06, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.692e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=9.521e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=2.101e-04, with an active set of 16 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=2.586e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=5.837e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 14 iterations, alpha=5.329e-04, previous alpha=5.196e-04, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      " 80%|██████████████████████████████████████████████████████████████████████████▊                   | 241/303 [01:52<00:28,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████████████████████████████████████████████████████████████████████████                   | 242/303 [01:52<00:28,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████████████████████████████████████████████████████████████████████████▍                  | 243/303 [01:52<00:27,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|███████████████████████████████████████████████████████████████████████████▋                  | 244/303 [01:53<00:27,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=6.034e-04, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=5.477e-04, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=3.019e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=2.517e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.509e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.466e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=6.711e-05, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 15 iterations, alpha=1.292e-04, previous alpha=6.252e-05, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=4.771e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 23 iterations, alpha=1.284e-03, previous alpha=6.711e-04, with an active set of 16 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=7.771e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=7.065e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=5.799e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=2.887e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 12 iterations, alpha=3.391e-03, previous alpha=1.787e-03, with an active set of 11 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.845e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=4.715e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=3.457e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 17 iterations, alpha=3.999e-04, previous alpha=7.786e-05, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      " 81%|████████████████████████████████████████████████████████████████████████████                  | 245/303 [01:53<00:26,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████████████████████████████████████████████████████████████████████████▎                 | 246/303 [01:54<00:26,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████████████████████████████████████████████████████████████████████████▋                 | 247/303 [01:54<00:25,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████████████████████████████████████████████████████████████████████████▉                 | 248/303 [01:55<00:25,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|█████████████████████████████████████████████████████████████████████████████▏                | 249/303 [01:55<00:25,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.368e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=2.326e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=2.324e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.051e-03, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 18 iterations, alpha=1.275e-03, previous alpha=1.050e-03, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.249e-02, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=8.099e-06, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 24 iterations, alpha=8.099e-06, previous alpha=6.766e-06, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=9.260e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 15 iterations, alpha=9.260e-04, previous alpha=9.122e-04, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      " 83%|█████████████████████████████████████████████████████████████████████████████▌                | 250/303 [01:56<00:24,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|█████████████████████████████████████████████████████████████████████████████▊                | 251/303 [01:56<00:24,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|██████████████████████████████████████████████████████████████████████████████▏               | 252/303 [01:57<00:23,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|██████████████████████████████████████████████████████████████████████████████▍               | 253/303 [01:57<00:23,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|██████████████████████████████████████████████████████████████████████████████▊               | 254/303 [01:58<00:22,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|███████████████████████████████████████████████████████████████████████████████               | 255/303 [01:58<00:22,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|███████████████████████████████████████████████████████████████████████████████▍              | 256/303 [01:59<00:21,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|███████████████████████████████████████████████████████████████████████████████▋              | 257/303 [01:59<00:21,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████████████████████████████████████████████████████████████████████████████              | 258/303 [01:59<00:20,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████████████████████████████████████████████████████████████████████████████▎             | 259/303 [02:00<00:20,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████████████████████████████████████████████████████████████████████████████▋             | 260/303 [02:00<00:20,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=3.603e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=1.977e-04, with an active set of 16 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=1.262e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=2.232e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 15 iterations, alpha=6.408e-04, previous alpha=4.574e-04, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      " 86%|████████████████████████████████████████████████████████████████████████████████▉             | 261/303 [02:01<00:19,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|█████████████████████████████████████████████████████████████████████████████████▎            | 262/303 [02:01<00:19,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.504e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=1.143e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 22 iterations, alpha=1.143e-05, previous alpha=1.141e-05, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=7.525e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=4.001e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=1.327e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 19 iterations, alpha=6.198e-04, previous alpha=9.037e-05, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      " 87%|█████████████████████████████████████████████████████████████████████████████████▌            | 263/303 [02:02<00:18,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|█████████████████████████████████████████████████████████████████████████████████▉            | 264/303 [02:02<00:18,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=2.395e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 21 iterations, alpha=1.378e-04, previous alpha=9.207e-05, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=3.337e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=2.460e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 13 iterations, alpha=2.165e-03, previous alpha=1.758e-03, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=6.661e-06, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 22 iterations, alpha=6.661e-06, previous alpha=5.014e-06, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      " 87%|██████████████████████████████████████████████████████████████████████████████████▏           | 265/303 [02:03<00:17,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|██████████████████████████████████████████████████████████████████████████████████▌           | 266/303 [02:03<00:17,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|██████████████████████████████████████████████████████████████████████████████████▊           | 267/303 [02:04<00:16,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|███████████████████████████████████████████████████████████████████████████████████▏          | 268/303 [02:04<00:16,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|███████████████████████████████████████████████████████████████████████████████████▍          | 269/303 [02:05<00:15,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=7.612e-04, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=3.806e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 13 iterations, alpha=2.462e-04, previous alpha=2.177e-04, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=3.499e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.749e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=4.121e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=2.295e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.781e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=4.422e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=2.120e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=2.102e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=4.754e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=4.712e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=2.057e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.029e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=9.515e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=7.555e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=5.988e-06, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 89%|███████████████████████████████████████████████████████████████████████████████████▊          | 270/303 [02:05<00:15,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████████████████████████████████████████████████████████████████████████████████          | 271/303 [02:05<00:14,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=9.545e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=2.020e-02, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 21 iterations, alpha=1.604e-03, previous alpha=1.604e-03, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=2.266e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=6.111e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=3.055e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=2.816e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 11 iterations, alpha=1.495e-03, previous alpha=1.249e-03, with an active set of 8 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=8.668e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=3.061e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.629e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 13 iterations, alpha=2.814e-03, previous alpha=1.508e-03, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=5.654e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=6.296e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=3.244e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=4.362e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=5.565e-06, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 90%|████████████████████████████████████████████████████████████████████████████████████▍         | 272/303 [02:06<00:14,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████████████████████████████████████████████████████████████████████████████████▋         | 273/303 [02:06<00:13,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=9.722e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 21 iterations, alpha=2.082e-03, previous alpha=1.645e-03, with an active set of 16 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=9.783e-05, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 90%|█████████████████████████████████████████████████████████████████████████████████████         | 274/303 [02:07<00:13,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=4.829e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=2.405e-02, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 17 iterations, alpha=1.061e-02, previous alpha=1.054e-02, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=2.207e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.519e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=7.139e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=1.776e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=4.722e-06, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=4.549e-07, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=4.529e-07, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=4.345e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.881e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.800e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=7.909e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 18 iterations, alpha=8.116e-04, previous alpha=7.210e-04, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.072e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=9.831e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 14 iterations, alpha=9.669e-04, previous alpha=9.647e-04, with an active set of 11 regressors.\n",
      "  warnings.warn(\n",
      " 91%|█████████████████████████████████████████████████████████████████████████████████████▎        | 275/303 [02:07<00:13,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████████████████████████████████████████████████████████████████████████████████▌        | 276/303 [02:08<00:12,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=4.543e-03, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=2.074e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=2.005e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=9.765e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 15 iterations, alpha=6.857e-04, previous alpha=3.240e-04, with an active set of 10 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=2.145e-04, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=1.073e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=1.817e-05, with an active set of 16 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=1.806e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=7.195e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 11 iterations, alpha=3.931e-03, previous alpha=3.449e-03, with an active set of 10 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=2.346e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.040e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=8.714e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 16 iterations, alpha=9.233e-04, previous alpha=6.972e-04, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      " 91%|█████████████████████████████████████████████████████████████████████████████████████▉        | 277/303 [02:08<00:12,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|██████████████████████████████████████████████████████████████████████████████████████▏       | 278/303 [02:09<00:11,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|██████████████████████████████████████████████████████████████████████████████████████▌       | 279/303 [02:09<00:11,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=2.827e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 17 iterations, alpha=9.182e-05, previous alpha=6.139e-05, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=3.720e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=6.388e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=3.021e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=1.373e-03, with an active set of 16 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=5.908e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 21 iterations, alpha=1.551e-03, previous alpha=6.001e-04, with an active set of 16 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=4.772e-06, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=3.970e-06, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 92%|██████████████████████████████████████████████████████████████████████████████████████▊       | 280/303 [02:10<00:10,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|███████████████████████████████████████████████████████████████████████████████████████▏      | 281/303 [02:10<00:10,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|███████████████████████████████████████████████████████████████████████████████████████▍      | 282/303 [02:11<00:09,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|███████████████████████████████████████████████████████████████████████████████████████▊      | 283/303 [02:11<00:09,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=2.443e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=2.975e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 21 iterations, alpha=2.409e-03, previous alpha=1.653e-03, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=7.038e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.126e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 16 iterations, alpha=9.542e-05, previous alpha=8.126e-05, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=1.079e-01, with an active set of 2 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 32 iterations, i.e. alpha=4.358e-03, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=8.656e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=4.281e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=2.215e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=3.070e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 16 iterations, alpha=3.059e-03, previous alpha=2.651e-03, with an active set of 11 regressors.\n",
      "  warnings.warn(\n",
      " 94%|████████████████████████████████████████████████████████████████████████████████████████      | 284/303 [02:12<00:08,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|████████████████████████████████████████████████████████████████████████████████████████▍     | 285/303 [02:12<00:08,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|████████████████████████████████████████████████████████████████████████████████████████▋     | 286/303 [02:12<00:07,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████████████████████████████████████████████████████████████████████████████████████     | 287/303 [02:13<00:07,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=8.629e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=6.825e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=1.812e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=1.619e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 25 iterations, alpha=1.812e-04, previous alpha=1.433e-04, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.097e-04, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=2.714e-06, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=2.529e-06, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 95%|█████████████████████████████████████████████████████████████████████████████████████████▎    | 288/303 [02:13<00:06,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████████████████████████████████████████████████████████████████████████████████████▋    | 289/303 [02:14<00:06,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=4.145e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=2.755e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 17 iterations, alpha=2.128e-04, previous alpha=1.834e-05, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/shap/explainers/_kernel.py:707: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=2.637e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=6.015e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=4.770e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 14 iterations, alpha=5.593e-04, previous alpha=3.999e-04, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      " 96%|█████████████████████████████████████████████████████████████████████████████████████████▉    | 290/303 [02:14<00:06,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/shap/explainers/_kernel.py:707: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      " 96%|██████████████████████████████████████████████████████████████████████████████████████████▎   | 291/303 [02:15<00:05,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|██████████████████████████████████████████████████████████████████████████████████████████▌   | 292/303 [02:15<00:05,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.749e-04, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=3.659e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=3.435e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=3.078e-06, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.333e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=6.543e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=6.486e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=6.272e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 18 iterations, alpha=6.333e-03, previous alpha=6.170e-03, with an active set of 11 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=2.162e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=8.326e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=1.429e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=8.853e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=4.427e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=5.065e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=9.314e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=3.532e-04, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 97%|██████████████████████████████████████████████████████████████████████████████████████████▉   | 293/303 [02:16<00:04,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|███████████████████████████████████████████████████████████████████████████████████████████▏  | 294/303 [02:16<00:04,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|███████████████████████████████████████████████████████████████████████████████████████████▌  | 295/303 [02:17<00:03,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.761e-05, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=1.337e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=9.082e-06, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=3.498e-06, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.272e-06, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=3.095e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=1.702e-04, with an active set of 16 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=2.820e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=4.094e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=2.472e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 14 iterations, alpha=3.385e-03, previous alpha=1.128e-03, with an active set of 11 regressors.\n",
      "  warnings.warn(\n",
      " 98%|███████████████████████████████████████████████████████████████████████████████████████████▊  | 296/303 [02:17<00:03,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|████████████████████████████████████████████████████████████████████████████████████████████▏ | 297/303 [02:18<00:02,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.672e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=7.058e-04, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=4.747e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=2.987e-04, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=2.588e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.311e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.051e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=4.995e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.539e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=2.337e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=1.449e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=1.449e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=5.277e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=6.002e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=3.570e-04, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=3.001e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=2.478e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.087e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.066e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=1.066e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=1.066e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=4.441e-06, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.193e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=5.053e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=5.053e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=3.947e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=3.697e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=2.526e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=2.397e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.024e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=6.057e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=3.804e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=2.852e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=1.221e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 98%|████████████████████████████████████████████████████████████████████████████████████████████▍ | 298/303 [02:18<00:02,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|████████████████████████████████████████████████████████████████████████████████████████████▊ | 299/303 [02:19<00:01,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=4.248e-06, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=3.504e-06, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 22 iterations, alpha=3.504e-06, previous alpha=4.835e-07, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=4.177e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=8.604e-04, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 15 iterations, alpha=3.887e-04, previous alpha=3.842e-04, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=5.021e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=2.899e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=2.229e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 14 iterations, alpha=2.291e-03, previous alpha=1.698e-03, with an active set of 11 regressors.\n",
      "  warnings.warn(\n",
      " 99%|█████████████████████████████████████████████████████████████████████████████████████████████ | 300/303 [02:19<00:01,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.776e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=3.431e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 20 iterations, alpha=1.267e-04, previous alpha=1.267e-04, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.412e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=5.604e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.844e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=7.230e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=6.507e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 17 iterations, alpha=1.190e-04, previous alpha=6.484e-05, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      " 99%|█████████████████████████████████████████████████████████████████████████████████████████████▍| 301/303 [02:19<00:00,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████▋| 302/303 [02:20<00:00,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 815us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████| 303/303 [02:20<00:00,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAP values calcolati.\n",
      "SHAP values per classe 0: [[-0.14063799  0.06793455  0.05650777  0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.03253891  0.0537707   0.          0.        ]\n",
      " [-0.04733766  0.36140393 -0.25460851 -0.0229401 ]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 1: [[-0.07673066  0.          0.          0.08036825]\n",
      " [ 0.          0.          0.          0.01338032]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.01138582 -0.06065173  0.00273181  0.04169595]\n",
      " [-0.01307293 -0.04530133  0.05893654  0.        ]]\n",
      "SHAP values per classe 2: [[-0.07552838  0.          0.          0.09598715]\n",
      " [ 0.          0.          0.          0.01492079]\n",
      " [-0.03153408  0.          0.          0.01038611]\n",
      " [-0.00782112 -0.08481351  0.07168339  0.        ]\n",
      " [ 0.         -0.02884215  0.          0.02673754]]\n",
      "SHAP values per classe 3: [[-0.05936874  0.02065959  0.10177327 -0.08006324]\n",
      " [-0.01035217  0.00287005 -0.01643332  0.01261236]\n",
      " [-0.00350435  0.         -0.01853361  0.02939478]\n",
      " [-0.01991732 -0.05289453  0.04026748  0.06705672]\n",
      " [-0.0103852  -0.05158062  0.06632747  0.        ]]\n",
      "SHAP values per classe 4: [[-0.10876678  0.          0.07102828  0.03894892]\n",
      " [-0.0083101   0.          0.          0.        ]\n",
      " [-0.06396569  0.0312342   0.01318129  0.        ]\n",
      " [ 0.          0.12952298 -0.17722672  0.        ]\n",
      " [-0.02515176 -0.05748361  0.05546174  0.01887937]]\n",
      "SHAP values per classe 5: [[-0.10607821  0.04739877  0.05860413  0.        ]\n",
      " [-0.00387271  0.01158644  0.          0.        ]\n",
      " [-0.02584433  0.00568601  0.         -0.01465422]\n",
      " [-0.03632568  0.45349122 -0.31354239 -0.05459509]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 6: [[-0.0853429  -0.00348393  0.          0.        ]\n",
      " [-0.01976904 -0.00503416  0.          0.        ]\n",
      " [-0.0160731   0.          0.          0.        ]\n",
      " [ 0.         -0.06167329  0.          0.0352644 ]\n",
      " [ 0.         -0.0368528   0.          0.        ]]\n",
      "SHAP values per classe 7: [[-0.06836209  0.00703754  0.06362102  0.        ]\n",
      " [ 0.          0.          0.07251635  0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.05203699  0.          0.01184077]\n",
      " [-0.02127636 -0.1494022  -0.4602021   0.598385  ]]\n",
      "SHAP values per classe 8: [[-0.05185143 -0.00591153 -0.04362074  0.11961755]\n",
      " [ 0.          0.         -0.15345761  0.        ]\n",
      " [-0.00997723 -0.00496131  0.          0.        ]\n",
      " [ 0.         -0.04951944  0.02069745  0.        ]\n",
      " [ 0.         -0.02704587  0.          0.        ]]\n",
      "SHAP values per classe 9: [[-0.09355219  0.02217423  0.05328678  0.        ]\n",
      " [ 0.         -0.00519729  0.          0.01044126]\n",
      " [-0.00517053  0.00239097  0.          0.00939879]\n",
      " [ 0.         -0.0385965   0.          0.00623994]\n",
      " [-0.01542167  0.05420426 -0.09463231  0.02905823]]\n",
      "SHAP values per classe 10: [[-0.09852309  0.          0.03048546  0.03036884]\n",
      " [-0.02222595  0.          0.          0.02953011]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.08128354  0.          0.03245545]\n",
      " [ 0.         -0.03625256  0.0309967   0.0292555 ]]\n",
      "SHAP values per classe 11: [[-0.105212    0.01087287  0.08671887  0.0103674 ]\n",
      " [-0.02941556 -0.02467155  0.050495    0.        ]\n",
      " [-0.00929109 -0.00345089  0.00213287  0.        ]\n",
      " [ 0.01557994 -0.08211176  0.0403252   0.        ]\n",
      " [ 0.         -0.05269004  0.05465867  0.        ]]\n",
      "SHAP values per classe 12: [[-0.09272627  0.04711176  0.          0.03738685]\n",
      " [ 0.          0.04611428  0.         -0.09486037]\n",
      " [-0.01687395  0.          0.          0.        ]\n",
      " [-0.01570187  0.04995956 -0.02781863  0.        ]\n",
      " [-0.0367047   0.14679214 -0.07078772 -0.02594143]]\n",
      "SHAP values per classe 13: [[-0.12805972  0.01178026  0.11788062 -0.01624826]\n",
      " [-0.00584796  0.          0.          0.00760484]\n",
      " [-0.02001024  0.          0.02537178  0.        ]\n",
      " [ 0.         -0.10672116  0.01028554  0.10123881]\n",
      " [ 0.         -0.07927479  0.07751791  0.        ]]\n",
      "SHAP values per classe 14: [[-0.06198559  0.02115201  0.         -0.01690419]\n",
      " [ 0.          0.          0.02727548 -0.00177735]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.10997277  0.73669757 -0.41569007 -0.17176917]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 15: [[-0.08204222  0.01138938  0.04108913  0.02923287]\n",
      " [ 0.          0.          0.          0.00407841]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.07750042  0.02784731  0.03841395]\n",
      " [ 0.         -0.04187876  0.          0.02857073]]\n",
      "SHAP values per classe 16: [[ 0.3361248  -0.04358798 -0.20713979 -0.0668137 ]\n",
      " [ 0.          0.0285162   0.03947015 -0.06456171]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.01685194 -0.13303075  0.09904185 -0.01555404]\n",
      " [ 0.06148937 -0.06961552  0.00329056  0.00779658]]\n",
      "SHAP values per classe 17: [[ 0.56661052 -0.11365527 -0.31736371 -0.10519815]\n",
      " [ 0.01313416 -0.00383001  0.00847219 -0.02914247]\n",
      " [ 0.02568215 -0.00108903  0.          0.        ]\n",
      " [ 0.03562312 -0.07432535  0.04009555  0.        ]\n",
      " [ 0.02548612 -0.0664192   0.          0.        ]]\n",
      "SHAP values per classe 18: [[-0.08676381  0.          0.          0.04100834]\n",
      " [-0.00393149  0.          0.          0.        ]\n",
      " [-0.01137273  0.          0.          0.        ]\n",
      " [ 0.         -0.04866198  0.03900434  0.00416487]\n",
      " [ 0.         -0.06040168  0.          0.        ]]\n",
      "SHAP values per classe 19: [[-0.06623349  0.          0.          0.05649002]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.05439918  0.          0.        ]\n",
      " [-0.0336583  -0.05749771  0.1857383  -0.08048225]]\n",
      "SHAP values per classe 20: [[-0.12359358  0.00930365  0.1283616  -0.00394502]\n",
      " [ 0.0211529  -0.00537803  0.04732773 -0.06664895]\n",
      " [ 0.04680963 -0.02977397  0.06345339 -0.12452995]\n",
      " [ 0.         -0.08996214  0.09469216  0.        ]\n",
      " [-0.04630817 -0.06433818  0.09780348  0.05897071]]\n",
      "SHAP values per classe 21: [[-0.07214536  0.          0.          0.        ]\n",
      " [ 0.          0.          0.05613757 -0.04040069]\n",
      " [ 0.          0.          0.02930227 -0.01529094]\n",
      " [ 0.         -0.06868701  0.03562372  0.        ]\n",
      " [ 0.         -0.04510813  0.          0.        ]]\n",
      "SHAP values per classe 22: [[ 0.          0.06186261  0.         -0.00761772]\n",
      " [ 0.21739476 -0.07004106 -0.05573755 -0.08144516]\n",
      " [ 0.          0.02869109 -0.01161201 -0.01555793]\n",
      " [-0.39533272  0.56014992 -0.08268039 -0.03554862]\n",
      " [ 0.          0.          0.         -0.01186944]]\n",
      "SHAP values per classe 23: [[ 0.          0.01581038  0.          0.        ]\n",
      " [ 0.58210951 -0.15025325 -0.14624511 -0.23266357]\n",
      " [ 0.          0.00467663  0.          0.        ]\n",
      " [ 0.03275587 -0.06737519  0.          0.        ]\n",
      " [ 0.08774305 -0.0206797   0.         -0.09213333]]\n",
      "SHAP values per classe 24: [[-1.14824939e-01  4.17431347e-02  2.79493222e-02  2.88356824e-02]\n",
      " [-1.21612940e-02  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [-2.46129700e-02  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [-2.21095478e-05  0.00000000e+00  1.79214997e-01  0.00000000e+00]\n",
      " [-1.31255967e-02  2.38301504e-01 -1.85570458e-01 -3.07621685e-02]]\n",
      "SHAP values per classe 25: [[-0.06417077  0.         -0.06913957  0.09896481]\n",
      " [ 0.          0.          0.22274325 -0.17902842]\n",
      " [-0.00817786 -0.00928493  0.          0.        ]\n",
      " [ 0.         -0.06770637  0.         -0.13602777]\n",
      " [ 0.         -0.03033727  0.          0.        ]]\n",
      "SHAP values per classe 26: [[-0.1021846   0.05006995  0.036143    0.        ]\n",
      " [-0.01125065  0.01243463  0.         -0.04573614]\n",
      " [-0.02418728  0.00912495  0.          0.        ]\n",
      " [ 0.          0.0249481   0.15307363 -0.15694801]\n",
      " [-0.05690729  0.57747929 -0.369298   -0.11039048]]\n",
      "SHAP values per classe 27: [[-1.16440338e-01 -1.24729407e-02  0.00000000e+00  0.00000000e+00]\n",
      " [-4.55911247e-03 -2.21239113e-05  1.18885174e-02 -1.25986783e-02]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  5.43290092e-03]\n",
      " [-1.42828351e-02 -8.69187621e-02  1.17843162e-02  3.15565609e-02]\n",
      " [ 0.00000000e+00 -5.66993930e-02  7.01914631e-02 -2.23148999e-02]]\n",
      "SHAP values per classe 28: [[ 0.51550549 -0.078998   -0.23812491 -0.14550749]\n",
      " [ 0.00921613  0.         -0.01677898  0.        ]\n",
      " [ 0.03309232 -0.0267778   0.          0.        ]\n",
      " [ 0.08508091 -0.10039956  0.         -0.01869087]\n",
      " [ 0.0096913  -0.03597506  0.          0.        ]]\n",
      "SHAP values per classe 29: [[ 0.36034778 -0.05450023 -0.19170857 -0.08709204]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.00838675  0.          0.00069309]\n",
      " [ 0.06332809 -0.13711288  0.          0.        ]\n",
      " [ 0.06158083 -0.07615248  0.05955043  0.        ]]\n",
      "SHAP values per classe 30: [[ 0.50569427 -0.10407929 -0.25712687 -0.13411215]\n",
      " [ 0.         -0.00902617  0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.03287475 -0.07577027  0.04618598  0.        ]\n",
      " [ 0.04194898 -0.0391579   0.          0.        ]]\n",
      "SHAP values per classe 31: [[-0.06195441  0.          0.0858704   0.        ]\n",
      " [-0.0088072   0.          0.03681134 -0.02883324]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.08828489  0.06564598  0.        ]\n",
      " [ 0.         -0.06549728  0.06995063  0.        ]]\n",
      "SHAP values per classe 32: [[-0.1169422   0.          0.11632385  0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.03934925 -0.04899088  0.08450926  0.        ]\n",
      " [ 0.         -0.06464189  0.06248501  0.        ]\n",
      " [ 0.         -0.0283916   0.01325307  0.        ]]\n",
      "SHAP values per classe 33: [[-0.11383011  0.          0.03563788  0.06384469]\n",
      " [-0.04251163  0.          0.          0.07728479]\n",
      " [-0.10090565 -0.03495509 -0.00815802  0.14096788]\n",
      " [ 0.00296679 -0.04790357  0.          0.03166638]\n",
      " [ 0.00510402 -0.04814603  0.0136846   0.01652626]]\n",
      "SHAP values per classe 34: [[ 0.57355312 -0.12471829 -0.19295252 -0.20028549]\n",
      " [ 0.         -0.00276671  0.          0.        ]\n",
      " [ 0.00637608  0.0093452   0.          0.        ]\n",
      " [ 0.03493565 -0.08376416 -0.0379231   0.04736424]\n",
      " [ 0.03238007 -0.04555479  0.          0.        ]]\n",
      "SHAP values per classe 35: [[-0.12095955 -0.01304651  0.12122131  0.02887085]\n",
      " [ 0.          0.00458389 -0.07428604  0.06992001]\n",
      " [-0.05708609 -0.00431508  0.          0.05853082]\n",
      " [ 0.0047519  -0.10143836  0.08303118  0.0108475 ]\n",
      " [ 0.         -0.0996957   0.10691893  0.        ]]\n",
      "SHAP values per classe 36: [[-0.06389077  0.          0.          0.0524932 ]\n",
      " [-0.00995596  0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.07012525 -0.0716416   0.1835197   0.        ]\n",
      " [ 0.         -0.03158127  0.          0.02325233]]\n",
      "SHAP values per classe 37: [[-0.1385001   0.06598277  0.          0.        ]\n",
      " [-0.00568027  0.01890479  0.          0.        ]\n",
      " [-0.0238565   0.05917069 -0.04338632  0.        ]\n",
      " [-0.03320746  0.32162208 -0.25786458  0.        ]\n",
      " [ 0.          0.          0.02259366 -0.00990114]]\n",
      "SHAP values per classe 38: [[-0.13383676  0.10677357  0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.04995734  0.23851127 -0.11133175 -0.06730462]\n",
      " [ 0.          0.02722511 -0.03858068  0.02614994]]\n",
      "SHAP values per classe 39: [[-0.08660394  0.          0.02795334  0.05559023]\n",
      " [-0.01884534  0.          0.03332763  0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.01106407 -0.08662197  0.          0.0511486 ]\n",
      " [-0.00556698 -0.05154433  0.03533324  0.00881562]]\n",
      "SHAP values per classe 40: [[ 0.67277014 -0.13368921 -0.28734648 -0.24287906]\n",
      " [ 0.          0.         -0.05657227  0.        ]\n",
      " [ 0.04012267  0.          0.          0.        ]\n",
      " [ 0.02129373 -0.07597796  0.02434324  0.03793426]\n",
      " [ 0.01907306 -0.03248325  0.02307549  0.        ]]\n",
      "SHAP values per classe 41: [[ 0.44193141 -0.08191681 -0.23821844 -0.13083655]\n",
      " [ 0.02772111  0.          0.02971772  0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.05090743 -0.09035998  0.01327716  0.        ]\n",
      " [ 0.         -0.04850363  0.          0.        ]]\n",
      "SHAP values per classe 42: [[-0.10386562  0.00937059  0.          0.08382496]\n",
      " [ 0.          0.02637905  0.          0.06987698]\n",
      " [-0.01919332 -0.02721148  0.          0.        ]\n",
      " [ 0.         -0.07685365  0.07736182  0.        ]\n",
      " [ 0.         -0.05348515  0.          0.0717167 ]]\n",
      "SHAP values per classe 43: [[-0.06603922  0.          0.0520692   0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.02176624  0.          0.        ]\n",
      " [-0.01383811 -0.04176247  0.10706032 -0.10357943]\n",
      " [ 0.         -0.01896494  0.          0.        ]]\n",
      "SHAP values per classe 44: [[ 0.39557887 -0.08024498 -0.19504577 -0.14601362]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.21934378 -0.06131138 -0.09820044 -0.04248668]\n",
      " [ 0.0285294  -0.07394447  0.          0.        ]\n",
      " [ 0.02922169 -0.04164834  0.          0.        ]]\n",
      "SHAP values per classe 45: [[-0.13573902  0.          0.05774954  0.04073023]\n",
      " [-0.00769093  0.          0.          0.        ]\n",
      " [-0.01565446  0.          0.          0.01468213]\n",
      " [ 0.         -0.05164989  0.          0.        ]\n",
      " [ 0.         -0.05575246  0.03183734  0.02719149]]\n",
      "SHAP values per classe 46: [[-0.08306007  0.03385562  0.01629262  0.        ]\n",
      " [-0.016218    0.          0.         -0.00549284]\n",
      " [ 0.          0.          0.09832728 -0.06140068]\n",
      " [-0.04460642  0.51178948 -0.46743692 -0.03237672]\n",
      " [ 0.          0.          0.          0.00881146]]\n",
      "SHAP values per classe 47: [[-0.08526103  0.          0.04541547  0.        ]\n",
      " [ 0.          0.          0.          0.01985767]\n",
      " [-0.0222399   0.          0.          0.        ]\n",
      " [-0.02193185  0.14858596 -0.09738937 -0.02787777]\n",
      " [-0.04708815  0.30241963 -0.13745318 -0.07258278]]\n",
      "SHAP values per classe 48: [[-0.06016995  0.0355059   0.03731337 -0.01562103]\n",
      " [ 0.          0.03709141  0.         -0.0108756 ]\n",
      " [-0.02185971  0.          0.02268274  0.        ]\n",
      " [ 0.         -0.08189853  0.          0.03242571]\n",
      " [ 0.02874825 -0.04993877  0.01378806  0.        ]]\n",
      "SHAP values per classe 49: [[-0.12373039  0.          0.14587941  0.        ]\n",
      " [ 0.          0.          0.02948114  0.        ]\n",
      " [-0.01318943 -0.00075271  0.00547313  0.01224369]\n",
      " [ 0.         -0.12658171  0.09265685  0.        ]\n",
      " [ 0.00796162 -0.07650771  0.06777329  0.        ]]\n",
      "SHAP values per classe 50: [[-0.15541228  0.          0.          0.06803601]\n",
      " [-0.0523032  -0.02540927  0.          0.        ]\n",
      " [-0.01118758 -0.00075383  0.          0.016549  ]\n",
      " [-0.0101513  -0.11733114  0.05152691  0.05025273]\n",
      " [ 0.03551754 -0.06914774  0.          0.05427597]]\n",
      "SHAP values per classe 51: [[-0.14122176  0.          0.19473206  0.        ]\n",
      " [-0.00508624  0.          0.          0.00958702]\n",
      " [-0.02347788  0.          0.          0.03651824]\n",
      " [ 0.         -0.07553712  0.04673572  0.        ]\n",
      " [ 0.         -0.08512062  0.04776218  0.01583527]]\n",
      "SHAP values per classe 52: [[-0.11730016  0.00901566  0.          0.10169057]\n",
      " [-0.00418367  0.         -0.05801882  0.06612852]\n",
      " [-0.0163512   0.          0.          0.01586485]\n",
      " [ 0.         -0.10007733  0.          0.01002671]\n",
      " [ 0.         -0.07408159  0.05353659  0.        ]]\n",
      "SHAP values per classe 53: [[-0.09056376  0.02050006  0.          0.08154331]\n",
      " [ 0.          0.          0.          0.05280033]\n",
      " [ 0.          0.          0.         -0.03880576]\n",
      " [ 0.         -0.06942059  0.07069073 -0.04268652]\n",
      " [ 0.         -0.04558557  0.          0.        ]]\n",
      "SHAP values per classe 54: [[ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.01654182  0.05722126  0.        ]\n",
      " [ 0.00344707  0.          0.          0.        ]\n",
      " [-0.03361934 -0.02805416  0.          0.09221504]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 55: [[-0.16065281  0.          0.10286367  0.05318549]\n",
      " [-0.0056664   0.10871697 -0.16268384  0.03355094]\n",
      " [-0.02064592  0.          0.          0.        ]\n",
      " [-0.00175219  0.          0.          0.09897559]\n",
      " [-0.00801823  0.28017478 -0.15746971 -0.1885338 ]]\n",
      "SHAP values per classe 56: [[ 0.11594092  0.          0.         -0.04420585]\n",
      " [ 0.          0.00631315 -0.02668773  0.        ]\n",
      " [ 0.          0.04093749  0.          0.        ]\n",
      " [-0.20794282  0.34307176 -0.03008685  0.        ]\n",
      " [ 0.          0.          0.          0.01949859]]\n",
      "SHAP values per classe 57: [[ 0.2749677  -0.02976704 -0.04369498 -0.13083042]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.0470448  -0.02170947  0.         -0.02705891]\n",
      " [ 0.03294136 -0.06871385  0.          0.        ]\n",
      " [ 0.         -0.00859089  0.          0.04237116]]\n",
      "SHAP values per classe 58: [[-0.16565545  0.01449448  0.11265703  0.01749891]\n",
      " [-0.00573709 -0.00104606  0.          0.00646016]\n",
      " [-0.01599073  0.          0.01366302  0.00677283]\n",
      " [ 0.01041884 -0.09715237  0.07548853  0.        ]\n",
      " [ 0.         -0.05647898  0.          0.01547941]]\n",
      "SHAP values per classe 59: [[-0.10098121  0.01873833  0.03400191  0.0403154 ]\n",
      " [ 0.          0.         -0.02420411  0.0240283 ]\n",
      " [-0.0104461  -0.01411263  0.01265805  0.        ]\n",
      " [ 0.         -0.07339312  0.03797347  0.02863815]\n",
      " [ 0.          0.01623916  0.          0.0146752 ]]\n",
      "SHAP values per classe 60: [[-0.10734127  0.         -0.02786458  0.        ]\n",
      " [-0.01863765  0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.0494494   0.          0.        ]\n",
      " [ 0.         -0.0365677   0.          0.        ]]\n",
      "SHAP values per classe 61: [[-0.14935326  0.          0.          0.11315057]\n",
      " [ 0.          0.00220564  0.          0.02066118]\n",
      " [-0.02006396  0.          0.          0.        ]\n",
      " [ 0.         -0.1184126   0.09448867  0.05400576]\n",
      " [ 0.         -0.08550172  0.03927123  0.        ]]\n",
      "SHAP values per classe 62: [[ 0.61534314 -0.10779918 -0.31990643 -0.15024085]\n",
      " [ 0.          0.          0.03354609  0.        ]\n",
      " [ 0.01077133  0.          0.          0.        ]\n",
      " [ 0.05436745 -0.09017993  0.          0.        ]\n",
      " [ 0.         -0.03335528  0.02377059  0.        ]]\n",
      "SHAP values per classe 63: [[-0.06358884  0.          0.          0.        ]\n",
      " [ 0.          0.          0.00556873  0.        ]\n",
      " [-0.02991522 -0.00226582  0.1490816  -0.055309  ]\n",
      " [ 0.         -0.05021171  0.07916664 -0.04043496]\n",
      " [ 0.         -0.03840315  0.          0.        ]]\n",
      "SHAP values per classe 64: [[-0.08253211  0.02365973  0.          0.        ]\n",
      " [-0.00490976  0.          0.          0.        ]\n",
      " [-0.01350196  0.          0.          0.        ]\n",
      " [-0.10417213  0.62282528 -0.36003355 -0.08972897]\n",
      " [-0.0021921   0.          0.          0.        ]]\n",
      "SHAP values per classe 65: [[-0.07558913  0.          0.24517549 -0.02562341]\n",
      " [ 0.          0.          0.44476577 -0.07915673]\n",
      " [-0.02043019  0.         -0.01932127  0.        ]\n",
      " [ 0.         -0.04691105  0.19802455 -0.07032272]\n",
      " [-0.01525926 -0.02070738  0.          0.        ]]\n",
      "SHAP values per classe 66: [[-0.14864389  0.          0.05271258  0.04533692]\n",
      " [-0.00629787  0.05134681 -0.06670162  0.06372713]\n",
      " [-0.01202744 -0.01223317  0.          0.10231855]\n",
      " [ 0.         -0.06505901  0.06134794  0.03692818]\n",
      " [ 0.         -0.04641549  0.00877037  0.03658102]]\n",
      "SHAP values per classe 67: [[-0.07055812  0.          0.1279401   0.        ]\n",
      " [-0.01749162  0.          0.00958063  0.        ]\n",
      " [ 0.         -0.08393094  0.          0.03628655]\n",
      " [ 0.          0.          0.07344509  0.        ]\n",
      " [ 0.         -0.08064099  0.06993543  0.02374326]]\n",
      "SHAP values per classe 68: [[-0.103405    0.0119671   0.04658177  0.04239398]\n",
      " [ 0.         -0.00626343  0.          0.01726333]\n",
      " [ 0.          0.          0.          0.01365002]\n",
      " [ 0.         -0.04633684  0.02118624  0.        ]\n",
      " [-0.00425472  0.          0.          0.        ]]\n",
      "SHAP values per classe 69: [[-0.0388212   0.          0.10100276 -0.07599113]\n",
      " [ 0.          0.          0.21248816 -0.20540866]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.07543402  0.1092297  -0.02816062]\n",
      " [ 0.00836978 -0.04065353  0.          0.        ]]\n",
      "SHAP values per classe 70: [[-0.08119566  0.          0.          0.11092598]\n",
      " [ 0.          0.         -0.01443225  0.01907774]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.06619878  0.          0.        ]\n",
      " [ 0.         -0.0359173   0.          0.        ]]\n",
      "SHAP values per classe 71: [[ 0.00017224  0.          0.05459777 -0.04552367]\n",
      " [-0.01421836  0.          0.          0.        ]\n",
      " [-0.06444479 -0.02009355  0.05919714  0.        ]\n",
      " [ 0.         -0.06522497  0.          0.04233442]\n",
      " [ 0.         -0.03408212  0.02920476  0.        ]]\n",
      "SHAP values per classe 72: [[ 0.43826624 -0.05394195 -0.23017768 -0.17141652]\n",
      " [ 0.         -0.01148881  0.          0.00478575]\n",
      " [ 0.01980296 -0.06201452  0.          0.        ]\n",
      " [ 0.04796903 -0.08227367  0.03281359  0.00880218]\n",
      " [ 0.01958623 -0.03969626  0.          0.00546191]]\n",
      "SHAP values per classe 73: [[-0.10485613  0.01205566  0.10189401  0.        ]\n",
      " [ 0.01836592 -0.00055314  0.00871503 -0.02374948]\n",
      " [ 0.00883324 -0.0138042   0.08416836 -0.08695356]\n",
      " [ 0.         -0.08345447  0.          0.        ]\n",
      " [-0.01660275 -0.05666508  0.05284729 -0.01669587]]\n",
      "SHAP values per classe 74: [[-0.11727701  0.          0.09314415 -0.0044686 ]\n",
      " [-0.01955499  0.01060391  0.          0.        ]\n",
      " [-0.01200388 -0.01070124  0.03107775 -0.0049355 ]\n",
      " [ 0.         -0.13327425  0.16269564  0.02309466]\n",
      " [ 0.         -0.06203771  0.05200986 -0.0044286 ]]\n",
      "SHAP values per classe 75: [[-0.10413742  0.05751561  0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.01717874  0.          0.          0.        ]\n",
      " [-0.0811936   0.31198352 -0.12497575 -0.0848193 ]\n",
      " [-0.01442973  0.07125615 -0.0611558   0.        ]]\n",
      "SHAP values per classe 76: [[-0.10855028  0.          0.06468621  0.03168688]\n",
      " [ 0.          0.          0.          0.11846429]\n",
      " [-0.00842529  0.          0.01507054  0.        ]\n",
      " [ 0.         -0.06676761  0.08258523  0.00070744]\n",
      " [-0.01440937 -0.06532173  0.22362108 -0.15728477]]\n",
      "SHAP values per classe 77: [[-0.10947501  0.          0.          0.18934613]\n",
      " [ 0.          0.          0.0561896  -0.23949239]\n",
      " [-0.01398787 -0.01092899  0.          0.05974078]\n",
      " [ 0.         -0.04897098  0.          0.0284138 ]\n",
      " [ 0.         -0.02423558  0.         -0.00128551]]\n",
      "SHAP values per classe 78: [[-0.07693959 -0.01410736  0.07943503  0.        ]\n",
      " [-0.00379408  0.         -0.06630235  0.06027196]\n",
      " [-0.00543784  0.         -0.03782489  0.02039879]\n",
      " [ 0.         -0.04540171  0.0369726   0.        ]\n",
      " [ 0.         -0.01835005  0.          0.        ]]\n",
      "SHAP values per classe 79: [[-0.11674458  0.00153406  0.08509431  0.        ]\n",
      " [-0.00864976  0.          0.          0.        ]\n",
      " [-0.01851774  0.         -0.00059155  0.        ]\n",
      " [-0.03202553 -0.09419369  0.03549512  0.        ]\n",
      " [ 0.         -0.09378732  0.08656177  0.        ]]\n",
      "SHAP values per classe 80: [[-0.16888645  0.          0.09535891  0.        ]\n",
      " [-0.01091709  0.          0.          0.        ]\n",
      " [-0.00399861  0.          0.          0.00230797]\n",
      " [ 0.02585192 -0.04258888  0.          0.02723995]\n",
      " [ 0.00337053 -0.03852144  0.          0.04040261]]\n",
      "SHAP values per classe 81: [[-0.13537687  0.          0.04832784  0.03637486]\n",
      " [-0.01229732  0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.06321163  0.03654378  0.02098897]\n",
      " [ 0.         -0.05045071  0.04666593  0.        ]]\n",
      "SHAP values per classe 82: [[-0.16528802  0.01990696  0.13940013  0.01139228]\n",
      " [ 0.          0.          0.05060206 -0.04910696]\n",
      " [-0.00909734 -0.00725319  0.04994703 -0.0272779 ]\n",
      " [ 0.         -0.10871315  0.09664172  0.        ]\n",
      " [ 0.         -0.08578455  0.09827097  0.        ]]\n",
      "SHAP values per classe 83: [[-0.08958609 -0.01011293  0.          0.        ]\n",
      " [-0.0206762   0.         -0.20024256  0.32554837]\n",
      " [-0.00543521  0.          0.04649016  0.        ]\n",
      " [ 0.         -0.05259208  0.08306512  0.        ]\n",
      " [ 0.         -0.02683204  0.          0.        ]]\n",
      "SHAP values per classe 84: [[ 0.00000000e+00  8.67664069e-03  1.24284014e-01  0.00000000e+00]\n",
      " [ 0.00000000e+00  1.95714698e-04  0.00000000e+00  2.35521958e-02]\n",
      " [ 7.30946642e-02 -1.60254890e-01  2.00813123e-01 -6.86665703e-02]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00 -7.66611565e-02  6.89670777e-02  0.00000000e+00]]\n",
      "SHAP values per classe 85: [[ 0.26984863  0.         -0.18117704 -0.05884003]\n",
      " [ 0.          0.          0.         -0.00043433]\n",
      " [ 0.07647465 -0.01470652  0.         -0.02317582]\n",
      " [ 0.02857525 -0.09766198  0.02989849 -0.00231547]\n",
      " [ 0.03071546 -0.04206059  0.          0.0098965 ]]\n",
      "SHAP values per classe 86: [[-0.15009227  0.03067832  0.08442947  0.        ]\n",
      " [-0.01930649  0.          0.01379309  0.        ]\n",
      " [-0.01967636  0.01921195 -0.02046131  0.        ]\n",
      " [ 0.02325911 -0.13506593  0.09782529  0.        ]\n",
      " [ 0.00067624 -0.09314125  0.08636708  0.01980003]]\n",
      "SHAP values per classe 87: [[ 0.35697692 -0.06997546 -0.10674139 -0.15692878]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.01623639 -0.04885129  0.         -0.04546715]\n",
      " [ 0.11531105 -0.07701877  0.          0.        ]\n",
      " [ 0.01746284 -0.03393268  0.03971931  0.        ]]\n",
      "SHAP values per classe 88: [[-0.08770396  0.01294915  0.          0.0753267 ]\n",
      " [-0.01722476  0.          0.          0.0114369 ]\n",
      " [-0.00900517 -0.00532399 -0.03619325  0.07432164]\n",
      " [ 0.         -0.06472813  0.0406788   0.        ]\n",
      " [ 0.         -0.08770516  0.          0.04983341]]\n",
      "SHAP values per classe 89: [[-0.12292774  0.06700115  0.06592554 -0.00110192]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.01782065  0.          0.         -0.00257745]\n",
      " [-0.10778128  0.49676909 -0.35187912 -0.04542267]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 90: [[-0.06636673  0.          0.          0.        ]\n",
      " [-0.00953073  0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.05374807  0.        ]\n",
      " [ 0.         -0.02733144  0.          0.        ]]\n",
      "SHAP values per classe 91: [[-0.1064945   0.          0.          0.08285786]\n",
      " [-0.005623    0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.06263923  0.          0.        ]\n",
      " [-0.02768175 -0.04020603  0.          0.        ]]\n",
      "SHAP values per classe 92: [[-0.13345921  0.          0.05407695  0.05874562]\n",
      " [-0.01234329  0.          0.00422004  0.00548156]\n",
      " [ 0.          0.          0.00921372  0.        ]\n",
      " [ 0.         -0.09555824  0.04627742  0.0204723 ]\n",
      " [ 0.          0.04480726 -0.06810339  0.        ]]\n",
      "SHAP values per classe 93: [[ 0.60897913 -0.1478238  -0.28384438 -0.16562356]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.03170382 -0.06899774  0.          0.        ]\n",
      " [ 0.00866815 -0.05001599  0.02976689  0.        ]]\n",
      "SHAP values per classe 94: [[-0.10700387  0.01990196  0.          0.        ]\n",
      " [-0.01765108  0.03342339 -0.03789196  0.0918393 ]\n",
      " [-0.01966786  0.          0.          0.        ]\n",
      " [-0.09738833  0.56781645 -0.32447373 -0.08914332]\n",
      " [ 0.          0.          0.01418053  0.08928118]]\n",
      "SHAP values per classe 95: [[ 0.62438432 -0.10108572 -0.28136158 -0.20850164]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.01303417  0.          0.          0.        ]\n",
      " [ 0.0496764  -0.1332272   0.04879833 -0.00103635]\n",
      " [ 0.         -0.02879515  0.04534816 -0.00612781]]\n",
      "SHAP values per classe 96: [[ 0.60201638 -0.10855185 -0.31133736 -0.17938239]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.01970584 -0.06592481  0.          0.        ]\n",
      " [ 0.00599525 -0.03504912  0.10267704 -0.00981016]]\n",
      "SHAP values per classe 97: [[-0.15995845  0.0195681   0.0012677   0.0388013 ]\n",
      " [-0.02265284  0.00395529  0.          0.00950856]\n",
      " [ 0.          0.          0.          0.01244751]\n",
      " [ 0.         -0.12595151  0.          0.03142433]\n",
      " [ 0.0101497  -0.08998371  0.04479316  0.02076525]]\n",
      "SHAP values per classe 98: [[ 0.          0.01299144  0.04084948 -0.01274091]\n",
      " [-0.02396782  0.          0.          0.        ]\n",
      " [ 0.         -0.02156206  0.01475766  0.        ]\n",
      " [-0.08373517  0.70449465 -0.41463282 -0.18269746]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 99: [[-0.15655692  0.01196978  0.          0.        ]\n",
      " [-0.00727771  0.          0.          0.        ]\n",
      " [-0.02755858  0.          0.16541808 -0.1592937 ]\n",
      " [ 0.         -0.14054086  0.10866392  0.02047236]\n",
      " [ 0.         -0.0917356   0.07750345 -0.00577426]]\n",
      "SHAP values per classe 100: [[-0.11085758  0.00791806  0.09734439  0.        ]\n",
      " [-0.00541759 -0.00328255  0.          0.01506617]\n",
      " [-0.00944953  0.          0.          0.        ]\n",
      " [ 0.00522495 -0.10707965  0.07760296  0.0196685 ]\n",
      " [-0.04880824 -0.11691866  0.0671747   0.07648401]]\n",
      "SHAP values per classe 101: [[-0.12542689  0.02896526  0.05039994  0.01785811]\n",
      " [-0.00475398  0.00570256  0.          0.        ]\n",
      " [-0.02422976  0.02769479  0.         -0.00459026]\n",
      " [-0.04593606  0.38811496 -0.31460131 -0.01474574]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 102: [[ 0.2477613  -0.09175636 -0.00833436 -0.1159045 ]\n",
      " [ 0.          0.          0.          0.0033597 ]\n",
      " [ 0.01909263 -0.01287339  0.         -0.03359908]\n",
      " [ 0.         -0.01919849  0.          0.        ]\n",
      " [ 0.01471488 -0.04209228  0.          0.        ]]\n",
      "SHAP values per classe 103: [[ 0.          0.06459625  0.         -0.04924223]\n",
      " [ 0.55679276 -0.32707299 -0.07586502 -0.13779843]\n",
      " [ 0.          0.         -0.08682778  0.        ]\n",
      " [-0.24786884  0.38897157 -0.0945859  -0.05794922]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 104: [[-0.03299624  0.05366244  0.         -0.0444723 ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.01294005  0.02704277  0.          0.        ]\n",
      " [-0.14655569  0.39201669 -0.1541176  -0.08251756]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 105: [[-0.09332777  0.02101116  0.00958258  0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.00561627  0.          0.          0.        ]\n",
      " [-0.08697945  0.6699257  -0.43205401 -0.15010699]\n",
      " [ 0.         -0.03134864  0.          0.        ]]\n",
      "SHAP values per classe 106: [[-0.10425221  0.01596713  0.08767333  0.        ]\n",
      " [-0.02949098  0.         -0.17508224  0.21525087]\n",
      " [-0.00809734 -0.01792613  0.          0.        ]\n",
      " [ 0.         -0.06658266  0.04257344  0.01909764]\n",
      " [ 0.         -0.04012504  0.07629224 -0.03376728]]\n",
      "SHAP values per classe 107: [[-0.08277261  0.          0.          0.09243571]\n",
      " [ 0.         -0.00347695  0.          0.03270106]\n",
      " [-0.03757172 -0.00107459  0.          0.        ]\n",
      " [ 0.         -0.06884547  0.03256233  0.        ]\n",
      " [ 0.         -0.03554517  0.          0.03893387]]\n",
      "SHAP values per classe 108: [[-0.08048751  0.05677744  0.03590333 -0.01057194]\n",
      " [-0.02841467  0.07698375 -0.06189448  0.        ]\n",
      " [-0.02337138  0.02385535  0.          0.        ]\n",
      " [ 0.          0.01890843 -0.00478068  0.01325697]\n",
      " [-0.0519571   0.24290238  0.         -0.07610814]]\n",
      "SHAP values per classe 109: [[ 0.52831004 -0.11475949 -0.22577754 -0.1352752 ]\n",
      " [ 0.         -0.00956993  0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.05919026 -0.11790495  0.         -0.21970094]\n",
      " [ 0.         -0.06068965  0.06708573  0.22998459]]\n",
      "SHAP values per classe 110: [[-0.09706799  0.          0.          0.02314787]\n",
      " [-0.00626793  0.          0.01410669 -0.01123779]\n",
      " [-0.0023773   0.          0.          0.        ]\n",
      " [-0.03142824  0.06246384 -0.08790501  0.07946856]\n",
      " [ 0.00286159 -0.02835835  0.00020567  0.        ]]\n",
      "SHAP values per classe 111: [[-0.05191513  0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.0086938 ]\n",
      " [ 0.         -0.00687013  0.          0.        ]\n",
      " [ 0.          0.          0.          0.03017139]\n",
      " [ 0.          0.          0.          0.01598639]]\n",
      "SHAP values per classe 112: [[ 0.17698377 -0.00403557  0.         -0.08021996]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.11790979  0.05050942  0.01293317]\n",
      " [ 0.         -0.06548073  0.00715804 -0.07012034]]\n",
      "SHAP values per classe 113: [[-0.11201721  0.01728435  0.05473937  0.047462  ]\n",
      " [-0.01856625  0.          0.          0.01365166]\n",
      " [-0.01750087  0.02424236  0.          0.        ]\n",
      " [ 0.         -0.11445552  0.08737744  0.        ]\n",
      " [ 0.         -0.04520386  0.05694963  0.        ]]\n",
      "SHAP values per classe 114: [[-0.10783821  0.          0.04863072  0.04380666]\n",
      " [ 0.          0.          0.          0.02038668]\n",
      " [ 0.         -0.0106421   0.          0.02479142]\n",
      " [ 0.         -0.06682229  0.          0.03445187]\n",
      " [ 0.         -0.03823313  0.03092958  0.01243455]]\n",
      "SHAP values per classe 115: [[ 0.          0.          0.          0.        ]\n",
      " [ 0.1802791   0.06690279 -0.3455772   0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.09194947  0.          0.        ]\n",
      " [-0.18489303 -0.12856808  0.43125991  0.        ]]\n",
      "SHAP values per classe 116: [[ 0.49044208 -0.0464091  -0.29050974 -0.14608604]\n",
      " [ 0.          0.00142266  0.         -0.00775226]\n",
      " [ 0.01768192 -0.0312428   0.05335696 -0.03685111]\n",
      " [ 0.         -0.07667741  0.          0.        ]\n",
      " [ 0.00335833 -0.03603971  0.          0.        ]]\n",
      "SHAP values per classe 117: [[ 0.         -0.00033492  0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.01655746  0.          0.          0.        ]\n",
      " [-0.00738132  0.          0.          0.03000914]\n",
      " [-0.01335711 -0.05716312  0.04622271  0.        ]]\n",
      "SHAP values per classe 118: [[-9.89020579e-02  0.00000000e+00  1.09422934e-01  0.00000000e+00]\n",
      " [ 9.11782146e-05  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  3.13205815e-02]\n",
      " [-1.11961444e-02 -8.81863572e-02  8.33977084e-02  0.00000000e+00]\n",
      " [ 0.00000000e+00 -7.13654968e-02  5.13708652e-02  0.00000000e+00]]\n",
      "SHAP values per classe 119: [[-0.13579423  0.          0.04700044  0.04731694]\n",
      " [ 0.          0.          0.          0.00383975]\n",
      " [-0.02163803 -0.00480899  0.02385775  0.01610607]\n",
      " [ 0.         -0.00521239 -0.01278806  0.04241106]\n",
      " [ 0.         -0.054762    0.          0.03409898]]\n",
      "SHAP values per classe 120: [[-0.08754502  0.00723266  0.14861942 -0.07357191]\n",
      " [-0.01094318  0.0399892   0.09534218 -0.12592388]\n",
      " [-0.00348929  0.00050448  0.          0.01322667]\n",
      " [ 0.         -0.12348674  0.06599225  0.04060548]\n",
      " [ 0.02011157 -0.08973544  0.11413299 -0.01864847]]\n",
      "SHAP values per classe 121: [[-0.09434519  0.          0.          0.03066093]\n",
      " [-0.00761219  0.          0.          0.03038334]\n",
      " [-0.00873566 -0.00862559  0.          0.00329087]\n",
      " [ 0.         -0.06474222  0.          0.        ]\n",
      " [ 0.         -0.03720159  0.          0.00727279]]\n",
      "SHAP values per classe 122: [[ 0.28158916 -0.0072763  -0.20151917 -0.08761396]\n",
      " [ 0.         -0.00974226  0.          0.01714183]\n",
      " [ 0.00771707 -0.00835201  0.          0.        ]\n",
      " [ 0.02790999 -0.12421362  0.08380299  0.        ]\n",
      " [ 0.         -0.05946503  0.          0.        ]]\n",
      "SHAP values per classe 123: [[-0.08483578  0.          0.02913171  0.04384416]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.05840793  0.03682199  0.01089891]\n",
      " [ 0.         -0.03281923  0.03101458  0.        ]]\n",
      "SHAP values per classe 124: [[ 0.26832424 -0.03074187 -0.14135431 -0.0844074 ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.14119642 -0.13857468  0.          0.        ]\n",
      " [ 0.         -0.0727197   0.05058432  0.02447391]]\n",
      "SHAP values per classe 125: [[ 0.5897783  -0.10492079 -0.30531975 -0.17010856]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.05108321 -0.03871638  0.         -0.02857077]\n",
      " [ 0.04695638 -0.06386524  0.          0.        ]\n",
      " [ 0.00914151 -0.03464801  0.02392423  0.0055719 ]]\n",
      "SHAP values per classe 126: [[-0.08622082  0.02466935  0.05027058  0.        ]\n",
      " [-0.00613399  0.          0.00194468  0.        ]\n",
      " [-0.00514971  0.00589406  0.          0.        ]\n",
      " [-0.10118897  0.51148075 -0.24831376 -0.13402789]\n",
      " [-0.018246    0.08449858 -0.06736213 -0.00615749]]\n",
      "SHAP values per classe 127: [[-0.09538918 -0.01318554  0.03329564  0.07154444]\n",
      " [-0.00937348 -0.01384431  0.          0.        ]\n",
      " [-0.01051307 -0.00564852  0.          0.        ]\n",
      " [ 0.         -0.0401078   0.02078284  0.        ]\n",
      " [ 0.         -0.02920352  0.03206914  0.        ]]\n",
      "SHAP values per classe 128: [[ 0.3084217  -0.07623276 -0.12608543 -0.14628254]\n",
      " [ 0.          0.          0.02303171  0.00167784]\n",
      " [ 0.05305339 -0.04103809  0.         -0.0348811 ]\n",
      " [ 0.04245114 -0.0674717   0.          0.        ]\n",
      " [ 0.         -0.03462114  0.          0.        ]]\n",
      "SHAP values per classe 129: [[ 0.61064248 -0.12560352 -0.26724417 -0.19778697]\n",
      " [ 0.00420373  0.          0.          0.01052658]\n",
      " [ 0.          0.         -0.01098121  0.        ]\n",
      " [ 0.03002094 -0.06735211  0.          0.        ]\n",
      " [ 0.01461132 -0.04719439  0.          0.        ]]\n",
      "SHAP values per classe 130: [[ 0.41137072 -0.05115718 -0.18337398 -0.1099323 ]\n",
      " [ 0.1286112  -0.0343027  -0.0750366   0.        ]\n",
      " [ 0.02476207 -0.02207227  0.         -0.03167771]\n",
      " [ 0.         -0.053652    0.07215215  0.        ]\n",
      " [ 0.20428953 -0.06454857  0.          0.        ]]\n",
      "SHAP values per classe 131: [[-0.08424703  0.          0.          0.        ]\n",
      " [ 0.          0.19647486 -0.07140658 -0.07876623]\n",
      " [-0.04176503  0.          0.          0.        ]\n",
      " [-0.03201022  0.1537049  -0.0728636   0.        ]\n",
      " [-0.01853625  0.0942788  -0.08636583  0.        ]]\n",
      "SHAP values per classe 132: [[-0.05653678  0.          0.          0.05361189]\n",
      " [-0.00561079  0.          0.          0.02271449]\n",
      " [-0.01673675 -0.03195361  0.          0.        ]\n",
      " [ 0.         -0.05287367  0.02670895  0.        ]\n",
      " [ 0.         -0.00278445  0.          0.0234581 ]]\n",
      "SHAP values per classe 133: [[-0.15917286  0.00983716  0.22420415 -0.07654457]\n",
      " [ 0.          0.0481715   0.          0.00941718]\n",
      " [-0.0140023   0.01295548 -0.04498552  0.01257221]\n",
      " [ 0.         -0.09880998  0.05751547  0.01438601]\n",
      " [-0.00513628 -0.12133012  0.08901651  0.        ]]\n",
      "SHAP values per classe 134: [[-0.12427513  0.01954761  0.0903846   0.02191241]\n",
      " [-0.00651144  0.          0.          0.01844797]\n",
      " [-0.01987258 -0.00902952  0.07756095 -0.02877129]\n",
      " [ 0.         -0.09754932  0.05267473  0.02784164]\n",
      " [ 0.         -0.08740176  0.02698709  0.0577115 ]]\n",
      "SHAP values per classe 135: [[-0.1170496   0.17414214 -0.05419879  0.        ]\n",
      " [-0.00716775  0.          0.          0.        ]\n",
      " [-0.02344187  0.01655405  0.          0.        ]\n",
      " [-0.03177326  0.11739279 -0.08205952  0.        ]\n",
      " [-0.02459485  0.21838823 -0.12852339 -0.03520317]]\n",
      "SHAP values per classe 136: [[-0.04749679  0.02543662  0.         -0.11227064]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.         -0.00274787 -0.03429266]\n",
      " [-0.13833978  0.41443284 -0.14630006 -0.09438611]\n",
      " [ 0.          0.          0.04601103 -0.05605597]]\n",
      "SHAP values per classe 137: [[ 0.33585469 -0.04619569 -0.18712215 -0.07653342]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.03289596 -0.1169149   0.          0.00464069]\n",
      " [ 0.0269869  -0.06372283  0.          0.01127038]]\n",
      "SHAP values per classe 138: [[-0.11399137  0.00861102  0.08100954  0.02796414]\n",
      " [-0.1052248  -0.11423614  0.          0.        ]\n",
      " [-0.04533936 -0.06775891 -0.02772208 -0.02084941]\n",
      " [ 0.00484984 -0.07273743  0.05134867  0.03452907]\n",
      " [ 0.00296099 -0.05887534  0.06287437  0.        ]]\n",
      "SHAP values per classe 139: [[ 0.272126   -0.02971944 -0.1038746  -0.07718959]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.0806818  -0.12030936  0.          0.00639199]\n",
      " [ 0.05031133 -0.08337422  0.          0.        ]]\n",
      "SHAP values per classe 140: [[ 0.34426023 -0.03304267 -0.23808467 -0.11316378]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.01408815  0.          0.          0.        ]\n",
      " [ 0.07415711 -0.13157735  0.          0.03023468]\n",
      " [ 0.03471745 -0.06703576  0.          0.        ]]\n",
      "SHAP values per classe 141: [[ 0.32839143 -0.04684781 -0.20635635 -0.0809283 ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.00890708]\n",
      " [ 0.06883086 -0.14081871  0.          0.        ]\n",
      " [ 0.09799593 -0.07184354  0.          0.06354447]]\n",
      "SHAP values per classe 142: [[-0.12182106  0.00708236  0.10318193  0.0050215 ]\n",
      " [-0.00357403  0.          0.00907441 -0.00446478]\n",
      " [-0.02078416  0.00643996  0.02546475  0.00037675]\n",
      " [ 0.         -0.07344278  0.          0.02088982]\n",
      " [ 0.         -0.06912386  0.05426907  0.        ]]\n",
      "SHAP values per classe 143: [[ 0.13439109  0.          0.         -0.07709491]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.01642787  0.        ]\n",
      " [ 0.08729717 -0.10387533  0.          0.        ]\n",
      " [ 0.06008149 -0.09431068  0.02717727  0.        ]]\n",
      "SHAP values per classe 144: [[ 0.54268928 -0.12625529 -0.26518034 -0.10729036]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.03810852 -0.04679174  0.         -0.02729947]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.02525027 -0.04844007  0.          0.        ]]\n",
      "SHAP values per classe 145: [[-0.18977804  0.          0.1053127   0.03732547]\n",
      " [-0.00041882  0.          0.         -0.00804907]\n",
      " [ 0.          0.          0.0323942  -0.04498962]\n",
      " [ 0.         -0.11524865  0.11826599 -0.0050722 ]\n",
      " [ 0.00516485 -0.08168424  0.06973799  0.        ]]\n",
      "SHAP values per classe 146: [[ 0.29550868 -0.03844597 -0.10206568 -0.11140873]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.09492043 -0.04296708  0.         -0.01650721]\n",
      " [ 0.06128481 -0.12741466  0.          0.04606758]\n",
      " [ 0.06248851 -0.08689256  0.          0.02536929]]\n",
      "SHAP values per classe 147: [[-0.14142658 -0.01502584  0.12526508  0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.01125334 -0.00345485  0.          0.03620851]\n",
      " [-0.01523983 -0.11062729  0.11242487  0.02039946]\n",
      " [ 0.         -0.05687208  0.03337131  0.01818864]]\n",
      "SHAP values per classe 148: [[ 0.25926423 -0.02157657 -0.14775467 -0.08198066]\n",
      " [ 0.          0.          0.          0.01519635]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.09463945 -0.21489942  0.          0.03455369]\n",
      " [ 0.          0.          0.08750484  0.        ]]\n",
      "SHAP values per classe 149: [[-0.10035135  0.01097882  0.10290816  0.        ]\n",
      " [ 0.02193596  0.02000342  0.04584186 -0.08432065]\n",
      " [-0.01574041 -0.02418934  0.0526856  -0.01716872]\n",
      " [ 0.00653784 -0.09384645  0.06641614  0.01920612]\n",
      " [ 0.00390205 -0.05628446  0.04587632  0.        ]]\n",
      "SHAP values per classe 150: [[-0.13775753  0.07497104  0.04723599  0.        ]\n",
      " [-0.00866216  0.          0.          0.        ]\n",
      " [-0.02507322  0.10397108 -0.05156284  0.        ]\n",
      " [-0.07172353  0.35515079 -0.25994175 -0.0348941 ]\n",
      " [ 0.         -0.04294202  0.06354936  0.        ]]\n",
      "SHAP values per classe 151: [[-0.07030666  0.          0.02557815  0.03734786]\n",
      " [ 0.          0.          0.          0.00874441]\n",
      " [-0.01258086  0.00840813  0.          0.        ]\n",
      " [-0.01092625 -0.01836739  0.02788281  0.        ]\n",
      " [ 0.         -0.02446312  0.01931715  0.        ]]\n",
      "SHAP values per classe 152: [[-0.15985866  0.03766547  0.06129554  0.05806371]\n",
      " [ 0.          0.00314571  0.00650628  0.        ]\n",
      " [-0.02171602  0.00649786  0.          0.        ]\n",
      " [ 0.         -0.12316979  0.05565702  0.01401275]\n",
      " [ 0.00387843 -0.07431211  0.06724664  0.        ]]\n",
      "SHAP values per classe 153: [[-0.13150141  0.29536855 -0.03888683 -0.06027205]\n",
      " [ 0.         -0.07037392  0.          0.        ]\n",
      " [-0.01471543  0.01642501  0.          0.        ]\n",
      " [-0.02530124  0.06731781 -0.06891101 -0.01037964]\n",
      " [-0.02159485  0.08227397 -0.08272872  0.        ]]\n",
      "SHAP values per classe 154: [[-0.07861231  0.          0.04488868  0.        ]\n",
      " [-0.00951855  0.00844175  0.         -0.01792059]\n",
      " [-0.02119151  0.          0.          0.0263357 ]\n",
      " [-0.08044159  0.483428   -0.20682858 -0.16055588]\n",
      " [-0.01708138  0.09927983 -0.07996978  0.        ]]\n",
      "SHAP values per classe 155: [[ 0.22204341  0.06857025 -0.10527974 -0.20032967]\n",
      " [ 0.          0.00679816  0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.10410156 -0.05536493  0.01961086]\n",
      " [ 0.         -0.06966504  0.02571244  0.00556922]]\n",
      "SHAP values per classe 156: [[ 0.39415041 -0.056748   -0.22044292 -0.08256903]\n",
      " [ 0.          0.00195806  0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.05815551 -0.10006028  0.02656029  0.        ]\n",
      " [ 0.05154732 -0.08258335  0.07488504  0.        ]]\n",
      "SHAP values per classe 157: [[-0.10119898  0.         -0.00832793  0.10550415]\n",
      " [-0.008237   -0.01925737  0.01783363  0.01606048]\n",
      " [-0.02807405  0.          0.065688   -0.05205462]\n",
      " [ 0.         -0.06854622  0.03707133  0.0220792 ]\n",
      " [ 0.         -0.03670092  0.01853518  0.01274945]]\n",
      "SHAP values per classe 158: [[ 0.46672728 -0.01992236 -0.2065336  -0.21561956]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.00109346  0.01892409 -0.02352729]\n",
      " [ 0.03536288 -0.07414622  0.02772832  0.00917831]\n",
      " [ 0.03886295 -0.0660035   0.          0.02264754]]\n",
      "SHAP values per classe 159: [[-0.08232258  0.05002293  0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.00802892  0.00553319  0.          0.        ]\n",
      " [-0.12644239  0.49206791 -0.30719596 -0.02596498]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 160: [[ 0.          0.          0.19308889 -0.1837265 ]\n",
      " [-0.03258443 -0.00425762  0.05845573  0.        ]\n",
      " [ 0.          0.          0.         -0.06693987]\n",
      " [ 0.         -0.06115476  0.          0.        ]\n",
      " [-0.00771499 -0.03839443  0.05509617  0.        ]]\n",
      "SHAP values per classe 161: [[-0.12510822 -0.00953846  0.0401147   0.0889304 ]\n",
      " [-0.01407948  0.         -0.01045795  0.02622052]\n",
      " [-0.00824368  0.         -0.01951288  0.05320085]\n",
      " [ 0.         -0.05329064  0.09178085  0.        ]\n",
      " [ 0.         -0.0419198   0.          0.09168814]]\n",
      "SHAP values per classe 162: [[-0.11452306  0.00934638  0.03598933  0.05320989]\n",
      " [ 0.         -0.13711953  0.          0.00614173]\n",
      " [-0.00256324 -0.09114568  0.          0.        ]\n",
      " [ 0.         -0.0786669   0.0630252   0.03630664]\n",
      " [-0.00554493 -0.00262811  0.02943704  0.03581809]]\n",
      "SHAP values per classe 163: [[-0.11837909  0.          0.06012196  0.01872408]\n",
      " [-0.00532517  0.          0.          0.        ]\n",
      " [-0.00212091  0.          0.          0.        ]\n",
      " [ 0.00754469 -0.07385311  0.02026818  0.02606139]\n",
      " [-0.01071867 -0.04790837  0.01247472  0.008851  ]]\n",
      "SHAP values per classe 164: [[-0.056085   -0.02492313  0.06574136  0.02690899]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.02129492 -0.02395561  0.05856482  0.        ]\n",
      " [ 0.         -0.02377524  0.          0.        ]\n",
      " [ 0.         -0.0227795   0.          0.        ]]\n",
      "SHAP values per classe 165: [[-0.06891259  0.          0.04139151  0.        ]\n",
      " [-0.02963304  0.          0.          0.        ]\n",
      " [ 0.          0.00518018 -0.01051068  0.        ]\n",
      " [ 0.00412312 -0.01587585  0.          0.        ]\n",
      " [-0.0692983   0.33982457 -0.16413061 -0.13145705]]\n",
      "SHAP values per classe 166: [[-0.14512357  0.08819571  0.04503087  0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.01924212  0.          0.          0.        ]\n",
      " [-0.06518054  0.3534607  -0.26575447 -0.01096906]\n",
      " [ 0.00915686  0.          0.         -0.0030986 ]]\n",
      "SHAP values per classe 167: [[-0.14862121  0.09394945  0.04720335  0.        ]\n",
      " [-0.01275645  0.0102602   0.          0.        ]\n",
      " [-0.03108177  0.04659648  0.          0.        ]\n",
      " [ 0.00540311  0.          0.05304769  0.        ]\n",
      " [-0.0209159   0.3627145  -0.29545711 -0.01893925]]\n",
      "SHAP values per classe 168: [[-0.08887375  0.          0.02852565  0.04397079]\n",
      " [-0.0338615  -0.02791323  0.07053997  0.        ]\n",
      " [ 0.          0.          0.          0.00339862]\n",
      " [-0.01038271 -0.04642846  0.          0.03767771]\n",
      " [ 0.         -0.03539665  0.          0.        ]]\n",
      "SHAP values per classe 169: [[-0.0984903   0.          0.0404108   0.05368136]\n",
      " [ 0.         -0.00340754 -0.00637578  0.00805802]\n",
      " [-0.00528704  0.          0.          0.        ]\n",
      " [ 0.         -0.07334889  0.04080639  0.        ]\n",
      " [ 0.          0.04158394 -0.05459068  0.01285551]]\n",
      "SHAP values per classe 170: [[-0.07286523  0.03109072  0.03594045  0.        ]\n",
      " [-0.00531027  0.          0.          0.        ]\n",
      " [-0.04623664  0.00677607  0.          0.        ]\n",
      " [ 0.          0.          0.          0.05293379]\n",
      " [-0.04813343  0.61393097 -0.16467974 -0.34715905]]\n",
      "SHAP values per classe 171: [[ 0.67298405 -0.12819789 -0.32034056 -0.16506419]\n",
      " [ 0.1073152  -0.00470466  0.01642686 -0.09522607]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.02877591 -0.0717688   0.03708093  0.        ]\n",
      " [ 0.00994042 -0.03747906  0.01556684  0.        ]]\n",
      "SHAP values per classe 172: [[ 0.08559451  0.          0.         -0.06775039]\n",
      " [ 0.          0.01680823  0.         -0.00812998]\n",
      " [ 0.          0.02604015 -0.00357252  0.        ]\n",
      " [-0.2238626   0.29523435 -0.05779249  0.        ]\n",
      " [ 0.04429126  0.          0.         -0.03999867]]\n",
      "SHAP values per classe 173: [[-0.08027323  0.          0.05172378  0.        ]\n",
      " [ 0.04867508  0.          0.          0.        ]\n",
      " [-0.09744866 -0.01082994  0.05868554  0.        ]\n",
      " [-0.06681392 -0.04684652  0.          0.        ]\n",
      " [-0.07908034  0.          0.          0.        ]]\n",
      "SHAP values per classe 174: [[-0.16049742  0.          0.13901424  0.        ]\n",
      " [ 0.          0.          0.          0.00491619]\n",
      " [-0.02162748  0.          0.          0.05612926]\n",
      " [ 0.         -0.12928819  0.1139975   0.        ]\n",
      " [ 0.         -0.08477644  0.05853444  0.02389223]]\n",
      "SHAP values per classe 175: [[-0.11507108  0.08502729  0.06339051  0.        ]\n",
      " [-0.00956608  0.          0.          0.01017197]\n",
      " [-0.03586231  0.          0.0201781   0.        ]\n",
      " [ 0.         -0.09230503  0.04825289  0.        ]\n",
      " [-0.00936763  0.2625265  -0.23663231  0.        ]]\n",
      "SHAP values per classe 176: [[-0.18372963  0.          0.          0.13348251]\n",
      " [-0.00864131 -0.00020753  0.          0.        ]\n",
      " [-0.01586827  0.          0.          0.05016035]\n",
      " [ 0.00609175 -0.1128087   0.          0.0803096 ]\n",
      " [ 0.00360665 -0.07702411  0.10370166 -0.01938216]]\n",
      "SHAP values per classe 177: [[ 0.30842054 -0.07880827 -0.11217063 -0.13056063]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.05469724 -0.04824637  0.01306846 -0.04500567]\n",
      " [ 0.02846249 -0.066783    0.01152736  0.        ]\n",
      " [ 0.07377687 -0.03212685 -0.00703768 -0.01240324]]\n",
      "SHAP values per classe 178: [[ 0.11233701 -0.00616961 -0.05610872 -0.05023996]\n",
      " [ 0.          0.00036258  0.          0.        ]\n",
      " [ 0.32548215 -0.11721729 -0.13084713 -0.08278391]\n",
      " [ 0.02893515 -0.20287623  0.          0.03406798]\n",
      " [ 0.01470951 -0.0432297   0.04165708  0.        ]]\n",
      "SHAP values per classe 179: [[-0.0871112   0.01327591  0.07717383  0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.05048676]\n",
      " [ 0.         -0.05127151  0.03560172  0.        ]\n",
      " [ 0.         -0.04656554  0.02771624  0.        ]]\n",
      "SHAP values per classe 180: [[ 0.03911255  0.03162589  0.         -0.04006158]\n",
      " [ 0.02981604  0.          0.         -0.03617102]\n",
      " [ 0.          0.0264644  -0.02917765  0.        ]\n",
      " [-0.42562653  0.60265458 -0.10393259 -0.03779314]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 181: [[ 0.          0.          0.         -0.01569881]\n",
      " [ 0.5659604  -0.29773753 -0.04092965 -0.14596754]\n",
      " [ 0.          0.0312722   0.          0.        ]\n",
      " [-0.25176659  0.44207856 -0.09643769 -0.0595012 ]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 182: [[-0.12764925  0.          0.          0.        ]\n",
      " [-0.00581871  0.          0.0338195   0.        ]\n",
      " [-0.02863879  0.05182847  0.          0.02633422]\n",
      " [-0.04804017  0.38229576 -0.29449333 -0.04797552]\n",
      " [ 0.          0.02121003  0.         -0.00638129]]\n",
      "SHAP values per classe 183: [[ 0.21463965 -0.00765984  0.         -0.05701812]\n",
      " [ 0.00951968 -0.00702519  0.         -0.02069415]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.08321518 -0.13359164  0.          0.        ]\n",
      " [ 0.04373493 -0.0756306   0.          0.        ]]\n",
      "SHAP values per classe 184: [[-0.1566556   0.06320365  0.07900149  0.        ]\n",
      " [-0.00999415  0.          0.          0.        ]\n",
      " [-0.03766008  0.          0.          0.        ]\n",
      " [ 0.0098316   0.          0.07186141  0.        ]\n",
      " [-0.01678821  0.41601202 -0.33989361 -0.01620912]]\n",
      "SHAP values per classe 185: [[-0.05846745  0.          0.          0.05371334]\n",
      " [-0.00848136  0.          0.08322643 -0.00332901]\n",
      " [-0.00551727 -0.00180144  0.          0.09474266]\n",
      " [ 0.         -0.06648381  0.          0.        ]\n",
      " [ 0.         -0.01901249 -0.07785995  0.10682175]]\n",
      "SHAP values per classe 186: [[-0.11634294 -0.0053491   0.          0.03024918]\n",
      " [-0.00424634  0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.07049925  0.          0.02428269]\n",
      " [ 0.         -0.04724287  0.          0.        ]]\n",
      "SHAP values per classe 187: [[ 0.33835872 -0.03926121 -0.16662762 -0.13372427]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.         -0.09692215  0.02881257]\n",
      " [ 0.0681164  -0.11652301  0.          0.        ]\n",
      " [ 0.04475531 -0.08506995  0.          0.01557203]]\n",
      "SHAP values per classe 188: [[-0.09527229 -0.02890004  0.          0.        ]\n",
      " [ 0.00463534  0.          0.          0.03649624]\n",
      " [ 0.          0.00610799  0.          0.        ]\n",
      " [ 0.         -0.05319244  0.          0.        ]\n",
      " [ 0.         -0.03668617  0.04186704  0.        ]]\n",
      "SHAP values per classe 189: [[-1.68153311e-01  3.73718905e-02  9.55019033e-02  5.84734619e-05]\n",
      " [-1.27717753e-02  2.41617540e-02  2.45580398e-03  0.00000000e+00]\n",
      " [-2.85844940e-02  5.25324629e-03  0.00000000e+00  1.80748390e-02]\n",
      " [ 0.00000000e+00 -8.31797372e-02  3.01199296e-02  2.16183430e-02]\n",
      " [ 0.00000000e+00  1.46050270e-01 -2.31616971e-01  8.75978923e-02]]\n",
      "SHAP values per classe 190: [[-0.09604239  0.          0.          0.05221661]\n",
      " [ 0.         -0.00118157  0.          0.        ]\n",
      " [-0.03937305  0.          0.11828372  0.        ]\n",
      " [ 0.         -0.07006594  0.          0.02857502]\n",
      " [ 0.         -0.03152779  0.04294127  0.        ]]\n",
      "SHAP values per classe 191: [[-0.11663145  0.08547136  0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.0246665   0.          0.          0.        ]\n",
      " [-0.06071823  0.51379344 -0.37156515 -0.06579965]\n",
      " [ 0.          0.          0.0213651   0.        ]]\n",
      "SHAP values per classe 192: [[ 0.29489145 -0.04565119 -0.06938498 -0.06765211]\n",
      " [ 0.          0.          0.          0.04578401]\n",
      " [ 0.03316842  0.          0.         -0.01624305]\n",
      " [ 0.08055561 -0.12788119  0.          0.00554588]\n",
      " [ 0.05526255 -0.08408343  0.          0.        ]]\n",
      "SHAP values per classe 193: [[-0.09250465  0.04676344  0.04654935  0.01135849]\n",
      " [-0.00343501  0.          0.          0.        ]\n",
      " [-0.05246829  0.01688227  0.          0.        ]\n",
      " [ 0.         -0.05069454  0.03564546  0.        ]\n",
      " [-0.0504296   0.59231968 -0.22547679 -0.19676823]]\n",
      "SHAP values per classe 194: [[-0.10717191  0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.08679189  0.        ]\n",
      " [ 0.         -0.06241415  0.         -0.02652844]\n",
      " [ 0.         -0.0381769   0.05876803  0.        ]]\n",
      "SHAP values per classe 195: [[-0.10386594  0.          0.00094038  0.07815612]\n",
      " [-0.01230939  0.          0.04925829  0.        ]\n",
      " [-0.00864379  0.         -0.069298    0.02747295]\n",
      " [ 0.         -0.08304832  0.04980384  0.01343786]\n",
      " [ 0.0131483  -0.04028113  0.          0.        ]]\n",
      "SHAP values per classe 196: [[ 0.          0.          0.06212962  0.        ]\n",
      " [ 0.02671356  0.00083167  0.         -0.02941189]\n",
      " [ 0.         -0.01453253  0.10263668 -0.0737413 ]\n",
      " [ 0.02372725 -0.10785847  0.00683512  0.01362262]\n",
      " [ 0.         -0.09983408  0.10316905 -0.06069685]]\n",
      "SHAP values per classe 197: [[ 0.          0.04716094  0.         -0.03084603]\n",
      " [ 0.43932899  0.          0.         -0.14382536]\n",
      " [-0.02997354  0.          0.          0.        ]\n",
      " [-0.22745626  0.36859747 -0.12618885 -0.03594198]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 198: [[-0.10281448  0.0492662   0.05286337  0.        ]\n",
      " [ 0.          0.          0.00888976  0.        ]\n",
      " [-0.02311474  0.02469793  0.          0.        ]\n",
      " [-0.02746661  0.06212972 -0.04299913  0.        ]\n",
      " [-0.01283666  0.10562357 -0.10333486  0.        ]]\n",
      "SHAP values per classe 199: [[ 0.09650769  0.         -0.02755815 -0.06842436]\n",
      " [ 0.          0.00994661  0.          0.01493751]\n",
      " [ 0.03550107  0.          0.          0.        ]\n",
      " [ 0.         -0.12017593  0.          0.        ]\n",
      " [ 0.          0.          0.08925473  0.        ]]\n",
      "SHAP values per classe 200: [[ 0.          0.          0.          0.        ]\n",
      " [-0.01184215  0.          0.02455938  0.        ]\n",
      " [-0.00709831  0.          0.          0.        ]\n",
      " [ 0.         -0.05447893  0.          0.        ]\n",
      " [ 0.         -0.02443974  0.          0.        ]]\n",
      "SHAP values per classe 201: [[-0.14259197  0.02685026  0.00711302  0.08087417]\n",
      " [-0.02259438  0.          0.          0.02422581]\n",
      " [-0.01460738  0.          0.          0.03060798]\n",
      " [ 0.         -0.09285072  0.05317811  0.02741976]\n",
      " [ 0.         -0.06803744  0.          0.04474568]]\n",
      "SHAP values per classe 202: [[-0.13882757  0.          0.05503734  0.06981086]\n",
      " [-0.01036767 -0.00643857  0.01374843  0.00551133]\n",
      " [-0.04272262 -0.13196665  0.16388462  0.        ]\n",
      " [ 0.         -0.03649967  0.          0.01405281]\n",
      " [ 0.         -0.03173101  0.          0.0155407 ]]\n",
      "SHAP values per classe 203: [[-0.09744439  0.          0.          0.08430646]\n",
      " [-0.0099036   0.          0.          0.01952179]\n",
      " [-0.00718349  0.          0.          0.00268051]\n",
      " [ 0.         -0.06649486  0.          0.01440174]\n",
      " [ 0.         -0.03415489  0.02037166  0.00637791]]\n",
      "SHAP values per classe 204: [[-0.11227936  0.00340294  0.05151171  0.02969797]\n",
      " [ 0.          0.01460769  0.03446382 -0.02837775]\n",
      " [ 0.         -0.00158044  0.          0.        ]\n",
      " [ 0.         -0.03318233 -0.05697362  0.03810003]\n",
      " [ 0.         -0.04118802  0.02069732  0.        ]]\n",
      "SHAP values per classe 205: [[-0.13543706  0.          0.05634463  0.07373364]\n",
      " [-0.00784854  0.          0.          0.        ]\n",
      " [-0.01564014 -0.00131135  0.          0.01222786]\n",
      " [ 0.          0.         -0.06718193  0.17107005]\n",
      " [ 0.00268244 -0.06439344 -0.01909753  0.0417037 ]]\n",
      "SHAP values per classe 206: [[-0.1420506   0.          0.         -0.00626855]\n",
      " [ 0.          0.15388554 -0.03727187  0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.29922409 -0.02972771 -0.12682163]\n",
      " [-0.03363002  0.13129001 -0.07918065  0.        ]]\n",
      "SHAP values per classe 207: [[-0.1477125  -0.034334    0.23965314  0.        ]\n",
      " [ 0.02991826  0.          0.04947544 -0.08076057]\n",
      " [-0.00474995 -0.00568896 -0.0086464   0.02266091]\n",
      " [ 0.         -0.04886279  0.          0.        ]\n",
      " [ 0.         -0.02085657 -0.05557444  0.09962002]]\n",
      "SHAP values per classe 208: [[-0.1481677  -0.02059212  0.17445891 -0.03234172]\n",
      " [ 0.00668072  0.03395403  0.         -0.05979584]\n",
      " [ 0.0012025   0.          0.          0.        ]\n",
      " [ 0.00745288 -0.07533552  0.05671447  0.        ]\n",
      " [ 0.00348535 -0.0450244   0.06309146 -0.05452116]]\n",
      "SHAP values per classe 209: [[-0.10678329  0.          0.          0.07560755]\n",
      " [-0.02640414  0.          0.          0.        ]\n",
      " [-0.00459223  0.          0.          0.        ]\n",
      " [ 0.         -0.06744326  0.          0.03375343]\n",
      " [-0.02848539 -0.12756331 -0.31666023  0.52702212]]\n",
      "SHAP values per classe 210: [[-0.10400935 -0.0148637   0.12136426  0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.00702805  0.          0.          0.        ]\n",
      " [ 0.         -0.04832831  0.0299358   0.        ]\n",
      " [ 0.         -0.03976632  0.03209055  0.        ]]\n",
      "SHAP values per classe 211: [[-0.12260655  0.06350336  0.10930081  0.        ]\n",
      " [ 0.          0.          0.          0.02494957]\n",
      " [-0.03051574  0.02861471  0.         -0.01015516]\n",
      " [-0.05680636  0.43709691 -0.28250399 -0.00453568]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 212: [[-1.19422902e-01  0.00000000e+00  5.38912208e-02  0.00000000e+00]\n",
      " [-7.54882510e-05 -6.57793902e-02  0.00000000e+00  1.71650441e-03]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00 -6.64149500e-02  0.00000000e+00  3.97620791e-02]\n",
      " [ 0.00000000e+00 -4.41669303e-02  5.76064608e-02  0.00000000e+00]]\n",
      "SHAP values per classe 213: [[-0.17676867  0.02274997  0.08079976  0.0523681 ]\n",
      " [-0.00686293  0.          0.          0.        ]\n",
      " [-0.01737166  0.          0.          0.03074742]\n",
      " [ 0.         -0.13804383  0.1308736   0.01462926]\n",
      " [ 0.00429286 -0.0900715   0.05935149  0.        ]]\n",
      "SHAP values per classe 214: [[-0.2394447   0.          0.          0.        ]\n",
      " [ 0.          0.09406087  0.          0.        ]\n",
      " [ 0.          0.01940756  0.          0.        ]\n",
      " [-0.10414547  0.47388139 -0.30719535 -0.08903095]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 215: [[-0.10034559  0.02905367  0.25992644 -0.15716463]\n",
      " [-0.00494779 -0.01388321 -0.01351267  0.00777905]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.12510398  0.12203421  0.01481622]\n",
      " [ 0.         -0.09696744  0.06331745  0.01441699]]\n",
      "SHAP values per classe 216: [[-0.10487519  0.01468653  0.          0.06713306]\n",
      " [-0.02399483  0.01404881 -0.00861077  0.01992241]\n",
      " [-0.00622396  0.         -0.03185539  0.03288602]\n",
      " [ 0.         -0.12322467  0.02613053  0.06103441]\n",
      " [-0.00875922 -0.03585011  0.03332392  0.03701935]]\n",
      "SHAP values per classe 217: [[-0.08392233  0.00997636  0.04914905  0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.01504459 -0.00626937 -0.02428515  0.04626306]\n",
      " [ 0.01350054 -0.08225284  0.03690382  0.03457898]\n",
      " [-0.01949611 -0.10504786  0.12275147  0.        ]]\n",
      "SHAP values per classe 218: [[ 2.15937931e-01 -5.41058471e-02 -1.26890507e-01 -3.34767086e-02]\n",
      " [ 0.00000000e+00  2.26097624e-05  0.00000000e+00  0.00000000e+00]\n",
      " [ 6.05422445e-02 -4.81226696e-02  0.00000000e+00 -5.76775124e-02]\n",
      " [ 4.52902492e-02 -1.16932252e-01  4.97918292e-02  0.00000000e+00]\n",
      " [ 2.29094816e-02 -5.26078577e-02  3.72422318e-02  0.00000000e+00]]\n",
      "SHAP values per classe 219: [[-0.11134148  0.          0.06288069  0.03641821]\n",
      " [-0.0121884   0.          0.01780471  0.        ]\n",
      " [ 0.          0.          0.          0.01735549]\n",
      " [ 0.         -0.05206527  0.          0.04565089]\n",
      " [ 0.         -0.02915396  0.01202808  0.02145942]]\n",
      "SHAP values per classe 220: [[-0.05947808  0.          0.03143601  0.01991959]\n",
      " [-0.01773312 -0.01542311  0.          0.06042876]\n",
      " [ 0.          0.          0.02993248  0.        ]\n",
      " [ 0.         -0.06025869  0.          0.02444412]\n",
      " [ 0.         -0.0282886   0.02049542  0.        ]]\n",
      "SHAP values per classe 221: [[-0.14747061  0.          0.03707977  0.        ]\n",
      " [-0.00143207 -0.08663793  0.09440837 -0.08937663]\n",
      " [-0.00701964  0.1539651   0.          0.        ]\n",
      " [-0.06097094  0.57502903 -0.38155126 -0.12425355]\n",
      " [ 0.          0.          0.02932856 -0.00368972]]\n",
      "SHAP values per classe 222: [[-0.11642026  0.00961227  0.09368606  0.        ]\n",
      " [ 0.01823291  0.0580767   0.          0.        ]\n",
      " [-0.00807911  0.00150298  0.          0.        ]\n",
      " [ 0.00924266 -0.16173675  0.10797993 -0.01659572]\n",
      " [ 0.00405356 -0.06494416  0.07093723 -0.00947968]]\n",
      "SHAP values per classe 223: [[-0.15953248  0.04816529  0.06456156  0.02685231]\n",
      " [-0.00986033  0.          0.08914716  0.        ]\n",
      " [-0.02455691  0.          0.          0.01888264]\n",
      " [-0.01663139  0.12643047 -0.16065329  0.        ]\n",
      " [ 0.          0.          0.03828236  0.02185008]]\n",
      "SHAP values per classe 224: [[ 0.44429693 -0.07826353 -0.19996725 -0.15317515]\n",
      " [ 0.          0.         -0.01832665  0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.05296168 -0.09603154  0.04797303  0.        ]\n",
      " [ 0.02926417 -0.0533966   0.02020836  0.        ]]\n",
      "SHAP values per classe 225: [[-0.11332588  0.          0.03497729  0.00774043]\n",
      " [-0.01100482  0.         -0.03283073  0.09073808]\n",
      " [-0.01904715  0.0172513   0.          0.00174615]\n",
      " [-0.03645586  0.1187905  -0.06224092 -0.0131526 ]\n",
      " [-0.00751864  0.13887566 -0.06074883  0.        ]]\n",
      "SHAP values per classe 226: [[-0.088115    0.          0.11487257 -0.0152308 ]\n",
      " [ 0.         -0.0079201   0.11794743  0.        ]\n",
      " [-0.0142059   0.          0.01436823  0.        ]\n",
      " [ 0.         -0.06762164  0.          0.        ]\n",
      " [ 0.03768581 -0.02794271 -0.13039943  0.02549573]]\n",
      "SHAP values per classe 227: [[-0.05489004  0.          0.11189335 -0.0609628 ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.03405731  0.          0.0444623   0.        ]\n",
      " [ 0.03099438 -0.12241762  0.0890074   0.01515718]\n",
      " [ 0.         -0.09400779  0.08371674  0.        ]]\n",
      "SHAP values per classe 228: [[-0.13082377  0.39323496 -0.05731771 -0.0374815 ]\n",
      " [-0.00657928  0.00877828 -0.01188768  0.        ]\n",
      " [-0.00758052  0.31226912  0.          0.        ]\n",
      " [-0.03821423  0.07846447 -0.07828612 -0.01627307]\n",
      " [-0.01385643  0.         -0.09615758 -0.02554546]]\n",
      "SHAP values per classe 229: [[-0.08903525  0.03094929  0.03176522  0.02868271]\n",
      " [ 0.          0.          0.01186579  0.        ]\n",
      " [-0.01528081  0.01241004  0.04616132 -0.04789634]\n",
      " [-0.10770017  0.62478827 -0.27834767 -0.21899577]\n",
      " [ 0.         -0.02519917  0.          0.        ]]\n",
      "SHAP values per classe 230: [[-0.14193634  0.00714161  0.13820067  0.        ]\n",
      " [-0.0101708   0.          0.          0.        ]\n",
      " [-0.01680863  0.          0.          0.        ]\n",
      " [ 0.         -0.1198726   0.30777411 -0.1629893 ]\n",
      " [ 0.         -0.07886814  0.07808285  0.        ]]\n",
      "SHAP values per classe 231: [[-0.10838628  0.          0.02792361  0.06702748]\n",
      " [-0.03854247 -0.00241945  0.          0.05982716]\n",
      " [ 0.         -0.00404278  0.          0.        ]\n",
      " [ 0.0032589  -0.06159206  0.01207725  0.03128018]\n",
      " [ 0.         -0.04005379  0.01999656  0.        ]]\n",
      "SHAP values per classe 232: [[-0.08448536  0.          0.          0.04912293]\n",
      " [-0.00904182  0.00508829  0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.06580785 -0.15877871  0.          0.57887008]\n",
      " [ 0.         -0.03559749  0.05022952  0.        ]]\n",
      "SHAP values per classe 233: [[ 0.26979193  0.00550075 -0.15952904 -0.1023396 ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.08210564 -0.02251877  0.         -0.02310637]\n",
      " [ 0.         -0.11286827  0.0455133   0.        ]\n",
      " [ 0.         -0.02572963  0.          0.        ]]\n",
      "SHAP values per classe 234: [[ 0.32011199 -0.03778389 -0.17112546 -0.06277279]\n",
      " [ 0.0196978   0.          0.          0.        ]\n",
      " [ 0.00798729  0.          0.         -0.09322214]\n",
      " [ 0.09105365 -0.12160411  0.          0.        ]\n",
      " [ 0.0458477  -0.07551217  0.01436084  0.00522936]]\n",
      "SHAP values per classe 235: [[-0.09544233  0.00835116  0.11058    -0.032661  ]\n",
      " [-0.03723386  0.01328672  0.12110204  0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.05779432 -0.16382154  0.16243419  0.09285024]\n",
      " [ 0.         -0.0691815   0.          0.        ]]\n",
      "SHAP values per classe 236: [[ 0.53603105 -0.06217802 -0.12314956 -0.28441247]\n",
      " [ 0.          0.          0.          0.00623681]\n",
      " [ 0.14320155 -0.06750349  0.         -0.03025264]\n",
      " [ 0.0229582  -0.06025269  0.          0.        ]\n",
      " [ 0.         -0.0248087   0.          0.        ]]\n",
      "SHAP values per classe 237: [[ 0.64613699 -0.16075598 -0.28322149 -0.19530342]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.0042307  -0.03079079  0.02011207  0.        ]\n",
      " [ 0.02600443 -0.06778174  0.03103323  0.        ]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 238: [[-0.05599981  0.08533421  0.         -0.04437309]\n",
      " [ 0.          0.0265072   0.00466705 -0.02605099]\n",
      " [-0.02926417  0.          0.          0.03721962]\n",
      " [-0.1997835   0.3947242  -0.21165567  0.        ]\n",
      " [ 0.          0.          0.          0.00487339]]\n",
      "SHAP values per classe 239: [[ 0.          0.03025867  0.         -0.06331894]\n",
      " [ 0.          0.04300494  0.          0.        ]\n",
      " [-0.01153004  0.00634641  0.          0.        ]\n",
      " [-0.19476364  0.41005296 -0.19500997 -0.00232447]\n",
      " [ 0.          0.          0.01854187  0.00634852]]\n",
      "SHAP values per classe 240: [[-0.07679941  0.         -0.02240984  0.09156111]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.02553546  0.          0.          0.        ]\n",
      " [ 0.         -0.06654465  0.06598577  0.        ]\n",
      " [ 0.         -0.02615757  0.          0.02078516]]\n",
      "SHAP values per classe 241: [[-0.12187025  0.03295965  0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.04368917  0.          0.        ]\n",
      " [-0.07048344  0.55574716 -0.3004776  -0.17828742]\n",
      " [ 0.          0.01004991  0.04195544 -0.00755914]]\n",
      "SHAP values per classe 242: [[ 0.33179656 -0.02760331 -0.19013152 -0.06967146]\n",
      " [ 0.          0.          0.          0.00097986]\n",
      " [ 0.          0.          0.          0.00174967]\n",
      " [ 0.09437887 -0.12519604  0.          0.        ]\n",
      " [ 0.         -0.0720268   0.         -0.02781456]]\n",
      "SHAP values per classe 243: [[ 0.40142724 -0.09077708 -0.16632149 -0.14432869]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.25054466 -0.01255431 -0.17538112 -0.0312145 ]\n",
      " [ 0.03406973 -0.08789442  0.          0.        ]\n",
      " [ 0.00135368 -0.02971706  0.05140451  0.        ]]\n",
      "SHAP values per classe 244: [[-0.15044118  0.07976477  0.          0.01160887]\n",
      " [ 0.          0.0631919  -0.05560917  0.0309159 ]\n",
      " [-0.01697773  0.          0.05768112  0.        ]\n",
      " [ 0.          0.          0.07450073  0.        ]\n",
      " [-0.04021612  0.34075715 -0.34030558  0.        ]]\n",
      "SHAP values per classe 245: [[-0.10368571  0.          0.06054422  0.0316404 ]\n",
      " [-0.02687994 -0.02637521 -0.13105448  0.16500787]\n",
      " [-0.01016572  0.          0.01862677 -0.03566223]\n",
      " [ 0.         -0.10288115  0.          0.        ]\n",
      " [ 0.         -0.05099196  0.07692329 -0.01995672]]\n",
      "SHAP values per classe 246: [[-0.11406501  0.          0.15812619  0.        ]\n",
      " [ 0.         -0.00280114  0.          0.02762304]\n",
      " [-0.00350456 -0.0048995   0.         -0.05638255]\n",
      " [-0.02592443 -0.11679788  0.1157902   0.        ]\n",
      " [-0.00162432 -0.02633453  0.02225353  0.        ]]\n",
      "SHAP values per classe 247: [[-0.10717662  0.02997764  0.05488213  0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.02350361  0.03045049  0.          0.        ]\n",
      " [-0.05152012  0.43867573 -0.35025312 -0.01860013]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 248: [[-0.06670946  0.          0.          0.0344621 ]\n",
      " [ 0.          0.          0.03781269  0.        ]\n",
      " [-0.00702056  0.          0.06770562  0.        ]\n",
      " [-0.01857741 -0.06401461  0.01556613  0.06677348]\n",
      " [ 0.         -0.02945683  0.02186035  0.        ]]\n",
      "SHAP values per classe 249: [[-0.09139889 -0.02006028  0.02530437  0.11643493]\n",
      " [ 0.         -0.03063683  0.05729373  0.        ]\n",
      " [ 0.          0.          0.          0.03799046]\n",
      " [ 0.         -0.06687027  0.04458954  0.        ]\n",
      " [ 0.          0.          0.         -0.01468398]]\n",
      "SHAP values per classe 250: [[-0.0957697   0.04422522  0.04344357  0.        ]\n",
      " [ 0.          0.          0.0207263   0.        ]\n",
      " [-0.01090549  0.          0.00787866  0.        ]\n",
      " [-0.03503984  0.18234326 -0.07813854 -0.046944  ]\n",
      " [-0.02629417  0.05366043 -0.03241667 -0.01400266]]\n",
      "SHAP values per classe 251: [[-0.13679471  0.07566535  0.03080385 -0.01895084]\n",
      " [ 0.          0.00894398  0.          0.        ]\n",
      " [-0.03163014  0.02514529  0.          0.        ]\n",
      " [ 0.          0.         -0.04848348  0.        ]\n",
      " [-0.02807463  0.33425927 -0.27912974  0.        ]]\n",
      "SHAP values per classe 252: [[-0.15449869  0.          0.13196531  0.03869767]\n",
      " [ 0.          0.         -0.10653551  0.04858385]\n",
      " [-0.00134213  0.          0.02212813  0.        ]\n",
      " [-0.00608003  0.         -0.07409514  0.05790062]\n",
      " [ 0.         -0.05431771  0.06457805 -0.00670753]]\n",
      "SHAP values per classe 253: [[-0.0859343   0.05193263  0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.01208799  0.015208    0.          0.        ]\n",
      " [-0.07444174  0.34075322 -0.21757247 -0.12168311]\n",
      " [-0.026891    0.2829031  -0.09683567  0.        ]]\n",
      "SHAP values per classe 254: [[-0.10493654  0.          0.          0.05279511]\n",
      " [-0.00822186  0.          0.          0.        ]\n",
      " [-0.0054013   0.          0.02244865  0.        ]\n",
      " [ 0.         -0.07751772  0.          0.03695561]\n",
      " [ 0.         -0.03991065  0.02233189  0.        ]]\n",
      "SHAP values per classe 255: [[-0.06498192  0.          0.05554831  0.        ]\n",
      " [ 0.0249805   0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.00118967 -0.05940749  0.03832781  0.        ]\n",
      " [ 0.         -0.02073528  0.01082454  0.        ]]\n",
      "SHAP values per classe 256: [[-0.11415201 -0.01026946 -0.01341997  0.13527125]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.06976192  0.          0.05122416]\n",
      " [ 0.         -0.006635    0.          0.02519849]]\n",
      "SHAP values per classe 257: [[-0.06627145  0.          0.04641582  0.        ]\n",
      " [ 0.02725045  0.          0.027681    0.        ]\n",
      " [ 0.          0.          0.02195972  0.        ]\n",
      " [ 0.         -0.04795219  0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 258: [[-0.04773815  0.          0.17526011 -0.02836532]\n",
      " [ 0.          0.07086306  0.         -0.0671477 ]\n",
      " [-0.00712078  0.         -0.00703788  0.        ]\n",
      " [-0.04878045  0.1946909  -0.05295071 -0.03651911]\n",
      " [ 0.          0.         -0.02470622  0.        ]]\n",
      "SHAP values per classe 259: [[-0.14770268  0.00881717  0.20394568 -0.09255194]\n",
      " [-0.00845225 -0.04803003  0.          0.04168462]\n",
      " [-0.04358573  0.          0.          0.        ]\n",
      " [ 0.         -0.02981097  0.          0.        ]\n",
      " [ 0.         -0.06921131  0.04095969  0.        ]]\n",
      "SHAP values per classe 260: [[-0.10933153  0.          0.          0.09116298]\n",
      " [-0.00807338  0.          0.00328968  0.00580094]\n",
      " [-0.0048078   0.00340827  0.00429008  0.        ]\n",
      " [ 0.         -0.07440337  0.04762242  0.01119913]\n",
      " [ 0.         -0.03519017  0.06185691  0.        ]]\n",
      "SHAP values per classe 261: [[-0.1266733   0.0136608   0.08724494  0.02035437]\n",
      " [-0.01016518 -0.02672015  0.          0.        ]\n",
      " [-0.00943821  0.         -0.00791522  0.01526518]\n",
      " [ 0.         -0.08297678  0.09695949  0.        ]\n",
      " [ 0.         -0.04511162  0.04355041  0.00669946]]\n",
      "SHAP values per classe 262: [[-0.08978053  0.          0.19731011  0.        ]\n",
      " [ 0.          0.          0.07215292 -0.11873804]\n",
      " [ 0.          0.          0.01414006 -0.03905958]\n",
      " [-0.00385816 -0.04865246  0.          0.        ]\n",
      " [ 0.         -0.0725481   0.18264915 -0.05489942]]\n",
      "SHAP values per classe 263: [[-0.10345758  0.05043167  0.04541594  0.        ]\n",
      " [-0.00738615  0.00707312 -0.00051809  0.        ]\n",
      " [-0.0199153   0.02146039  0.          0.        ]\n",
      " [-0.04579471  0.30269096 -0.20754835 -0.01950038]\n",
      " [-0.00829773  0.11989298 -0.1214845  -0.01811497]]\n",
      "SHAP values per classe 264: [[-0.1490115   0.10193637  0.02764083  0.00905425]\n",
      " [ 0.03190647  0.04583462 -0.08090056  0.        ]\n",
      " [ 0.08379932 -0.07001228  0.03851552 -0.0331357 ]\n",
      " [-0.00763907  0.19431629 -0.05643095 -0.03023165]\n",
      " [-0.14974426  0.3380521  -0.19150769  0.        ]]\n",
      "SHAP values per classe 265: [[-0.09253864  0.          0.03938478  0.04700679]\n",
      " [-0.0077438   0.          0.          0.02048373]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.06455589  0.03691381  0.02760389]\n",
      " [ 0.         -0.03812957  0.03824676  0.        ]]\n",
      "SHAP values per classe 266: [[ 0.45618744 -0.0995271  -0.22797132 -0.1217843 ]\n",
      " [ 0.00713339  0.          0.         -0.02843848]\n",
      " [ 0.          0.          0.         -0.03777569]\n",
      " [ 0.06059585 -0.12376845  0.08553441  0.        ]\n",
      " [ 0.02137097 -0.04987181  0.          0.        ]]\n",
      "SHAP values per classe 267: [[-0.06164731  0.          0.          0.11721555]\n",
      " [ 0.          0.          0.          0.04655093]\n",
      " [ 0.          0.          0.02645881 -0.02071624]\n",
      " [ 0.         -0.03068415 -0.06267956  0.11340052]\n",
      " [ 0.         -0.03833239  0.         -0.0294985 ]]\n",
      "SHAP values per classe 268: [[-0.13177734  0.00757671  0.          0.06658953]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.01298281  0.          0.          0.        ]\n",
      " [ 0.         -0.05766371  0.          0.        ]\n",
      " [ 0.          0.01638666  0.          0.        ]]\n",
      "SHAP values per classe 269: [[ 0.          0.06262217  0.          0.        ]\n",
      " [ 0.          0.          0.03180473 -0.04964322]\n",
      " [ 0.          0.          0.01565759  0.        ]\n",
      " [-0.31903994  0.5728358  -0.16466153 -0.06707827]\n",
      " [ 0.13914323  0.         -0.1408153   0.        ]]\n",
      "SHAP values per classe 270: [[-0.10289148  0.01181833  0.11719961 -0.01118621]\n",
      " [-0.01111517  0.          0.          0.        ]\n",
      " [-0.00667877 -0.00117924  0.          0.01801032]\n",
      " [ 0.         -0.09059708  0.07341588  0.        ]\n",
      " [ 0.         -0.08971174  0.07184253  0.00862965]]\n",
      "SHAP values per classe 271: [[ 0.42073307 -0.17581812  0.          0.        ]\n",
      " [-0.0237144   0.00919452  0.          0.00387249]\n",
      " [ 0.          0.          0.         -0.00162487]\n",
      " [ 0.          0.         -0.15217479 -0.06848484]\n",
      " [ 0.         -0.04803409  0.          0.03940972]]\n",
      "SHAP values per classe 272: [[-0.05927365  0.          0.28165514 -0.12320096]\n",
      " [ 0.          0.          0.          0.02369273]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.03258629 -0.06429469  0.          0.        ]\n",
      " [ 0.         -0.02612558  0.          0.        ]]\n",
      "SHAP values per classe 273: [[-0.11290758  0.04799699  0.06288639  0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.00435592]\n",
      " [-0.05305355  0.52823855 -0.38143062 -0.08423583]\n",
      " [-0.02112535  0.          0.          0.        ]]\n",
      "SHAP values per classe 274: [[ 0.35187103 -0.0169214  -0.22864591 -0.08353281]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.10109767 -0.14458705  0.06522494  0.        ]\n",
      " [ 0.         -0.07152991  0.          0.        ]]\n",
      "SHAP values per classe 275: [[-0.11505175  0.00915082  0.03544121  0.05865178]\n",
      " [-0.00539021  0.          0.          0.02050315]\n",
      " [-0.05065181 -0.12430161  0.04787028  0.02627964]\n",
      " [ 0.         -0.02969833  0.04646472  0.04290382]\n",
      " [ 0.         -0.10786049  0.          0.02961413]]\n",
      "SHAP values per classe 276: [[-0.19763487  0.          0.          0.        ]\n",
      " [-0.00675849 -0.00343995 -0.03343134  0.04868362]\n",
      " [ 0.          0.          0.11744904  0.01943646]\n",
      " [ 0.         -0.12111077  0.07201074  0.00546437]\n",
      " [ 0.         -0.08375473  0.03333286  0.02851286]]\n",
      "SHAP values per classe 277: [[ 0.10225469 -0.01447772  0.         -0.09856938]\n",
      " [ 0.11062676 -0.04018536  0.         -0.11363244]\n",
      " [ 0.00213033  0.          0.02481342 -0.00406601]\n",
      " [ 0.02129361 -0.07134771  0.05046856  0.        ]\n",
      " [ 0.02204929 -0.041894    0.          0.        ]]\n",
      "SHAP values per classe 278: [[ 0.34539632 -0.03248139 -0.16295526 -0.1531896 ]\n",
      " [ 0.02315048  0.00310752  0.         -0.018141  ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.07990528 -0.13199598  0.          0.        ]\n",
      " [ 0.02045582 -0.08487737  0.          0.01437659]]\n",
      "SHAP values per classe 279: [[-0.14330238  0.          0.05934072  0.06248809]\n",
      " [-0.00496756  0.01128717  0.          0.        ]\n",
      " [-0.03340671  0.          0.          0.        ]\n",
      " [ 0.         -0.13696422  0.07847999  0.        ]\n",
      " [ 0.          0.         -0.10568245  0.12180839]]\n",
      "SHAP values per classe 280: [[-0.03328553  0.         -0.02365652  0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.05449356  0.         -0.16239427]\n",
      " [-0.04400646 -0.08766584  0.          0.1262091 ]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 281: [[-0.16333225 -0.01191902  0.19635626  0.        ]\n",
      " [-0.00787839  0.          0.02373163 -0.01499597]\n",
      " [-0.00602262  0.          0.          0.        ]\n",
      " [ 0.         -0.09055439  0.07725532  0.        ]\n",
      " [ 0.         -0.08105605  0.          0.05024804]]\n",
      "SHAP values per classe 282: [[-0.05225063 -0.00549669  0.0193684   0.03271983]\n",
      " [-0.00697659  0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.0225303   0.06409817  0.        ]\n",
      " [ 0.         -0.01300759  0.          0.        ]]\n",
      "SHAP values per classe 283: [[ 0.0285415   0.         -0.01787594 -0.0364964 ]\n",
      " [-0.01842724 -0.01889397  0.          0.        ]\n",
      " [-0.11586717  0.          0.26156907 -0.09542051]\n",
      " [ 0.         -0.09576122  0.12802531  0.        ]\n",
      " [ 0.         -0.06551401  0.          0.05281819]]\n",
      "SHAP values per classe 284: [[ 0.65904541 -0.09493733 -0.31902436 -0.20047469]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.00950066  0.          0.          0.        ]\n",
      " [ 0.         -0.12196313  0.07840552  0.        ]\n",
      " [ 0.         -0.02524996  0.01883587  0.        ]]\n",
      "SHAP values per classe 285: [[-0.0715559   0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.04494402  0.        ]\n",
      " [ 0.         -0.05366707  0.          0.00048684]\n",
      " [-0.02413206 -0.03984787 -0.01556171  0.05426989]]\n",
      "SHAP values per classe 286: [[-0.10883296  0.0458527   0.05389514  0.        ]\n",
      " [-0.00892662  0.01730486  0.          0.00795005]\n",
      " [-0.02325061  0.01935092  0.          0.        ]\n",
      " [-0.03942222  0.43371623 -0.31187072 -0.08155458]\n",
      " [-0.00285706  0.00364189  0.          0.02055075]]\n",
      "SHAP values per classe 287: [[-0.11179434  0.          0.03941494  0.07644818]\n",
      " [ 0.          0.          0.          0.01123001]\n",
      " [ 0.         -0.00388604  0.          0.        ]\n",
      " [ 0.         -0.07082781  0.          0.029753  ]\n",
      " [ 0.001385   -0.10864282  0.          0.0538099 ]]\n",
      "SHAP values per classe 288: [[ 0.33052442 -0.04755908 -0.19942706 -0.06677558]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.00405092  0.         -0.01247583]\n",
      " [ 0.07979679 -0.12440516  0.0348539   0.        ]\n",
      " [ 0.06263799 -0.07903903  0.0514589   0.01729831]]\n",
      "SHAP values per classe 289: [[-0.12504709  0.00483881  0.09007276  0.02108664]\n",
      " [-0.0340097   0.          0.          0.03729652]\n",
      " [-0.02455784  0.         -0.00521727  0.        ]\n",
      " [ 0.00706382 -0.07220525  0.1124386  -0.04049198]\n",
      " [-0.00791965 -0.0810672   0.01827454  0.0760967 ]]\n",
      "SHAP values per classe 290: [[-0.13657396  0.07132429  0.03298191  0.        ]\n",
      " [-0.00905157  0.          0.          0.        ]\n",
      " [-0.02289342  0.01559176  0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.01350645  0.32658812 -0.28694588 -0.03075946]]\n",
      "SHAP values per classe 291: [[ 0.29482725 -0.07420734 -0.09574524 -0.1135125 ]\n",
      " [ 0.41787951 -0.08164615 -0.20210584 -0.08329909]\n",
      " [ 0.          0.         -0.00480278  0.        ]\n",
      " [ 0.         -0.05608501  0.02018901  0.        ]\n",
      " [ 0.         -0.01330965  0.          0.        ]]\n",
      "SHAP values per classe 292: [[-0.07258829  0.02394436  0.07064369  0.00729066]\n",
      " [ 0.          0.00970835  0.          0.        ]\n",
      " [-0.03987718  0.          0.         -0.02611784]\n",
      " [-0.08520377  0.67973065 -0.37353179 -0.15220506]\n",
      " [ 0.         -0.02616336  0.          0.        ]]\n",
      "SHAP values per classe 293: [[-0.10720703  0.04445969  0.03759744  0.        ]\n",
      " [-0.0069725   0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.05495069  0.0718001   0.         -0.08717121]\n",
      " [-0.00257477  0.10324641 -0.0747858   0.        ]]\n",
      "SHAP values per classe 294: [[-0.15983622 -0.02056558  0.04486744  0.12380462]\n",
      " [-0.0125534   0.          0.          0.        ]\n",
      " [-0.01651294  0.          0.          0.00643002]\n",
      " [ 0.05350881 -0.01613973  0.          0.        ]\n",
      " [ 0.         -0.06288248  0.046548    0.01038283]]\n",
      "SHAP values per classe 295: [[-0.13539858  0.05111491  0.0752537   0.        ]\n",
      " [-0.00638566  0.         -0.02775295  0.        ]\n",
      " [-0.01837423  0.          0.          0.00068237]\n",
      " [-0.06246252  0.49323271 -0.35011361 -0.07098771]\n",
      " [ 0.00568853  0.          0.03265272  0.        ]]\n",
      "SHAP values per classe 296: [[-0.06515782  0.          0.          0.        ]\n",
      " [ 0.         -0.00056879  0.          0.        ]\n",
      " [ 0.          0.          0.          0.02768855]\n",
      " [ 0.00518487 -0.05975506  0.04559368  0.        ]\n",
      " [-0.01487721 -0.03278521  0.          0.        ]]\n",
      "SHAP values per classe 297: [[-0.09728557  0.          0.04673624  0.        ]\n",
      " [-0.00425024  0.          0.          0.        ]\n",
      " [ 0.          0.0089044   0.         -0.03399007]\n",
      " [-0.07412816  0.53769671 -0.33724771 -0.10479021]\n",
      " [ 0.          0.          0.02355637  0.        ]]\n",
      "SHAP values per classe 298: [[-0.10179089  0.03989333  0.          0.        ]\n",
      " [-0.00532224  0.          0.          0.        ]\n",
      " [-0.06288168  0.04372638  0.          0.        ]\n",
      " [-0.04694373  0.38142696 -0.2905633  -0.04870404]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 299: [[-0.17159343  0.          0.16366381  0.        ]\n",
      " [ 0.          0.          0.          0.01778169]\n",
      " [-0.02824989  0.0064037   0.0030253   0.        ]\n",
      " [ 0.01062027 -0.12937994  0.08763583  0.01816162]\n",
      " [ 0.         -0.06846853  0.          0.09348614]]\n",
      "SHAP values per classe 300: [[-0.08573298  0.00486025  0.04862063  0.03321165]\n",
      " [ 0.          0.         -0.05382142  0.        ]\n",
      " [-0.01009571  0.          0.          0.        ]\n",
      " [ 0.         -0.072235    0.0347469   0.02625028]\n",
      " [-0.0225857   0.03817174  0.          0.        ]]\n",
      "SHAP values per classe 301: [[-0.11465955  0.05969063  0.04503594  0.        ]\n",
      " [-0.00530563  0.          0.00242044  0.        ]\n",
      " [-0.02261902  0.02260353  0.          0.        ]\n",
      " [-0.02371063  0.13261941 -0.09731002 -0.01555405]\n",
      " [-0.00673767  0.05653713 -0.04453589  0.        ]]\n",
      "SHAP values per classe 302: [[ 0.33459448 -0.03090843 -0.16031636 -0.08277678]\n",
      " [ 0.          0.          0.05664138  0.        ]\n",
      " [ 0.          0.00577864  0.          0.        ]\n",
      " [ 0.06780873 -0.12549515  0.05874976  0.        ]\n",
      " [ 0.06680398 -0.0684239   0.          0.        ]]\n",
      "SHAP GED: 10.764705882352942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training del detector...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib/python3.9/site-packages/albumentations/core/bbox_utils.py:476: RuntimeWarning: invalid value encountered in divide\n",
      "  & (clipped_box_areas / denormalized_box_areas >= min_visibility - epsilon)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint salvato per l'epoca 10.\n",
      "------------------\n",
      "Epoch 12/150\n",
      "Inference completata\n",
      "Load .json metadata:  ./tmp/train/B_20181212_110313.json\n",
      "Load .json metadata:  ./tmp/train/B_5bed71eae40c4.json\n",
      "Load .json metadata:  ./tmp/train/B_20181212_110321.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_mihrab_mezquita_cordoba.json\n",
      "Load .json metadata:  ./tmp/train/B_5bad4cbc18c44.json\n",
      "Load .json metadata:  ./tmp/train/R_5c1f82413637d.json\n",
      "Load .json metadata:  ./tmp/train/G_5c67d991a4cf7.json\n",
      "Load .json metadata:  ./tmp/train/B_5dd7d6e26f601.json\n",
      "Load .json metadata:  ./tmp/train/M_alcazaba_malaga3.json\n",
      "Load .json metadata:  ./tmp/train/G_casa_bailio_cordoba.json\n",
      "Load .json metadata:  ./tmp/train/G_5babc82fc022f.json\n",
      "Load .json metadata:  ./tmp/train/M_5e4fb912bf15b.json\n",
      "Load .json metadata:  ./tmp/train/R_5c75195fbb8f2.json\n",
      "Load .json metadata:  ./tmp/train/G_5bb8f33edfa1f.json\n",
      "Load .json metadata:  ./tmp/train/M_5bb0d93bcd653.json\n",
      "Load .json metadata:  ./tmp/train/B_5c15322219e6f.json\n",
      "Load .json metadata:  ./tmp/train/B_facultad_derecho_granada2.json\n",
      "Load .json metadata:  ./tmp/train/M_patio_yeso_reales_alcazares_sevilla3.json\n",
      "Load .json metadata:  ./tmp/train/B_iglesia_caridad_sevilla2.json\n",
      "Load .json metadata:  ./tmp/train/M_20181212_112649.json\n",
      "Load .json metadata:  ./tmp/train/R_ayuntamiento_baeza3.json\n",
      "Load .json metadata:  ./tmp/train/R_5bc0b3ee639ce.json\n",
      "Load .json metadata:  ./tmp/train/B_convento_siervas_de_maria_granada.json\n",
      "Load .json metadata:  ./tmp/train/B_casa_almirante_cadiz2.json\n",
      "Load .json metadata:  ./tmp/train/G_20181212_105119.json\n",
      "Load .json metadata:  ./tmp/train/G_catedral_leon12.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc76ea8caf7b.json\n",
      "Load .json metadata:  ./tmp/train/M_medina_azahara3.json\n",
      "Load .json metadata:  ./tmp/train/G_5baeaa86ac71e.json\n",
      "Load .json metadata:  ./tmp/train/B_catedral_granada4.json\n",
      "Load .json metadata:  ./tmp/train/M_5bae5bf050e24.json\n",
      "Load .json metadata:  ./tmp/train/M_5baf14eb92e6d.json\n",
      "Load .json metadata:  ./tmp/train/B_5c80ebc6ddf27.json\n",
      "Load .json metadata:  ./tmp/train/B_iglesia_gracia_granada.json\n",
      "Load .json metadata:  ./tmp/train/G_iglesia_san_nicolas_ubeda4.json\n",
      "Load .json metadata:  ./tmp/train/R_5bf7c972311d4.json\n",
      "Load .json metadata:  ./tmp/train/M_5bec1e4b72f12.json\n",
      "Load .json metadata:  ./tmp/train/B_iglesia_caridad_sevilla5.json\n",
      "Load .json metadata:  ./tmp/train/M_5bd579c5023a7.json\n",
      "Load .json metadata:  ./tmp/train/R_5bb5f3109fda8.json\n",
      "Load .json metadata:  ./tmp/train/B_santos_justo_pastor_granada8.json\n",
      "Load .json metadata:  ./tmp/train/G_casa_bailio_cordoba2.json\n",
      "Load .json metadata:  ./tmp/train/B_iglesia_san_jeronimo_granada3.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_del_vino_granada6.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_de_las_pesas_granada4.json\n",
      "Load .json metadata:  ./tmp/train/M_5bec1e6a04058.json\n",
      "Load .json metadata:  ./tmp/train/M_5de6b189c985e.json\n",
      "Load .json metadata:  ./tmp/train/B_museo_bellas_artes_sevilla6.json\n",
      "Load .json metadata:  ./tmp/train/M_5bae5eef7467f.json\n",
      "Load .json metadata:  ./tmp/train/M_20181212_115504.json\n",
      "Load .json metadata:  ./tmp/train/R_puerta_puente_cordoba15.json\n",
      "Load .json metadata:  ./tmp/train/B_5baff8c138f48.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc0ca38b7006.json\n",
      "Load .json metadata:  ./tmp/train/G_5cadb7eb3a84a.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_monaita_granada6.json\n",
      "Load .json metadata:  ./tmp/train/B_5bdb2454edef4.json\n",
      "Load .json metadata:  ./tmp/train/G_catedral_leon10.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_san_isidro_mezquita_cordoba5.json\n",
      "Load .json metadata:  ./tmp/train/B_5bebfefce3f27.json\n",
      "Load .json metadata:  ./tmp/train/G_5b8ecc4c3cde4.json\n",
      "Load .json metadata:  ./tmp/train/G_5baf18213b6f1.json\n",
      "Load .json metadata:  ./tmp/train/G_iglesia_santa_maría_del_pi_barcelona3.json\n",
      "Load .json metadata:  ./tmp/train/R_casa_cabildo_jerez6.json\n",
      "Load .json metadata:  ./tmp/train/B_5c48452e4af47.json\n",
      "Load .json metadata:  ./tmp/train/M_5d99bad3a10f2.json\n",
      "Load .json metadata:  ./tmp/train/R_puerta_puente_cordoba4.json\n",
      "Load .json metadata:  ./tmp/train/R_plaza_santa_teresa_ubeda3.json\n",
      "Load .json metadata:  ./tmp/train/B_casa_marqueses_de_cartagena_granada4.json\n",
      "Load .json metadata:  ./tmp/train/B_colegio_bartolome_santiago_granada.json\n",
      "Load .json metadata:  ./tmp/train/G_5b8d77afb94e9.json\n",
      "Load .json metadata:  ./tmp/train/R_5bd6baf8e455c.json\n",
      "Load .json metadata:  ./tmp/train/B_basilica_angustias_granada3.json\n",
      "Load .json metadata:  ./tmp/train/B_5bacbbeed360e.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_monaita_granada5.json\n",
      "Load .json metadata:  ./tmp/train/B_casa-mariana_pineda_granada.json\n",
      "Load .json metadata:  ./tmp/train/R_5bdefaf7351c6.json\n",
      "Load .json metadata:  ./tmp/train/R_palacio_cadenas_ubeda.json\n",
      "Load .json metadata:  ./tmp/train/G_hospital_san_sebastian_cordoba9.json\n",
      "Load .json metadata:  ./tmp/train/G_torre_fadrique2.json\n",
      "Load .json metadata:  ./tmp/train/G_convento_clarisas_palencia4.json\n",
      "Load .json metadata:  ./tmp/train/M_medina_azahara23.json\n",
      "Load .json metadata:  ./tmp/train/G_casa_abrantes_granada6.json\n",
      "Load .json metadata:  ./tmp/train/B_catedral_guadix2.json\n",
      "Load .json metadata:  ./tmp/train/B_5c878e7d3d3f0.json\n",
      "Load .json metadata:  ./tmp/train/G_5de139e53bea1.json\n",
      "Load .json metadata:  ./tmp/train/M_dintel_adovelado5.json\n",
      "Load .json metadata:  ./tmp/train/B_san_felipe_neri_baeza.json\n",
      "Load .json metadata:  ./tmp/train/M_5bafb615991d4.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc765746e381.json\n",
      "Load .json metadata:  ./tmp/train/B_5c14f6b287d17.json\n",
      "Load .json metadata:  ./tmp/train/G_5c62923184bbc.json\n",
      "Load .json metadata:  ./tmp/train/B_casa_cadenas_cadiz3.json\n",
      "Load .json metadata:  ./tmp/train/G_casa_zafra_granada.json\n",
      "Load .json metadata:  ./tmp/train/B_iglesia_caridad_sevilla6.json\n",
      "Load .json metadata:  ./tmp/train/B_5bb0aaee9afc9.json\n",
      "Load .json metadata:  ./tmp/train/B_5dd8f69aee967.json\n",
      "Load .json metadata:  ./tmp/train/M_5c38860a8e338.json\n",
      "Load .json metadata:  ./tmp/train/R_5bb35143c8292.json\n",
      "Load .json metadata:  ./tmp/train/R_20181212_110343.json\n",
      "Load .json metadata:  ./tmp/train/M_5bbe3f16a2771.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc7645ea64dc.json\n",
      "Load .json metadata:  ./tmp/train/G_puerta_apostoles_catedra_valencia3.json\n",
      "Load .json metadata:  ./tmp/train/M_20181212_115516.json\n",
      "Load .json metadata:  ./tmp/train/B_casa_museo_sefardi_granada2.json\n",
      "Load .json metadata:  ./tmp/train/M_5defb57b27d8b.json\n",
      "Load .json metadata:  ./tmp/train/R_5c07fc9b36ec9.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_monaita_granada2.json\n",
      "Load .json metadata:  ./tmp/train/B_palacio_quemadas_cordoba2.json\n",
      "Load .json metadata:  ./tmp/train/R_iglesia_guadahortuna3.json\n",
      "Load .json metadata:  ./tmp/train/M_5e4fb8674b6b0.json\n",
      "Load .json metadata:  ./tmp/train/M_corral_carbon_granada4.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_del_vino_granada12.json\n",
      "Load .json metadata:  ./tmp/train/R_casa_lonja_sevilla_patio.json\n",
      "Load .json metadata:  ./tmp/train/G_puerta_apostoles_catedra_valencia5.json\n",
      "Load .json metadata:  ./tmp/train/G_iglesia_san_nicolas_ubeda2.json\n",
      "Load .json metadata:  ./tmp/train/B_5ce90d44c81b5.json\n",
      "Load .json metadata:  ./tmp/train/M_medina_azahara16.json\n",
      "Load .json metadata:  ./tmp/train/M_5db2c2a620a94.json\n",
      "Load .json metadata:  ./tmp/train/R_san_pedro_cordoba6.json\n",
      "Load .json metadata:  ./tmp/train/R_5bc601592c5ae.json\n",
      "Load .json metadata:  ./tmp/train/B_iglesia_san_juan_de_dios_granada.json\n",
      "Load .json metadata:  ./tmp/train/B_5c4c5d588f969.json\n",
      "Load .json metadata:  ./tmp/train/G_catedral_burgos11.json\n",
      "Load .json metadata:  ./tmp/train/R_5bae51ba6d784.json\n",
      "Load .json metadata:  ./tmp/train/M_5bd35122f11d2.json\n",
      "Load .json metadata:  ./tmp/train/B_5d9e1bfaeb1b0.json\n",
      "Load .json metadata:  ./tmp/train/M_5db2e7f92118d.json\n",
      "Load .json metadata:  ./tmp/train/G_puerta_apostoles_catedra_valencia7.json\n",
      "Load .json metadata:  ./tmp/train/R_5bc2c464cce14.json\n",
      "Load .json metadata:  ./tmp/train/R_iglesia_salvador_ubeda3.json\n",
      "Load .json metadata:  ./tmp/train/M_5bdec6139317d.json\n",
      "Load .json metadata:  ./tmp/train/B_5bbb3a49e5e1d.json\n",
      "Load .json metadata:  ./tmp/train/B_5d98e54e59775.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_elvira_granada3.json\n",
      "Load .json metadata:  ./tmp/train/G_puerta_apostoles_catedral_valencia.json\n",
      "Load .json metadata:  ./tmp/train/B_5c7be6a013c47.json\n",
      "Load .json metadata:  ./tmp/train/M_5bba4d3b86c50.json\n",
      "Load .json metadata:  ./tmp/train/R_5bc4cf3b20c2e.json\n",
      "Load .json metadata:  ./tmp/train/G_iglesia_san_pablo_ubeda5.json\n",
      "Load .json metadata:  ./tmp/train/B_convento_esclavas_puerto_santa_maria.json\n",
      "Load .json metadata:  ./tmp/train/B_5da39ec706056.json\n",
      "Load .json metadata:  ./tmp/train/M_medina_azahara5.json\n",
      "Load .json metadata:  ./tmp/train/G_catedral_burgos9.json\n",
      "Load .json metadata:  ./tmp/train/G_iglesia_san_pablo_ubeda8.json\n",
      "Load .json metadata:  ./tmp/train/R_carcel_martos5.json\n",
      "Load .json metadata:  ./tmp/train/M_5e4fb7d4eb466.json\n",
      "Load .json metadata:  ./tmp/train/G_5cb4506788a6c.json\n",
      "Load .json metadata:  ./tmp/train/G_casa_inquisicion_alhama.json\n",
      "Load .json metadata:  ./tmp/train/B_chancilleria_granada5.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc4cdf0585e4.json\n",
      "Load .json metadata:  ./tmp/train/M_20181212_145543.json\n",
      "Load .json metadata:  ./tmp/train/G_alcazaba-almeria.json\n",
      "Load .json metadata:  ./tmp/train/R_casa_cabildo_jerez5.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc76500a43e5.json\n",
      "Load .json metadata:  ./tmp/train/R_5bcaed60a57a5.json\n",
      "Load .json metadata:  ./tmp/train/M_dintel_adovelado4.json\n",
      "Load .json metadata:  ./tmp/train/B_5bae520c3096f.json\n",
      "Load .json metadata:  ./tmp/train/M_patio_yeso_reales_alcazares_sevilla4.json\n",
      "Load .json metadata:  ./tmp/train/G_monasterio_concepcion_granada4.json\n",
      "Load .json metadata:  ./tmp/train/G_catedral_leon8.json\n",
      "Load .json metadata:  ./tmp/train/R_5bae6379a7219.json\n",
      "Load .json metadata:  ./tmp/train/B_5d90ba3786f84.json\n",
      "Load .json metadata:  ./tmp/train/B_5bacbc2c46129.json\n",
      "Load .json metadata:  ./tmp/train/G_5d853bf14c54f.json\n",
      "Load .json metadata:  ./tmp/train/M_aljibe_san_miguel_bajo.json\n",
      "Load .json metadata:  ./tmp/train/M_5bb0a6a0a9219.json\n",
      "Load .json metadata:  ./tmp/train/M_alcazaba_malaga2.json\n",
      "Load .json metadata:  ./tmp/train/R_5da5cd3e7a1ca.json\n",
      "Load .json metadata:  ./tmp/train/B_5baff87c5d061.json\n",
      "Load .json metadata:  ./tmp/train/B_5bd34562c7157.json\n",
      "Load .json metadata:  ./tmp/train/G_palacio_jabalquinto_baeza13.json\n",
      "Load .json metadata:  ./tmp/train/G_5bac8c5becc42.json\n",
      "Load .json metadata:  ./tmp/train/B_5c191ae226d3d.json\n",
      "Load .json metadata:  ./tmp/train/B_palacio_quemadas_cordoba3.json\n",
      "Load .json metadata:  ./tmp/train/G_5cf2f7b8bb83b.json\n",
      "Load .json metadata:  ./tmp/train/M_5e4fd06f4005c.json\n",
      "Load .json metadata:  ./tmp/train/G_hospital_san_sebastian_cordoba4.json\n",
      "Load .json metadata:  ./tmp/train/M_medina_azahara22.json\n",
      "Load .json metadata:  ./tmp/train/R_puerta_puente_cordoba16.json\n",
      "Load .json metadata:  ./tmp/train/R_5bb897329f5cd.json\n",
      "Load .json metadata:  ./tmp/train/R_5bb90da49c913.json\n",
      "Load .json metadata:  ./tmp/train/B_5c13837ca48df.json\n",
      "Load .json metadata:  ./tmp/train/G_catedral_sevilla6.json\n",
      "Load .json metadata:  ./tmp/train/M_5bf678c169e06.json\n",
      "Load .json metadata:  ./tmp/train/B_5cadbcbc0e666.json\n",
      "Load .json metadata:  ./tmp/train/M_5bcaecccd162f.json\n",
      "Load .json metadata:  ./tmp/train/G_catedral_leon2.json\n",
      "Load .json metadata:  ./tmp/train/B_5df7681a6a1d3.json\n",
      "Load .json metadata:  ./tmp/train/M_alminar_san_jose_granada6.json\n",
      "Load .json metadata:  ./tmp/train/M_20181212_115543.json\n",
      "Load .json metadata:  ./tmp/train/B_santos_justo_pastor_granada3.json\n",
      "Load .json metadata:  ./tmp/train/R_5c1914b7dafda.json\n",
      "Load .json metadata:  ./tmp/train/M_5dd41d557867b.json\n",
      "Load .json metadata:  ./tmp/train/M_5c879cd0ed2cc.json\n",
      "Load .json metadata:  ./tmp/train/R_puerta_puente_cordoba10.json\n",
      "Load .json metadata:  ./tmp/train/G_puerta_bautismo_catedral_sevilla9.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_justicia_granada2.json\n",
      "Load .json metadata:  ./tmp/train/M_5bdedf6d54d29.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_justicia_granada.json\n",
      "Load .json metadata:  ./tmp/train/R_carcel_martos3.json\n",
      "Load .json metadata:  ./tmp/train/R_5c1903a4925ea.json\n",
      "Load .json metadata:  ./tmp/train/B_colegio_san_telmo_sevilla6.json\n",
      "Load .json metadata:  ./tmp/train/G_5d3da546e111e.json\n",
      "Load .json metadata:  ./tmp/train/G_casa_zafra_granada5.json\n",
      "Load .json metadata:  ./tmp/train/G_catedral_toledo2.json\n",
      "Load .json metadata:  ./tmp/train/R_5df9f2036b740.json\n",
      "Load .json metadata:  ./tmp/train/G_5de134de77277.json\n",
      "Load .json metadata:  ./tmp/train/B_convento_magdalena_granada.json\n",
      "Load .json metadata:  ./tmp/train/G_5cc07126bd06d.json\n",
      "Load .json metadata:  ./tmp/train/R_5bb350a2e289a.json\n",
      "Load .json metadata:  ./tmp/train/B_5c4065a551b5d.json\n",
      "Load .json metadata:  ./tmp/train/B_5bd07567077f8.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_elvira_granada2.json\n",
      "Load .json metadata:  ./tmp/train/R_casa_torres_ubeda3.json\n",
      "Load .json metadata:  ./tmp/train/G_catedral_burgos.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc0c8c89fd21.json\n",
      "Load .json metadata:  ./tmp/train/G_casa_abrantes_granada4.json\n",
      "Load .json metadata:  ./tmp/train/M_5db2c2d58820d.json\n",
      "Load .json metadata:  ./tmp/train/B_5ce8393752ba0.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc7645dbbec1.json\n",
      "Load .json metadata:  ./tmp/train/R_iglesia_san_andres.json\n",
      "Load .json metadata:  ./tmp/train/B_chancilleria_granada14.json\n",
      "Load .json metadata:  ./tmp/train/G_palacio_jabalquinto_baeza11.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_monaita_granada.json\n",
      "Load .json metadata:  ./tmp/train/G_5bc1d52645376.json\n",
      "Load .json metadata:  ./tmp/train/R_5c9d17dc28b0e.json\n",
      "Load .json metadata:  ./tmp/train/M_alminar_san_jose_granada4.json\n",
      "Load .json metadata:  ./tmp/train/M_corral_carbon_granada2.json\n",
      "Load .json metadata:  ./tmp/train/G_puerta_apostoles_catedra_valencia2.json\n",
      "Load .json metadata:  ./tmp/train/R_puerta_puente_cordoba5.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc765017d63d.json\n",
      "Load .json metadata:  ./tmp/train/G_casa_abrantes_granada7.json\n",
      "Load .json metadata:  ./tmp/train/R_5bf67925573b1.json\n",
      "Load .json metadata:  ./tmp/train/B_casa_almirante_cadiz5.json\n",
      "Load .json metadata:  ./tmp/train/B_palacio_quemadas_cordoba.json\n",
      "Load .json metadata:  ./tmp/train/G_palacio_jabalquinto_baeza2.json\n",
      "Load .json metadata:  ./tmp/train/B_5bb0b452a19f9.json\n",
      "Load .json metadata:  ./tmp/train/G_catedral_leon6.json\n",
      "Load .json metadata:  ./tmp/train/R_ayuntamiento_baeza13.json\n",
      "Load .json metadata:  ./tmp/train/B_palacio_ansoti_granada9.json\n",
      "Load .json metadata:  ./tmp/train/B_5b8a5bebf2b05.json\n",
      "Load .json metadata:  ./tmp/train/M_20181212_145535.json\n",
      "Load .json metadata:  ./tmp/train/R_palacio_cadenas_ubeda6.json\n",
      "Load .json metadata:  ./tmp/train/G_5d9f62eb395ce.json\n",
      "Load .json metadata:  ./tmp/train/M_5c879cb97a78b.json\n",
      "Load .json metadata:  ./tmp/train/G_hospital_san_sebastian_cordoba3.json\n",
      "Load .json metadata:  ./tmp/train/G_torre_fadrique.json\n",
      "Load .json metadata:  ./tmp/train/G_5cc07109e57de.json\n",
      "Load .json metadata:  ./tmp/train/G_5c4838d6e0fd8.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc8b5000bde2.json\n",
      "Load .json metadata:  ./tmp/train/B_iglesia_angustias_granada2.json\n",
      "Load .json metadata:  ./tmp/train/M_medina_azahara32.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc765338c390.json\n",
      "Load .json metadata:  ./tmp/train/M_5cad9cd45d2e9.json\n",
      "Load .json metadata:  ./tmp/train/G_5bb28d496a53a.json\n",
      "Load .json metadata:  ./tmp/train/M_medina_azahara28.json\n",
      "Load .json metadata:  ./tmp/train/B_5baf982ee2bfd.json\n",
      "Load .json metadata:  ./tmp/train/M_5d31db347e7fe.json\n",
      "Load .json metadata:  ./tmp/train/B_5e3ec0560f9a0.json\n",
      "Load .json metadata:  ./tmp/train/G_5c13847fdc587.json\n",
      "Load .json metadata:  ./tmp/train/B_casa_almirante_cadiz3.json\n",
      "Load .json metadata:  ./tmp/train/G_iglesia_san_pablo_ubeda7.json\n",
      "Load .json metadata:  ./tmp/train/R_5bb78e09c8a9a.json\n",
      "Load .json metadata:  ./tmp/train/B_IMG_0357.json\n",
      "Load .json metadata:  ./tmp/train/R_5c7134cd2811e.json\n",
      "Load .json metadata:  ./tmp/train/M_5d9dcd1b591de.json\n",
      "Load .json metadata:  ./tmp/train/B_catedral_jaen3.json\n",
      "Load .json metadata:  ./tmp/train/R_iglesia_san_cecilio_granada5.json\n",
      "Load .json metadata:  ./tmp/train/R_palacio_carlos_v_granada18.json\n",
      "Load .json metadata:  ./tmp/train/B_compas_convento_santa_isabel_granada3.json\n",
      "Load .json metadata:  ./tmp/train/G_casa_abrantes_granada3.json\n",
      "Load .json metadata:  ./tmp/train/B_casa_museo_sefardi_granada.json\n",
      "Load .json metadata:  ./tmp/train/B_5df11afa505fc.json\n",
      "Load .json metadata:  ./tmp/train/G_iglesia_sabiote.json\n",
      "Load .json metadata:  ./tmp/train/M_5dd41b35bc692.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc75ff931f5d.json\n",
      "Load .json metadata:  ./tmp/train/B_iglesia_san_pedro_pablo_granada3.json\n",
      "Load .json metadata:  ./tmp/train/M_5bbcca54787e1.json\n",
      "Load .json metadata:  ./tmp/train/M_5bec3b41cead0.json\n",
      "Load .json metadata:  ./tmp/train/B_convento_carmelitas_descalzas_granada4.json\n",
      "Load .json metadata:  ./tmp/train/R_iglesia_asuncion_jodar.json\n",
      "Load .json metadata:  ./tmp/train/G_monasterio_concepcion_granada3.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc75fefdc08e.json\n",
      "Load .json metadata:  ./tmp/train/B_5baf578813fe8.json\n",
      "Load .json metadata:  ./tmp/train/B_5be5b11d168b4.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc75e0d6a8e0.json\n",
      "Load .json metadata:  ./tmp/train/G_iglesia_sabiote5.json\n",
      "Load .json metadata:  ./tmp/train/B_5bacb65418a73.json\n",
      "Load .json metadata:  ./tmp/train/B_casa_marqueses_caicedo_granada.json\n",
      "Load .json metadata:  ./tmp/train/R_iglesia_anunciacion_sevilla.json\n",
      "Load .json metadata:  ./tmp/train/B_5bb0a2afa286c.json\n",
      "Load .json metadata:  ./tmp/train/M_20181212_113410.json\n",
      "Load .json metadata:  ./tmp/train/G_catedral_burgos10.json\n",
      "Load .json metadata:  ./tmp/train/G_catedral_leon3.json\n",
      "Load .json metadata:  ./tmp/train/M_5bec3b6fce57a.json\n",
      "Load .json metadata:  ./tmp/train/R_iglesia_guadahortuna2.json\n",
      "Load .json metadata:  ./tmp/train/M_5d99bc04097a3.json\n",
      "Load .json metadata:  ./tmp/train/B_catedral_granada6.json\n",
      "Load .json metadata:  ./tmp/train/G_5bdf14be71c61.json\n",
      "Load .json metadata:  ./tmp/train/B_IMG_0330.json\n",
      "Load .json metadata:  ./tmp/train/M_5baf1bc3da161.json\n",
      "Load .json metadata:  ./tmp/train/R_iglesia_del_sagrario_jaen2.json\n",
      "Load .json metadata:  ./tmp/train/M_alminar_san_jose_granada3.json\n",
      "Load .json metadata:  ./tmp/train/G_iglesia_san_pablo_ubeda4.json\n",
      "Load .json metadata:  ./tmp/train/M_5c7bc23b3c8df.json\n",
      "Load .json metadata:  ./tmp/train/R_5bf817556125f.json\n",
      "Load .json metadata:  ./tmp/train/R_palacio_carlos_v_granada2.json\n",
      "Load .json metadata:  ./tmp/train/B_5ddba404ec262.json\n",
      "Load .json metadata:  ./tmp/train/B_5bd33eb67044c.json\n",
      "Load .json metadata:  ./tmp/train/B_5bb5f3dfac1c3.json\n",
      "Load .json metadata:  ./tmp/train/G_casa_zafra_granada3.json\n",
      "Load .json metadata:  ./tmp/train/M_medina_azahara34.json\n",
      "Load .json metadata:  ./tmp/train/G_capilla_real_granada3.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_de_las_pesas_granada5.json\n",
      "Load .json metadata:  ./tmp/train/G_5bcaece80705a.json\n",
      "Load .json metadata:  ./tmp/train/R_iglesia_san_jeronimo_granada.json\n",
      "Load .json metadata:  ./tmp/train/B_5bad4af6cbe6a.json\n",
      "Load .json metadata:  ./tmp/train/G_5da5cf2a09f80.json\n",
      "Load .json metadata:  ./tmp/train/R_5bf817543af18.json\n",
      "Load .json metadata:  ./tmp/train/B_palacio_ansoti2.json\n",
      "Load .json metadata:  ./tmp/train/B_casa_marqueses_caicedo_granada2.json\n",
      "Load .json metadata:  ./tmp/train/R_5bd575da84afe.json\n",
      "Load .json metadata:  ./tmp/train/R_iglesia_del_sagrario_jaen.json\n",
      "Load .json metadata:  ./tmp/train/B_convento_carmelitas_descalzas_granada6.json\n",
      "Load .json metadata:  ./tmp/train/G_5da6fe91a1b08.json\n",
      "Load .json metadata:  ./tmp/train/M_5c82f4cdc538e.json\n",
      "Load .json metadata:  ./tmp/train/R_puerta_puente_cordoba13.json\n",
      "Load .json metadata:  ./tmp/train/M_5bdee1652730b.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc7649e7f853.json\n",
      "Load .json metadata:  ./tmp/train/M_5db444d933327.json\n",
      "Load .json metadata:  ./tmp/train/G_catedral_burgos8.json\n",
      "Load .json metadata:  ./tmp/train/M_medina_azahara8.json\n",
      "Load .json metadata:  ./tmp/train/B_san_felipe_neri_baeza2.json\n",
      "Load .json metadata:  ./tmp/train/M_5c45b1d2472c7.json\n",
      "Load .json metadata:  ./tmp/train/M_5b8eceba8b412.json\n",
      "Load .json metadata:  ./tmp/train/G_5db2fc59d9b68.json\n",
      "Load .json metadata:  ./tmp/train/R_5bded6103ee40.json\n",
      "Load .json metadata:  ./tmp/train/B_5bb71c65a6474.json\n",
      "Load .json metadata:  ./tmp/train/B_5cb9a29a5424f.json\n",
      "Load .json metadata:  ./tmp/train/R_5bc9b16bd7277.json\n",
      "Load .json metadata:  ./tmp/train/R_palacio_cadenas_ubeda16.json\n",
      "Load .json metadata:  ./tmp/train/M_medina_azahara6.json\n",
      "Load .json metadata:  ./tmp/train/B_iglesia_caridad_sevilla9.json\n",
      "Load .json metadata:  ./tmp/train/G_5ced8dfa04cf1.json\n",
      "Load .json metadata:  ./tmp/train/R_5bcdbfa0a31fb.json\n",
      "Load .json metadata:  ./tmp/train/R_san_grabiel_loja2.json\n",
      "Load .json metadata:  ./tmp/train/B_iglesia_caridad_sevilla8.json\n",
      "Load .json metadata:  ./tmp/train/B_iglesia_san_francisco_cordoba.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc764f8d06ab.json\n",
      "Load .json metadata:  ./tmp/train/R_colegio_niñas_nobles_granada3.json\n",
      "Load .json metadata:  ./tmp/train/B_5bd354095e856.json\n",
      "Load .json metadata:  ./tmp/train/B_5bdb228d13793.json\n",
      "Load .json metadata:  ./tmp/train/G_5dd41b5a94b5e.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc75e652da1b.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc4d231daaf1.json\n",
      "Load .json metadata:  ./tmp/train/B_5c14f51720f9a.json\n",
      "Load .json metadata:  ./tmp/train/G_5c010d67518b6.json\n",
      "Load .json metadata:  ./tmp/train/M_5bd753b475e1b.json\n",
      "Load .json metadata:  ./tmp/train/G_5bc8af93c364c.json\n",
      "Load .json metadata:  ./tmp/train/B_iglesia_señora_gracia_estepa.json\n",
      "Load .json metadata:  ./tmp/train/G_monasterio_concepcion_granada.json\n",
      "Load .json metadata:  ./tmp/train/B_5c2ba60f43651.json\n",
      "Load .json metadata:  ./tmp/train/B_5bb0b4dfa6fc4.json\n",
      "Load .json metadata:  ./tmp/train/M_5bd3504ad94ce.json\n",
      "Load .json metadata:  ./tmp/train/B_5bccafb89cf2f.json\n",
      "Load .json metadata:  ./tmp/train/M_aljibe_san_miguel_bajo4.json\n",
      "Load .json metadata:  ./tmp/train/G_catedral_leon9.json\n",
      "Load .json metadata:  ./tmp/train/R_convento_santa_clara_ubeda2.json\n",
      "Load .json metadata:  ./tmp/train/G_5b8ecc074657b.json\n",
      "Load .json metadata:  ./tmp/train/R_iglesia_del_sagrario_jaen5.json\n",
      "Load .json metadata:  ./tmp/train/B_5bec3a03c184c.json\n",
      "Load .json metadata:  ./tmp/train/G_5c82f51ed64ae.json\n",
      "Load .json metadata:  ./tmp/train/M_20181212_122859.json\n",
      "Load .json metadata:  ./tmp/train/G_torre_fadrique4.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc764753c2e3.json\n",
      "Load .json metadata:  ./tmp/train/G_5bad4abe0539c.json\n",
      "Load .json metadata:  ./tmp/train/G_puerta_bautismo_catedral_sevilla3.json\n",
      "Load .json metadata:  ./tmp/train/B_5e53b78a07e5e.json\n",
      "Load .json metadata:  ./tmp/train/M_5bacb800b40e1.json\n",
      "Load .json metadata:  ./tmp/train/R_ayuntamiento_baeza5.json\n",
      "Load .json metadata:  ./tmp/train/R_5bd19e2979917.json\n",
      "Load .json metadata:  ./tmp/train/M_5c9d17c407acd.json\n",
      "Load .json metadata:  ./tmp/train/R_ayuntamiento_baeza8.json\n",
      "Load .json metadata:  ./tmp/train/M_5e4fbfcdcf33a.json\n",
      "Load .json metadata:  ./tmp/train/B_chancilleria_granada13.json\n",
      "Load .json metadata:  ./tmp/train/G_iglesia_san_miguel_cordoba2.json\n",
      "Load .json metadata:  ./tmp/train/R_5bb8b808d52c6.json\n",
      "Load .json metadata:  ./tmp/train/R_5bb28db47335d.json\n",
      "Load .json metadata:  ./tmp/train/B_fabrica_tabaco_sevilla8.json\n",
      "Load .json metadata:  ./tmp/train/G_catedral_burgos3.json\n",
      "Load .json metadata:  ./tmp/train/B_5bcdf5e2a5c10.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc306e82d209.json\n",
      "Load .json metadata:  ./tmp/train/G_puerta_bautismo_catedral_sevilla11.json\n",
      "Load .json metadata:  ./tmp/train/G_puerta_bautismo_catedral_sevilla12.json\n",
      "Load .json metadata:  ./tmp/train/B_5cf8001418164.json\n",
      "Load .json metadata:  ./tmp/train/G_5bdf0bf35d6ef.json\n",
      "Load .json metadata:  ./tmp/train/M_20181212_113415.json\n",
      "Load .json metadata:  ./tmp/train/M_5c7026209438f.json\n",
      "Load .json metadata:  ./tmp/train/B_santos_justo_pastor_granada7.json\n",
      "Load .json metadata:  ./tmp/train/M_patio_doncella_reales_alcazares_sevilla13.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc9a5fe2bed8.json\n",
      "Load .json metadata:  ./tmp/train/R_palacio_carlos_v_granada14.json\n",
      "Load .json metadata:  ./tmp/train/M_5bae64dc35949.json\n",
      "Load .json metadata:  ./tmp/train/M_corral_carbon_granada11.json\n",
      "Load .json metadata:  ./tmp/train/B_casa_marqueses_de_cartagena_granada3.json\n",
      "Load .json metadata:  ./tmp/train/B_IMG_0339.json\n",
      "Load .json metadata:  ./tmp/train/B_5b8ecb55cc725.json\n",
      "Load .json metadata:  ./tmp/train/R_5c024c2323973.json\n",
      "Load .json metadata:  ./tmp/train/B_5bf6cf1b04611.json\n",
      "Load .json metadata:  ./tmp/train/B_5c8cdc1b5564c.json\n",
      "Load .json metadata:  ./tmp/train/G_5b8eccf9cacde.json\n",
      "Load .json metadata:  ./tmp/train/B_carmelitas_calzadas_granada.json\n",
      "Load .json metadata:  ./tmp/train/G_5d98cc88e4a26.json\n",
      "Load .json metadata:  ./tmp/train/G_5ccefd1dbdf9e.json\n",
      "Load .json metadata:  ./tmp/train/R_20181212_110248.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc75e8d06c33.json\n",
      "Load .json metadata:  ./tmp/train/B_5be6b71806804.json\n",
      "Load .json metadata:  ./tmp/train/G_hospital_san_sebastian_cordoba7.json\n",
      "Load .json metadata:  ./tmp/train/R_ayuntamiento_sevilla3.json\n",
      "Load .json metadata:  ./tmp/train/B_iglesia_san_pedro_pablo_granada2.json\n",
      "Load .json metadata:  ./tmp/train/B_iglesia_angustias_granada3.json\n",
      "Load .json metadata:  ./tmp/train/R_5bd3450596f60.json\n",
      "Load .json metadata:  ./tmp/train/B_5bae52157ff90.json\n",
      "Load .json metadata:  ./tmp/train/B_5bb4ea3b75f38.json\n",
      "Load .json metadata:  ./tmp/train/R_5c09688c5bd6d.json\n",
      "Load .json metadata:  ./tmp/train/M_5c0bb6ad8a829.json\n",
      "Load .json metadata:  ./tmp/train/R_iglesia_santa_ana_granada.json\n",
      "Load .json metadata:  ./tmp/train/G_5ddab25a85cf9.json\n",
      "Load .json metadata:  ./tmp/train/R_puerta_compas_cartuja_granada.json\n",
      "Load .json metadata:  ./tmp/train/M_medina_azahara27.json\n",
      "Load .json metadata:  ./tmp/train/R_palacio_carlos_v_granada4.json\n",
      "Load .json metadata:  ./tmp/train/M_dintel_adovelado7.json\n",
      "Load .json metadata:  ./tmp/train/R_5de6b1e7a7256.json\n",
      "Load .json metadata:  ./tmp/train/B_5c0a71a53b060.json\n",
      "Load .json metadata:  ./tmp/train/B_catedral_granada7.json\n",
      "Load .json metadata:  ./tmp/train/B_5bddc20b3a228.json\n",
      "Load .json metadata:  ./tmp/train/B_convento_carmelitas_descalzas_granada3.json\n",
      "Load .json metadata:  ./tmp/train/R_5bdd586f9ce77.json\n",
      "Load .json metadata:  ./tmp/train/B_convento_carmelitas_descalzas_granada.json\n",
      "Load .json metadata:  ./tmp/train/R_puerta_perdon_catedral_granada6.json\n",
      "Load .json metadata:  ./tmp/train/B_5bec3a053928b.json\n",
      "Load .json metadata:  ./tmp/train/R_curia_granada.json\n",
      "Load .json metadata:  ./tmp/train/G_5bb2417649091.json\n",
      "Load .json metadata:  ./tmp/train/B_5cadbc893b98b.json\n",
      "Load .json metadata:  ./tmp/train/B_casa_cadenas_cadiz4.json\n",
      "Load .json metadata:  ./tmp/train/B_5da8720703692.json\n",
      "Load .json metadata:  ./tmp/train/M_5bd34f039bd23.json\n",
      "Load .json metadata:  ./tmp/train/B_palacio_mendoza_granada.json\n",
      "Load .json metadata:  ./tmp/train/G_5dd2b36c2d262.json\n",
      "Load .json metadata:  ./tmp/train/G_cathedral.json\n",
      "Load .json metadata:  ./tmp/train/G_puerta_infierno_catedral_toledo3.json\n",
      "Load .json metadata:  ./tmp/train/M_5bec3b4e60282.json\n",
      "Load .json metadata:  ./tmp/train/G_5bc06c2a9953c.json\n",
      "Load .json metadata:  ./tmp/train/R_catedral_santa_maria_sevilla.json\n",
      "Load .json metadata:  ./tmp/train/M_medina_azahara.json\n",
      "Load .json metadata:  ./tmp/train/G_basilica_santa_maria_arcos_frontera4.json\n",
      "Load .json metadata:  ./tmp/train/B_hospital_real_granada.json\n",
      "Load .json metadata:  ./tmp/train/G_hospital_san_sebastian_cordoba10.json\n",
      "Load .json metadata:  ./tmp/train/B_5cb31f11d9127.json\n",
      "Load .json metadata:  ./tmp/train/B_iglesia_san_francisco_cordoba2.json\n",
      "Load .json metadata:  ./tmp/train/G_5c0d0f01f22fb.json\n",
      "Load .json metadata:  ./tmp/train/B_5ddd37fa3005f.json\n",
      "Load .json metadata:  ./tmp/train/M_corral_carbon_granada10.json\n",
      "Load .json metadata:  ./tmp/train/B_5c2c923e98eb3.json\n",
      "Load .json metadata:  ./tmp/train/G_convento_clarisas_palencia.json\n",
      "Load .json metadata:  ./tmp/train/B_facultad_derecho_granada6.json\n",
      "Load .json metadata:  ./tmp/train/M_5bd34e85bb4d0.json\n",
      "Load .json metadata:  ./tmp/train/B_5d90d036cd46d.json\n",
      "Load .json metadata:  ./tmp/train/B_5cadb8073058a.json\n",
      "Load .json metadata:  ./tmp/train/R_5c0a52d721023.json\n",
      "Load .json metadata:  ./tmp/train/G_catedral_sevilla2.json\n",
      "Load .json metadata:  ./tmp/train/R_puerta_puente_cordoba.json\n",
      "Load .json metadata:  ./tmp/train/B_colegio_san_telmo_sevilla4.json\n",
      "Load .json metadata:  ./tmp/train/M_alhambra2.json\n",
      "Load .json metadata:  ./tmp/train/B_hospital_san_juan_de_dios_granada3.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc76e871b47e.json\n",
      "Load .json metadata:  ./tmp/train/B_colegio_san_telmo_sevilla5.json\n",
      "Load .json metadata:  ./tmp/train/G_5cd4510ecd2a1.json\n",
      "Load .json metadata:  ./tmp/train/G_5d98cbcf8b124.json\n",
      "Load .json metadata:  ./tmp/train/G_5d07bb5a78cf0.json\n",
      "Load .json metadata:  ./tmp/train/B_5b8ecac4ebfae.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc4cdce3fab8.json\n",
      "Load .json metadata:  ./tmp/train/G_5bc743ec098e2.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_atarazanas_malaga8.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_atarazanas_malaga4.json\n",
      "Load .json metadata:  ./tmp/train/B_5bacb69c505b0.json\n",
      "Load .json metadata:  ./tmp/train/M_5e4fb9bc9e1ae.json\n",
      "Load .json metadata:  ./tmp/train/G_iglesia_sabiote6.json\n",
      "Load .json metadata:  ./tmp/train/G_5bc76dba8ef2f.json\n",
      "Load .json metadata:  ./tmp/train/R_iglesia_salvador_ubeda4.json\n",
      "Load .json metadata:  ./tmp/train/B_5cf7f31d58a0d.json\n",
      "Load .json metadata:  ./tmp/train/M_medina_azahara19.json\n",
      "Load .json metadata:  ./tmp/train/G_5cb6fbc6f2a4a.json\n",
      "Load .json metadata:  ./tmp/train/G_5bec3a78bce6d.json\n",
      "Load .json metadata:  ./tmp/train/G_5c62926eae2a5.json\n",
      "Load .json metadata:  ./tmp/train/B_5cada1e3cfdea.json\n",
      "Load .json metadata:  ./tmp/train/G_iglesia_nuestra_señora_de_la_o_chipiona2.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc765452f841.json\n",
      "Load .json metadata:  ./tmp/train/R_5bd5a68809887.json\n",
      "Load .json metadata:  ./tmp/train/G_5bec50ea6cb7f.json\n",
      "Load .json metadata:  ./tmp/train/M_medina_azahara18.json\n",
      "Load .json metadata:  ./tmp/train/M_5c879cb402953.json\n",
      "Load .json metadata:  ./tmp/train/G_5d62cfd4039d2.json\n",
      "Load .json metadata:  ./tmp/train/M_medina_azahara20.json\n",
      "Load .json metadata:  ./tmp/train/B_5d6648730c69e.json\n",
      "Load .json metadata:  ./tmp/train/G_20181212_105125.json\n",
      "Load .json metadata:  ./tmp/train/R_iglesia_del_sagrario_jaen3.json\n",
      "Load .json metadata:  ./tmp/train/R_iglesia_salvador_ubeda2.json\n",
      "Load .json metadata:  ./tmp/train/B_20181212_105924.json\n",
      "Load .json metadata:  ./tmp/train/B_santos_justo_pastor_granada6.json\n",
      "Load .json metadata:  ./tmp/train/B_5bb5f605c1f88.json\n",
      "Load .json metadata:  ./tmp/train/M_ermita_sansebastian.json\n",
      "Load .json metadata:  ./tmp/train/M_5be5e804a3167.json\n",
      "Load .json metadata:  ./tmp/train/G_5c877f6795355.json\n",
      "Load .json metadata:  ./tmp/train/G_5cadb87f04f94.json\n",
      "Load .json metadata:  ./tmp/train/G_puerta_bautismo_catedral_sevilla10.json\n",
      "Load .json metadata:  ./tmp/train/B_san_juan_cordoba.json\n",
      "Load .json metadata:  ./tmp/train/B_5d9dcbaf77eae.json\n",
      "Load .json metadata:  ./tmp/train/B_catedral_granada.json\n",
      "Load .json metadata:  ./tmp/train/B_5da5d013f0299.json\n",
      "Load .json metadata:  ./tmp/train/M_5db2e772b2a7e.json\n",
      "Load .json metadata:  ./tmp/train/M_5ced1021171f9.json\n",
      "Load .json metadata:  ./tmp/train/R_santa_maria_antequera4.json\n",
      "Load .json metadata:  ./tmp/train/G_iglesia_san_nicolas_ubeda5.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_elvira_granada4.json\n",
      "Load .json metadata:  ./tmp/train/G_5bdf0bbee1eb6.json\n",
      "Load .json metadata:  ./tmp/train/B_convento_merced_granada.json\n",
      "Load .json metadata:  ./tmp/train/R_5c191267b06b1.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_san_isidro_mezquita_cordoba7.json\n",
      "Load .json metadata:  ./tmp/train/B_20181212_105011.json\n",
      "Load .json metadata:  ./tmp/train/M_20181212_115640.json\n",
      "Load .json metadata:  ./tmp/train/B_5bcaedfc23bdb.json\n",
      "Load .json metadata:  ./tmp/train/M_dintel_adovelado2.json\n",
      "Load .json metadata:  ./tmp/train/G_5bdf0b71aba0a.json\n",
      "Load .json metadata:  ./tmp/train/G_5b8ecbee59495.json\n",
      "Load .json metadata:  ./tmp/train/R_5c4066194de97.json\n",
      "Load .json metadata:  ./tmp/train/M_medina_azahara26.json\n",
      "Load .json metadata:  ./tmp/train/R_5db1cfe3aed90.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_elvira_granada6.json\n",
      "Load .json metadata:  ./tmp/train/B_5d66482a8551f.json\n",
      "Load .json metadata:  ./tmp/train/B_5bb4e71f205dd.json\n",
      "Load .json metadata:  ./tmp/train/R_5bb8b7efe4c9c.json\n",
      "Load .json metadata:  ./tmp/train/B_5bd5754e6f78b.json\n",
      "Load .json metadata:  ./tmp/train/G_5c2f2f40203c3.json\n",
      "Load .json metadata:  ./tmp/train/G_5da4ce32a9cbf.json\n",
      "Load .json metadata:  ./tmp/train/R_ayuntamiento_sevilla6.json\n",
      "Load .json metadata:  ./tmp/train/G_5ddc200ecb1a5.json\n",
      "Load .json metadata:  ./tmp/train/G_catedral_toledo4.json\n",
      "Load .json metadata:  ./tmp/train/G_5bb24276e44cc.json\n",
      "Load .json metadata:  ./tmp/train/B_5bb78d37dd05b.json\n",
      "Load .json metadata:  ./tmp/train/M_patio_doncella_reales_alcazares_sevilla6.json\n",
      "Load .json metadata:  ./tmp/train/G_iglesia_san_miguel_cordoba.json\n",
      "Load .json metadata:  ./tmp/train/R_santa_maria_antequera.json\n",
      "Load .json metadata:  ./tmp/train/M_5bad538f2022e.json\n",
      "Load .json metadata:  ./tmp/train/B_5bded5483c8c8.json\n",
      "Load .json metadata:  ./tmp/train/B_5ce83a2b2d61c.json\n",
      "Load .json metadata:  ./tmp/train/B_5def64aa85fc0.json\n",
      "Load .json metadata:  ./tmp/train/R_ayuntamiento_baeza6.json\n",
      "Load .json metadata:  ./tmp/train/B_5c096afcab1bf.json\n",
      "Load .json metadata:  ./tmp/train/G_san_bartolome_andujar2.json\n",
      "Load .json metadata:  ./tmp/train/M_dintel_adovelado.json\n",
      "Load .json metadata:  ./tmp/train/M_5cad9d871f944.json\n",
      "Load .json metadata:  ./tmp/train/M_5baf14b3d8aec.json\n",
      "Load .json metadata:  ./tmp/train/M_5c1385195448d.json\n",
      "Load .json metadata:  ./tmp/train/G_monasterio_concepcion_granada2.json\n",
      "Load .json metadata:  ./tmp/train/R_5be9a1419232a.json\n",
      "Load .json metadata:  ./tmp/train/G_basilica_santa_maria_arcos_frontera7.json\n",
      "Load .json metadata:  ./tmp/train/B_5c0acbbb675b5.json\n",
      "Load .json metadata:  ./tmp/train/M_corral_carbon_granada6.json\n",
      "Load .json metadata:  ./tmp/train/G_5bc76b1661432.json\n",
      "Load .json metadata:  ./tmp/train/M_corral_carbon_granada7.json\n",
      "Load .json metadata:  ./tmp/train/B_palacio_ansoti4.json\n",
      "Load .json metadata:  ./tmp/train/M_medina_azahara11.json\n",
      "Load .json metadata:  ./tmp/train/R_palacio_carlos_v_granada3.json\n",
      "Load .json metadata:  ./tmp/train/G_5bd3513c8e708.json\n",
      "Load .json metadata:  ./tmp/train/B_colegio_san_fernando_granada.json\n",
      "Load .json metadata:  ./tmp/train/M_5e4fb99bb2bc3.json\n",
      "Load .json metadata:  ./tmp/train/B_IMG_1131.json\n",
      "Load .json metadata:  ./tmp/train/B_5c794e4eb432a.json\n",
      "Load .json metadata:  ./tmp/train/M_5e4fb8cac7644.json\n",
      "Load .json metadata:  ./tmp/train/M_ermita_sansebastian2.json\n",
      "Load .json metadata:  ./tmp/train/B_hospital_real_granada2.json\n",
      "Load .json metadata:  ./tmp/train/B_casa_calle_san_matias_granada2.json\n",
      "Load .json metadata:  ./tmp/train/G_5c67dcd823270.json\n",
      "Load .json metadata:  ./tmp/train/R_5bde0353e3682.json\n",
      "Load .json metadata:  ./tmp/train/R_5bb5f42a2c989.json\n",
      "Load .json metadata:  ./tmp/train/R_5bdef0fa697b6.json\n",
      "Load .json metadata:  ./tmp/train/B_5c3dc13138c7a.json\n",
      "Load .json metadata:  ./tmp/train/G_puerta_bautismo_catedral_sevilla6.json\n",
      "Load .json metadata:  ./tmp/train/B_museo_bellas_artes_sevilla5.json\n",
      "Load .json metadata:  ./tmp/train/B_colegio_bartolome_santiago_granada3.json\n",
      "Load .json metadata:  ./tmp/train/B_san_felipe_neri_baeza8.json\n",
      "Load .json metadata:  ./tmp/train/B_5c2764eb103ed.json\n",
      "Load .json metadata:  ./tmp/train/B_5df7426bc0bff.json\n",
      "Load .json metadata:  ./tmp/train/M_5bbcca84a8516.json\n",
      "Load .json metadata:  ./tmp/train/R_palacio_carlos_v_granada20.json\n",
      "Load .json metadata:  ./tmp/train/B_convento_jesus_nazareno_chiclana2.json\n",
      "Load .json metadata:  ./tmp/train/B_5baff856046e5.json\n",
      "Load .json metadata:  ./tmp/train/G_palacio_jabalquinto_baeza14.json\n",
      "Load .json metadata:  ./tmp/train/M_20181212_115538.json\n",
      "Load .json metadata:  ./tmp/train/R_puerta_puente_cordoba8.json\n",
      "Load .json metadata:  ./tmp/train/B_IMG_0378.json\n",
      "Load .json metadata:  ./tmp/train/G_puerta_bautismo_catedral_sevilla7.json\n",
      "Load .json metadata:  ./tmp/train/G_5c7d00c96fbbb.json\n",
      "Load .json metadata:  ./tmp/train/R_iglesia_san_ildefonso_jaen2.json\n",
      "Load .json metadata:  ./tmp/train/R_5c7d015d64d2e.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_del_vino_granada7.json\n",
      "Load .json metadata:  ./tmp/train/R_5bb90f5617705.json\n",
      "Load .json metadata:  ./tmp/train/B_5bb0a2c4b9b8b.json\n",
      "Load .json metadata:  ./tmp/train/G_puerta_apostoles_catedral_murcia3.json\n",
      "Load .json metadata:  ./tmp/train/G_5d98c684abe28.json\n",
      "Load .json metadata:  ./tmp/train/B_5c484246ab3f1.json\n",
      "Load .json metadata:  ./tmp/train/R_palacio_cadenas_ubeda9.json\n",
      "Load .json metadata:  ./tmp/train/M_patio_doncella_reales_alcazares_sevilla9.json\n",
      "Load .json metadata:  ./tmp/train/M_5bd34f9db3310.json\n",
      "Load .json metadata:  ./tmp/train/B_5c2c947748ce6.json\n",
      "Load .json metadata:  ./tmp/train/B_IMG_1132.json\n",
      "Load .json metadata:  ./tmp/train/B_iglesia_san_anton_granada2.json\n",
      "Load .json metadata:  ./tmp/train/B_casa_calle_san_matias_granada3.json\n",
      "Load .json metadata:  ./tmp/train/G_iglesia_san_pablo_ubeda6.json\n",
      "Load .json metadata:  ./tmp/train/G_5da6fcf439ccd.json\n",
      "Load .json metadata:  ./tmp/train/G_5c0d0d49c0423.json\n",
      "Load .json metadata:  ./tmp/train/B_5c4066fd86767.json\n",
      "Load .json metadata:  ./tmp/train/G_iglesia_san_miguel_cordoba4.json\n",
      "Load .json metadata:  ./tmp/train/R_santa_maria_antequera5.json\n",
      "Load .json metadata:  ./tmp/train/B_5d0e5f2316005.json\n",
      "Load .json metadata:  ./tmp/train/M_5bc745d744106.json\n",
      "Load .json metadata:  ./tmp/train/R_iglesia_san_bartolome.json\n",
      "Load .json metadata:  ./tmp/train/B_5c878f098b516.json\n",
      "Load .json metadata:  ./tmp/train/R_5bd96e97c779b.json\n",
      "Load .json metadata:  ./tmp/train/B_iglesia_san_jeronimo_granada2.json\n",
      "Load .json metadata:  ./tmp/train/R_5bacb84ca1ce0.json\n",
      "Load .json metadata:  ./tmp/train/B_5df95dd4cf94d.json\n",
      "Load .json metadata:  ./tmp/train/R_carcel_martos.json\n",
      "Load .json metadata:  ./tmp/train/G_5d9f61bbc6dc2.json\n",
      "Load .json metadata:  ./tmp/train/G_hospital_san_sebastian_cordoba11.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_del_vino_granada9.json\n",
      "Load .json metadata:  ./tmp/train/M_patio_doncella_reales_alcazares_sevilla11.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_monaita_granada4.json\n",
      "Load .json metadata:  ./tmp/train/R_catedral_puerta_perdon_granada.json\n",
      "Load .json metadata:  ./tmp/train/G_5bb28cf500312.json\n",
      "Load .json metadata:  ./tmp/train/R_5bf7c979ad2be.json\n",
      "Load .json metadata:  ./tmp/train/G_basilica_santa_maria_arcos_frontera2.json\n",
      "Load .json metadata:  ./tmp/train/B_san_felipe_neri_baeza4.json\n",
      "Load .json metadata:  ./tmp/train/R_5bb5f7e3b6c72.json\n",
      "Load .json metadata:  ./tmp/train/R_5d98aefd76ce6.json\n",
      "Load .json metadata:  ./tmp/train/B_IMG_1002.json\n",
      "Load .json metadata:  ./tmp/train/R_palacio_carlos_v_granada17.json\n",
      "Load .json metadata:  ./tmp/train/G_5c0a9e2643692.json\n",
      "Load .json metadata:  ./tmp/train/G_hospital_san_sebastian_cordoba2.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_del_vino_granada10.json\n",
      "Load .json metadata:  ./tmp/train/G_5e5a2e8dc057b.json\n",
      "Load .json metadata:  ./tmp/train/B_hospital_real_granada5.json\n",
      "Load .json metadata:  ./tmp/train/B_chancilleria_granada10.json\n",
      "Load .json metadata:  ./tmp/train/G_catedral_sevilla4.json\n",
      "Load .json metadata:  ./tmp/train/R_5bb0b22d051f2.json\n",
      "Load .json metadata:  ./tmp/train/R_ayuntamiento_sevilla.json\n",
      "Load .json metadata:  ./tmp/train/R_palacio_cadenas_ubeda18.json\n",
      "Load .json metadata:  ./tmp/train/B_5ced7d9be567d.json\n",
      "Load .json metadata:  ./tmp/train/G_pinaculo3.json\n",
      "Load .json metadata:  ./tmp/train/M_medina_azahara30.json\n",
      "Load .json metadata:  ./tmp/train/G_5c877f4185ccc.json\n",
      "Load .json metadata:  ./tmp/train/M_20181212_150121.json\n",
      "Load .json metadata:  ./tmp/train/B_5bae53895ec1c.json\n",
      "Load .json metadata:  ./tmp/train/M_patio_yeso_reales_alcazares_sevilla.json\n",
      "Load .json metadata:  ./tmp/train/M_medina_azahara24.json\n",
      "Load .json metadata:  ./tmp/train/B_iglesia_san_anton_granada3.json\n",
      "Load .json metadata:  ./tmp/train/G_hospital_san_sebastian_cordoba8.json\n",
      "Load .json metadata:  ./tmp/train/G_hospital_san_sebastian_cordoba6.json\n",
      "Load .json metadata:  ./tmp/train/B_5bb1ff537029b.json\n",
      "Load .json metadata:  ./tmp/train/G_5c1799d2dde1a.json\n",
      "Load .json metadata:  ./tmp/train/B_5bdb1d1c42d96.json\n",
      "Load .json metadata:  ./tmp/train/B_catedral_jaen.json\n",
      "Load .json metadata:  ./tmp/train/B_5baf98b804126.json\n",
      "Load .json metadata:  ./tmp/train/R_iglesia_santa_fe_granada.json\n",
      "Load .json metadata:  ./tmp/train/R_5bb0b25a063e4.json\n",
      "Load .json metadata:  ./tmp/train/R_palacio_carlos_v_granada15.json\n",
      "Load .json metadata:  ./tmp/train/B_chancilleria_granada9.json\n",
      "Load .json metadata:  ./tmp/train/R_5c0966aea69f7.json\n",
      "Load .json metadata:  ./tmp/train/B_hospital_rreal_granada2.json\n",
      "Load .json metadata:  ./tmp/train/G_hospital_san_sebastian_cordoba5.json\n",
      "Load .json metadata:  ./tmp/train/R_5bc1abdd2b50a.json\n",
      "Load .json metadata:  ./tmp/train/B_5c12755aad84a.json\n",
      "Load .json metadata:  ./tmp/train/B_5bb7972ad3e16.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc76484d31a1.json\n",
      "Load .json metadata:  ./tmp/train/B_5ddba624afba4.json\n",
      "Load .json metadata:  ./tmp/train/G_5d111a858480b.json\n",
      "Load .json metadata:  ./tmp/train/R_san_pedro_cordoba4.json\n",
      "Load .json metadata:  ./tmp/train/B_san_felipe_neri_baeza3.json\n",
      "Load .json metadata:  ./tmp/train/R_5c48450f3f550.json\n",
      "Load .json metadata:  ./tmp/train/R_5bc76d793e6e7.json\n",
      "Load .json metadata:  ./tmp/train/B_5bba92638b868.json\n",
      "Load .json metadata:  ./tmp/train/G_iglesia_santa_maría_del_pi_barcelona2.json\n",
      "Load .json metadata:  ./tmp/train/B_5bfe9d813c0ca.json\n",
      "Load .json metadata:  ./tmp/train/B_5bb5f69957c0a.json\n",
      "Load .json metadata:  ./tmp/train/M_20181212_150254.json\n",
      "Load .json metadata:  ./tmp/train/R_palacio_carlos_v_granada11.json\n",
      "Load .json metadata:  ./tmp/train/B_5c025913a9ddb.json\n",
      "Load .json metadata:  ./tmp/train/G_5c699dfd45a1a.json\n",
      "Load .json metadata:  ./tmp/train/M_20181212_130014.json\n",
      "Load .json metadata:  ./tmp/train/R_puerta_perdon_catedral_granada4.json\n",
      "Load .json metadata:  ./tmp/train/R_san_pedro_cordoba5.json\n",
      "Load .json metadata:  ./tmp/train/B_iglesia_salvador_sevilla.json\n",
      "Load .json metadata:  ./tmp/train/B_san_felipe_neri_baeza7.json\n",
      "Load .json metadata:  ./tmp/train/M_corral_carbon_granada3.json\n",
      "Load .json metadata:  ./tmp/train/M_5bcc9ce820ba1.json\n",
      "Load .json metadata:  ./tmp/train/G_catedral_leon4.json\n",
      "Load .json metadata:  ./tmp/train/B_5bb1c89ba7002.json\n",
      "Load .json metadata:  ./tmp/train/M_20181212_115637.json\n",
      "Load .json metadata:  ./tmp/train/R_5dfa0add8bffc.json\n",
      "Load .json metadata:  ./tmp/train/R_san_pedro_cordoba3.json\n",
      "Load .json metadata:  ./tmp/train/B_5bd0751729011.json\n",
      "Load .json metadata:  ./tmp/train/G_5bb48060bc6a0.json\n",
      "Load .json metadata:  ./tmp/train/B_facultad_derecho_granada5.json\n",
      "Load .json metadata:  ./tmp/train/G_palacio_jabalquinto_baeza.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_del_vino_granada4.json\n",
      "Load .json metadata:  ./tmp/train/G_5cf2f6096b752.json\n",
      "Load .json metadata:  ./tmp/train/G_5c0d10a4df5cb.json\n",
      "Load .json metadata:  ./tmp/train/B_5cf7e81e4e982.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_del_vino_granada.json\n",
      "Load .json metadata:  ./tmp/train/M_5e4fb8e1009fb.json\n",
      "Load .json metadata:  ./tmp/train/R_5bc6e43c0907f.json\n",
      "Load .json metadata:  ./tmp/train/R_5de0eaa225937.json\n",
      "Load .json metadata:  ./tmp/train/G_catedral_burgos4.json\n",
      "Load .json metadata:  ./tmp/train/R_5bb768f243f4d.json\n",
      "Load .json metadata:  ./tmp/train/M_5d623f48dabcd.json\n",
      "Load .json metadata:  ./tmp/train/B_iglesia_caridad_sevilla3.json\n",
      "Load .json metadata:  ./tmp/train/G_catedral_leon5.json\n",
      "Load .json metadata:  ./tmp/train/R_puerta_perdon_catedral_granada12.json\n",
      "Load .json metadata:  ./tmp/train/M_patio_doncella_reales_alcazares_sevilla8.json\n",
      "Load .json metadata:  ./tmp/train/B_5bec4cccf3ed2.json\n",
      "Load .json metadata:  ./tmp/train/B_5c4841c1ca3e2.json\n",
      "Load .json metadata:  ./tmp/train/G_basilica_santa_maria_arcos_frontera3.json\n",
      "Load .json metadata:  ./tmp/train/G_5d74bc786cba6.json\n",
      "Load .json metadata:  ./tmp/train/G_IMG_1052.json\n",
      "Load .json metadata:  ./tmp/train/G_convento_clarisas_palencia5.json\n",
      "Load .json metadata:  ./tmp/train/G_5c2ca09d347ad.json\n",
      "Load .json metadata:  ./tmp/train/M_5bbcca3f7448f.json\n",
      "Load .json metadata:  ./tmp/train/B_parroquia_mayor_santa_maria_encarnacion_huescar.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_justicia_granada5.json\n",
      "Load .json metadata:  ./tmp/train/M_medina_azahara36.json\n",
      "Load .json metadata:  ./tmp/train/R_iglesia_san_cecilio_granada4.json\n",
      "Load .json metadata:  ./tmp/train/G_palacio_jabalquinto_baeza5.json\n",
      "Load .json metadata:  ./tmp/train/R_5bbe3480002dc.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_san_isidro_mezquita_cordoba3.json\n",
      "Load .json metadata:  ./tmp/train/G_5c0d0de30a8f2.json\n",
      "Load .json metadata:  ./tmp/train/G_casa_abrantes_granada.json\n",
      "Load .json metadata:  ./tmp/train/G_5d98c47b04a88.json\n",
      "Load .json metadata:  ./tmp/train/M_20181212_125945.json\n",
      "Load .json metadata:  ./tmp/train/R_puerta_perdon_catedral_granada2.json\n",
      "Load .json metadata:  ./tmp/train/B_5bae55d7aad09.json\n",
      "Load .json metadata:  ./tmp/train/B_5c80d24a04008.json\n",
      "Load .json metadata:  ./tmp/train/G_5db2a2cad60a2.json\n",
      "Load .json metadata:  ./tmp/train/B_colegio_bartolome_santiago_granada4.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc75f2c9c6a4.json\n",
      "Load .json metadata:  ./tmp/train/R_5bc76d50783ef.json\n",
      "Load .json metadata:  ./tmp/train/M_5bc5c30c3eaf6.json\n",
      "Load .json metadata:  ./tmp/train/B_chancilleria_granada11.json\n",
      "Load .json metadata:  ./tmp/train/G_convento_clarisas_palencia2.json\n",
      "Load .json metadata:  ./tmp/train/R_5bc4d1797c791.json\n",
      "Load .json metadata:  ./tmp/train/B_chancilleria_granada2.json\n",
      "Load .json metadata:  ./tmp/train/R_5d559f8ccff2a.json\n",
      "Load .json metadata:  ./tmp/train/G_5bad41c85ae3d.json\n",
      "Load .json metadata:  ./tmp/train/B_casa_almirante_cadiz.json\n",
      "Load .json metadata:  ./tmp/train/R_puerta_perdon_catedral_granada7.json\n",
      "Load .json metadata:  ./tmp/train/B_basilica_angustias_granada2.json\n",
      "Load .json metadata:  ./tmp/train/R_palacio_cadenas_ubeda10.json\n",
      "Load .json metadata:  ./tmp/train/M_5bd4b5dfc5dd4.json\n",
      "Load .json metadata:  ./tmp/train/M_5c1b60d5c92de.json\n",
      "Load .json metadata:  ./tmp/train/G_palacio_jabalquinto_baeza10.json\n",
      "Load .json metadata:  ./tmp/train/R_san_grabiel_loja3.json\n",
      "Load .json metadata:  ./tmp/train/M_dintel_adovelado6.json\n",
      "Load .json metadata:  ./tmp/train/B_museo_bellas_artes_sevilla3.json\n",
      "Load .json metadata:  ./tmp/train/B_5c0b9bda7349b.json\n",
      "Load .json metadata:  ./tmp/train/B_5c19275826ba9.json\n",
      "Load .json metadata:  ./tmp/train/G_5dac7070aa7e2.json\n",
      "Load .json metadata:  ./tmp/train/G_5bc76e72997a7.json\n",
      "Load .json metadata:  ./tmp/train/G_20181212_105521.json\n",
      "Load .json metadata:  ./tmp/train/B_san_felipe_neri_baeza5.json\n",
      "Load .json metadata:  ./tmp/train/R_ayuntamiento_baeza9.json\n",
      "Load .json metadata:  ./tmp/train/B_5c15224895f85.json\n",
      "Load .json metadata:  ./tmp/train/B_5be5d7c4bb9bb.json\n",
      "Load .json metadata:  ./tmp/train/M_5db2c2e015c8c.json\n",
      "Load .json metadata:  ./tmp/train/R_5bb74d7c3e166.json\n",
      "Load .json metadata:  ./tmp/train/B_5cadabdf51477.json\n",
      "Load .json metadata:  ./tmp/train/G_5c7ba984d24b3.json\n",
      "Load .json metadata:  ./tmp/train/B_5ba898dd6f92c.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_san_isidro_mezquita_cordoba4.json\n",
      "Load .json metadata:  ./tmp/train/M_corral_carbon_granada8.json\n",
      "Load .json metadata:  ./tmp/train/B_chancilleria_granada12.json\n",
      "Load .json metadata:  ./tmp/train/R_5bf437f158eb5.json\n",
      "Load .json metadata:  ./tmp/train/B_iglesia_señora_gracia_estepa3.json\n",
      "Load .json metadata:  ./tmp/train/B_catedral_granada9.json\n",
      "Load .json metadata:  ./tmp/train/R_palacio_carlos_v_granada8.json\n",
      "Load .json metadata:  ./tmp/train/M_20181212_105457.json\n",
      "Load .json metadata:  ./tmp/train/B_casatercia_baena.json\n",
      "Load .json metadata:  ./tmp/train/B_5c17dbfe94db3.json\n",
      "Load .json metadata:  ./tmp/train/B_colegio_san_fernando_granada2.json\n",
      "Load .json metadata:  ./tmp/train/R_ayuntamiento_baeza10.json\n",
      "Load .json metadata:  ./tmp/train/B_casa_conde_gabia_granada.json\n",
      "Load .json metadata:  ./tmp/train/B_colegio_san_telmo_sevilla2.json\n",
      "Load .json metadata:  ./tmp/train/G_5e0b2c3b44d7a.json\n",
      "Load .json metadata:  ./tmp/train/R_palacio_carlos_v_granada16.json\n",
      "Load .json metadata:  ./tmp/train/B_casa_calle_san_matias_granada.json\n",
      "Load .json metadata:  ./tmp/train/R_5c23b9ae08c28.json\n",
      "Load .json metadata:  ./tmp/train/B_5bb8ee994df2a.json\n",
      "Load .json metadata:  ./tmp/train/B_san_juan_dios_antequera2.json\n",
      "Load .json metadata:  ./tmp/train/B_chancilleria_granada15.json\n",
      "Load .json metadata:  ./tmp/train/B_palacio_bibataubin_granada.json\n",
      "Load .json metadata:  ./tmp/train/G_5df0cfe41c9e2.json\n",
      "Load .json metadata:  ./tmp/train/B_hospital_san_juan_de_dios_granada2.json\n",
      "Load .json metadata:  ./tmp/train/M_5bdee0fc89299.json\n",
      "Load .json metadata:  ./tmp/train/R_5bfabb729d3b7.json\n",
      "Load .json metadata:  ./tmp/train/R_5bec3f44c6943.json\n",
      "Load .json metadata:  ./tmp/train/R_5bb602378e74b.json\n",
      "Load .json metadata:  ./tmp/train/R_casa_torres_ubeda5.json\n",
      "Load .json metadata:  ./tmp/train/B_5ced0fbf8575d.json\n",
      "Load .json metadata:  ./tmp/train/B_catedral_granada8.json\n",
      "Load .json metadata:  ./tmp/train/R_palacio_cadenas_ubeda2.json\n",
      "Load .json metadata:  ./tmp/train/R_palacio_carlos_v_granada7.json\n",
      "Load .json metadata:  ./tmp/train/G_puerta_bautismo_catedral_sevilla5.json\n",
      "Load .json metadata:  ./tmp/train/B_convento_jesus_nazareno_chiclana4.json\n",
      "Load .json metadata:  ./tmp/train/R_5c1514396c39f.json\n",
      "Load .json metadata:  ./tmp/train/G_20181212_105032.json\n",
      "Load .json metadata:  ./tmp/train/R_5ce695bde2c12.json\n",
      "Load .json metadata:  ./tmp/train/B_5c4c40ffaee5b.json\n",
      "Load .json metadata:  ./tmp/train/M_5ca46555b8d6f.json\n",
      "Load .json metadata:  ./tmp/train/R_ayuntamiento_baeza12.json\n",
      "Load .json metadata:  ./tmp/train/R_5c0cf59f3c68c.json\n",
      "Load .json metadata:  ./tmp/train/R_5e1b37e6a0cca.json\n",
      "Load .json metadata:  ./tmp/train/M_patio_doncella_reales_alcazares_sevilla4.json\n",
      "Load .json metadata:  ./tmp/train/M_patio_yeso_reales_alcazares_sevilla6.json\n",
      "Load .json metadata:  ./tmp/train/G_puerta_apostoles_catedra_valencia4.json\n",
      "Load .json metadata:  ./tmp/train/G_iglesia_san_miguel_cordoba3.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_visires_mezquita_cordoba.json\n",
      "Load .json metadata:  ./tmp/train/B_5c0d00ee1c0cd.json\n",
      "Load .json metadata:  ./tmp/train/G_iglesia_sabiote3.json\n",
      "Load .json metadata:  ./tmp/train/R_5bfab9bb46da6.json\n",
      "Load .json metadata:  ./tmp/train/M_5bb0a6aa5f6e4.json\n",
      "Load .json metadata:  ./tmp/train/R_san_pedro_cordoba.json\n",
      "Load .json metadata:  ./tmp/train/M_20181212_110915.json\n",
      "Load .json metadata:  ./tmp/train/G_5d9f5b7f5da26.json\n",
      "Load .json metadata:  ./tmp/train/G_5da98678c6c25.json\n",
      "Load .json metadata:  ./tmp/train/R_ayuntamiento_baeza2.json\n",
      "Load .json metadata:  ./tmp/train/B_chancilleria_granada3.json\n",
      "Load .json metadata:  ./tmp/train/B_hospital_rreal_granada.json\n",
      "Load .json metadata:  ./tmp/train/R_5bb79917b8e2f.json\n",
      "Load .json metadata:  ./tmp/train/R_5bc4b222ab8b9.json\n",
      "Load .json metadata:  ./tmp/train/B_5bb727333c120.json\n",
      "Load .json metadata:  ./tmp/train/G_puerta_perdon_catedral_toledo.json\n",
      "Load .json metadata:  ./tmp/train/R_santa_maria_puebla_fadrique.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_justicia_granada4.json\n",
      "Load .json metadata:  ./tmp/train/B_5beff5707aec9.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_atarazanas_malaga.json\n",
      "Load .json metadata:  ./tmp/train/M_aljibe_san_miguel_bajo3.json\n",
      "Load .json metadata:  ./tmp/train/B_casa_almirante_cadiz4.json\n",
      "Load .json metadata:  ./tmp/train/R_iglesia_salvador_ubeda5.json\n",
      "Load .json metadata:  ./tmp/train/B_palacio_ansoti6.json\n",
      "Load .json metadata:  ./tmp/train/G_catedral_sevilla.json\n",
      "Load .json metadata:  ./tmp/train/M_5bccb0f95a19f.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc75ea2043a1.json\n",
      "Load .json metadata:  ./tmp/train/B_5bacbc0c24a80.json\n",
      "Load .json metadata:  ./tmp/train/R_5d559e35666bb.json\n",
      "Load .json metadata:  ./tmp/train/M_5c24c231d82db.json\n",
      "Load .json metadata:  ./tmp/train/R_palacio_carlos_v_granada6.json\n",
      "Load .json metadata:  ./tmp/train/G_5d9dcda7e43c1.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_san_isidro_mezquita_cordoba.json\n",
      "Load .json metadata:  ./tmp/train/R_casa_lonja_sevilla_patio2.json\n",
      "Load .json metadata:  ./tmp/train/G_alcazaba-almeria2.json\n",
      "Load .json metadata:  ./tmp/train/G_5c0d1111d3183.json\n",
      "Load .json metadata:  ./tmp/train/G_5d9f5b784eef2.json\n",
      "Load .json metadata:  ./tmp/train/R_puerta_puente_cordoba2.json\n",
      "Load .json metadata:  ./tmp/train/R_5c23bd0b1c5b3.json\n",
      "Load .json metadata:  ./tmp/train/B_5bfab9d919e44.json\n",
      "Load .json metadata:  ./tmp/train/B_hospital_san_juan_de_dios_granada6.json\n",
      "Load .json metadata:  ./tmp/train/B_5c1913fa4368f.json\n",
      "Load .json metadata:  ./tmp/train/M_5c879cbec00c9.json\n",
      "Load .json metadata:  ./tmp/train/G_puerta_apostoles_catedra_valencia6.json\n",
      "Load .json metadata:  ./tmp/train/B_fabrica_tabaco_sevilla4.json\n",
      "Load .json metadata:  ./tmp/train/R_plaza_santa_teresa_ubeda2.json\n",
      "Load .json metadata:  ./tmp/train/R_palacio_carlos_v_granada13.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc75ddc3d1ba.json\n",
      "Load .json metadata:  ./tmp/train/G_5c2b98e90a715.json\n",
      "Load .json metadata:  ./tmp/train/R_ayuntamiento_sevilla9.json\n",
      "Load .json metadata:  ./tmp/train/M_20181212_112635.json\n",
      "Load .json metadata:  ./tmp/train/B_5bdf15a853ace.json\n",
      "Load .json metadata:  ./tmp/train/M_medina_azahara33.json\n",
      "Load .json metadata:  ./tmp/train/M_20181212_112338.json\n",
      "Load .json metadata:  ./tmp/train/B_5bfabad3ce768.json\n",
      "Load .json metadata:  ./tmp/train/B_5bae53c39b2b7.json\n",
      "Load .json metadata:  ./tmp/train/B_5cd7c70902846.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc75ee5ebe5d.json\n",
      "Load .json metadata:  ./tmp/train/G_santa_maria_del_mar_barcelona2.json\n",
      "Load .json metadata:  ./tmp/train/G_palacio_salcedo2.json\n",
      "Load .json metadata:  ./tmp/train/B_san_felipe_neri_baeza6.json\n",
      "Load .json metadata:  ./tmp/train/B_iglesia_señora_gracia_estepa2.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_mihrab_mezquita_cordoba4.json\n",
      "Load .json metadata:  ./tmp/train/G_5df76902c546e.json\n",
      "Load .json metadata:  ./tmp/train/R_5c261a545bbe2.json\n",
      "Load .json metadata:  ./tmp/train/R_5bcaeef31f64b.json\n",
      "Load .json metadata:  ./tmp/train/B_parroquia_nuestra_señora_de_la_o_chipiona.json\n",
      "Load .json metadata:  ./tmp/train/M_5c700b74d7c96.json\n",
      "Load .json metadata:  ./tmp/train/B_catedral_granada3.json\n",
      "Load .json metadata:  ./tmp/train/M_5c6fda72e1704.json\n",
      "Load .json metadata:  ./tmp/train/G_5c740a02c0dac.json\n",
      "Load .json metadata:  ./tmp/train/R_puerta_puente_cordoba11.json\n",
      "Load .json metadata:  ./tmp/train/B_5cada883c36bc.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_atarazanas_malaga2.json\n",
      "Load .json metadata:  ./tmp/val/M_5db2c3273aa37.json\n",
      "Load .json metadata:  ./tmp/val/B_casa_marqueses_de_cartagena_granada5.json\n",
      "Load .json metadata:  ./tmp/val/G_5df806400189c.json\n",
      "Load .json metadata:  ./tmp/val/B_5bd0a18e3a7cf.json\n",
      "Load .json metadata:  ./tmp/val/B_5c45af8e61851.json\n",
      "Load .json metadata:  ./tmp/val/B_5c68094c5269c.json\n",
      "Load .json metadata:  ./tmp/val/R_casa_cabildo_jerez8.json\n",
      "Load .json metadata:  ./tmp/val/B_5de179ec7b386.json\n",
      "Load .json metadata:  ./tmp/val/M_patio_doncella_reales_alcazares_sevilla12.json\n",
      "Load .json metadata:  ./tmp/val/B_5d2af2ba74f7c.json\n",
      "Load .json metadata:  ./tmp/val/M_puerta_justicia_granada3.json\n",
      "Load .json metadata:  ./tmp/val/R_iglesia_asuncion_jodar2.json\n",
      "Load .json metadata:  ./tmp/val/G_5b8ecbfc3afd4.json\n",
      "Load .json metadata:  ./tmp/val/R_5db7125d0d87f.json\n",
      "Load .json metadata:  ./tmp/val/B_5c8a449b2672b.json\n",
      "Load .json metadata:  ./tmp/val/B_5bae55f40f890.json\n",
      "Load .json metadata:  ./tmp/val/M_5bc3179bc5bd7.json\n",
      "Load .json metadata:  ./tmp/val/M_5bbcca8260a77.json\n",
      "Load .json metadata:  ./tmp/val/B_hospital_san_juan_de_dios_granada.json\n",
      "Load .json metadata:  ./tmp/val/G_5d3603beb29ee.json\n",
      "Load .json metadata:  ./tmp/val/G_5cadb9254e5bb.json\n",
      "Load .json metadata:  ./tmp/val/R_puerta_puente_cordoba7.json\n",
      "Load .json metadata:  ./tmp/val/G_5bc06c895d7f1.json\n",
      "Load .json metadata:  ./tmp/val/M_5bacf44fbf465.json\n",
      "Load .json metadata:  ./tmp/val/B_5bae63c34ffa2.json\n",
      "Load .json metadata:  ./tmp/val/G_5bad24e5bfd54.json\n",
      "Load .json metadata:  ./tmp/val/R_20181212_114849.json\n",
      "Load .json metadata:  ./tmp/val/B_5d9dc590766ab.json\n",
      "Load .json metadata:  ./tmp/val/M_patio_doncella_reales_alcazares_sevilla7.json\n",
      "Load .json metadata:  ./tmp/val/R_casa_arandas.json\n",
      "Load .json metadata:  ./tmp/val/G_casa_abrantes_granada8.json\n",
      "Load .json metadata:  ./tmp/val/B_catedral_jaen5.json\n",
      "Load .json metadata:  ./tmp/val/B_5c876de809b23.json\n",
      "Load .json metadata:  ./tmp/val/R_5bb78ee318b3f.json\n",
      "Load .json metadata:  ./tmp/val/M_20181212_122208.json\n",
      "Load .json metadata:  ./tmp/val/M_5c45b1ab7eacc.json\n",
      "Load .json metadata:  ./tmp/val/G_5bc4b0000a171.json\n",
      "Load .json metadata:  ./tmp/val/M_puerta_atarazanas_malaga7.json\n",
      "Load .json metadata:  ./tmp/val/R_5be6b690211bf.json\n",
      "Load .json metadata:  ./tmp/val/B_5bad4ad9c95b3.json\n",
      "Load .json metadata:  ./tmp/val/G_convento_clarisas_palencia3.json\n",
      "Load .json metadata:  ./tmp/val/M_puerta_de_las_pesas_granada2.json\n",
      "Load .json metadata:  ./tmp/val/G_5c267e2387828.json\n",
      "Load .json metadata:  ./tmp/val/G_5d9f5d4905e1d.json\n",
      "Load .json metadata:  ./tmp/val/B_5cd6a30c8eeae.json\n",
      "Load .json metadata:  ./tmp/val/R_5d208b11429c6.json\n",
      "Load .json metadata:  ./tmp/val/G_catedral_toledo3.json\n",
      "Load .json metadata:  ./tmp/val/R_5bcc411061ead.json\n",
      "Load .json metadata:  ./tmp/val/M_5e5f7d583c41f.json\n",
      "Load .json metadata:  ./tmp/val/B_5bfabb1a9d451.json\n",
      "Load .json metadata:  ./tmp/val/B_iglesia_san_juan_de_dios_granada2.json\n",
      "Load .json metadata:  ./tmp/val/G_casa_abrantes_granada2.json\n",
      "Load .json metadata:  ./tmp/val/M_puerta_del_vino_granada8.json\n",
      "Load .json metadata:  ./tmp/val/B_5cada2796e206.json\n",
      "Load .json metadata:  ./tmp/val/B_chancilleria_granada7.json\n",
      "Load .json metadata:  ./tmp/val/M_5c2ce172117a7.json\n",
      "Load .json metadata:  ./tmp/val/G_5cc0716275b2e.json\n",
      "Load .json metadata:  ./tmp/val/G_5b8a5fbbcc59f.json\n",
      "Load .json metadata:  ./tmp/val/R_convento_santa_clara_ubeda.json\n",
      "Load .json metadata:  ./tmp/val/G_5d09350c0fda2.json\n",
      "Load .json metadata:  ./tmp/val/M_5bd1dff352ca4.json\n",
      "Load .json metadata:  ./tmp/val/M_5c75185ba9a61.json\n",
      "Load .json metadata:  ./tmp/val/B_palacio_ansoti5.json\n",
      "Load .json metadata:  ./tmp/val/M_5bacb65e7ea39.json\n",
      "Load .json metadata:  ./tmp/val/G_hospital_san_sebastian_cordoba.json\n",
      "Load .json metadata:  ./tmp/val/B_casa_cadenas_cadiz.json\n",
      "Load .json metadata:  ./tmp/val/G_capilla_real_granada4.json\n",
      "Load .json metadata:  ./tmp/val/G_20181212_105134.json\n",
      "Load .json metadata:  ./tmp/val/R_5c60427368d45.json\n",
      "Load .json metadata:  ./tmp/val/G_catedral_toledo.json\n",
      "Load .json metadata:  ./tmp/val/B_5bec4cd58ecc0.json\n",
      "Load .json metadata:  ./tmp/val/B_IMG_0329.json\n",
      "Load .json metadata:  ./tmp/val/G_capilla_real_granada2_2.json\n",
      "Load .json metadata:  ./tmp/val/R_plaza_santa_teresa_ubeda.json\n",
      "Load .json metadata:  ./tmp/val/G_iglesia_san_pablo_ubeda9.json\n",
      "Load .json metadata:  ./tmp/val/B_iglesia_san_juan_de_dios_granada3.json\n",
      "Load .json metadata:  ./tmp/val/R_ayuntamiento_baeza7.json\n",
      "Load .json metadata:  ./tmp/val/G_igl_arcos_frontera.json\n",
      "Load .json metadata:  ./tmp/val/B_5c14f985ec8cb.json\n",
      "Load .json metadata:  ./tmp/val/M_20181212_115509.json\n",
      "Load .json metadata:  ./tmp/val/B_5bc75e93a80c2.json\n",
      "Load .json metadata:  ./tmp/val/B_5bc75f886de87.json\n",
      "Load .json metadata:  ./tmp/val/R_5bfdb2389a627.json\n",
      "Load .json metadata:  ./tmp/val/M_medina_azahara9.json\n",
      "Load .json metadata:  ./tmp/val/M_puerta_monaita_granada3.json\n",
      "Load .json metadata:  ./tmp/val/R_palacio_carlos_v_granada.json\n",
      "Load .json metadata:  ./tmp/val/R_san_pedro_cordoba2.json\n",
      "Load .json metadata:  ./tmp/val/B_5c596ad870071.json\n",
      "Load .json metadata:  ./tmp/val/B_5bcdf776e2630.json\n",
      "Load .json metadata:  ./tmp/val/G_5bec3a72c823a.json\n",
      "Load .json metadata:  ./tmp/val/B_palacio_bibataubin_granada4.json\n",
      "Load .json metadata:  ./tmp/val/G_5c877f504a07b.json\n",
      "Load .json metadata:  ./tmp/val/M_puerta_atarazanas_malaga3.json\n",
      "Load .json metadata:  ./tmp/val/G_puerta_bautismo_catedral_sevilla2.json\n",
      "Load .json metadata:  ./tmp/val/R_casa_torres_ubeda4.json\n",
      "Load .json metadata:  ./tmp/val/G_IMG_0369.json\n",
      "Load .json metadata:  ./tmp/val/M_puerta_de_las_pesas_granada6.json\n",
      "Load .json metadata:  ./tmp/val/R_puerta_perdon_catedral_granada5.json\n",
      "Load .json metadata:  ./tmp/val/M_5c85601a50e23.json\n",
      "Load .json metadata:  ./tmp/val/M_5dd41a8a19a4a.json\n",
      "Load .json metadata:  ./tmp/val/M_medina_azahara10.json\n",
      "Load .json metadata:  ./tmp/val/B_convento_santa_ines_granada2.json\n",
      "Load .json metadata:  ./tmp/val/G_basilica_santa_maria_arcos_frontera.json\n",
      "Load .json metadata:  ./tmp/val/B_5be5b0ed738a7.json\n",
      "Load .json metadata:  ./tmp/val/M_5c9620edef2ff.json\n",
      "Load .json metadata:  ./tmp/val/M_5e4fb97a24480.json\n",
      "Load .json metadata:  ./tmp/val/R_puerta_granada_granada.json\n",
      "Load .json metadata:  ./tmp/val/B_facultad_derecho_granada4.json\n",
      "Load .json metadata:  ./tmp/val/R_colegio_niñas_nobles_granada2.json\n",
      "Load .json metadata:  ./tmp/val/R_5bb733b336220.json\n",
      "Load .json metadata:  ./tmp/val/B_fabrica_tabaco_sevilla2.json\n",
      "Load .json metadata:  ./tmp/val/G_pinaculo4.json\n",
      "Load .json metadata:  ./tmp/val/R_capilla_san_francisco_baeza5.json\n",
      "Load .json metadata:  ./tmp/val/M_medina_azahara35.json\n",
      "Load .json metadata:  ./tmp/val/B_IMG_1004.json\n",
      "Load .json metadata:  ./tmp/val/R_5c15277c84aab.json\n",
      "Load .json metadata:  ./tmp/val/G_5cd8200569568.json\n",
      "Load .json metadata:  ./tmp/val/R_5bdef11ecc329.json\n",
      "Load .json metadata:  ./tmp/val/B_catedral_guadix5.json\n",
      "Load .json metadata:  ./tmp/val/B_5c878f865c701.json\n",
      "Load .json metadata:  ./tmp/val/M_20181212_113400.json\n",
      "Load .json metadata:  ./tmp/val/M_5db079dfc13c7.json\n",
      "Load .json metadata:  ./tmp/val/R_5bb4547e1c1e9.json\n",
      "Load .json metadata:  ./tmp/val/R_5cba22808268e.json\n",
      "Load .json metadata:  ./tmp/val/R_5bc0b4b6c8948.json\n",
      "Load .json metadata:  ./tmp/val/B_fabrica_tabaco_sevilla5.json\n",
      "Load .json metadata:  ./tmp/val/B_5ca466a359d1d.json\n",
      "Load .json metadata:  ./tmp/val/R_5bcaf9bf6194d.json\n",
      "Load .json metadata:  ./tmp/val/B_catedral_granada5.json\n",
      "Load .json metadata:  ./tmp/val/B_5cdeec644d080.json\n",
      "Load .json metadata:  ./tmp/val/B_IMG_1055.json\n",
      "Load .json metadata:  ./tmp/val/M_5e5245bcb4ee4.json\n",
      "Load .json metadata:  ./tmp/val/G_iglesia_san_pablo_ubeda3.json\n",
      "Load .json metadata:  ./tmp/val/M_5bccb200d68f2.json\n",
      "Load .json metadata:  ./tmp/val/M_5da4ceed0c3d9.json\n",
      "Load .json metadata:  ./tmp/val/B_IMG_1054.json\n",
      "Load .json metadata:  ./tmp/val/B_5c878f258d48a.json\n",
      "Load .json metadata:  ./tmp/val/B_catedral_granada10.json\n",
      "Load .json metadata:  ./tmp/val/R_iglesia_salvador_granada.json\n",
      "Load .json metadata:  ./tmp/val/B_5bb7b650342fc.json\n",
      "Load .json metadata:  ./tmp/val/G_5d9dcdcba5a00.json\n",
      "Load .json metadata:  ./tmp/val/B_5c0a71fb016ae.json\n",
      "Load .json metadata:  ./tmp/val/B_IMG_0362.json\n",
      "Load .json metadata:  ./tmp/val/B_5bc75e23a2930.json\n",
      "Load .json metadata:  ./tmp/val/G_casa_abrantes_granada5.json\n",
      "Load .json metadata:  ./tmp/val/B_basilica_angustias_granada5.json\n",
      "Load .json metadata:  ./tmp/val/B_5b8ecb06eab42.json\n",
      "Load .json metadata:  ./tmp/val/R_san_grabiel_loja.json\n",
      "Load .json metadata:  ./tmp/val/B_IMG_0359.json\n",
      "Load .json metadata:  ./tmp/val/R_puerta_perdon_catedral_granada8.json\n",
      "Load .json metadata:  ./tmp/val/R_monasterio_cartuja_granada.json\n",
      "Load .json metadata:  ./tmp/val/R_palacio_cadenas_ubeda13.json\n",
      "Load .json metadata:  ./tmp/val/B_IMG_1034.json\n",
      "Load .json metadata:  ./tmp/val/B_5cd3273f34c66.json\n",
      "Load .json metadata:  ./tmp/val/M_puerta_mihrab_mezquita_cordoba2.json\n",
      "Load .json metadata:  ./tmp/val/G_5d98cad22479c.json\n",
      "Load .json metadata:  ./tmp/val/M_patio_yeso_reales_alcazares_sevilla2.json\n",
      "Load .json metadata:  ./tmp/val/B_5bec3a0558cf5.json\n",
      "Load .json metadata:  ./tmp/val/R_casa_cabildo_jerez3.json\n",
      "Load .json metadata:  ./tmp/val/M_5bd577ad73bb0.json\n",
      "Load .json metadata:  ./tmp/val/G_5ced8f6051d21.json\n",
      "Load .json metadata:  ./tmp/val/B_5bfaba8fb40e3.json\n",
      "Load .json metadata:  ./tmp/val/G_puerta_bautismo_catedral_sevilla8.json\n",
      "Load .json metadata:  ./tmp/val/R_5bb78bd53e5ad.json\n",
      "Load .json metadata:  ./tmp/val/B_5c12759d8cc79.json\n",
      "Load .json metadata:  ./tmp/val/G_5bc76dc28fd08.json\n",
      "Load .json metadata:  ./tmp/val/G_5bc9a11663f9b.json\n",
      "Load .json metadata:  ./tmp/val/B_5e4ed1c6cbdec.json\n",
      "Load .json metadata:  ./tmp/val/G_iglesia_san_pablo_ubeda10.json\n",
      "Load .json metadata:  ./tmp/val/G_5de135380f7c3.json\n",
      "Load .json metadata:  ./tmp/val/M_medina_azahara29.json\n",
      "Load .json metadata:  ./tmp/val/M_5baf1a3f2e94b.json\n",
      "Load .json metadata:  ./tmp/val/M_5d623f17ab783.json\n",
      "Load .json metadata:  ./tmp/val/B_basilica_angustias_granada4.json\n",
      "Load .json metadata:  ./tmp/val/B_catedral_guadix7.json\n",
      "Load .json metadata:  ./tmp/val/R_palacio_carlos_v_granada12.json\n",
      "Load .json metadata:  ./tmp/val/B_chancilleria_granada.json\n",
      "Load .json metadata:  ./tmp/val/G_puerta_apostoles_catedral_murcia6.json\n",
      "Load .json metadata:  ./tmp/val/G_iglesia_sabiote4.json\n",
      "Load .json metadata:  ./tmp/val/B_5d9dd3c5b2f16.json\n",
      "Load .json metadata:  ./tmp/val/G_5bc1aaf94ea6d.json\n",
      "Load .json metadata:  ./tmp/val/B_san_juan_dios_antequera.json\n",
      "Load .json metadata:  ./tmp/val/G_5bc9a70361bff.json\n",
      "Load .json metadata:  ./tmp/val/B_5c1cde9e6260a.json\n",
      "Load .json metadata:  ./tmp/val/M_5de6aa806cbef.json\n",
      "Load .json metadata:  ./tmp/val/B_colegio_san_telmo_sevilla.json\n",
      "Load .json metadata:  ./tmp/val/B_IMG_0358.json\n",
      "Load .json metadata:  ./tmp/val/G_palacio_salcedo.json\n",
      "Load .json metadata:  ./tmp/val/R_5d98bfa797969.json\n",
      "Load .json metadata:  ./tmp/val/R_5bc6037474c90.json\n",
      "Load .json metadata:  ./tmp/val/B_5c62af60bdd94.json\n",
      "Load .json metadata:  ./tmp/val/M_5e51856c4c5d0.json\n",
      "Load .json metadata:  ./tmp/val/G_5bb8e97e9badf.json\n",
      "Load .json metadata:  ./tmp/val/B_5babaafb202cf.json\n",
      "Load .json metadata:  ./tmp/val/R_convento_santa_clara_ubeda4.json\n",
      "Load .json metadata:  ./tmp/val/B_5e0354ada9bdf.json\n",
      "Load .json metadata:  ./tmp/val/B_5cf7f3fe6fcc7.json\n",
      "Load .json metadata:  ./tmp/val/M_medina_azahara4.json\n",
      "Load .json metadata:  ./tmp/val/R_5c15348990691.json\n",
      "Load .json metadata:  ./tmp/val/G_palacio_jabalquinto_baeza9.json\n",
      "Load .json metadata:  ./tmp/val/R_5be5e8d4933d2.json\n",
      "Load .json metadata:  ./tmp/val/R_palacio_carlos_v_granada10.json\n",
      "Load .json metadata:  ./tmp/val/R_5c0aaaa13f0d4.json\n",
      "Load .json metadata:  ./tmp/val/G_5c877f35824a9.json\n",
      "Load .json metadata:  ./tmp/val/G_capilla_real_granada5.json\n",
      "Load .json metadata:  ./tmp/val/G_puerta_apostoles_catedral_murcia.json\n",
      "Load .json metadata:  ./tmp/val/R_puerta_perdon_catedral_granada3.json\n",
      "Load .json metadata:  ./tmp/val/M_puerta_elvira_granada.json\n",
      "Load .json metadata:  ./tmp/val/G_5d9c62a9002f9.json\n",
      "Load .json metadata:  ./tmp/val/M_20181212_150308.json\n",
      "Load .json metadata:  ./tmp/val/R_catedral_santa_maria_sevilla2.json\n",
      "Load .json metadata:  ./tmp/val/G_5dd41c407dad2.json\n",
      "Load .json metadata:  ./tmp/val/B_5dfb6b3ec6d75.json\n",
      "Load .json metadata:  ./tmp/val/G_5c6299b35348d.json\n",
      "Load .json metadata:  ./tmp/val/R_ayuntamiento_sevilla8.json\n",
      "Load .json metadata:  ./tmp/val/R_iglesia_san_cecilio_granada.json\n",
      "Load .json metadata:  ./tmp/val/B_museo_bellas_artes_sevilla4.json\n",
      "Load .json metadata:  ./tmp/val/G_5bc4b0208afce.json\n",
      "Load .json metadata:  ./tmp/val/R_5ce91ca209e93.json\n",
      "Load .json metadata:  ./tmp/val/B_IMG_0340.json\n",
      "Load .json metadata:  ./tmp/val/M_5be567087517e.json\n",
      "Load .json metadata:  ./tmp/val/B_facultad_derecho_granada3.json\n",
      "Load .json metadata:  ./tmp/val/B_palacio_ansoti7.json\n",
      "Load .json metadata:  ./tmp/val/B_5c878f1213e55.json\n",
      "Load .json metadata:  ./tmp/val/B_catedral_guadix.json\n",
      "Load .json metadata:  ./tmp/val/B_5d53cdc09e048.json\n",
      "Load .json metadata:  ./tmp/val/B_iglesia_caridad_sevilla4.json\n",
      "Load .json metadata:  ./tmp/val/M_5bae5ed261c0c.json\n",
      "Load .json metadata:  ./tmp/val/M_5c961ed2964b2.json\n",
      "Load .json metadata:  ./tmp/val/B_casa_marqueses_de_cartagena_granada6.json\n",
      "Load .json metadata:  ./tmp/val/R_iglesia_san_cecilio_granada2.json\n",
      "Load .json metadata:  ./tmp/val/B_casa_monte_de_piedad_granada.json\n",
      "Load .json metadata:  ./tmp/val/G_5c82f5c3c0a67.json\n",
      "Load .json metadata:  ./tmp/val/G_puerta_infierno_catedral_toledo2.json\n",
      "Load .json metadata:  ./tmp/val/M_5c38866fefaad.json\n",
      "Load .json metadata:  ./tmp/val/B_5d9dcbbfc416a.json\n",
      "Load .json metadata:  ./tmp/val/B_5be98c369a004.json\n",
      "Load .json metadata:  ./tmp/val/B_5ba899636f449.json\n",
      "Load .json metadata:  ./tmp/val/B_5c8778ca611a2.json\n",
      "Load .json metadata:  ./tmp/val/B_5bc75e6119173.json\n",
      "Load .json metadata:  ./tmp/val/M_20181212_130052.json\n",
      "Load .json metadata:  ./tmp/val/M_5db2e635ab8ed.json\n",
      "Load .json metadata:  ./tmp/val/R_palacio_carlos_v_granada19.json\n",
      "Load .json metadata:  ./tmp/val/M_puerta_de_las_pesas_granada.json\n",
      "Load .json metadata:  ./tmp/val/M_5bcdf82621374.json\n",
      "Load .json metadata:  ./tmp/val/B_compas_convento_santa_isabel_granada.json\n",
      "Load .json metadata:  ./tmp/val/M_5bad4996b3cf4.json\n",
      "Load .json metadata:  ./tmp/val/M_5db2bfe305c0b.json\n",
      "Load .json metadata:  ./tmp/val/B_5bd0a549b5653.json\n",
      "Load .json metadata:  ./tmp/val/G_puerta_bautismo_catedral_sevilla.json\n",
      "Load .json metadata:  ./tmp/val/M_5d0383b7abaf0.json\n",
      "Load .json metadata:  ./tmp/val/R_iglesia_san_cecilio_granada3.json\n",
      "Load .json metadata:  ./tmp/val/M_5baf19070489a.json\n",
      "Load .json metadata:  ./tmp/val/M_corral_carbon_granada9.json\n",
      "Load .json metadata:  ./tmp/val/B_iglesia_san_basilio_granada.json\n",
      "Load .json metadata:  ./tmp/val/B_casa_cadenas_cadiz2.json\n",
      "Load .json metadata:  ./tmp/val/M_corral_carbon_granada.json\n",
      "Load .json metadata:  ./tmp/val/B_5c80d1f310860.json\n",
      "Load .json metadata:  ./tmp/val/G_5c67d9d394832.json\n",
      "Load .json metadata:  ./tmp/val/R_iglesia_anunciacion_sevilla2.json\n",
      "Load .json metadata:  ./tmp/val/B_iglesia_perpetuo_socorro_granada.json\n",
      "Load .json metadata:  ./tmp/val/G_5d98c6d57f872.json\n",
      "Load .json metadata:  ./tmp/val/B_5bed739fdf02e.json\n",
      "Load .json metadata:  ./tmp/val/B_5cf7e7d0e7106.json\n",
      "Load .json metadata:  ./tmp/val/G_5bc4b2d9006fc.json\n",
      "Load .json metadata:  ./tmp/val/R_catedral_puerta_san_jeronimo_granada.json\n",
      "Load .json metadata:  ./tmp/val/R_palacio_cadenas_ubeda4.json\n",
      "Load .json metadata:  ./tmp/val/M_20181212_112853.json\n",
      "Load .json metadata:  ./tmp/val/R_iglesia_santo_domingo_granada.json\n",
      "Load .json metadata:  ./tmp/val/G_5cadb7f561357.json\n",
      "Load .json metadata:  ./tmp/val/G_5cc07140b8e70.json\n",
      "Load .json metadata:  ./tmp/val/B_5bd2cda2a9579.json\n",
      "Load .json metadata:  ./tmp/val/B_convento_carmelitas_descalzas_granada5.json\n",
      "Load .json metadata:  ./tmp/val/B_basilica_angustias_granada.json\n",
      "Load .json metadata:  ./tmp/val/R_5bd33de5f3fa8.json\n",
      "Load .json metadata:  ./tmp/val/G_puerta_apostoles_catedral_murcia4.json\n",
      "Load .json metadata:  ./tmp/val/B_5bdd80e6ea7c8.json\n",
      "Load .json metadata:  ./tmp/val/G_iglesia_nuestra_señora_de_la_o_chipiona.json\n",
      "Load .json metadata:  ./tmp/val/G_iglesia_santa_maría_del_pi_barcelona.json\n",
      "Load .json metadata:  ./tmp/val/R_5db2c3759cdbd.json\n",
      "Load .json metadata:  ./tmp/val/B_palacio_bibataubin_granada3.json\n",
      "Load .json metadata:  ./tmp/val/G_pinaculo2.json\n",
      "Load .json metadata:  ./tmp/val/G_5c138466132c4.json\n",
      "Load .json metadata:  ./tmp/val/M_patio_doncella_reales_alcazares_sevilla.json\n",
      "Load .json metadata:  ./tmp/val/G_catedral_sevilla3.json\n",
      "Load .json metadata:  ./tmp/val/M_patio_doncella_reales_alcazares_sevilla5.json\n",
      "Load .json metadata:  ./tmp/val/B_5bae4188a9817.json\n",
      "Load .json metadata:  ./tmp/val/M_20181212_150258.json\n",
      "Load .json metadata:  ./tmp/val/G_pinaculo5.json\n",
      "Load .json metadata:  ./tmp/val/B_5bd074b099963.json\n",
      "Load .json metadata:  ./tmp/val/R_5bee96a235a67.json\n",
      "Load .json metadata:  ./tmp/val/M_corralcarbon.json\n",
      "Load .json metadata:  ./tmp/val/R_5bb5f65db689e.json\n",
      "Load .json metadata:  ./tmp/val/R_20181212_110256.json\n",
      "Load .json metadata:  ./tmp/val/B_5bc75e9246655.json\n",
      "Load .json metadata:  ./tmp/val/R_puerta_perdon_catedral_granada.json\n",
      "Load .json metadata:  ./tmp/val/R_palacio_carlos_v_granada9.json\n",
      "Load .json metadata:  ./tmp/val/B_IMG_1135.json\n",
      "Load .json metadata:  ./tmp/val/M_alcazaba_malaga.json\n",
      "Load .json metadata:  ./tmp/val/G_iglesia_san_pablo_ubeda2.json\n",
      "Load .json metadata:  ./tmp/val/G_5cb9a35070358.json\n",
      "Load .json metadata:  ./tmp/val/M_ermita_sansebastian3.json\n",
      "Load .json metadata:  ./tmp/val/G_5d4f11234ab2d.json\n",
      "Training del classificatore...\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib/python3.9/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.2633 - loss: 1.5962\n",
      "Epoch 2/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6631 - loss: 1.1123\n",
      "Epoch 3/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7745 - loss: 0.8357\n",
      "Epoch 4/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8367 - loss: 0.6472\n",
      "Epoch 5/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8759 - loss: 0.5063\n",
      "Epoch 6/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8959 - loss: 0.4216\n",
      "Epoch 7/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9176 - loss: 0.3524\n",
      "Epoch 8/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9260 - loss: 0.3117\n",
      "Epoch 9/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9140 - loss: 0.2923\n",
      "Epoch 10/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9288 - loss: 0.2671\n",
      "Epoch 11/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9222 - loss: 0.2522\n",
      "Epoch 12/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9455 - loss: 0.2110\n",
      "Epoch 13/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9330 - loss: 0.2280\n",
      "Epoch 14/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9338 - loss: 0.2046\n",
      "Epoch 15/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9364 - loss: 0.2003\n",
      "Epoch 16/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9321 - loss: 0.2031\n",
      "Epoch 17/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9276 - loss: 0.2070\n",
      "Epoch 18/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9320 - loss: 0.1831\n",
      "Epoch 19/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9214 - loss: 0.1996\n",
      "Epoch 20/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9480 - loss: 0.1559\n",
      "Epoch 21/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9472 - loss: 0.1705\n",
      "Epoch 22/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9471 - loss: 0.1408\n",
      "Epoch 23/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9463 - loss: 0.1543\n",
      "Epoch 24/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9401 - loss: 0.1500\n",
      "Epoch 25/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9480 - loss: 0.1419\n",
      "Epoch 26/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9448 - loss: 0.1494\n",
      "Epoch 27/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9537 - loss: 0.1345\n",
      "Epoch 28/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9346 - loss: 0.1549\n",
      "Epoch 29/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9388 - loss: 0.1440\n",
      "Epoch 30/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9420 - loss: 0.1373\n",
      "Epoch 31/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9535 - loss: 0.1429\n",
      "Epoch 32/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9524 - loss: 0.1269\n",
      "Epoch 33/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9492 - loss: 0.1531\n",
      "Epoch 34/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9540 - loss: 0.1192\n",
      "Epoch 35/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9539 - loss: 0.1361\n",
      "Epoch 36/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9597 - loss: 0.1214\n",
      "Epoch 37/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9553 - loss: 0.1295\n",
      "Epoch 38/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9349 - loss: 0.1755\n",
      "Epoch 39/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9339 - loss: 0.1646\n",
      "Epoch 40/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9431 - loss: 0.1431\n",
      "Epoch 41/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9527 - loss: 0.1326\n",
      "Epoch 42/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9530 - loss: 0.1288\n",
      "Epoch 43/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9466 - loss: 0.1474\n",
      "Epoch 44/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9420 - loss: 0.1571\n",
      "Epoch 45/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9413 - loss: 0.1538\n",
      "Epoch 46/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9536 - loss: 0.1237\n",
      "Epoch 47/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9586 - loss: 0.1194\n",
      "Epoch 48/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9657 - loss: 0.1079\n",
      "Epoch 49/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9512 - loss: 0.1304\n",
      "Epoch 50/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9535 - loss: 0.1342\n",
      "Epoch 51/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9530 - loss: 0.1159\n",
      "Epoch 52/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9543 - loss: 0.1207\n",
      "Epoch 53/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9578 - loss: 0.1133\n",
      "Epoch 54/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9545 - loss: 0.1105\n",
      "Epoch 55/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9598 - loss: 0.1133\n",
      "Epoch 56/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9642 - loss: 0.0996\n",
      "Epoch 57/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9637 - loss: 0.1102\n",
      "Epoch 58/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9586 - loss: 0.1140\n",
      "Epoch 59/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9582 - loss: 0.1102\n",
      "Epoch 60/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9572 - loss: 0.1198\n",
      "Epoch 61/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9556 - loss: 0.1246\n",
      "Epoch 62/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9534 - loss: 0.1170\n",
      "Epoch 63/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9542 - loss: 0.1137\n",
      "Epoch 64/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9610 - loss: 0.1029\n",
      "Epoch 65/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9568 - loss: 0.1071\n",
      "Epoch 66/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9491 - loss: 0.1348\n",
      "Epoch 67/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9564 - loss: 0.1129\n",
      "Epoch 68/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9591 - loss: 0.1074\n",
      "Epoch 69/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9621 - loss: 0.1054\n",
      "Epoch 70/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9547 - loss: 0.1110\n",
      "Epoch 71/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9440 - loss: 0.1260\n",
      "Epoch 72/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9573 - loss: 0.1053\n",
      "Epoch 73/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9657 - loss: 0.0987\n",
      "Epoch 74/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9658 - loss: 0.0978\n",
      "Epoch 75/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9673 - loss: 0.0950\n",
      "Epoch 76/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9618 - loss: 0.0960\n",
      "Epoch 77/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9641 - loss: 0.0988\n",
      "Epoch 78/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9504 - loss: 0.1328\n",
      "Epoch 79/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9471 - loss: 0.1256\n",
      "Epoch 80/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9652 - loss: 0.1064\n",
      "Epoch 81/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9496 - loss: 0.1217\n",
      "Epoch 82/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9459 - loss: 0.1144\n",
      "Epoch 83/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9596 - loss: 0.1086\n",
      "Epoch 84/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9604 - loss: 0.1011\n",
      "Epoch 85/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9394 - loss: 0.1499\n",
      "Epoch 86/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9564 - loss: 0.1087\n",
      "Epoch 87/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9567 - loss: 0.1111\n",
      "Epoch 88/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9554 - loss: 0.1073\n",
      "Epoch 89/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9688 - loss: 0.0846 \n",
      "Epoch 90/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9554 - loss: 0.1082\n",
      "Epoch 91/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9628 - loss: 0.1039\n",
      "Epoch 92/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9652 - loss: 0.0903\n",
      "Epoch 93/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9663 - loss: 0.0858\n",
      "Epoch 94/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9582 - loss: 0.1039\n",
      "Epoch 95/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9575 - loss: 0.1043\n",
      "Epoch 96/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9546 - loss: 0.1102\n",
      "Epoch 97/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9682 - loss: 0.0885\n",
      "Epoch 98/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9566 - loss: 0.1004\n",
      "Epoch 99/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9585 - loss: 0.0993\n",
      "Epoch 100/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9473 - loss: 0.1254\n",
      "Epoch 101/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9613 - loss: 0.1010\n",
      "Epoch 102/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9612 - loss: 0.0991\n",
      "Epoch 103/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9644 - loss: 0.0997\n",
      "Epoch 104/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9546 - loss: 0.1038\n",
      "Epoch 105/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9562 - loss: 0.0964\n",
      "Epoch 106/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9600 - loss: 0.0959\n",
      "Epoch 107/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9616 - loss: 0.1018\n",
      "Epoch 108/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9688 - loss: 0.0829\n",
      "Epoch 109/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9620 - loss: 0.0962\n",
      "Epoch 110/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9583 - loss: 0.0975\n",
      "Epoch 111/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9646 - loss: 0.0954\n",
      "Epoch 112/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9606 - loss: 0.1018\n",
      "Epoch 113/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9637 - loss: 0.0965\n",
      "Epoch 114/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9558 - loss: 0.1017\n",
      "Epoch 115/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9573 - loss: 0.1027\n",
      "Epoch 116/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9615 - loss: 0.0826\n",
      "Epoch 117/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9620 - loss: 0.0994\n",
      "Epoch 118/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9576 - loss: 0.1122\n",
      "Epoch 119/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9492 - loss: 0.1206\n",
      "Epoch 120/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9663 - loss: 0.0901\n",
      "Epoch 121/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9624 - loss: 0.1079\n",
      "Epoch 122/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9609 - loss: 0.0992\n",
      "Epoch 123/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9699 - loss: 0.0834\n",
      "Epoch 124/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9652 - loss: 0.0912\n",
      "Epoch 125/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9567 - loss: 0.0925\n",
      "Epoch 126/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9716 - loss: 0.0821\n",
      "Epoch 127/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9575 - loss: 0.0866\n",
      "Epoch 128/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9649 - loss: 0.0955\n",
      "Epoch 129/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9589 - loss: 0.0938 \n",
      "Epoch 130/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9703 - loss: 0.0896\n",
      "Epoch 131/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9596 - loss: 0.0900\n",
      "Epoch 132/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9688 - loss: 0.0859\n",
      "Epoch 133/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9670 - loss: 0.0810\n",
      "Epoch 134/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9673 - loss: 0.0854\n",
      "Epoch 135/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9699 - loss: 0.0866\n",
      "Epoch 136/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9559 - loss: 0.1069\n",
      "Epoch 137/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9537 - loss: 0.0945\n",
      "Epoch 138/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9609 - loss: 0.0911\n",
      "Epoch 139/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9562 - loss: 0.1025\n",
      "Epoch 140/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9557 - loss: 0.1088\n",
      "Epoch 141/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9573 - loss: 0.0983\n",
      "Epoch 142/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9520 - loss: 0.1042\n",
      "Epoch 143/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9662 - loss: 0.0750\n",
      "Epoch 144/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9613 - loss: 0.0911\n",
      "Epoch 145/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9662 - loss: 0.0934\n",
      "Epoch 146/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9571 - loss: 0.1024\n",
      "Epoch 147/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9549 - loss: 0.1075\n",
      "Epoch 148/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9695 - loss: 0.0711\n",
      "Epoch 149/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9531 - loss: 0.1090\n",
      "Epoch 150/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9690 - loss: 0.0810\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8754 - loss: 0.7587 \n",
      "Loss: 0.7306636571884155, Accuracy: 0.8811880946159363\n",
      "Calcolo degli SHAP values...\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 272 background data samples could cause slower run times. Consider using shap.sample(data, K) or shap.kmeans(data, K) to summarize the background as K samples.\n",
      "  0%|                                                                                                        | 0/303 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▎                                                                                               | 1/303 [00:00<02:19,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 794us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.292e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=2.050e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.854e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=1.025e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=2.470e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=6.066e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=3.033e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=3.407e-06, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=2.932e-05, with an active set of 16 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "  1%|▋                                                                                               | 2/303 [00:00<02:19,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 794us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▉                                                                                               | 3/303 [00:01<02:18,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 799us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=1.175e-06, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=7.174e-07, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=3.317e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=1.027e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=1.019e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=3.770e-05, with an active set of 16 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=6.784e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=3.316e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 10 iterations, alpha=3.365e-03, previous alpha=2.967e-03, with an active set of 9 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=5.821e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "  1%|█▎                                                                                              | 4/303 [00:01<02:18,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▌                                                                                              | 5/303 [00:02<02:17,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 795us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▉                                                                                              | 6/303 [00:02<02:17,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 792us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|██▏                                                                                             | 7/303 [00:03<02:17,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 792us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██▌                                                                                             | 8/303 [00:03<02:16,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██▊                                                                                             | 9/303 [00:04<02:16,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|███▏                                                                                           | 10/303 [00:04<02:15,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=8.724e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=4.927e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=3.415e-06, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=1.929e-06, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=6.323e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=5.489e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=1.518e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=9.521e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=1.880e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=1.392e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=6.961e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=4.026e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.699e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=6.787e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=4.106e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=7.509e-06, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "  4%|███▍                                                                                           | 11/303 [00:05<02:14,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 799us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▊                                                                                           | 12/303 [00:05<02:14,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|████                                                                                           | 13/303 [00:06<02:14,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 794us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████▍                                                                                          | 14/303 [00:06<02:13,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 799us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████▋                                                                                          | 15/303 [00:06<02:13,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 798us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|█████                                                                                          | 16/303 [00:07<02:12,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=7.009e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=6.125e-03, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=8.438e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=6.492e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.916e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 16 iterations, alpha=1.729e-03, previous alpha=9.724e-04, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=2.630e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 18 iterations, alpha=6.557e-04, previous alpha=4.786e-04, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=2.475e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=3.528e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 13 iterations, alpha=3.413e-03, previous alpha=3.406e-03, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      "  6%|█████▎                                                                                         | 17/303 [00:07<02:12,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=3.963e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=8.069e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 9 iterations, alpha=3.557e-03, previous alpha=3.556e-03, with an active set of 8 regressors.\n",
      "  warnings.warn(\n",
      "  6%|█████▋                                                                                         | 18/303 [00:08<02:12,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 794us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|█████▉                                                                                         | 19/303 [00:08<02:11,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 793us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██████▎                                                                                        | 20/303 [00:09<02:11,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=3.209e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=2.771e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.017e-02, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=2.397e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 18 iterations, alpha=2.208e-03, previous alpha=9.444e-04, with an active set of 11 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=4.648e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=4.648e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=2.324e-02, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 29 iterations, i.e. alpha=1.426e-03, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 29 iterations, i.e. alpha=7.445e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.681e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.293e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 10 iterations, alpha=1.228e-03, previous alpha=5.911e-04, with an active set of 9 regressors.\n",
      "  warnings.warn(\n",
      "  7%|██████▌                                                                                        | 21/303 [00:09<02:10,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 794us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██████▉                                                                                        | 22/303 [00:10<02:10,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 794us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|███████▏                                                                                       | 23/303 [00:10<02:09,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|███████▌                                                                                       | 24/303 [00:11<02:09,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|███████▊                                                                                       | 25/303 [00:11<02:09,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 18 iterations, alpha=3.318e-04, previous alpha=3.306e-04, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/shap/explainers/_kernel.py:707: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=4.625e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=4.147e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "  9%|████████▏                                                                                      | 26/303 [00:12<02:08,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 799us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|████████▍                                                                                      | 27/303 [00:12<02:07,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 794us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|████████▊                                                                                      | 28/303 [00:12<02:07,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█████████                                                                                      | 29/303 [00:13<02:06,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/shap/explainers/_kernel.py:707: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      " 10%|█████████▍                                                                                     | 30/303 [00:13<02:06,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█████████▋                                                                                     | 31/303 [00:14<02:06,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 799us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|██████████                                                                                     | 32/303 [00:14<02:05,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|██████████▎                                                                                    | 33/303 [00:15<02:05,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.276e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=6.380e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 10 iterations, alpha=6.371e-03, previous alpha=5.640e-03, with an active set of 7 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=2.135e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.068e-02, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=4.381e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 10 iterations, alpha=4.782e-03, previous alpha=2.467e-03, with an active set of 9 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=5.708e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=4.865e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 11 iterations, alpha=3.879e-03, previous alpha=2.770e-03, with an active set of 10 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=2.135e-02, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=2.942e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=9.833e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 11%|██████████▋                                                                                    | 34/303 [00:15<02:04,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|██████████▉                                                                                    | 35/303 [00:16<02:03,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|███████████▎                                                                                   | 36/303 [00:16<02:03,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=2.719e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=7.287e-04, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=6.758e-04, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 17 iterations, alpha=4.912e-04, previous alpha=2.679e-04, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=4.323e-04, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=1.198e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=6.328e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=2.080e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=1.561e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.120e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.007e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=3.907e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.895e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=3.007e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.056e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=6.056e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 15 iterations, alpha=8.854e-04, previous alpha=5.107e-05, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=5.328e-06, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 12%|███████████▌                                                                                   | 37/303 [00:17<02:03,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|███████████▉                                                                                   | 38/303 [00:17<02:02,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.254e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=8.753e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=4.377e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=4.369e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=2.188e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 24 iterations, alpha=8.548e-04, previous alpha=7.591e-04, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=3.450e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=3.450e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.725e-02, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.366e-02, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.188e-02, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=6.119e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=5.498e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=5.197e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 13 iterations, alpha=4.925e-03, previous alpha=3.723e-03, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=9.357e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=1.004e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.395e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=6.717e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=2.679e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=2.214e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.448e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.000e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.005e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=9.125e-05, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=3.413e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=2.561e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 15 iterations, alpha=2.544e-03, previous alpha=1.870e-06, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      " 13%|████████████▏                                                                                  | 39/303 [00:18<02:02,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|████████████▌                                                                                  | 40/303 [00:18<02:02,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=1.286e-06, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 24 iterations, alpha=2.290e-06, previous alpha=4.790e-07, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=6.582e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=2.561e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=1.223e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=4.967e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=4.578e-04, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=3.267e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.749e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=5.622e-05, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=2.151e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=9.540e-06, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 14%|████████████▊                                                                                  | 41/303 [00:18<02:01,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=4.061e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=4.659e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=4.405e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 25 iterations, alpha=3.262e-03, previous alpha=2.695e-03, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=2.001e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=3.050e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 8 iterations, alpha=2.944e-03, previous alpha=2.851e-03, with an active set of 7 regressors.\n",
      "  warnings.warn(\n",
      " 14%|█████████████▏                                                                                 | 42/303 [00:19<02:01,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.563e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=3.549e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=8.317e-04, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=6.080e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=4.323e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=2.152e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=1.137e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 19 iterations, alpha=5.506e-04, previous alpha=7.654e-05, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      " 14%|█████████████▍                                                                                 | 43/303 [00:19<02:00,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 28 iterations, alpha=1.719e-04, previous alpha=1.658e-04, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/shap/explainers/_kernel.py:707: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      " 15%|█████████████▊                                                                                 | 44/303 [00:20<02:00,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|██████████████                                                                                 | 45/303 [00:20<01:59,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 14 iterations, alpha=9.948e-04, previous alpha=9.895e-04, with an active set of 11 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/shap/explainers/_kernel.py:707: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      " 15%|██████████████▍                                                                                | 46/303 [00:21<01:59,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|██████████████▋                                                                                | 47/303 [00:21<01:58,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|███████████████                                                                                | 48/303 [00:22<01:58,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|███████████████▎                                                                               | 49/303 [00:22<01:57,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=7.531e-03, with an active set of 2 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=3.728e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 6 iterations, alpha=3.027e-03, previous alpha=2.914e-03, with an active set of 5 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=5.778e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=2.889e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 8 iterations, alpha=2.626e-03, previous alpha=2.296e-03, with an active set of 7 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=8.778e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=4.389e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 12 iterations, alpha=3.380e-02, previous alpha=2.844e-02, with an active set of 9 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=6.229e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=5.832e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=1.175e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=3.964e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 16 iterations, alpha=5.832e-04, previous alpha=3.459e-05, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      " 17%|███████████████▋                                                                               | 50/303 [00:23<01:57,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|███████████████▉                                                                               | 51/303 [00:23<01:56,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|████████████████▎                                                                              | 52/303 [00:24<01:56,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=5.648e-03, with an active set of 2 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=2.824e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=2.223e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=2.150e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.013e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=4.350e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.864e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.400e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=7.798e-05, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 15 iterations, alpha=9.175e-04, previous alpha=3.902e-05, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=6.075e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=3.038e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 7 iterations, alpha=2.425e-02, previous alpha=2.074e-02, with an active set of 6 regressors.\n",
      "  warnings.warn(\n",
      " 17%|████████████████▌                                                                              | 53/303 [00:24<01:55,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|████████████████▉                                                                              | 54/303 [00:25<01:55,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█████████████████▏                                                                             | 55/303 [00:25<01:55,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█████████████████▌                                                                             | 56/303 [00:25<01:54,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=2.308e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=9.444e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=2.254e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 16 iterations, alpha=2.234e-03, previous alpha=1.906e-03, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=3.464e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=8.215e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 13 iterations, alpha=7.078e-03, previous alpha=6.834e-03, with an active set of 10 regressors.\n",
      "  warnings.warn(\n",
      " 19%|█████████████████▊                                                                             | 57/303 [00:26<01:54,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=8.957e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=3.880e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 15 iterations, alpha=4.921e-04, previous alpha=1.932e-04, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      " 19%|██████████████████▏                                                                            | 58/303 [00:26<01:53,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=7.050e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=1.164e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 19 iterations, alpha=1.164e-03, previous alpha=1.163e-03, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=2.191e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 17 iterations, alpha=3.868e-04, previous alpha=3.775e-04, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      " 19%|██████████████████▍                                                                            | 59/303 [00:27<01:53,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██████████████████▊                                                                            | 60/303 [00:27<01:52,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████████████████▏                                                                           | 61/303 [00:28<01:52,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████████████████▍                                                                           | 62/303 [00:28<01:51,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=5.889e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=1.786e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=8.932e-06, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=7.838e-06, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.731e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=3.343e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=2.511e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.110e-03, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 14 iterations, alpha=1.270e-03, previous alpha=6.984e-04, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=1.794e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.085e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=4.767e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=3.909e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=3.672e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 11 iterations, alpha=3.419e-03, previous alpha=1.228e-03, with an active set of 10 regressors.\n",
      "  warnings.warn(\n",
      " 21%|███████████████████▊                                                                           | 63/303 [00:29<01:51,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|████████████████████                                                                           | 64/303 [00:29<01:50,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|████████████████████▍                                                                          | 65/303 [00:30<01:50,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=2.750e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.484e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.305e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=6.359e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=2.542e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.276e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=2.373e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=2.138e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=6.729e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=3.706e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.191e-03, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 15 iterations, alpha=1.838e-03, previous alpha=4.632e-04, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.221e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=8.673e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=5.040e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=2.446e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=5.682e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=1.615e-05, with an active set of 16 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 22%|████████████████████▋                                                                          | 66/303 [00:30<01:50,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|█████████████████████                                                                          | 67/303 [00:31<01:49,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|█████████████████████▎                                                                         | 68/303 [00:31<01:48,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|█████████████████████▋                                                                         | 69/303 [00:31<01:48,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 13 iterations, alpha=4.106e-04, previous alpha=4.106e-04, with an active set of 10 regressors.\n",
      "  warnings.warn(\n",
      " 23%|█████████████████████▉                                                                         | 70/303 [00:32<01:48,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██████████████████████▎                                                                        | 71/303 [00:32<01:47,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.471e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=3.874e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=3.861e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.685e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 16 iterations, alpha=1.690e-03, previous alpha=1.537e-03, with an active set of 9 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=4.330e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 13 iterations, alpha=6.685e-03, previous alpha=5.781e-03, with an active set of 10 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=4.959e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=2.351e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=9.406e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=9.291e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 14 iterations, alpha=9.512e-04, previous alpha=4.625e-04, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      " 24%|██████████████████████▌                                                                        | 72/303 [00:33<01:46,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██████████████████████▉                                                                        | 73/303 [00:33<01:46,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|███████████████████████▏                                                                       | 74/303 [00:34<01:46,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=2.481e-07, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 18 iterations, alpha=9.758e-05, previous alpha=8.339e-05, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      " 25%|███████████████████████▌                                                                       | 75/303 [00:34<01:45,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=6.244e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=5.014e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 15 iterations, alpha=4.429e-04, previous alpha=3.940e-04, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.476e-02, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=6.106e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=2.912e-03, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 18 iterations, alpha=2.306e-03, previous alpha=1.971e-03, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=4.473e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=1.682e-04, with an active set of 16 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 25%|███████████████████████▊                                                                       | 76/303 [00:35<01:45,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|████████████████████████▏                                                                      | 77/303 [00:35<01:45,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|████████████████████████▍                                                                      | 78/303 [00:36<01:44,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=2.446e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 21 iterations, alpha=3.310e-03, previous alpha=3.224e-03, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      " 26%|████████████████████████▊                                                                      | 79/303 [00:36<01:44,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|█████████████████████████                                                                      | 80/303 [00:37<01:43,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|█████████████████████████▍                                                                     | 81/303 [00:37<01:43,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|█████████████████████████▋                                                                     | 82/303 [00:38<01:42,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██████████████████████████                                                                     | 83/303 [00:38<01:42,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██████████████████████████▎                                                                    | 84/303 [00:38<01:41,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=8.386e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=3.858e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=2.264e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=2.146e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=5.549e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=4.358e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=2.145e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=1.187e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=6.086e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.121e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 28%|██████████████████████████▋                                                                    | 85/303 [00:39<01:41,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=2.445e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=1.223e-05, with an active set of 16 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=1.184e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=3.259e-05, with an active set of 16 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 28%|██████████████████████████▉                                                                    | 86/303 [00:39<01:40,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|███████████████████████████▎                                                                   | 87/303 [00:40<01:40,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 795us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|███████████████████████████▌                                                                   | 88/303 [00:40<01:39,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|███████████████████████████▉                                                                   | 89/303 [00:41<01:39,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████████████████████▏                                                                  | 90/303 [00:41<01:38,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████████████████████▌                                                                  | 91/303 [00:42<01:38,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 798us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=3.594e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 21 iterations, alpha=5.052e-04, previous alpha=4.958e-04, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 23 iterations, alpha=3.012e-05, previous alpha=1.998e-05, with an active set of 16 regressors.\n",
      "  warnings.warn(\n",
      " 30%|████████████████████████████▊                                                                  | 92/303 [00:42<01:37,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.139e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=3.328e-04, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=3.201e-04, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=1.255e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=5.006e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 18 iterations, alpha=2.021e-04, previous alpha=1.266e-05, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.491e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 18 iterations, alpha=1.294e-04, previous alpha=9.927e-05, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=3.380e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=3.210e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 14 iterations, alpha=2.960e-04, previous alpha=2.273e-04, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=2.670e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=7.144e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=7.789e-05, with an active set of 16 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 31%|█████████████████████████████▏                                                                 | 93/303 [00:43<01:37,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|█████████████████████████████▍                                                                 | 94/303 [00:43<01:36,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=2.770e-04, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.385e-04, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=3.388e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 15 iterations, alpha=3.298e-05, previous alpha=2.432e-05, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=2.700e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.350e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.329e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=6.751e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=6.672e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=2.377e-03, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=2.073e-03, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=7.036e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=1.503e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=7.516e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=2.630e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.771e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.546e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=7.267e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=3.793e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 19 iterations, alpha=1.596e-03, previous alpha=2.822e-05, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=5.996e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=2.998e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 14 iterations, alpha=9.442e-03, previous alpha=6.085e-03, with an active set of 11 regressors.\n",
      "  warnings.warn(\n",
      " 31%|█████████████████████████████▊                                                                 | 95/303 [00:44<01:36,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 794us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|██████████████████████████████                                                                 | 96/303 [00:44<01:35,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 792us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|██████████████████████████████▍                                                                | 97/303 [00:44<01:35,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=9.323e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.492e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.267e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=5.110e-04, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=4.507e-04, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.272e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=5.529e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=2.573e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=6.007e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.845e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.551e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=2.190e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=1.695e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=9.216e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=2.470e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.916e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.807e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=2.203e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.102e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=9.269e-05, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=2.354e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=8.934e-07, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 32%|██████████████████████████████▋                                                                | 98/303 [00:45<01:34,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 839us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███████████████████████████████                                                                | 99/303 [00:45<01:34,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 815us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.355e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.084e-04, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 11 iterations, alpha=1.033e-04, previous alpha=6.071e-05, with an active set of 10 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=9.984e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.146e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=3.797e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=3.372e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=7.927e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=1.703e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=5.126e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=2.614e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 16 iterations, alpha=1.912e-03, previous alpha=1.892e-03, with an active set of 11 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=6.635e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=3.317e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 19 iterations, alpha=3.317e-05, previous alpha=2.848e-05, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      " 33%|███████████████████████████████                                                               | 100/303 [00:46<01:34,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███████████████████████████████▎                                                              | 101/303 [00:46<01:33,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.211e-04, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.085e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=2.772e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 16 iterations, alpha=3.651e-05, previous alpha=1.466e-05, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=5.243e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=3.963e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=3.625e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=1.465e-03, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=1.069e-03, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=2.764e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=7.647e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=1.971e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=8.396e-06, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 22 iterations, alpha=1.932e-04, previous alpha=3.231e-06, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      " 34%|███████████████████████████████▋                                                              | 102/303 [00:47<02:02,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.929e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.822e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=8.775e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=8.623e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=4.310e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 17 iterations, alpha=6.110e-04, previous alpha=4.236e-04, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=6.778e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=2.139e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=3.415e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=2.778e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 22 iterations, alpha=2.727e-04, previous alpha=2.178e-04, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=4.767e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=2.839e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=5.895e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=2.620e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=4.605e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 17 iterations, alpha=2.614e-04, previous alpha=2.455e-04, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      " 34%|███████████████████████████████▉                                                              | 103/303 [00:48<01:53,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|████████████████████████████████▎                                                             | 104/303 [00:48<01:46,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=2.152e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=4.145e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=2.792e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=1.757e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 19 iterations, alpha=1.610e-04, previous alpha=1.233e-04, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.694e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=8.471e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=6.002e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 14 iterations, alpha=6.189e-04, previous alpha=3.346e-04, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      " 35%|████████████████████████████████▌                                                             | 105/303 [00:49<01:41,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|████████████████████████████████▉                                                             | 106/303 [00:49<01:38,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=2.017e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=3.511e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 13 iterations, alpha=2.910e-03, previous alpha=2.815e-03, with an active set of 10 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=4.493e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.180e-02, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=2.594e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=2.344e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 14 iterations, alpha=4.215e-03, previous alpha=2.142e-03, with an active set of 11 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=3.012e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=2.705e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 18 iterations, alpha=3.604e-04, previous alpha=1.474e-04, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=1.451e-03, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=5.481e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 18 iterations, alpha=5.481e-04, previous alpha=5.412e-04, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      " 35%|█████████████████████████████████▏                                                            | 107/303 [00:50<01:36,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|█████████████████████████████████▌                                                            | 108/303 [00:50<01:34,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=3.857e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=4.085e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 25 iterations, alpha=3.029e-03, previous alpha=2.320e-03, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=2.546e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=2.474e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.047e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=7.931e-04, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=4.041e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 16 iterations, alpha=3.997e-04, previous alpha=3.247e-04, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=3.989e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=7.962e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=3.399e-03, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=3.212e-03, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 16 iterations, alpha=3.038e-03, previous alpha=2.326e-03, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      " 36%|█████████████████████████████████▊                                                            | 109/303 [00:51<01:32,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.355e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.344e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 10 iterations, alpha=7.391e-04, previous alpha=6.059e-04, with an active set of 9 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.936e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.144e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 13 iterations, alpha=9.019e-04, previous alpha=8.803e-04, with an active set of 10 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=4.388e-05, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=1.882e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=1.851e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.668e-06, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.641e-06, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 36%|██████████████████████████████████▏                                                           | 110/303 [00:51<01:31,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|██████████████████████████████████▍                                                           | 111/303 [00:51<01:30,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.584e-02, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 29 iterations, i.e. alpha=3.009e-03, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=2.275e-03, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=3.805e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 16 iterations, alpha=2.097e-04, previous alpha=1.785e-04, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=3.384e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 37%|██████████████████████████████████▋                                                           | 112/303 [00:52<01:29,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███████████████████████████████████                                                           | 113/303 [00:52<01:29,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.024e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=2.110e-04, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=3.051e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=3.033e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=8.331e-04, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=8.315e-04, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=4.149e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=4.017e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=5.156e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=3.815e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=1.900e-05, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 38%|███████████████████████████████████▎                                                          | 114/303 [00:53<01:28,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███████████████████████████████████▋                                                          | 115/303 [00:53<01:27,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███████████████████████████████████▉                                                          | 116/303 [00:54<01:27,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|████████████████████████████████████▎                                                         | 117/303 [00:54<01:26,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|████████████████████████████████████▌                                                         | 118/303 [00:55<01:26,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|████████████████████████████████████▉                                                         | 119/303 [00:55<01:26,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████████████████████████▏                                                        | 120/303 [00:56<01:25,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████████████████████████▌                                                        | 121/303 [00:56<01:25,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.643e-04, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=8.215e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 19 iterations, alpha=3.300e-05, previous alpha=2.317e-05, with an active set of 16 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=2.373e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 28 iterations, alpha=2.069e-03, previous alpha=2.052e-03, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=8.777e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.460e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=2.918e-06, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 40%|█████████████████████████████████████▊                                                        | 122/303 [00:57<01:24,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=7.035e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=5.729e-03, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 32 iterations, alpha=3.254e-03, previous alpha=1.518e-03, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=2.079e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 18 iterations, alpha=2.079e-04, previous alpha=2.013e-04, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=2.843e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=6.511e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 13 iterations, alpha=5.788e-03, previous alpha=5.566e-03, with an active set of 10 regressors.\n",
      "  warnings.warn(\n",
      " 41%|██████████████████████████████████████▏                                                       | 123/303 [00:57<01:24,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|██████████████████████████████████████▍                                                       | 124/303 [00:58<01:23,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|██████████████████████████████████████▊                                                       | 125/303 [00:58<01:23,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|███████████████████████████████████████                                                       | 126/303 [00:58<01:22,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|███████████████████████████████████████▍                                                      | 127/303 [00:59<01:22,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=3.899e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.950e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=8.584e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=4.292e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=4.198e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.500e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.254e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 16 iterations, alpha=2.406e-03, previous alpha=7.759e-04, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.413e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=9.948e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=8.500e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=4.180e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=3.084e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=3.134e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=2.396e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 14 iterations, alpha=2.328e-04, previous alpha=2.255e-04, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      " 42%|███████████████████████████████████████▋                                                      | 128/303 [00:59<01:21,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=5.461e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=7.433e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=3.427e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=5.621e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 18 iterations, alpha=5.295e-05, previous alpha=3.048e-05, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=7.138e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=2.476e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=2.218e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 43%|████████████████████████████████████████                                                      | 129/303 [01:00<01:21,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████████████████████████████████████████▎                                                     | 130/303 [01:00<01:20,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████████████████████████████████████████▋                                                     | 131/303 [01:01<01:20,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████████████████████████████████████████▉                                                     | 132/303 [01:01<01:20,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|█████████████████████████████████████████▎                                                    | 133/303 [01:02<01:19,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|█████████████████████████████████████████▌                                                    | 134/303 [01:02<01:19,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=8.339e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=8.008e-04, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=5.102e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=1.101e-05, with an active set of 16 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=4.167e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=3.127e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=3.089e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.342e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=9.043e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 16 iterations, alpha=1.213e-03, previous alpha=5.612e-04, with an active set of 11 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=7.285e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.571e-02, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.558e-02, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=6.471e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 15 iterations, alpha=6.965e-03, previous alpha=2.570e-03, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.171e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 23 iterations, alpha=7.517e-05, previous alpha=7.390e-05, with an active set of 16 regressors.\n",
      "  warnings.warn(\n",
      " 45%|█████████████████████████████████████████▉                                                    | 135/303 [01:03<01:18,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/shap/explainers/_kernel.py:707: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 16 iterations, alpha=4.080e-04, previous alpha=3.978e-04, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      " 45%|██████████████████████████████████████████▏                                                   | 136/303 [01:03<01:18,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=4.658e-04, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=5.599e-05, with an active set of 16 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.880e-02, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 30 iterations, alpha=3.076e-03, previous alpha=1.692e-03, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=6.422e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 23 iterations, alpha=4.424e-04, previous alpha=4.423e-04, with an active set of 16 regressors.\n",
      "  warnings.warn(\n",
      " 45%|██████████████████████████████████████████▌                                                   | 137/303 [01:04<01:17,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|██████████████████████████████████████████▊                                                   | 138/303 [01:04<01:17,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=5.118e-05, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=1.309e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=1.244e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=2.586e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=4.596e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=2.219e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 17 iterations, alpha=3.940e-03, previous alpha=1.253e-03, with an active set of 10 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=7.835e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=1.178e-02, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=2.431e-03, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=1.947e-03, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=3.065e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=3.163e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 21 iterations, alpha=4.813e-03, previous alpha=4.813e-03, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      " 46%|███████████████████████████████████████████                                                   | 139/303 [01:05<01:16,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|███████████████████████████████████████████▍                                                  | 140/303 [01:05<01:16,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/shap/explainers/_kernel.py:707: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.934e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=7.009e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=3.235e-05, with an active set of 16 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=4.169e-05, with an active set of 16 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 47%|███████████████████████████████████████████▋                                                  | 141/303 [01:05<01:15,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████████████████████████████████████████████                                                  | 142/303 [01:06<01:15,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████████████████████████████████████████████▎                                                 | 143/303 [01:06<01:14,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████████████████████████████████████████████▋                                                 | 144/303 [01:07<01:14,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████████████████████████████████████████████▉                                                 | 145/303 [01:07<01:13,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|█████████████████████████████████████████████▎                                                | 146/303 [01:08<01:13,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|█████████████████████████████████████████████▌                                                | 147/303 [01:08<01:12,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|█████████████████████████████████████████████▉                                                | 148/303 [01:09<01:12,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=5.045e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=1.891e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=4.185e-04, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=2.640e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=2.543e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=2.170e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 12 iterations, alpha=2.425e-03, previous alpha=2.094e-03, with an active set of 9 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=2.528e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.198e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=5.368e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=2.283e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.423e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.219e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=3.904e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 14 iterations, alpha=2.033e-03, previous alpha=1.334e-04, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=6.945e-04, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=2.978e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.315e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=5.603e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=3.041e-05, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 49%|██████████████████████████████████████████████▏                                               | 149/303 [01:09<01:11,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████████████████████████████▌                                               | 150/303 [01:10<01:11,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████████████████████████████▊                                               | 151/303 [01:10<01:10,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=2.438e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=2.204e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 23 iterations, alpha=1.503e-04, previous alpha=1.281e-04, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=2.512e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.684e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 13 iterations, alpha=1.344e-03, previous alpha=5.710e-04, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=6.169e-05, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=2.135e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=1.038e-05, with an active set of 16 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.125e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=4.143e-04, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=3.640e-04, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.568e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.385e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 15 iterations, alpha=5.482e-04, previous alpha=1.343e-04, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      " 50%|███████████████████████████████████████████████▏                                              | 152/303 [01:11<01:10,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|███████████████████████████████████████████████▍                                              | 153/303 [01:11<01:10,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=3.545e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.282e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=6.716e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=5.088e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 17 iterations, alpha=5.449e-05, previous alpha=2.171e-05, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=5.442e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 51%|███████████████████████████████████████████████▊                                              | 154/303 [01:12<01:09,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=2.858e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.236e-02, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=9.250e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 11 iterations, alpha=1.155e-02, previous alpha=8.156e-03, with an active set of 10 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=2.002e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.857e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=8.285e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=7.889e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=3.467e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 15 iterations, alpha=4.767e-03, previous alpha=1.826e-03, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.635e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=4.054e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=4.054e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.949e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 51%|████████████████████████████████████████████████                                              | 155/303 [01:12<01:08,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|████████████████████████████████████████████████▍                                             | 156/303 [01:12<01:08,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=6.834e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 36 iterations, alpha=1.382e-03, previous alpha=9.380e-04, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.425e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=3.252e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=2.643e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.147e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 15 iterations, alpha=2.002e-04, previous alpha=5.895e-05, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=9.575e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=2.444e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=9.572e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=2.901e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 15 iterations, alpha=9.512e-05, previous alpha=1.567e-05, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=3.946e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=6.833e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 15 iterations, alpha=4.535e-03, previous alpha=4.285e-03, with an active set of 10 regressors.\n",
      "  warnings.warn(\n",
      " 52%|████████████████████████████████████████████████▋                                             | 157/303 [01:13<01:07,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=8.058e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=4.109e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=4.090e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=1.709e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 17 iterations, alpha=2.400e-03, previous alpha=1.701e-03, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=2.461e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=1.320e-03, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=1.219e-03, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 52%|█████████████████████████████████████████████████                                             | 158/303 [01:13<01:07,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=4.551e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 21 iterations, alpha=3.528e-04, previous alpha=3.179e-04, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/shap/explainers/_kernel.py:707: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=1.370e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=7.605e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=7.570e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 52%|█████████████████████████████████████████████████▎                                            | 159/303 [01:14<01:07,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=4.206e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=6.176e-05, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=2.357e-02, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=2.878e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=2.842e-05, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=6.098e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.488e-02, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=7.439e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=5.243e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 19 iterations, alpha=6.324e-03, previous alpha=1.976e-03, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      " 53%|█████████████████████████████████████████████████▋                                            | 160/303 [01:14<01:06,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████████████████████████████████████████████████▉                                            | 161/303 [01:15<01:06,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|██████████████████████████████████████████████████▎                                           | 162/303 [01:15<01:05,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=2.292e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.146e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.027e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 18 iterations, alpha=1.146e-04, previous alpha=7.658e-05, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=2.301e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.150e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 11 iterations, alpha=7.386e-03, previous alpha=6.210e-03, with an active set of 10 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=4.455e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=3.589e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=2.326e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.316e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=2.169e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 14 iterations, alpha=1.693e-03, previous alpha=2.042e-04, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=2.499e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=2.075e-02, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=2.625e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=2.271e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=2.195e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 54%|██████████████████████████████████████████████████▌                                           | 163/303 [01:16<01:05,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|██████████████████████████████████████████████████▉                                           | 164/303 [01:16<01:04,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|███████████████████████████████████████████████████▏                                          | 165/303 [01:17<01:04,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|███████████████████████████████████████████████████▍                                          | 166/303 [01:17<01:03,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|███████████████████████████████████████████████████▊                                          | 167/303 [01:18<01:03,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|████████████████████████████████████████████████████                                          | 168/303 [01:18<01:02,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|████████████████████████████████████████████████████▍                                         | 169/303 [01:19<01:02,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=3.325e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=1.071e-05, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=8.546e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=1.154e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=9.787e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=3.062e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=2.272e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 17 iterations, alpha=1.817e-04, previous alpha=1.015e-04, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=2.440e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=2.865e-05, with an active set of 16 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 56%|████████████████████████████████████████████████████▋                                         | 170/303 [01:19<01:01,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=8.841e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 14 iterations, alpha=8.637e-05, previous alpha=4.072e-05, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=7.374e-06, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=8.394e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=4.208e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=6.975e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 17 iterations, alpha=4.078e-04, previous alpha=6.128e-05, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      " 56%|█████████████████████████████████████████████████████                                         | 171/303 [01:19<01:01,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████████████████████████████████████████████████████▎                                        | 172/303 [01:20<01:00,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████████████████████████████████████████████████████▋                                        | 173/303 [01:20<01:00,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████████████████████████████████████████████████████▉                                        | 174/303 [01:21<01:00,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 15 iterations, alpha=1.368e-04, previous alpha=1.066e-04, with an active set of 10 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=5.280e-04, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=4.399e-04, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=2.097e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 15 iterations, alpha=3.267e-04, previous alpha=1.912e-04, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=8.408e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=5.578e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=3.846e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.833e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.710e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 13 iterations, alpha=2.104e-03, previous alpha=1.240e-03, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=2.154e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.077e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=9.685e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=6.308e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 8 iterations, alpha=5.874e-03, previous alpha=4.676e-03, with an active set of 7 regressors.\n",
      "  warnings.warn(\n",
      " 58%|██████████████████████████████████████████████████████▎                                       | 175/303 [01:21<00:59,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=3.113e-06, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=9.615e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=4.808e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=3.796e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=2.577e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.887e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.570e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 12 iterations, alpha=2.128e-03, previous alpha=1.175e-03, with an active set of 9 regressors.\n",
      "  warnings.warn(\n",
      " 58%|██████████████████████████████████████████████████████▌                                       | 176/303 [01:22<00:58,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|██████████████████████████████████████████████████████▉                                       | 177/303 [01:22<00:58,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|███████████████████████████████████████████████████████▏                                      | 178/303 [01:23<00:58,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=7.248e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=7.731e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=7.731e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=6.707e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=2.099e-03, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=2.099e-03, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=1.837e-03, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=2.193e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=2.138e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=6.654e-04, with an active set of 16 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=3.264e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=3.264e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=2.367e-03, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.560e-03, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=7.355e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=1.433e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.373e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=5.171e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.089e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 59%|███████████████████████████████████████████████████████▌                                      | 179/303 [01:23<00:57,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|███████████████████████████████████████████████████████▊                                      | 180/303 [01:24<00:57,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.255e-04, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=7.526e-05, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=7.159e-05, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=3.208e-05, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 14 iterations, alpha=3.535e-05, previous alpha=1.117e-05, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=5.749e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=1.623e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=4.930e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=2.111e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=6.249e-06, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 18 iterations, alpha=6.249e-06, previous alpha=5.172e-06, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=2.769e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=4.285e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 13 iterations, alpha=4.285e-03, previous alpha=4.247e-03, with an active set of 10 regressors.\n",
      "  warnings.warn(\n",
      " 60%|████████████████████████████████████████████████████████▏                                     | 181/303 [01:24<00:56,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=6.302e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=1.863e-05, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.272e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=2.608e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=1.075e-04, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 60%|████████████████████████████████████████████████████████▍                                     | 182/303 [01:25<00:56,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|████████████████████████████████████████████████████████▊                                     | 183/303 [01:25<00:55,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|█████████████████████████████████████████████████████████                                     | 184/303 [01:25<00:55,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=2.860e-04, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=2.732e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 18 iterations, alpha=2.686e-04, previous alpha=1.952e-05, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=4.983e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=2.080e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=9.792e-05, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=4.832e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=4.705e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=2.828e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 61%|█████████████████████████████████████████████████████████▍                                    | 185/303 [01:26<00:54,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=4.658e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.849e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.837e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=9.178e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=5.341e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=3.761e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=1.653e-03, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=2.757e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=4.546e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.289e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=6.343e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=3.011e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=2.831e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=9.759e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=9.336e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=4.495e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=2.160e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 61%|█████████████████████████████████████████████████████████▋                                    | 186/303 [01:26<00:54,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████████████████████████████████████████████████████████                                    | 187/303 [01:27<00:53,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████████████████████████████████████████████████████████▎                                   | 188/303 [01:27<00:53,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████████████████████████████████████████████████████████▋                                   | 189/303 [01:28<00:53,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████████████████████████████████████████████████████████▉                                   | 190/303 [01:28<00:52,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|███████████████████████████████████████████████████████████▎                                  | 191/303 [01:29<00:52,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|███████████████████████████████████████████████████████████▌                                  | 192/303 [01:29<00:51,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|███████████████████████████████████████████████████████████▊                                  | 193/303 [01:30<00:51,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=2.374e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=2.813e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.214e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=5.958e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=4.135e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=7.280e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=4.109e-03, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=1.728e-03, with an active set of 16 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=9.203e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=6.819e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 14 iterations, alpha=1.877e-03, previous alpha=1.194e-03, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      " 64%|████████████████████████████████████████████████████████████▏                                 | 194/303 [01:30<00:50,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|████████████████████████████████████████████████████████████▍                                 | 195/303 [01:31<00:50,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|████████████████████████████████████████████████████████████▊                                 | 196/303 [01:31<00:49,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=1.007e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=4.327e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=3.350e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=3.013e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 17 iterations, alpha=1.260e-03, previous alpha=1.022e-03, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.265e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.160e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=4.738e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=4.478e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=2.108e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.061e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=7.123e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=9.485e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=5.127e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=3.263e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=1.232e-03, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=1.238e-04, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.313e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.220e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=6.007e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=5.531e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 14 iterations, alpha=5.567e-04, previous alpha=4.269e-04, with an active set of 11 regressors.\n",
      "  warnings.warn(\n",
      " 65%|█████████████████████████████████████████████████████████████                                 | 197/303 [01:32<00:49,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|█████████████████████████████████████████████████████████████▍                                | 198/303 [01:32<00:49,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|█████████████████████████████████████████████████████████████▋                                | 199/303 [01:32<00:48,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████████████████████████████████████████████████████████████                                | 200/303 [01:33<00:48,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=2.481e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=3.011e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 15 iterations, alpha=1.489e-03, previous alpha=1.065e-03, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=2.693e-04, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.329e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=9.302e-05, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=1.828e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=6.287e-06, with an active set of 16 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=7.224e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.666e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 13 iterations, alpha=1.579e-03, previous alpha=1.548e-03, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=2.945e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.645e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 13 iterations, alpha=9.355e-04, previous alpha=6.161e-04, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      " 66%|██████████████████████████████████████████████████████████████▎                               | 201/303 [01:33<00:47,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=4.404e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 17 iterations, alpha=4.404e-04, previous alpha=3.473e-04, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 18 iterations, alpha=8.789e-04, previous alpha=8.610e-04, with an active set of 11 regressors.\n",
      "  warnings.warn(\n",
      " 67%|██████████████████████████████████████████████████████████████▋                               | 202/303 [01:34<00:47,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████████████████████████████████████████████████████████████▉                               | 203/303 [01:34<00:46,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|███████████████████████████████████████████████████████████████▎                              | 204/303 [01:35<00:46,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=3.397e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.975e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.613e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 20 iterations, alpha=8.321e-05, previous alpha=7.269e-05, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=1.466e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=6.544e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=3.635e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=1.123e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=1.325e-05, with an active set of 16 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=1.376e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=8.523e-03, with an active set of 2 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=5.197e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.660e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 11 iterations, alpha=1.823e-03, previous alpha=1.516e-03, with an active set of 10 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=3.511e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=7.850e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=2.297e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 18 iterations, alpha=1.521e-03, previous alpha=6.527e-04, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      " 68%|███████████████████████████████████████████████████████████████▌                              | 205/303 [01:35<00:45,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=8.330e-03, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 5 iterations, alpha=4.173e-03, previous alpha=4.162e-03, with an active set of 4 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=5.361e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 20 iterations, alpha=4.475e-04, previous alpha=4.475e-04, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      " 68%|███████████████████████████████████████████████████████████████▉                              | 206/303 [01:36<00:45,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=4.091e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=4.088e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=1.651e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=4.109e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=1.956e-04, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.163e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=5.640e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 12 iterations, alpha=5.936e-04, previous alpha=2.414e-04, with an active set of 11 regressors.\n",
      "  warnings.warn(\n",
      " 68%|████████████████████████████████████████████████████████████████▏                             | 207/303 [01:36<00:44,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|████████████████████████████████████████████████████████████████▌                             | 208/303 [01:37<00:44,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=5.097e-04, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=2.721e-04, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 13 iterations, alpha=2.721e-04, previous alpha=2.698e-04, with an active set of 10 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=1.238e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=9.910e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=2.528e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=2.024e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=7.637e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=2.558e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=4.742e-06, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=1.042e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=6.864e-06, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 69%|████████████████████████████████████████████████████████████████▊                             | 209/303 [01:37<00:43,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|█████████████████████████████████████████████████████████████████▏                            | 210/303 [01:38<00:43,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|█████████████████████████████████████████████████████████████████▍                            | 211/303 [01:38<00:42,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=4.582e-04, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=7.580e-05, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=3.790e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.321e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.218e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=3.111e-06, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.915e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=9.576e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=8.471e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=4.296e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=4.067e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=3.896e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.859e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 14 iterations, alpha=3.017e-03, previous alpha=1.499e-03, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=6.123e-04, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.650e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=5.269e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=6.010e-06, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=5.439e-06, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=9.398e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=4.622e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=4.467e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 10 iterations, alpha=4.502e-03, previous alpha=3.769e-03, with an active set of 9 regressors.\n",
      "  warnings.warn(\n",
      " 70%|█████████████████████████████████████████████████████████████████▊                            | 212/303 [01:39<00:42,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████████████████████████████████████████                            | 213/303 [01:39<00:41,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|██████████████████████████████████████████████████████████████████▍                           | 214/303 [01:39<00:41,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|██████████████████████████████████████████████████████████████████▋                           | 215/303 [01:40<00:40,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.234e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.984e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.806e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 20 iterations, alpha=1.429e-03, previous alpha=8.910e-04, with an active set of 11 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=5.335e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=4.610e-03, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=4.417e-03, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 28 iterations, alpha=4.117e-03, previous alpha=9.470e-04, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      " 71%|███████████████████████████████████████████████████████████████████                           | 216/303 [01:40<00:40,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████████████████████████████████████████████████████████████████▎                          | 217/303 [01:41<00:40,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=6.354e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=5.828e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=1.363e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=1.180e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 17 iterations, alpha=1.363e-04, previous alpha=8.791e-05, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      " 72%|███████████████████████████████████████████████████████████████████▋                          | 218/303 [01:41<00:39,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████████████████████████████████████████████████████████████████▉                          | 219/303 [01:42<00:39,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=1.752e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=3.503e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=4.410e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=1.053e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 24 iterations, alpha=2.161e-04, previous alpha=4.716e-05, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=2.019e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.867e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.672e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 13 iterations, alpha=1.612e-03, previous alpha=1.266e-03, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=5.049e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=3.998e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=1.440e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=1.140e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 73%|████████████████████████████████████████████████████████████████████▎                         | 220/303 [01:42<00:38,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|████████████████████████████████████████████████████████████████████▌                         | 221/303 [01:43<00:38,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|████████████████████████████████████████████████████████████████████▊                         | 222/303 [01:43<00:37,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|█████████████████████████████████████████████████████████████████████▏                        | 223/303 [01:44<00:37,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=2.803e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=4.405e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=6.938e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=4.957e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=1.319e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=2.054e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=9.940e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 12 iterations, alpha=1.060e-03, previous alpha=9.620e-04, with an active set of 11 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=3.995e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 17 iterations, alpha=3.995e-04, previous alpha=3.973e-04, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      " 74%|█████████████████████████████████████████████████████████████████████▍                        | 224/303 [01:44<00:36,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|█████████████████████████████████████████████████████████████████████▊                        | 225/303 [01:45<00:36,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|██████████████████████████████████████████████████████████████████████                        | 226/303 [01:45<00:35,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=1.537e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=1.473e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 24 iterations, alpha=6.278e-04, previous alpha=3.656e-04, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=2.212e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=8.756e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 9 iterations, alpha=8.501e-03, previous alpha=8.102e-03, with an active set of 8 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=9.903e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=6.386e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=2.802e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.251e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 15 iterations, alpha=8.337e-04, previous alpha=5.889e-04, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=3.969e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=1.725e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=1.269e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 75%|██████████████████████████████████████████████████████████████████████▍                       | 227/303 [01:46<00:35,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=2.947e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.176e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=4.828e-04, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 12 iterations, alpha=6.321e-04, previous alpha=2.975e-04, with an active set of 11 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=6.306e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=7.177e-03, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=3.484e-03, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=2.921e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 22 iterations, alpha=4.050e-04, previous alpha=2.387e-04, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      " 75%|██████████████████████████████████████████████████████████████████████▋                       | 228/303 [01:46<00:34,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████████████████████████████████████████████████████████████████████                       | 229/303 [01:46<00:34,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████████████████████████████████████████████████████████████████████▎                      | 230/303 [01:47<00:33,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████████████████████████████████████████████████████████████████████▋                      | 231/303 [01:47<00:33,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████████████████████████████████████████████████████████████████████▉                      | 232/303 [01:48<00:33,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=2.589e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.295e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.214e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=4.498e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 14 iterations, alpha=8.448e-04, previous alpha=4.218e-04, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.763e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=2.788e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=6.508e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 12 iterations, alpha=4.910e-04, previous alpha=2.886e-04, with an active set of 11 regressors.\n",
      "  warnings.warn(\n",
      " 77%|████████████████████████████████████████████████████████████████████████▎                     | 233/303 [01:48<00:32,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|████████████████████████████████████████████████████████████████████████▌                     | 234/303 [01:49<00:32,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|████████████████████████████████████████████████████████████████████████▉                     | 235/303 [01:49<00:31,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|█████████████████████████████████████████████████████████████████████████▏                    | 236/303 [01:50<00:31,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|█████████████████████████████████████████████████████████████████████████▌                    | 237/303 [01:50<00:30,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=1.714e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=8.568e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=2.439e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=2.220e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=7.923e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=4.983e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 15 iterations, alpha=1.724e-03, previous alpha=4.173e-04, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=2.446e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=1.223e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=9.247e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=4.607e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=3.615e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=3.370e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.588e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.553e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=7.011e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=1.944e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=1.139e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=9.152e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=2.634e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=2.495e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.226e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 13 iterations, alpha=4.621e-03, previous alpha=1.098e-03, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=5.004e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=2.502e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.955e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 11 iterations, alpha=9.611e-03, previous alpha=5.283e-03, with an active set of 10 regressors.\n",
      "  warnings.warn(\n",
      " 79%|█████████████████████████████████████████████████████████████████████████▊                    | 238/303 [01:51<00:30,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|██████████████████████████████████████████████████████████████████████████▏                   | 239/303 [01:51<00:29,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|██████████████████████████████████████████████████████████████████████████▍                   | 240/303 [01:52<00:29,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=5.013e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=1.204e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=1.815e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=1.444e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 80%|██████████████████████████████████████████████████████████████████████████▊                   | 241/303 [01:52<00:28,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=5.200e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=9.747e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=6.660e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 22 iterations, alpha=5.214e-04, previous alpha=3.822e-04, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      " 80%|███████████████████████████████████████████████████████████████████████████                   | 242/303 [01:52<00:28,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=5.173e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=4.421e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=3.878e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=3.491e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.707e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.417e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 12 iterations, alpha=2.167e-03, previous alpha=8.333e-04, with an active set of 11 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.840e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=6.430e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=5.079e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 17 iterations, alpha=4.107e-04, previous alpha=2.301e-04, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=3.104e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=9.146e-04, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 19 iterations, alpha=7.927e-04, previous alpha=4.950e-04, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      " 80%|███████████████████████████████████████████████████████████████████████████▍                  | 243/303 [01:53<00:27,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|███████████████████████████████████████████████████████████████████████████▋                  | 244/303 [01:53<00:27,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████████████████████████████████████████████████████████████████████████                  | 245/303 [01:54<00:26,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████████████████████████████████████████████████████████████████████████▎                 | 246/303 [01:54<00:26,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=1.079e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 20 iterations, alpha=9.617e-06, previous alpha=8.784e-06, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=4.407e-04, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=1.574e-04, with an active set of 16 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.324e-02, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=6.619e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=6.526e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 13 iterations, alpha=6.574e-03, previous alpha=6.426e-03, with an active set of 10 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=8.240e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=4.120e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.931e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.177e-03, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 14 iterations, alpha=1.827e-03, previous alpha=9.057e-04, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      " 82%|████████████████████████████████████████████████████████████████████████████▋                 | 247/303 [01:55<00:26,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████████████████████████████████████████████████████████████████████████▉                 | 248/303 [01:55<00:25,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|█████████████████████████████████████████████████████████████████████████████▏                | 249/303 [01:56<00:25,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|█████████████████████████████████████████████████████████████████████████████▌                | 250/303 [01:56<00:24,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=2.954e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=4.365e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 20 iterations, alpha=1.119e-03, previous alpha=1.107e-03, with an active set of 11 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=4.095e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=6.832e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 15 iterations, alpha=6.832e-04, previous alpha=5.205e-04, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      " 83%|█████████████████████████████████████████████████████████████████████████████▊                | 251/303 [01:57<00:24,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|██████████████████████████████████████████████████████████████████████████████▏               | 252/303 [01:57<00:23,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|██████████████████████████████████████████████████████████████████████████████▍               | 253/303 [01:58<00:23,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|██████████████████████████████████████████████████████████████████████████████▊               | 254/303 [01:58<00:22,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|███████████████████████████████████████████████████████████████████████████████               | 255/303 [01:59<00:22,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=8.998e-05, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=1.438e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=1.432e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=5.091e-06, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=5.080e-06, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=8.835e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.202e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=5.471e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=8.787e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 84%|███████████████████████████████████████████████████████████████████████████████▍              | 256/303 [01:59<00:21,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|███████████████████████████████████████████████████████████████████████████████▋              | 257/303 [01:59<00:21,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████████████████████████████████████████████████████████████████████████████              | 258/303 [02:00<00:20,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████████████████████████████████████████████████████████████████████████████▎             | 259/303 [02:00<00:20,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████████████████████████████████████████████████████████████████████████████▋             | 260/303 [02:01<00:20,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=1.137e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=5.170e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=1.377e-03, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=5.918e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=5.434e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=3.189e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=9.185e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=8.398e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=4.073e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=4.057e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=6.413e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 19 iterations, alpha=1.079e-03, previous alpha=8.305e-04, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      " 86%|████████████████████████████████████████████████████████████████████████████████▉             | 261/303 [02:01<00:19,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|█████████████████████████████████████████████████████████████████████████████████▎            | 262/303 [02:02<00:19,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=1.311e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 8 iterations, alpha=4.390e-03, previous alpha=4.390e-03, with an active set of 7 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=1.045e-01, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.690e-02, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.321e-02, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 20 iterations, alpha=3.399e-02, previous alpha=3.090e-03, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      " 87%|█████████████████████████████████████████████████████████████████████████████████▌            | 263/303 [02:02<00:18,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|█████████████████████████████████████████████████████████████████████████████████▉            | 264/303 [02:03<00:18,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|██████████████████████████████████████████████████████████████████████████████████▏           | 265/303 [02:03<00:17,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|██████████████████████████████████████████████████████████████████████████████████▌           | 266/303 [02:04<00:17,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|██████████████████████████████████████████████████████████████████████████████████▊           | 267/303 [02:04<00:16,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|███████████████████████████████████████████████████████████████████████████████████▏          | 268/303 [02:05<00:16,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|███████████████████████████████████████████████████████████████████████████████████▍          | 269/303 [02:05<00:15,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.314e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.948e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.863e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 16 iterations, alpha=1.585e-04, previous alpha=1.299e-04, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=4.937e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=3.097e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 11 iterations, alpha=1.719e-03, previous alpha=1.261e-03, with an active set of 10 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=4.036e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=3.701e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=3.622e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.164e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=3.685e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 16 iterations, alpha=3.068e-04, previous alpha=7.732e-05, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      " 89%|███████████████████████████████████████████████████████████████████████████████████▊          | 270/303 [02:06<00:15,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████████████████████████████████████████████████████████████████████████████████          | 271/303 [02:06<00:14,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████████████████████████████████████████████████████████████████████████████████▍         | 272/303 [02:06<00:14,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=2.143e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 32 iterations, i.e. alpha=8.877e-04, with an active set of 16 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=8.073e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=4.037e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 16 iterations, alpha=4.037e-04, previous alpha=6.620e-05, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      " 90%|████████████████████████████████████████████████████████████████████████████████████▋         | 273/303 [02:07<00:13,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████████████████████████████████████████████████████████████████████████████████         | 274/303 [02:07<00:13,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████████████████████████████████████████████████████████████████████████████████▎        | 275/303 [02:08<00:13,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=8.617e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=9.728e-04, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.125e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=5.735e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 14 iterations, alpha=9.972e-05, previous alpha=5.482e-05, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.039e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 24 iterations, alpha=7.827e-04, previous alpha=6.712e-04, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=3.586e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=2.467e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 22 iterations, alpha=2.467e-05, previous alpha=4.207e-06, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=2.477e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=6.637e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 28 iterations, alpha=6.637e-04, previous alpha=5.316e-04, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      " 91%|█████████████████████████████████████████████████████████████████████████████████████▌        | 276/303 [02:08<00:12,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=2.817e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=2.808e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=6.006e-06, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 17 iterations, alpha=2.217e-05, previous alpha=5.985e-06, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      " 91%|█████████████████████████████████████████████████████████████████████████████████████▉        | 277/303 [02:09<00:12,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|██████████████████████████████████████████████████████████████████████████████████████▏       | 278/303 [02:09<00:11,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|██████████████████████████████████████████████████████████████████████████████████████▌       | 279/303 [02:10<00:11,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|██████████████████████████████████████████████████████████████████████████████████████▊       | 280/303 [02:10<00:10,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|███████████████████████████████████████████████████████████████████████████████████████▏      | 281/303 [02:11<00:10,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|███████████████████████████████████████████████████████████████████████████████████████▍      | 282/303 [02:11<00:09,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=1.425e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 19 iterations, alpha=6.942e-04, previous alpha=3.957e-04, with an active set of 16 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=5.954e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=3.055e-04, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=7.219e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=2.866e-05, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 93%|███████████████████████████████████████████████████████████████████████████████████████▊      | 283/303 [02:12<00:09,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=6.409e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=3.205e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=2.754e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.837e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.563e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=7.414e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=6.072e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=5.974e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=3.931e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.557e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.557e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=5.226e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=5.226e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.538e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=7.688e-04, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=3.580e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=3.325e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.863e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=3.065e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.989e-06, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=1.144e-01, with an active set of 1 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=6.263e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 16 iterations, alpha=3.616e-02, previous alpha=1.866e-02, with an active set of 11 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=3.139e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.569e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 10 iterations, alpha=1.177e-02, previous alpha=1.073e-02, with an active set of 7 regressors.\n",
      "  warnings.warn(\n",
      " 94%|████████████████████████████████████████████████████████████████████████████████████████      | 284/303 [02:12<00:08,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|████████████████████████████████████████████████████████████████████████████████████████▍     | 285/303 [02:13<00:08,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|████████████████████████████████████████████████████████████████████████████████████████▋     | 286/303 [02:13<00:07,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.997e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=1.119e-03, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=6.518e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=4.500e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 20 iterations, alpha=2.573e-04, previous alpha=1.596e-04, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=8.698e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.862e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=4.627e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 21 iterations, alpha=4.541e-04, previous alpha=1.656e-04, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      " 95%|█████████████████████████████████████████████████████████████████████████████████████████     | 287/303 [02:13<00:07,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=8.204e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=9.875e-04, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 13 iterations, alpha=9.875e-04, previous alpha=9.868e-04, with an active set of 8 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 19 iterations, alpha=2.472e-04, previous alpha=1.417e-04, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=4.644e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 15 iterations, alpha=4.644e-04, previous alpha=4.431e-04, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      " 95%|█████████████████████████████████████████████████████████████████████████████████████████▎    | 288/303 [02:14<00:06,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=8.105e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=6.765e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 18 iterations, alpha=3.558e-03, previous alpha=3.349e-03, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=5.315e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=5.086e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=3.268e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.964e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=6.485e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=5.913e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=2.391e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 16 iterations, alpha=1.432e-03, previous alpha=4.964e-05, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=2.122e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=3.604e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=6.965e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 22 iterations, alpha=3.435e-04, previous alpha=3.343e-04, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      " 95%|█████████████████████████████████████████████████████████████████████████████████████████▋    | 289/303 [02:14<00:06,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=1.227e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=6.134e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=5.136e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=5.114e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=2.248e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 14 iterations, alpha=1.787e-03, previous alpha=8.098e-04, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=3.182e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.591e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.318e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=6.340e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=5.287e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=2.402e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=2.341e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.957e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 13 iterations, alpha=3.555e-03, previous alpha=1.412e-03, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=1.500e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.117e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=3.974e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 96%|█████████████████████████████████████████████████████████████████████████████████████████▉    | 290/303 [02:15<00:06,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|██████████████████████████████████████████████████████████████████████████████████████████▎   | 291/303 [02:15<00:05,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=3.240e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=5.354e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 23 iterations, alpha=6.007e-04, previous alpha=3.816e-04, with an active set of 16 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.919e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=4.173e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 16 iterations, alpha=1.286e-03, previous alpha=1.081e-03, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=9.128e-03, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=3.905e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.220e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 13 iterations, alpha=8.731e-04, previous alpha=6.143e-04, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=5.481e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=8.784e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 21 iterations, alpha=3.928e-03, previous alpha=3.529e-03, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      " 96%|██████████████████████████████████████████████████████████████████████████████████████████▌   | 292/303 [02:16<00:05,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|██████████████████████████████████████████████████████████████████████████████████████████▉   | 293/303 [02:16<00:04,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|███████████████████████████████████████████████████████████████████████████████████████████▏  | 294/303 [02:17<00:04,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|███████████████████████████████████████████████████████████████████████████████████████████▌  | 295/303 [02:17<00:03,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 864us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|███████████████████████████████████████████████████████████████████████████████████████████▊  | 296/303 [02:18<00:03,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|████████████████████████████████████████████████████████████████████████████████████████████▏ | 297/303 [02:18<00:02,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|████████████████████████████████████████████████████████████████████████████████████████████▍ | 298/303 [02:19<00:02,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|████████████████████████████████████████████████████████████████████████████████████████████▊ | 299/303 [02:19<00:01,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████████████████████████████████████████████████████████████████████████████████████████ | 300/303 [02:19<00:01,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.420e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=4.315e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 17 iterations, alpha=4.315e-05, previous alpha=4.259e-05, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=5.909e-04, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=3.453e-04, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=3.406e-04, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 14 iterations, alpha=1.783e-04, previous alpha=1.695e-04, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.191e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 15 iterations, alpha=1.191e-04, previous alpha=1.175e-04, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      " 99%|█████████████████████████████████████████████████████████████████████████████████████████████▍| 301/303 [02:20<00:00,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████▋| 302/303 [02:20<00:00,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████| 303/303 [02:21<00:00,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAP values calcolati.\n",
      "SHAP values per classe 0: [[-0.11065293  0.0485753   0.05319008  0.00649755]\n",
      " [-0.01168253  0.01709185  0.         -0.00699601]\n",
      " [-0.02589265  0.0211927   0.          0.        ]\n",
      " [-0.03005368  0.33083352 -0.22395023 -0.05129408]\n",
      " [ 0.          0.          0.00872842  0.        ]]\n",
      "SHAP values per classe 1: [[-0.08211508  0.          0.          0.08435917]\n",
      " [-0.01494277  0.          0.          0.02291864]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.06457764  0.04412776  0.01975446]\n",
      " [ 0.         -0.02326559  0.02367596  0.        ]]\n",
      "SHAP values per classe 2: [[-0.08007579  0.          0.24471511  0.        ]\n",
      " [-0.00542465  0.05067285  0.          0.03939567]\n",
      " [ 0.         -0.07088034  0.          0.        ]\n",
      " [ 0.         -0.06464438  0.          0.01790336]\n",
      " [ 0.         -0.02008071  0.          0.        ]]\n",
      "SHAP values per classe 3: [[-0.11387735 -0.08277041  0.14714637  0.        ]\n",
      " [-0.00096418  0.         -0.00059376  0.        ]\n",
      " [ 0.          0.          0.         -0.05258764]\n",
      " [ 0.         -0.01767886  0.04686651  0.        ]\n",
      " [-0.0043403   0.          0.01555873  0.        ]]\n",
      "SHAP values per classe 4: [[-0.14384863  0.          0.04446902  0.10745433]\n",
      " [-0.00509685  0.          0.          0.        ]\n",
      " [-0.02453831  0.          0.          0.        ]\n",
      " [-0.00630603  0.         -0.12532777  0.14384073]\n",
      " [ 0.          0.          0.          0.04410596]]\n",
      "SHAP values per classe 5: [[-0.12356877  0.02570859  0.          0.02732378]\n",
      " [-0.0128493   0.          0.01348881  0.        ]\n",
      " [-0.01611805  0.04442486  0.         -0.03005248]\n",
      " [-0.03587318  0.40880141 -0.18810937 -0.1250779 ]\n",
      " [ 0.          0.          0.          0.0122708 ]]\n",
      "SHAP values per classe 6: [[-0.11044457 -0.00297271  0.07679708  0.0103451 ]\n",
      " [-0.00682435  0.          0.          0.0103025 ]\n",
      " [ 0.          0.          0.          0.02372773]\n",
      " [ 0.         -0.076516    0.03916636  0.01982951]\n",
      " [ 0.         -0.01920908  0.          0.        ]]\n",
      "SHAP values per classe 7: [[-0.06290191  0.          0.          0.02658836]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.00629858 -0.06108578  0.          0.03455975]\n",
      " [ 0.         -0.01158902  0.          0.00617939]\n",
      " [ 0.         -0.02284771  0.02676988  0.        ]]\n",
      "SHAP values per classe 8: [[-0.04306451  0.01133738  0.03714126  0.        ]\n",
      " [ 0.         -0.06976721 -0.09191157  0.        ]\n",
      " [ 0.         -0.08640977 -0.18888454  0.        ]\n",
      " [ 0.         -0.03992476  0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 9: [[-0.0778118   0.0102008   0.06722213  0.00660822]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.02807737  0.        ]\n",
      " [ 0.         -0.03273601  0.          0.01935802]\n",
      " [-0.01328008  0.04611648 -0.03241569  0.01857468]]\n",
      "SHAP values per classe 10: [[-0.11230114  0.          0.03904041  0.05309252]\n",
      " [-0.00665879  0.          0.          0.01310823]\n",
      " [ 0.          0.          0.          0.01047804]\n",
      " [ 0.         -0.05139402  0.01969343  0.02309825]\n",
      " [ 0.         -0.0850381   0.11406873  0.0120496 ]]\n",
      "SHAP values per classe 11: [[-0.11998151 -0.04464675  0.11898695  0.04257117]\n",
      " [-0.0121546  -0.05115238  0.050333    0.02104452]\n",
      " [ 0.         -0.02448026  0.01326263 -0.00534798]\n",
      " [ 0.         -0.12903254  0.11227831  0.        ]\n",
      " [ 0.         -0.05874175  0.06434934 -0.00875837]]\n",
      "SHAP values per classe 12: [[-0.05537206  0.01968624  0.          0.        ]\n",
      " [ 0.          0.01746732  0.         -0.0097103 ]\n",
      " [-0.00966711  0.0073377   0.          0.        ]\n",
      " [-0.0258291   0.14401963 -0.02538441 -0.08545645]\n",
      " [-0.03513426  0.12051889 -0.08112598  0.        ]]\n",
      "SHAP values per classe 13: [[-0.10080892  0.          0.08846767  0.        ]\n",
      " [ 0.          0.          0.         -0.07238035]\n",
      " [-0.00865202  0.          0.01144467  0.        ]\n",
      " [-0.00356568 -0.08205919  0.05724819  0.00372253]\n",
      " [ 0.         -0.03759158  0.          0.        ]]\n",
      "SHAP values per classe 14: [[-0.0515588   0.          0.0554933   0.        ]\n",
      " [-0.00902589  0.          0.         -0.00815549]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.09663764  0.76491901 -0.48863265 -0.17435152]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 15: [[-0.13134555 -0.04803323  0.05971462  0.06825942]\n",
      " [ 0.         -0.02194984  0.02415278  0.        ]\n",
      " [-0.00896875  0.00193136  0.          0.00816735]\n",
      " [ 0.         -0.0614524   0.03242719  0.01982828]\n",
      " [ 0.         -0.01910778  0.0298504   0.        ]]\n",
      "SHAP values per classe 16: [[ 0.35894557 -0.20714898 -0.09650423 -0.0538955 ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.10435274  0.          0.          0.00340802]\n",
      " [ 0.02789996 -0.07573838  0.          0.        ]\n",
      " [-0.03699888 -0.08731993  0.          0.        ]]\n",
      "SHAP values per classe 17: [[ 0.58584966 -0.22474916 -0.22149519 -0.17413584]\n",
      " [ 0.          0.00160962  0.          0.        ]\n",
      " [ 0.          0.          0.         -0.00220645]\n",
      " [ 0.02630087 -0.06453632  0.03767707  0.        ]\n",
      " [ 0.         -0.11297021  0.          0.        ]]\n",
      "SHAP values per classe 18: [[-0.07370597  0.          0.          0.        ]\n",
      " [ 0.         -0.01653094  0.          0.        ]\n",
      " [-0.00343368  0.          0.          0.        ]\n",
      " [ 0.         -0.02908115  0.          0.        ]\n",
      " [ 0.         -0.0159742   0.          0.        ]]\n",
      "SHAP values per classe 19: [[-0.04986887  0.         -0.00032212  0.01260964]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.07498312  0.06261843  0.        ]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 20: [[-0.11010754  0.          0.09022212  0.        ]\n",
      " [-0.02134851  0.          0.02922977  0.        ]\n",
      " [ 0.03944842 -0.01210887  0.17309818 -0.19817329]\n",
      " [ 0.         -0.08179326  0.06216746  0.00624595]\n",
      " [ 0.         -0.0669989   0.06822049  0.        ]]\n",
      "SHAP values per classe 21: [[-0.04123797 -0.01977022  0.          0.00538584]\n",
      " [ 0.          0.          0.00912668  0.        ]\n",
      " [ 0.          0.          0.          0.03477779]\n",
      " [ 0.         -0.08116537  0.06307612  0.        ]\n",
      " [ 0.         -0.03076753  0.03264149  0.        ]]\n",
      "SHAP values per classe 22: [[ 0.          0.0554573   0.          0.        ]\n",
      " [ 0.06481258  0.          0.04804171 -0.0795846 ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.25634611  0.56155566 -0.18363928 -0.08053163]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 23: [[ 0.         -0.01509625  0.          0.        ]\n",
      " [ 0.46462787 -0.07179826 -0.14655185 -0.17804145]\n",
      " [ 0.         -0.00133627  0.         -0.01098513]\n",
      " [ 0.07598008 -0.11487042  0.          0.        ]\n",
      " [ 0.03318068 -0.03259683  0.          0.        ]]\n",
      "SHAP values per classe 24: [[-0.13955173  0.          0.05650003  0.        ]\n",
      " [-0.0088048   0.          0.          0.02241675]\n",
      " [ 0.          0.          0.          0.07455763]\n",
      " [ 0.         -0.09678644  0.09216561  0.04214534]\n",
      " [-0.00786886  0.01173316 -0.15774007  0.0635626 ]]\n",
      "SHAP values per classe 25: [[-0.0611599   0.02775097 -0.01787518  0.07446737]\n",
      " [-0.01057171  0.          0.          0.04552677]\n",
      " [-0.00687794  0.         -0.0437271   0.0526708 ]\n",
      " [ 0.         -0.09207876  0.          0.04714915]\n",
      " [ 0.          0.          0.          0.02121463]]\n",
      "SHAP values per classe 26: [[-0.10693087  0.06548945  0.03372371  0.        ]\n",
      " [-0.0177182   0.0185457   0.          0.        ]\n",
      " [-0.01320356  0.          0.          0.        ]\n",
      " [ 0.          0.          0.04553684  0.03179119]\n",
      " [-0.04971833  0.4164469  -0.31902705 -0.03657618]]\n",
      "SHAP values per classe 27: [[-0.12930344  0.          0.11715367  0.        ]\n",
      " [-0.01356788  0.02321675  0.00170348 -0.01625955]\n",
      " [ 0.          0.01005719  0.          0.        ]\n",
      " [ 0.         -0.0708357   0.05346987  0.        ]\n",
      " [ 0.         -0.00980341  0.06197373 -0.04721361]]\n",
      "SHAP values per classe 28: [[ 0.60451021 -0.08542684 -0.3633969  -0.15057291]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.09411889 -0.0419817   0.         -0.08144129]\n",
      " [ 0.0180876  -0.05679155  0.03344269  0.        ]\n",
      " [ 0.         -0.044127    0.0579852   0.        ]]\n",
      "SHAP values per classe 29: [[ 0.38836344 -0.11509596 -0.13248761 -0.12566324]\n",
      " [ 0.03524571 -0.08805304  0.          0.03918065]\n",
      " [ 0.          0.          0.         -0.01008972]\n",
      " [ 0.07917689 -0.12363843  0.05063704  0.        ]\n",
      " [ 0.04612135 -0.05746971  0.02462919  0.        ]]\n",
      "SHAP values per classe 30: [[ 0.57931768 -0.23434302 -0.17651267 -0.16125502]\n",
      " [ 0.          0.07905323  0.         -0.02762567]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.03224331 -0.02744975  0.          0.        ]\n",
      " [ 0.02716221 -0.0270923   0.05769543  0.        ]]\n",
      "SHAP values per classe 31: [[-0.0456939   0.          0.10115425 -0.04616769]\n",
      " [ 0.          0.          0.03756401 -0.02224625]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.05223166  0.03009733  0.        ]\n",
      " [ 0.         -0.02524448  0.05004466 -0.03722248]]\n",
      "SHAP values per classe 32: [[-0.07104924  0.164833    0.          0.        ]\n",
      " [ 0.         -0.00205443  0.          0.        ]\n",
      " [-0.00439634  0.00407706  0.          0.00751411]\n",
      " [-0.01742885 -0.12208332  0.          0.12751949]\n",
      " [-0.00321134 -0.05930855  0.03463359  0.        ]]\n",
      "SHAP values per classe 33: [[-0.1099855   0.          0.          0.06367776]\n",
      " [-0.00774552  0.05432015  0.          0.        ]\n",
      " [ 0.          0.          0.          0.01791   ]\n",
      " [ 0.         -0.00531096  0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 34: [[ 0.58312764 -0.14265034 -0.23068158 -0.19284001]\n",
      " [-0.00147258  0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.12849571  0.          0.        ]\n",
      " [ 0.02237214 -0.03464376  0.          0.        ]]\n",
      "SHAP values per classe 35: [[-0.11282339  0.          0.04171427  0.04705368]\n",
      " [-0.05356837  0.          0.05473982  0.        ]\n",
      " [-0.00781186  0.          0.          0.01653109]\n",
      " [ 0.         -0.13122486  0.09599755  0.05108232]\n",
      " [-0.00189426 -0.07398488  0.05795417  0.02150889]]\n",
      "SHAP values per classe 36: [[-0.06248667  0.          0.02804433  0.03115858]\n",
      " [-0.00558975  0.          0.          0.        ]\n",
      " [ 0.         -0.0089267   0.          0.01712497]\n",
      " [ 0.         -0.04907208  0.          0.01802493]\n",
      " [ 0.         -0.01113373  0.02395658  0.        ]]\n",
      "SHAP values per classe 37: [[-0.1241816   0.          0.09935279  0.03027771]\n",
      " [-0.02252834  0.05619865  0.          0.        ]\n",
      " [-0.02851289  0.04518845  0.          0.        ]\n",
      " [ 0.          0.25126035 -0.16226975 -0.05453483]\n",
      " [ 0.         -0.10797809  0.02958715  0.02614212]]\n",
      "SHAP values per classe 38: [[-0.07605779 -0.20724339  0.04193289  0.        ]\n",
      " [-0.0254014   0.11302346 -0.00438687  0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.03934574  0.20615216 -0.06235137 -0.12817132]\n",
      " [-0.01964914  0.0909725  -0.13256907  0.04488744]]\n",
      "SHAP values per classe 39: [[-0.10880127  0.          0.04633484  0.        ]\n",
      " [-0.01455436  0.          0.01678695  0.01721203]\n",
      " [-0.01064566 -0.04164246  0.          0.01266527]\n",
      " [ 0.         -0.06617302  0.05583568  0.01629417]\n",
      " [-0.00889638 -0.00726344  0.0422186   0.02538787]]\n",
      "SHAP values per classe 40: [[ 0.72523335 -0.10901407 -0.32484787 -0.21878477]\n",
      " [ 0.          0.          0.02647737  0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.02572843 -0.12027111  0.          0.        ]\n",
      " [ 0.          0.          0.04800794  0.        ]]\n",
      "SHAP values per classe 41: [[ 0.51993378 -0.06195594 -0.07484316 -0.07711409]\n",
      " [ 0.          0.         -0.00173304  0.        ]\n",
      " [-0.00467414  0.03573445 -0.0197379   0.        ]\n",
      " [ 0.06150494  0.          0.          0.        ]\n",
      " [ 0.         -0.15495218  0.          0.        ]]\n",
      "SHAP values per classe 42: [[ 0.         -0.04661637  0.          0.        ]\n",
      " [-0.01061756  0.         -0.00918289  0.05733433]\n",
      " [ 0.         -0.00067378 -0.04280086  0.03185179]\n",
      " [ 0.         -0.09785172  0.03550422  0.03390282]\n",
      " [ 0.          0.          0.          0.06381215]]\n",
      "SHAP values per classe 43: [[-0.06231102  0.01666932  0.4492078  -0.35282915]\n",
      " [-0.00863453  0.04046892  0.00663093  0.00436697]\n",
      " [ 0.          0.         -0.0216243   0.03689317]\n",
      " [ 0.         -0.10616197 -0.26418179  0.36431665]\n",
      " [ 0.         -0.02805755  0.03794272 -0.02115822]]\n",
      "SHAP values per classe 44: [[ 0.4856096  -0.096816   -0.22139653 -0.11647884]\n",
      " [ 0.00461614  0.          0.         -0.03175341]\n",
      " [ 0.06801865 -0.05556215  0.08435346 -0.10841896]\n",
      " [ 0.         -0.04014258  0.03882826  0.        ]\n",
      " [ 0.         -0.00943129  0.          0.        ]]\n",
      "SHAP values per classe 45: [[-0.11457208  0.          0.04578096  0.06831598]\n",
      " [-0.01847641  0.          0.          0.        ]\n",
      " [ 0.          0.         -0.0349881   0.03442507]\n",
      " [-0.01392239 -0.12527377  0.          0.        ]\n",
      " [-0.00919992 -0.05322466  0.03676165  0.01548536]]\n",
      "SHAP values per classe 46: [[-0.10118249  0.06169616  0.03434161 -0.01120897]\n",
      " [-0.01620217  0.          0.          0.        ]\n",
      " [-0.01448355  0.02441642  0.03548524 -0.05327211]\n",
      " [-0.01954996  0.53107749 -0.45906776 -0.06730491]\n",
      " [ 0.          0.          0.         -0.02471268]]\n",
      "SHAP values per classe 47: [[-0.09242547  0.02257375  0.03806001  0.        ]\n",
      " [-0.00777955  0.01623335  0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.01473961  0.06821471  0.          0.        ]\n",
      " [-0.03976204  0.180579   -0.11948173  0.        ]]\n",
      "SHAP values per classe 48: [[-0.12577471  0.08949031  0.03675431  0.        ]\n",
      " [-0.00477831  0.          0.          0.        ]\n",
      " [-0.03734285  0.03782659  0.          0.        ]\n",
      " [ 0.          0.         -0.01159018  0.        ]\n",
      " [ 0.          0.          0.06981172  0.        ]]\n",
      "SHAP values per classe 49: [[-0.08701677 -0.00590725  0.00276256 -0.04820676]\n",
      " [ 0.          0.00209511 -0.14093061 -0.01871169]\n",
      " [-0.06820373 -0.04043198  0.14607848  0.        ]\n",
      " [ 0.         -0.06307588  0.0724584  -0.01061034]\n",
      " [ 0.         -0.11440001 -0.06100682  0.01432685]]\n",
      "SHAP values per classe 50: [[-0.12140513  0.05458368  0.          0.03602455]\n",
      " [-0.00820912 -0.03468701  0.          0.        ]\n",
      " [-0.00219108  0.          0.          0.01586836]\n",
      " [-0.00582338 -0.15741992  0.0246988   0.08024222]\n",
      " [ 0.         -0.04927508  0.00714755  0.03981885]]\n",
      "SHAP values per classe 51: [[-0.14289248  0.          0.10457446  0.0193353 ]\n",
      " [-0.00858512 -0.00505965  0.          0.        ]\n",
      " [-0.01913951  0.          0.0234396   0.        ]\n",
      " [ 0.         -0.08000747  0.04667585  0.02743424]\n",
      " [ 0.         -0.02647867  0.02486526  0.        ]]\n",
      "SHAP values per classe 52: [[-0.1358549  -0.05686696  0.15688591  0.        ]\n",
      " [-0.04466865  0.         -0.05029131  0.04497328]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.13754826  0.07668305  0.04298163]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 53: [[-0.07025405  0.0299766   0.          0.02895379]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.00892858  0.          0.          0.        ]\n",
      " [ 0.         -0.04923271  0.          0.02208492]\n",
      " [-0.01867181  0.06313788  0.          0.        ]]\n",
      "SHAP values per classe 54: [[-0.04701333  0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.00201662  0.          0.          0.        ]\n",
      " [ 0.         -0.0390291   0.05999797  0.        ]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 55: [[-0.11353309  0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.00952485  0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.0158653   0.28666116 -0.28177105  0.01191996]]\n",
      "SHAP values per classe 56: [[ 0.2555629  -0.18257625 -0.01739119 -0.05825734]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.02585983  0.          0.          0.01460097]\n",
      " [-0.16684832  0.2648466  -0.056439   -0.03877442]\n",
      " [ 0.01450519  0.          0.          0.        ]]\n",
      "SHAP values per classe 57: [[ 0.25466495 -0.09059628 -0.06393188 -0.12409936]\n",
      " [ 0.          0.          0.00458623  0.        ]\n",
      " [ 0.01359127 -0.02778313  0.07735724 -0.06893673]\n",
      " [ 0.07025568 -0.07623231  0.03452675  0.        ]\n",
      " [ 0.07269502 -0.05304939 -0.13443483  0.        ]]\n",
      "SHAP values per classe 58: [[-0.11771434  0.          0.07448211  0.01762993]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.07998483  0.1179904  -0.00594248]\n",
      " [ 0.         -0.03419662  0.05208173  0.        ]]\n",
      "SHAP values per classe 59: [[-0.11295724  0.03885746  0.02676642  0.055463  ]\n",
      " [-0.01445422  0.          0.005881    0.00200939]\n",
      " [ 0.          0.          0.          0.00526449]\n",
      " [ 0.00359965 -0.06285983  0.02454104  0.02879449]\n",
      " [-0.00325598  0.01008752 -0.0277506   0.01751421]]\n",
      "SHAP values per classe 60: [[-0.07373453  0.          0.          0.06431718]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.10264104  0.09862311  0.        ]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 61: [[-0.1468809   0.003244    0.          0.1060738 ]\n",
      " [-0.0117472   0.         -0.01195136  0.00866776]\n",
      " [-0.02679343  0.07839862  0.          0.        ]\n",
      " [ 0.         -0.13487011  0.04770615  0.11347324]\n",
      " [ 0.         -0.07725731  0.05626184  0.        ]]\n",
      "SHAP values per classe 62: [[ 0.68184664 -0.14237083 -0.29893833 -0.20930922]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.01645818  0.          0.        ]\n",
      " [ 0.02852625 -0.03873233  0.02187223  0.        ]\n",
      " [ 0.00977524 -0.04929558  0.          0.        ]]\n",
      "SHAP values per classe 63: [[-0.02807642  0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.05409574  0.          0.        ]\n",
      " [ 0.         -0.02970451  0.11970669 -0.07685548]]\n",
      "SHAP values per classe 64: [[-0.12554293  0.          0.          0.        ]\n",
      " [-0.00538588  0.          0.         -0.02849983]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.04652446  0.61082157 -0.23075499 -0.15946837]\n",
      " [ 0.          0.          0.03160345  0.        ]]\n",
      "SHAP values per classe 65: [[-0.04533081  0.          0.02574709  0.        ]\n",
      " [ 0.          0.         -0.00021635  0.05288457]\n",
      " [ 0.          0.         -0.00303367  0.        ]\n",
      " [ 0.         -0.0628493   0.05689198  0.        ]\n",
      " [ 0.         -0.02045879  0.01821589 -0.00039366]]\n",
      "SHAP values per classe 66: [[-0.13831128 -0.08671966  0.02359657  0.04963597]\n",
      " [-0.01225686  0.          0.          0.        ]\n",
      " [-0.04510706 -0.12624244  0.          0.02079198]\n",
      " [ 0.00251941 -0.08350221  0.08459025  0.02292331]\n",
      " [-0.01907705 -0.05505694  0.02314683  0.        ]]\n",
      "SHAP values per classe 67: [[-0.03570513  0.03102345  0.02939203 -0.01542772]\n",
      " [ 0.          0.          0.02169283  0.00653531]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.02134415 -0.09402408  0.04920387  0.02178512]\n",
      " [ 0.01931399 -0.11396962  0.          0.00722839]]\n",
      "SHAP values per classe 68: [[-0.14560574  0.          0.0708262   0.08089855]\n",
      " [-0.00692566  0.02148278  0.          0.        ]\n",
      " [-0.00727079  0.03271195  0.          0.        ]\n",
      " [ 0.00458456  0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 69: [[-0.10050429  0.          0.09682774  0.        ]\n",
      " [ 0.         -0.02604387  0.08852915 -0.12823098]\n",
      " [-0.02031914 -0.00560561  0.          0.        ]\n",
      " [ 0.         -0.0659011   0.00786681  0.04459525]\n",
      " [ 0.          0.          0.11177142 -0.04346625]]\n",
      "SHAP values per classe 70: [[-0.08296536  0.          0.          0.0708439 ]\n",
      " [-0.00761843 -0.0139229   0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.07624328  0.          0.0262042 ]\n",
      " [ 0.         -0.02694097  0.          0.        ]]\n",
      "SHAP values per classe 71: [[ 0.02713678  0.          0.03556261 -0.05102562]\n",
      " [ 0.         -0.0164759   0.          0.00333791]\n",
      " [-0.01592457  0.          0.          0.03725086]\n",
      " [-0.10618473 -0.0899905   0.          0.15081258]\n",
      " [-0.0234973   0.          0.          0.        ]]\n",
      "SHAP values per classe 72: [[ 0.45258961 -0.1238013  -0.13970389 -0.17783376]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.00247897  0.          0.        ]\n",
      " [ 0.08853582 -0.11807238  0.          0.00946981]\n",
      " [ 0.04525291  0.          0.          0.        ]]\n",
      "SHAP values per classe 73: [[-0.11462874  0.          0.          0.        ]\n",
      " [-0.01008286  0.          0.0254476  -0.01341906]\n",
      " [ 0.0142361  -0.00777633  0.12554584 -0.16760089]\n",
      " [ 0.         -0.07399275  0.04147292 -0.00747897]\n",
      " [ 0.         -0.03730762  0.11212867 -0.03763354]]\n",
      "SHAP values per classe 74: [[-0.11303621  0.          0.05559011  0.        ]\n",
      " [-0.00829453 -0.00926321  0.00569332  0.        ]\n",
      " [ 0.          0.          0.         -0.0013967 ]\n",
      " [ 0.         -0.11080224  0.07784581  0.03135615]\n",
      " [ 0.         -0.06459252  0.03097069  0.        ]]\n",
      "SHAP values per classe 75: [[-0.08302522  0.10474542  0.          0.        ]\n",
      " [ 0.         -0.0911944   0.          0.        ]\n",
      " [-0.015024    0.14603149 -0.05975884 -0.01952809]\n",
      " [-0.0442635   0.2194008  -0.09913236 -0.12291607]\n",
      " [-0.01864279  0.0668517  -0.08145981  0.        ]]\n",
      "SHAP values per classe 76: [[-0.06409571  0.          0.05314888  0.        ]\n",
      " [-0.00388323  0.00624257  0.          0.        ]\n",
      " [-0.00723132  0.          0.00761974  0.        ]\n",
      " [-0.00900096 -0.04837786  0.04996931  0.        ]\n",
      " [-0.00407902 -0.03059565  0.04202566  0.        ]]\n",
      "SHAP values per classe 77: [[-0.11681007  0.          0.          0.        ]\n",
      " [ 0.          0.          0.09042075  0.        ]\n",
      " [ 0.         -0.00713861 -0.03554389  0.03167824]\n",
      " [ 0.         -0.05312071  0.          0.01727052]\n",
      " [ 0.         -0.03299806  0.          0.        ]]\n",
      "SHAP values per classe 78: [[-0.08045199  0.          0.          0.03021584]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.00689281 -0.00199065  0.          0.04064766]\n",
      " [ 0.         -0.06261318  0.06378706  0.01643728]\n",
      " [ 0.         -0.0188817   0.          0.        ]]\n",
      "SHAP values per classe 79: [[-0.12105014  0.          0.03427412  0.00720854]\n",
      " [-0.01077939  0.03970094  0.0177444   0.        ]\n",
      " [ 0.         -0.0098047   0.          0.        ]\n",
      " [ 0.         -0.16675973  0.09890936  0.00932776]\n",
      " [ 0.00736818 -0.04468612  0.0612133   0.        ]]\n",
      "SHAP values per classe 80: [[-0.08414204  0.08934185  0.         -0.00109721]\n",
      " [ 0.         -0.0629589   0.          0.07440212]\n",
      " [ 0.         -0.00395437  0.          0.        ]\n",
      " [ 0.         -0.05250513  0.04018428  0.        ]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 81: [[-0.12433979  0.          0.0606093   0.06210498]\n",
      " [-0.0089465   0.          0.          0.        ]\n",
      " [-0.01943296 -0.01192441  0.01871788  0.        ]\n",
      " [ 0.         -0.04572647  0.03040322  0.02006897]\n",
      " [ 0.         -0.02250328  0.         -0.00256722]]\n",
      "SHAP values per classe 82: [[-0.1515293   0.01622189  0.1246179   0.        ]\n",
      " [-0.00583608  0.          0.00657989 -0.00989529]\n",
      " [-0.02500726  0.          0.09137733 -0.05965423]\n",
      " [ 0.         -0.14919676  0.12493554  0.01273201]\n",
      " [ 0.         -0.06756359  0.05316488  0.        ]]\n",
      "SHAP values per classe 83: [[-0.06232286  0.          0.          0.01214765]\n",
      " [-0.00508469  0.          0.          0.        ]\n",
      " [-0.00641163 -0.00795779 -0.0017892   0.01256819]\n",
      " [-0.00252323 -0.06656722  0.          0.07507899]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 84: [[-0.08163977  0.01626275  0.08428987  0.        ]\n",
      " [ 0.          0.00195871  0.          0.        ]\n",
      " [ 0.13716277 -0.10399309  0.03666523 -0.12647783]\n",
      " [ 0.         -0.08857197  0.0661301   0.        ]\n",
      " [ 0.         -0.03558631  0.05295455 -0.00463168]]\n",
      "SHAP values per classe 85: [[ 0.33292921 -0.08231105 -0.16570005 -0.04617872]\n",
      " [ 0.          0.         -0.11681806  0.        ]\n",
      " [ 0.         -0.00536612  0.08251236 -0.06480041]\n",
      " [ 0.05730536 -0.07854927  0.          0.        ]\n",
      " [ 0.03255427 -0.07867146  0.          0.        ]]\n",
      "SHAP values per classe 86: [[-0.14577753  0.04196383  0.08093724  0.02536908]\n",
      " [-0.01303827  0.          0.          0.00588872]\n",
      " [-0.02421049  0.          0.          0.        ]\n",
      " [ 0.         -0.08774882  0.1266968   0.02214227]\n",
      " [ 0.         -0.04828872  0.05095262  0.        ]]\n",
      "SHAP values per classe 87: [[ 0.31340467 -0.1001363  -0.03599553 -0.11471565]\n",
      " [ 0.25356524  0.         -0.38254282  0.        ]\n",
      " [ 0.08534413 -0.05053411  0.11358382 -0.12154038]\n",
      " [ 0.         -0.05582101  0.          0.        ]\n",
      " [ 0.07326423 -0.03374418  0.01168495  0.        ]]\n",
      "SHAP values per classe 88: [[-0.09126199  0.01556026  0.01227335  0.05603663]\n",
      " [-0.00331465  0.          0.          0.        ]\n",
      " [-0.02126554  0.04091335  0.01283352  0.        ]\n",
      " [ 0.         -0.05404649  0.02048882  0.        ]\n",
      " [ 0.          0.11562704  0.          0.        ]]\n",
      "SHAP values per classe 89: [[-0.10205488  0.0676511   0.         -0.01199329]\n",
      " [-0.01272819  0.0233818   0.         -0.00752221]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.04791001  0.40565665 -0.24180792 -0.10303914]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 90: [[-0.05435738  0.          0.          0.03251335]\n",
      " [-0.01077841  0.          0.          0.        ]\n",
      " [-0.01686438 -0.0118883   0.          0.02825666]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.11514152  0.          0.08947595]]\n",
      "SHAP values per classe 91: [[-1.24045723e-01 -4.02225126e-03  2.86969772e-02  8.98066843e-02]\n",
      " [-1.01270672e-02  3.88950945e-01  6.30810660e-02 -1.09085306e-04]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  5.22262757e-02]\n",
      " [ 0.00000000e+00 -4.80645546e-01  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00 -4.38740670e-01  1.99566150e-02  0.00000000e+00]]\n",
      "SHAP values per classe 92: [[-0.10633347 -0.00991626  0.05482846  0.06889444]\n",
      " [-0.00232657  0.          0.          0.        ]\n",
      " [-0.00499863  0.          0.          0.        ]\n",
      " [ 0.         -0.05868208  0.          0.05194564]\n",
      " [ 0.          0.         -0.01051305  0.00542904]]\n",
      "SHAP values per classe 93: [[ 0.67978205 -0.25385867 -0.22267819 -0.17633438]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.01976755 -0.04469644  0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 94: [[-0.08563688  0.0453423   0.          0.        ]\n",
      " [-0.058315    0.02769352  0.04409831  0.02548058]\n",
      " [-0.00471097  0.          0.          0.        ]\n",
      " [-0.03953614  0.58657331 -0.28371966 -0.23261022]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 95: [[ 0.67448346 -0.25705983 -0.21027308 -0.19434498]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.01729413 -0.02572505  0.        ]\n",
      " [ 0.03128909 -0.05610556  0.          0.        ]\n",
      " [ 0.01665582  0.          0.          0.        ]]\n",
      "SHAP values per classe 96: [[ 6.93995222e-01 -2.09415427e-01 -2.31286102e-01 -2.12055757e-01]\n",
      " [ 0.00000000e+00  4.44834194e-02  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [-6.36349893e-04 -3.53934028e-02  0.00000000e+00  0.00000000e+00]\n",
      " [ 8.65282344e-03 -2.57615273e-02  0.00000000e+00  0.00000000e+00]]\n",
      "SHAP values per classe 97: [[-0.14476052  0.          0.08367341  0.        ]\n",
      " [-0.01524894  0.02005865  0.          0.        ]\n",
      " [-0.02013753  0.04073811 -0.01546624  0.        ]\n",
      " [ 0.         -0.09961587  0.08061784  0.01358333]\n",
      " [ 0.          0.          0.05214091  0.        ]]\n",
      "SHAP values per classe 98: [[-6.12410302e-02  0.00000000e+00  5.96121072e-02  0.00000000e+00]\n",
      " [-5.65982130e-03  4.86050216e-04  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  2.53261863e-02  0.00000000e+00  0.00000000e+00]\n",
      " [-1.00607423e-01  7.61239410e-01 -4.56991353e-01 -2.02088103e-01]\n",
      " [ 0.00000000e+00 -1.44998038e-02  1.52798927e-02  0.00000000e+00]]\n",
      "SHAP values per classe 99: [[-0.13407149  0.05553898  0.09406226  0.        ]\n",
      " [-0.01843879  0.0024852   0.          0.00737811]\n",
      " [-0.02667661  0.         -0.01051358  0.01665614]\n",
      " [ 0.         -0.12683484  0.15530492  0.01798085]\n",
      " [ 0.         -0.05466147  0.          0.        ]]\n",
      "SHAP values per classe 100: [[-0.11966063  0.00259177  0.07889335  0.        ]\n",
      " [-0.00697667  0.02108107  0.         -0.05529104]\n",
      " [-0.03961384 -0.07612163  0.01977387  0.        ]\n",
      " [ 0.00251862 -0.09004752  0.08633084  0.        ]\n",
      " [ 0.         -0.0976032   0.          0.        ]]\n",
      "SHAP values per classe 101: [[-0.11457511  0.08122167  0.01935458  0.        ]\n",
      " [-0.02242752  0.01485756  0.0312933   0.        ]\n",
      " [-0.0239188   0.          0.          0.        ]\n",
      " [-0.04482797  0.35156026 -0.23524779 -0.08047617]\n",
      " [ 0.          0.          0.         -0.00914084]]\n",
      "SHAP values per classe 102: [[ 0.21094351  0.         -0.1961415  -0.04773505]\n",
      " [ 0.         -0.01235539  0.         -0.01102021]\n",
      " [ 0.          0.          0.06874748 -0.0737235 ]\n",
      " [ 0.07978739 -0.14063042  0.          0.        ]\n",
      " [ 0.         -0.03863151  0.02452635  0.        ]]\n",
      "SHAP values per classe 103: [[-0.09928877  0.0604766   0.04298863 -0.00435395]\n",
      " [ 0.29005104  0.         -0.19787029 -0.07391018]\n",
      " [ 0.          0.00893808  0.          0.        ]\n",
      " [-0.36320501  0.60146073 -0.09404238 -0.11764723]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 104: [[ 0.          0.          0.02740878 -0.03431522]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.20500971  0.53863941 -0.22378674 -0.10073657]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 105: [[-0.07361808  0.0151642   0.          0.        ]\n",
      " [-0.00898192  0.05926043  0.          0.        ]\n",
      " [-0.01011612  0.          0.          0.        ]\n",
      " [-0.08969711  0.67509108 -0.39384635 -0.21881272]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 106: [[-0.07799093 -0.01952862 -0.17991126  0.24484926]\n",
      " [ 0.          0.04201502 -0.01245308  0.        ]\n",
      " [-0.00182446  0.         -0.01125039  0.00586147]\n",
      " [ 0.          0.         -0.17139115  0.12286726]\n",
      " [ 0.          0.          0.          0.02214561]]\n",
      "SHAP values per classe 107: [[-0.1190665   0.          0.          0.04030325]\n",
      " [-0.00464127  0.          0.          0.        ]\n",
      " [ 0.          0.         -0.06688608  0.01597583]\n",
      " [-0.01378397 -0.08796721  0.09161305  0.01591246]\n",
      " [ 0.         -0.01808609  0.          0.01484007]]\n",
      "SHAP values per classe 108: [[-0.09192817  0.          0.          0.        ]\n",
      " [-0.00917349 -0.02630928  0.          0.01201725]\n",
      " [ 0.          0.12073139  0.         -0.04812582]\n",
      " [-0.03137228  0.          0.          0.        ]\n",
      " [-0.06213455  0.3506192  -0.24144568 -0.04917593]]\n",
      "SHAP values per classe 109: [[ 0.59422247 -0.26662692 -0.19153964 -0.15230989]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.02094345 -0.00649661  0.         -0.01855376]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 110: [[-0.16894889 -0.21481663 -0.06813196  0.        ]\n",
      " [-0.01343274  0.          0.          0.        ]\n",
      " [ 0.          0.         -0.04913444  0.04879736]\n",
      " [-0.00450164  0.         -0.0725778   0.0523013 ]\n",
      " [-0.00361415  0.          0.          0.        ]]\n",
      "SHAP values per classe 111: [[-0.03301305  0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.03690576]\n",
      " [ 0.          0.0454373  -0.0624836   0.        ]\n",
      " [ 0.          0.03527686 -0.03752575  0.        ]\n",
      " [ 0.16137485  0.          0.          0.        ]]\n",
      "SHAP values per classe 112: [[ 0.04491205 -0.03244625  0.02848469 -0.05880921]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.03913559  0.         -0.00463114]\n",
      " [ 0.         -0.05940835  0.          0.        ]\n",
      " [ 0.         -0.06182313  0.13888917 -0.0153656 ]]\n",
      "SHAP values per classe 113: [[-0.10504854  0.0126632   0.06277602  0.01711304]\n",
      " [-0.01477709  0.          0.01431145  0.        ]\n",
      " [ 0.          0.01175726  0.         -0.02214412]\n",
      " [ 0.         -0.13235125  0.09882161  0.        ]\n",
      " [ 0.         -0.03158492  0.02971995  0.01095423]]\n",
      "SHAP values per classe 114: [[-0.10768547  0.          0.0387948   0.05716089]\n",
      " [-0.00850184  0.          0.          0.01781395]\n",
      " [ 0.          0.          0.          0.01621959]\n",
      " [ 0.         -0.05197627  0.02511773  0.02220133]\n",
      " [ 0.         -0.01487071  0.          0.        ]]\n",
      "SHAP values per classe 115: [[-0.14351055  0.          0.03185393  0.03109131]\n",
      " [-0.01234859  0.          0.         -0.00400116]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.05972431  0.08523164  0.        ]\n",
      " [ 0.         -0.05114657  0.05600873 -0.01290882]]\n",
      "SHAP values per classe 116: [[ 0.4769735  -0.04384733 -0.28386548 -0.10602368]\n",
      " [ 0.07601796 -0.02851335  0.         -0.02363468]\n",
      " [ 0.03900265  0.          0.         -0.0742266 ]\n",
      " [-0.00048401 -0.08766751  0.         -0.009123  ]\n",
      " [ 0.07818241 -0.06401058  0.          0.        ]]\n",
      "SHAP values per classe 117: [[-0.06534747  0.08207924  0.          0.04146015]\n",
      " [-0.00447439  0.00905126 -0.06574027  0.        ]\n",
      " [ 0.          0.00735385 -0.05840415  0.01317364]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.05711668  0.          0.        ]]\n",
      "SHAP values per classe 118: [[-0.11731239  0.          0.13874478  0.        ]\n",
      " [-0.01071881 -0.00331626  0.          0.        ]\n",
      " [-0.02119466  0.          0.          0.        ]\n",
      " [ 0.         -0.0598123   0.06177401  0.        ]\n",
      " [ 0.00187824 -0.01508535  0.06567937  0.        ]]\n",
      "SHAP values per classe 119: [[-0.11228165  0.          0.02399104  0.05803575]\n",
      " [-0.01317935  0.         -0.01516884  0.04267505]\n",
      " [-0.00363597 -0.0092266  -0.03355134  0.03220381]\n",
      " [ 0.         -0.08791684  0.02395927  0.04863898]\n",
      " [ 0.         -0.0344302   0.          0.03081329]]\n",
      "SHAP values per classe 120: [[-0.09421423  0.          0.11825766 -0.01972383]\n",
      " [ 0.         -0.02223108  0.0120257   0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.12197889  0.16297068  0.        ]\n",
      " [ 0.         -0.01985067  0.06866013 -0.05303352]]\n",
      "SHAP values per classe 121: [[-0.08503655  0.          0.          0.07204935]\n",
      " [-0.00712704  0.02154893  0.          0.02375223]\n",
      " [ 0.         -0.01559641  0.          0.        ]\n",
      " [ 0.         -0.0751099   0.04111522  0.01469016]\n",
      " [ 0.         -0.01333296  0.03571787  0.        ]]\n",
      "SHAP values per classe 122: [[ 0.31147177 -0.0662491  -0.2150219  -0.06168472]\n",
      " [ 0.06984564  0.          0.          0.        ]\n",
      " [ 0.         -0.0020924   0.          0.        ]\n",
      " [ 0.16201936 -0.12852895  0.          0.0108164 ]\n",
      " [ 0.         -0.08790075  0.          0.        ]]\n",
      "SHAP values per classe 123: [[-0.07030937  0.          0.05177177  0.02559545]\n",
      " [-0.00858154  0.          0.          0.00639059]\n",
      " [-0.02220255  0.          0.          0.        ]\n",
      " [ 0.         -0.06777414  0.03959044  0.02976174]\n",
      " [-0.00421194  0.          0.          0.01243807]]\n",
      "SHAP values per classe 124: [[ 0.2054894  -0.06341074 -0.06141752 -0.05387906]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.02214471  0.          0.        ]\n",
      " [ 0.0288214  -0.06045824  0.          0.        ]\n",
      " [ 0.0626189   0.          0.         -0.00429113]]\n",
      "SHAP values per classe 125: [[ 6.71585689e-01 -1.53758665e-01 -3.76045775e-01 -1.16048394e-01]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 1.88733321e-02 -1.36851288e-02  7.61736241e-02 -8.62887301e-02]\n",
      " [ 5.87295759e-02 -4.71329219e-02  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00 -5.55958788e-04  0.00000000e+00  0.00000000e+00]]\n",
      "SHAP values per classe 126: [[-0.08128855  0.00116604  0.          0.        ]\n",
      " [-0.0076049   0.01089174  0.         -0.06533137]\n",
      " [-0.00763882  0.          0.          0.07316357]\n",
      " [-0.03206561  0.2267938  -0.06883309 -0.1265742 ]\n",
      " [-0.03115292  0.         -0.06895173  0.0785867 ]]\n",
      "SHAP values per classe 127: [[-0.08551181  0.          0.          0.04961977]\n",
      " [-0.00543053  0.          0.          0.        ]\n",
      " [-0.01140576  0.          0.          0.0505274 ]\n",
      " [-0.0061129  -0.04057625  0.          0.06384842]\n",
      " [ 0.         -0.01250448  0.          0.        ]]\n",
      "SHAP values per classe 128: [[ 0.38172299 -0.09639604 -0.1194447  -0.13907878]\n",
      " [ 0.          0.          0.00263849  0.        ]\n",
      " [ 0.         -0.01814586  0.12032154 -0.10168698]\n",
      " [ 0.04300247 -0.06263676  0.13614618 -0.11824462]\n",
      " [ 0.05691111 -0.02982301 -0.09751238  0.        ]]\n",
      "SHAP values per classe 129: [[ 0.69276158 -0.24369288 -0.21287767 -0.19352392]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.02322011 -0.08043392  0.03559628  0.        ]\n",
      " [ 0.00418404 -0.02237248  0.03957849  0.        ]]\n",
      "SHAP values per classe 130: [[ 0.2166457  -0.05404156 -0.05012233 -0.11804944]\n",
      " [ 0.07546807 -0.06630028 -0.0097711   0.        ]\n",
      " [ 0.          0.03748887  0.02231212 -0.07208351]\n",
      " [ 0.0561933  -0.05881468  0.01436001  0.        ]\n",
      " [ 0.13525709 -0.13237621  0.          0.        ]]\n",
      "SHAP values per classe 131: [[-0.055001   -0.29955107  0.          0.        ]\n",
      " [ 0.          0.17991345  0.          0.01012089]\n",
      " [-0.00673664 -0.44569812  0.          0.        ]\n",
      " [-0.02873207  0.         -0.04069813 -0.02849518]\n",
      " [-0.02205088  0.         -0.05772442  0.        ]]\n",
      "SHAP values per classe 132: [[-0.05543577  0.          0.          0.03371388]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.02209651 -0.02687227  0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 133: [[-0.12071506 -0.01328445  0.09743941  0.        ]\n",
      " [-0.01166246  0.03631804  0.01039094  0.        ]\n",
      " [-0.03956558  0.          0.01672178  0.02359904]\n",
      " [ 0.00822576 -0.10006019  0.10851967  0.        ]\n",
      " [ 0.         -0.0476878   0.06532931  0.        ]]\n",
      "SHAP values per classe 134: [[-0.09828426  0.          0.09528201 -0.01443238]\n",
      " [-0.03441591  0.          0.          0.        ]\n",
      " [ 0.          0.         -0.02968602 -0.07465192]\n",
      " [ 0.         -0.12316854  0.0455436   0.05396488]\n",
      " [ 0.         -0.13436248  0.14990237  0.07625507]]\n",
      "SHAP values per classe 135: [[-0.09565503 -0.04158452  0.10866141  0.        ]\n",
      " [-0.01155347 -0.01763077  0.         -0.00682976]\n",
      " [-0.00546381  0.03231614 -0.01161435  0.        ]\n",
      " [-0.02676686  0.19015326 -0.1268494  -0.04709139]\n",
      " [-0.02736024  0.          0.          0.        ]]\n",
      "SHAP values per classe 136: [[-0.06115809  0.03397434  0.05746077  0.        ]\n",
      " [ 0.         -0.05616644  0.          0.        ]\n",
      " [-0.02798585  0.01676951  0.          0.        ]\n",
      " [-0.04830624  0.55296939 -0.15264112 -0.3671933 ]\n",
      " [-0.01866425  0.          0.         -0.0133002 ]]\n",
      "SHAP values per classe 137: [[ 0.34596707 -0.0935822  -0.14334433 -0.09909346]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.00654211]\n",
      " [ 0.         -0.10153078  0.08753252  0.        ]\n",
      " [ 0.14965539 -0.07989624 -0.04756476  0.00910157]]\n",
      "SHAP values per classe 138: [[-0.1236324   0.          0.05938632  0.        ]\n",
      " [-0.00561425  0.         -0.01203525  0.        ]\n",
      " [ 0.          0.02387646  0.          0.        ]\n",
      " [ 0.         -0.07879158  0.          0.        ]\n",
      " [-0.01712491 -0.11575247  0.19326146 -0.02154676]]\n",
      "SHAP values per classe 139: [[ 0.20695675 -0.01332125  0.         -0.06051451]\n",
      " [ 0.          0.          0.         -0.00999655]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.00773803  0.          0.          0.        ]\n",
      " [ 0.05546469 -0.04717921  0.          0.        ]]\n",
      "SHAP values per classe 140: [[ 0.3731824  -0.08525837 -0.16112872 -0.10317523]\n",
      " [ 0.          0.          0.          0.01578315]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.05347019 -0.0474329   0.          0.        ]]\n",
      "SHAP values per classe 141: [[ 0.23551972 -0.03358398 -0.1051574  -0.084131  ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.10172326  0.         -0.01316237]\n",
      " [ 0.1110906  -0.12836375  0.          0.        ]\n",
      " [ 0.07049243 -0.07651406  0.          0.        ]]\n",
      "SHAP values per classe 142: [[-0.10457303  0.01867482  0.08209742  0.        ]\n",
      " [-0.02538667  0.          0.03857067 -0.00943985]\n",
      " [-0.00112889  0.00327154  0.          0.        ]\n",
      " [ 0.         -0.07138913  0.06842627  0.        ]\n",
      " [-0.02982242 -0.05270079  0.08074549 -0.01359833]]\n",
      "SHAP values per classe 143: [[ 0.25106163 -0.0118761  -0.12977952 -0.1104483 ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.01948628]\n",
      " [ 0.09705037 -0.09947452 -0.03426902  0.        ]\n",
      " [ 0.01661468 -0.02839626  0.         -0.01355053]]\n",
      "SHAP values per classe 144: [[ 0.53147423 -0.05418775 -0.29977408 -0.12618601]\n",
      " [ 0.          0.19297774  0.         -0.01021068]\n",
      " [ 0.01026145 -0.00519659  0.03402108 -0.06151534]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.02022572 -0.02622425  0.          0.        ]]\n",
      "SHAP values per classe 145: [[-0.12878531  0.          0.10340187  0.        ]\n",
      " [-0.00938482  0.          0.01744986 -0.00487458]\n",
      " [-0.03537178 -0.07003068  0.15344405 -0.04973422]\n",
      " [ 0.         -0.06801727  0.06343766  0.        ]\n",
      " [ 0.         -0.00354633  0.04103137  0.        ]]\n",
      "SHAP values per classe 146: [[ 0.29718776 -0.03057864 -0.19877387 -0.06084615]\n",
      " [ 0.          0.02175174  0.          0.        ]\n",
      " [ 0.05394764 -0.04045225  0.         -0.06276464]\n",
      " [ 0.12085616 -0.16277889  0.          0.        ]\n",
      " [ 0.02771329 -0.04840368  0.          0.        ]]\n",
      "SHAP values per classe 147: [[-0.09981673  0.01060014  0.15525099 -0.0771269 ]\n",
      " [-0.01599234 -0.00310921  0.00270687  0.02241742]\n",
      " [ 0.01037501  0.01303875  0.         -0.01995443]\n",
      " [ 0.         -0.15126718  0.14516539  0.        ]\n",
      " [-0.00327218 -0.03069707  0.02769543  0.        ]]\n",
      "SHAP values per classe 148: [[ 0.37913441 -0.16504101 -0.12182019 -0.06998582]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.03367432  0.         -0.00649505]\n",
      " [ 0.05768909 -0.07261747  0.          0.        ]]\n",
      "SHAP values per classe 149: [[-0.08992644  0.          0.10772275 -0.01737709]\n",
      " [ 0.         -0.00230018  0.0583347  -0.04113001]\n",
      " [-0.00302248 -0.01001538  0.05257383 -0.02652226]\n",
      " [ 0.         -0.13657097  0.11922489 -0.00628858]\n",
      " [ 0.         -0.02836784  0.04091452 -0.01460479]]\n",
      "SHAP values per classe 150: [[-0.1106867   0.07301368  0.02735915  0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.02248655  0.36569486 -0.1912507  -0.13480882]\n",
      " [-0.00958783  0.          0.          0.        ]]\n",
      "SHAP values per classe 151: [[-0.05122657  0.          0.0131685   0.0323177 ]\n",
      " [-0.00303761 -0.00285312  0.          0.        ]\n",
      " [ 0.          0.          0.00914542  0.        ]\n",
      " [ 0.         -0.0435727   0.          0.03073035]\n",
      " [ 0.         -0.02906657  0.05712224  0.        ]]\n",
      "SHAP values per classe 152: [[-0.12022063  0.01218818  0.08033071  0.01317514]\n",
      " [-0.00872071  0.0067363   0.          0.01172   ]\n",
      " [-0.02547808  0.          0.02891587  0.        ]\n",
      " [ 0.         -0.19628992  0.15610447  0.0114009 ]\n",
      " [ 0.         -0.03571772  0.04703975  0.        ]]\n",
      "SHAP values per classe 153: [[-0.08929621  0.          0.03430276  0.        ]\n",
      " [-0.01484162  0.          0.          0.00146111]\n",
      " [ 0.          0.12054357  0.         -0.081888  ]\n",
      " [-0.02421795  0.13547564 -0.05429052 -0.05709765]\n",
      " [-0.04356528  0.23306722 -0.17130562 -0.01093163]]\n",
      "SHAP values per classe 154: [[-0.10166275 -0.0396702   0.          0.        ]\n",
      " [-0.00824599  0.          0.          0.        ]\n",
      " [-0.03523513  0.         -0.0865387   0.        ]\n",
      " [-0.04280689  0.41160098 -0.1346607  -0.10515455]\n",
      " [ 0.          0.0626722   0.          0.        ]]\n",
      "SHAP values per classe 155: [[ 0.          0.0285338   0.         -0.06430519]\n",
      " [ 0.          0.          0.          0.02875364]\n",
      " [ 0.          0.01184026  0.          0.        ]\n",
      " [-0.14733667  0.43034773 -0.11602735 -0.09460869]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 156: [[ 4.21241628e-01 -1.06078802e-01 -1.28008163e-01 -7.60028221e-02]\n",
      " [ 4.45553845e-02  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 4.02361993e-02  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 1.16923669e-02 -1.05046719e-01  0.00000000e+00 -2.09959476e-04]\n",
      " [ 0.00000000e+00 -5.77582212e-02  0.00000000e+00  0.00000000e+00]]\n",
      "SHAP values per classe 157: [[-0.10086883 -0.00181891  0.01829104  0.09306493]\n",
      " [-0.00504352  0.00168789  0.          0.02450605]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.1106077   0.02432547  0.07009487]\n",
      " [ 0.         -0.03212525  0.          0.        ]]\n",
      "SHAP values per classe 158: [[ 0.17141785  0.06454923  0.05979173 -0.2967653 ]\n",
      " [ 0.08165808  0.         -0.19527579  0.19181925]\n",
      " [ 0.09020003 -0.13186343  0.12508994 -0.06466533]\n",
      " [ 0.05944016 -0.11300984  0.0310073   0.02801494]\n",
      " [ 0.         -0.00810663  0.07672052  0.03109109]]\n",
      "SHAP values per classe 159: [[-0.10661081  0.05464481  0.03623102  0.        ]\n",
      " [ 0.          0.          0.          0.01100294]\n",
      " [-0.01630824  0.          0.         -0.02173891]\n",
      " [-0.06441784  0.46485397 -0.29030555 -0.07989662]\n",
      " [ 0.          0.          0.         -0.04066967]]\n",
      "SHAP values per classe 160: [[-0.00767242  0.0902202   0.03465717 -0.0974703 ]\n",
      " [-0.00811326  0.0170255   0.          0.        ]\n",
      " [ 0.         -0.0128678   0.          0.        ]\n",
      " [ 0.         -0.03635178  0.06502605  0.        ]\n",
      " [ 0.         -0.03584771  0.03185027  0.        ]]\n",
      "SHAP values per classe 161: [[-0.11125568  0.01475031  0.          0.08427676]\n",
      " [-0.01020932  0.          0.          0.        ]\n",
      " [-0.02986892  0.          0.          0.02260862]\n",
      " [ 0.         -0.09096379  0.05441075  0.        ]\n",
      " [ 0.         -0.01053687  0.          0.        ]]\n",
      "SHAP values per classe 162: [[-0.12036946  0.          0.01907822  0.09344496]\n",
      " [-0.0154472  -0.00490219  0.          0.        ]\n",
      " [-0.02287772  0.01148939  0.          0.03155938]\n",
      " [ 0.         -0.05713193  0.04230961  0.04578774]\n",
      " [ 0.         -0.03494138  0.09266857  0.        ]]\n",
      "SHAP values per classe 163: [[-0.09312115  0.          0.06403326  0.        ]\n",
      " [-0.00643118  0.          0.          0.        ]\n",
      " [-0.02771194  0.          0.          0.        ]\n",
      " [ 0.00255709 -0.08582848  0.05790516  0.01448235]\n",
      " [ 0.         -0.02185792  0.0211004   0.        ]]\n",
      "SHAP values per classe 164: [[-0.03430494  0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.01559188]\n",
      " [-0.01761651  0.          0.          0.        ]\n",
      " [ 0.         -0.06797221  0.05307104  0.0213868 ]\n",
      " [ 0.         -0.00984157  0.          0.        ]]\n",
      "SHAP values per classe 165: [[-0.06909159  0.04324387  0.02617207  0.        ]\n",
      " [-0.00676593  0.00477233  0.          0.        ]\n",
      " [ 0.          0.          0.000427    0.        ]\n",
      " [ 0.         -0.01053998  0.          0.        ]\n",
      " [-0.10658606  0.31240128 -0.15610107 -0.02618036]]\n",
      "SHAP values per classe 166: [[-0.14012534  0.06078053  0.02873565  0.        ]\n",
      " [-0.00833461  0.          0.          0.01468349]\n",
      " [-0.02052962  0.02729941  0.00294887  0.        ]\n",
      " [-0.01831463  0.2623612  -0.19072483 -0.02689811]\n",
      " [ 0.          0.          0.02145586  0.00641483]]\n",
      "SHAP values per classe 167: [[-0.13894776  0.          0.1396801   0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.01625892  0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.01911506  0.42130015 -0.37449092  0.        ]]\n",
      "SHAP values per classe 168: [[-0.06366861  0.          0.          0.05360842]\n",
      " [ 0.          0.          0.          0.01753276]\n",
      " [-0.00511956  0.          0.          0.        ]\n",
      " [-0.01194377 -0.06047629  0.03518942  0.02202854]\n",
      " [ 0.         -0.01169078  0.          0.        ]]\n",
      "SHAP values per classe 169: [[-0.10769556  0.          0.03711218  0.05886778]\n",
      " [-0.01505196  0.          0.          0.01052308]\n",
      " [ 0.          0.          0.         -0.03876733]\n",
      " [ 0.         -0.06766588  0.03348831  0.02483305]\n",
      " [ 0.         -0.00361244  0.          0.        ]]\n",
      "SHAP values per classe 170: [[-0.11476025  0.06728997  0.          0.        ]\n",
      " [-0.02234602  0.          0.          0.        ]\n",
      " [-0.01000646  0.          0.          0.        ]\n",
      " [ 0.          0.          0.01143772  0.        ]\n",
      " [-0.05389363  0.52207085 -0.24078127 -0.19892451]]\n",
      "SHAP values per classe 171: [[ 0.63150608 -0.19262363 -0.211755   -0.18337557]\n",
      " [ 0.02355619 -0.01315494  0.07150065 -0.06904556]\n",
      " [ 0.          0.08271721  0.          0.        ]\n",
      " [ 0.01793183 -0.06838545  0.          0.        ]\n",
      " [ 0.         -0.01417612  0.          0.        ]]\n",
      "SHAP values per classe 172: [[ 0.05539905  0.          0.01926217 -0.0647799 ]\n",
      " [ 0.00719408  0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.35986076  0.41708733 -0.03705584 -0.02863725]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 173: [[-0.11546787  0.          0.0209386   0.07437943]\n",
      " [-0.01614342  0.          0.0757924   0.        ]\n",
      " [-0.01254591  0.          0.          0.        ]\n",
      " [ 0.         -0.05215364  0.          0.03433658]\n",
      " [ 0.         -0.01766789  0.          0.        ]]\n",
      "SHAP values per classe 174: [[-0.14327555  0.          0.13093713  0.        ]\n",
      " [-0.00932659 -0.0100305   0.02085093  0.05966207]\n",
      " [-0.02104266  0.          0.05162461 -0.02820985]\n",
      " [ 0.         -0.11518371  0.08444401  0.        ]\n",
      " [ 0.          0.          0.244251   -0.18242257]]\n",
      "SHAP values per classe 175: [[-0.11875965  0.05467898  0.          0.        ]\n",
      " [-0.02169083  0.08802767  0.          0.        ]\n",
      " [-0.03736709 -0.05483173  0.          0.        ]\n",
      " [ 0.         -0.13108682  0.          0.13574619]\n",
      " [-0.01202448  0.04940319 -0.21122118  0.19121365]]\n",
      "SHAP values per classe 176: [[-0.11348496 -0.00537992  0.09915497  0.        ]\n",
      " [-0.01536964  0.          0.0224751   0.02129602]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.00961742 -0.10954755  0.11406624  0.        ]\n",
      " [ 0.         -0.02876237  0.04744679  0.        ]]\n",
      "SHAP values per classe 177: [[ 0.65912738 -0.09434414 -0.39200585 -0.13716024]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.05313467 -0.0316788   0.09159531 -0.10046579]\n",
      " [ 0.0280872  -0.07008566  0.          0.        ]\n",
      " [ 0.00667797 -0.0281551   0.01227426  0.        ]]\n",
      "SHAP values per classe 178: [[ 0.23626513  0.         -0.13775976 -0.04003905]\n",
      " [ 0.121332   -0.08058184 -0.04129963 -0.05643858]\n",
      " [ 0.04799666  0.          0.         -0.08203795]\n",
      " [ 0.1543445  -0.07384334  0.14413732 -0.16771173]\n",
      " [ 0.         -0.06711068  0.01686014 -0.01024271]]\n",
      "SHAP values per classe 179: [[-0.05223679  0.         -0.0500108   0.11669502]\n",
      " [-0.01923302  0.          0.          0.00614534]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.05016856  0.07963874  0.        ]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 180: [[ 0.          0.          0.03445888 -0.0338409 ]\n",
      " [ 0.          0.02000471  0.         -0.08762944]\n",
      " [ 0.          0.01295403  0.          0.        ]\n",
      " [-0.17631185  0.5755264  -0.22980555 -0.08004392]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 181: [[-0.03492055  0.080359    0.          0.        ]\n",
      " [ 0.05984916  0.          0.0872401  -0.15378118]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.43157761  0.62651906 -0.06325024 -0.07976435]\n",
      " [ 0.          0.         -0.16880978  0.        ]]\n",
      "SHAP values per classe 182: [[-0.11148464  0.04363319  0.03536513  0.02903025]\n",
      " [-0.0063828   0.00630186  0.          0.        ]\n",
      " [-0.00804937  0.          0.         -0.00423875]\n",
      " [-0.04410192  0.42347298 -0.26528375 -0.10912596]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 183: [[ 0.31423813 -0.02600116 -0.11781726 -0.10256537]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.05908663 -0.16978736  0.          0.03032278]\n",
      " [ 0.03153522 -0.05436764  0.04225018  0.        ]]\n",
      "SHAP values per classe 184: [[-0.11486483  0.09326267  0.02797691  0.        ]\n",
      " [-0.0105432   0.          0.          0.        ]\n",
      " [-0.02587384  0.          0.          0.        ]\n",
      " [-0.0132734  -0.18250829  0.14914435  0.03434438]\n",
      " [-0.02490789  0.36491099 -0.34706691  0.04030787]]\n",
      "SHAP values per classe 185: [[-0.05749642  0.06556811 -0.0166321   0.04269741]\n",
      " [ 0.         -0.19388256 -0.27610755  0.45414354]\n",
      " [ 0.          0.          0.          0.06689253]\n",
      " [-0.03038775  0.          0.          0.        ]\n",
      " [ 0.          0.          0.02575072  0.        ]]\n",
      "SHAP values per classe 186: [[-0.10883465  0.          0.          0.11558688]\n",
      " [-0.00261225  0.          0.          0.        ]\n",
      " [ 0.         -0.00177437  0.          0.02742123]\n",
      " [ 0.         -0.05345025  0.          0.        ]\n",
      " [ 0.         -0.02340188  0.          0.00046702]]\n",
      "SHAP values per classe 187: [[ 0.33870821 -0.08491891 -0.14617772 -0.08787838]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.08589302 -0.08891194  0.          0.        ]\n",
      " [ 0.02772905 -0.06192487  0.          0.        ]]\n",
      "SHAP values per classe 188: [[-0.07315099  0.         -0.00628479  0.07159341]\n",
      " [ 0.          0.         -0.01558807  0.00976406]\n",
      " [ 0.          0.         -0.01313687  0.02049138]\n",
      " [ 0.         -0.09299714  0.04417205  0.03240788]\n",
      " [ 0.         -0.02038659  0.          0.02510549]]\n",
      "SHAP values per classe 189: [[-0.15351016  0.          0.08515346  0.06695082]\n",
      " [-0.01667363  0.00702005  0.          0.02712297]\n",
      " [-0.02029916  0.01851333  0.          0.        ]\n",
      " [ 0.         -0.15015131  0.01726194  0.12887941]\n",
      " [ 0.          0.01377875 -0.12980549  0.10987375]]\n",
      "SHAP values per classe 190: [[-0.1078942   0.01271758  0.          0.05702098]\n",
      " [-0.00876875  0.          0.          0.00745441]\n",
      " [-0.00270569  0.          0.          0.        ]\n",
      " [ 0.         -0.0691761   0.03240223  0.01327658]\n",
      " [-0.00238904 -0.03138758  0.03722004  0.        ]]\n",
      "SHAP values per classe 191: [[-0.11335042  0.09475701  0.          0.        ]\n",
      " [-0.00213663  0.          0.          0.        ]\n",
      " [-0.02868306  0.          0.          0.        ]\n",
      " [-0.04368541  0.53497142 -0.32271404 -0.15051649]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 192: [[ 0.37883947 -0.11900624 -0.14963928 -0.0902935 ]\n",
      " [ 0.          0.         -0.03319281  0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.04481357 -0.13100622  0.          0.        ]\n",
      " [ 0.04789447 -0.0491535   0.          0.        ]]\n",
      "SHAP values per classe 193: [[-0.05628082 -0.16850571 -0.01416696  0.        ]\n",
      " [-0.00482998  0.          0.          0.        ]\n",
      " [-0.03068141  0.         -0.14980118  0.        ]\n",
      " [ 0.          0.          0.          0.01303682]\n",
      " [-0.04705696  0.19465474 -0.07812723 -0.01253093]]\n",
      "SHAP values per classe 194: [[-0.04920309  0.01692297  0.02888631  0.        ]\n",
      " [-0.00368569  0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.05838384  0.10939402 -0.0470577 ]\n",
      " [ 0.         -0.03261284  0.          0.        ]]\n",
      "SHAP values per classe 195: [[-0.13274699  0.00240402  0.08100253  0.01211708]\n",
      " [-0.0076222  -0.03997032  0.          0.        ]\n",
      " [-0.00164073  0.          0.          0.04145213]\n",
      " [ 0.         -0.07345556  0.05250866  0.05051704]\n",
      " [ 0.          0.02307093  0.          0.02616839]]\n",
      "SHAP values per classe 196: [[-0.16202099  0.          0.          0.        ]\n",
      " [-0.00892747  0.          0.         -0.02422368]\n",
      " [ 0.00703854 -0.0058788   0.17689588 -0.17490283]\n",
      " [ 0.         -0.11366895  0.23960779  0.        ]\n",
      " [ 0.         -0.0382107  -0.01829365  0.        ]]\n",
      "SHAP values per classe 197: [[ 0.          0.03167589  0.          0.        ]\n",
      " [ 0.18969349  0.          0.         -0.11733942]\n",
      " [ 0.          0.         -0.10939059  0.        ]\n",
      " [-0.33552698  0.62509106 -0.05451862 -0.1122181 ]\n",
      " [-0.04570009  0.02235618  0.          0.        ]]\n",
      "SHAP values per classe 198: [[-0.10460685  0.07031034  0.          0.        ]\n",
      " [-0.02710714  0.          0.          0.        ]\n",
      " [-0.01468137  0.00604845  0.05839994  0.01254519]\n",
      " [-0.02089782  0.02644689 -0.12490391 -0.05990994]\n",
      " [-0.01033551  0.03441809 -0.10404149  0.        ]]\n",
      "SHAP values per classe 199: [[ 0.52663402 -0.23651798 -0.16050111 -0.0885883 ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.0579013  -0.06043406  0.06651717 -0.07743055]\n",
      " [ 0.02132781 -0.06375193  0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 200: [[-0.12724252  0.          0.          0.        ]\n",
      " [-0.01051808  0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.06753934]\n",
      " [ 0.         -0.05112337  0.03704566  0.        ]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 201: [[-0.12361134  0.          0.02274708  0.03688106]\n",
      " [-0.0122975   0.01023045  0.          0.        ]\n",
      " [-0.0071335   0.03294995 -0.04870092  0.01488654]\n",
      " [ 0.         -0.15667293  0.05238666  0.10097853]\n",
      " [ 0.         -0.00578877  0.          0.01658897]]\n",
      "SHAP values per classe 202: [[-0.11112171  0.0068478   0.0906958   0.01166715]\n",
      " [-0.01662098  0.01236586  0.          0.        ]\n",
      " [-0.00420447  0.02048271  0.          0.        ]\n",
      " [ 0.         -0.13183599  0.13011006  0.00570564]\n",
      " [-0.00447411 -0.05207998  0.03447167  0.        ]]\n",
      "SHAP values per classe 203: [[-0.10062967  0.          0.00678182  0.07524435]\n",
      " [-0.0129313   0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.01161907]\n",
      " [ 0.         -0.07233254  0.          0.02715385]\n",
      " [ 0.         -0.02497549  0.02419556  0.        ]]\n",
      "SHAP values per classe 204: [[-0.12915754  0.          0.02227901  0.06882355]\n",
      " [-0.00692048  0.          0.         -0.01354083]\n",
      " [ 0.          0.         -0.03641826  0.        ]\n",
      " [-0.0121747   0.          0.06103777  0.        ]\n",
      " [-0.00779798  0.          0.          0.        ]]\n",
      "SHAP values per classe 205: [[-1.15905317e-01  0.00000000e+00  2.40703364e-02  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [-3.14259228e-05  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [-2.38662675e-02  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00 -2.81799936e-02  0.00000000e+00  1.69079660e-02]]\n",
      "SHAP values per classe 206: [[-0.04878557  0.03276833  0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.00449199  0.00477362  0.          0.        ]\n",
      " [-0.0682531   0.30980786 -0.07726098 -0.15728952]\n",
      " [-0.0319848   0.09892945 -0.08740783  0.        ]]\n",
      "SHAP values per classe 207: [[-0.13451892  0.          0.05211052  0.        ]\n",
      " [ 0.          0.          0.08722832  0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.07154604  0.          0.        ]\n",
      " [ 0.         -0.024213    0.          0.        ]]\n",
      "SHAP values per classe 208: [[-0.06790438  0.          0.13118155 -0.06673885]\n",
      " [-0.00235094  0.          0.04293764  0.        ]\n",
      " [-0.03318818  0.          0.07000054  0.        ]\n",
      " [ 0.         -0.06929367  0.0709966  -0.00373556]\n",
      " [ 0.         -0.02756283  0.05952129 -0.02561542]]\n",
      "SHAP values per classe 209: [[-0.12151352  0.          0.03282508  0.04472586]\n",
      " [-0.01428296  0.          0.          0.        ]\n",
      " [-0.00791566  0.          0.          0.01802916]\n",
      " [ 0.         -0.12966456  0.          0.0740423 ]\n",
      " [ 0.         -0.04259268  0.04145748  0.        ]]\n",
      "SHAP values per classe 210: [[-0.07485576  0.          0.01987506  0.03131301]\n",
      " [-0.00701185  0.          0.          0.        ]\n",
      " [ 0.          0.         -0.01586092  0.        ]\n",
      " [ 0.         -0.05965725  0.          0.06199345]\n",
      " [-0.00338429 -0.0440847  -0.01502013  0.06399356]]\n",
      "SHAP values per classe 211: [[-0.10494816  0.06229782  0.          0.        ]\n",
      " [-0.0091692   0.          0.          0.        ]\n",
      " [ 0.          0.          0.         -0.01646977]\n",
      " [-0.03228806  0.37083471 -0.26578812 -0.08101996]\n",
      " [ 0.          0.00337379  0.          0.        ]]\n",
      "SHAP values per classe 212: [[-0.14699889  0.01417118  0.04585204  0.05104458]\n",
      " [ 0.02237054  0.00279948  0.          0.01835868]\n",
      " [-0.00252678  0.          0.          0.02653033]\n",
      " [-0.02592638 -0.15747582  0.          0.08027773]\n",
      " [ 0.01659065 -0.040776    0.          0.        ]]\n",
      "SHAP values per classe 213: [[-0.13510282  0.          0.03693533  0.02522217]\n",
      " [ 0.          0.         -0.05120907  0.        ]\n",
      " [-0.0207152   0.          0.01310687  0.0180477 ]\n",
      " [ 0.         -0.1248521   0.09773443  0.02057622]\n",
      " [ 0.         -0.04803099  0.07674122 -0.02665198]]\n",
      "SHAP values per classe 214: [[-0.10127537  0.06829918  0.          0.        ]\n",
      " [-0.00910443 -0.09402604  0.05208366  0.        ]\n",
      " [-0.04061475  0.13691343  0.          0.        ]\n",
      " [-0.03494444  0.4486396  -0.27779928 -0.11801328]\n",
      " [ 0.         -0.02258704  0.          0.        ]]\n",
      "SHAP values per classe 215: [[-0.10511267  0.          0.          0.        ]\n",
      " [ 0.          0.          0.02288759  0.        ]\n",
      " [-0.02388346  0.          0.          0.        ]\n",
      " [ 0.         -0.11002498  0.10970118  0.00545229]\n",
      " [ 0.         -0.02138135  0.05095643 -0.02031458]]\n",
      "SHAP values per classe 216: [[-0.09979891  0.02483575  0.04716155  0.01612511]\n",
      " [-0.01087314 -0.01248831  0.          0.02042791]\n",
      " [ 0.          0.         -0.02461141  0.03588807]\n",
      " [ 0.         -0.08287461  0.09239287 -0.03972225]\n",
      " [ 0.         -0.01879308 -0.05991352  0.15706212]]\n",
      "SHAP values per classe 217: [[-0.09578879  0.          0.          0.00678123]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.01448822 -0.00978977 -0.01974149  0.03765482]\n",
      " [ 0.         -0.12979069  0.07738754  0.04526447]\n",
      " [ 0.         -0.01157164  0.          0.        ]]\n",
      "SHAP values per classe 218: [[ 0.31180996 -0.01255288 -0.19286552 -0.09274199]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.06841478 -0.08795843  0.06430575 -0.04978496]\n",
      " [ 0.02924392 -0.08610901  0.06706453  0.        ]\n",
      " [ 0.02309836 -0.04597939  0.          0.        ]]\n",
      "SHAP values per classe 219: [[-0.14323057  0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.         -0.01163081  0.01389697]\n",
      " [ 0.         -0.0882006   0.07347902  0.18530609]\n",
      " [ 0.         -0.02605244  0.          0.        ]]\n",
      "SHAP values per classe 220: [[-0.06059275 -0.01092013  0.07223544  0.        ]\n",
      " [-0.03208321 -0.012444    0.02907183  0.        ]\n",
      " [ 0.          0.          0.          0.03455052]\n",
      " [ 0.         -0.06241471  0.          0.06130512]\n",
      " [-0.00244997 -0.02483924  0.          0.0449153 ]]\n",
      "SHAP values per classe 221: [[-0.1226854   0.          0.          0.1115025 ]\n",
      " [-0.0032203   0.          0.         -0.01566174]\n",
      " [-0.01886912  0.          0.          0.17508018]\n",
      " [-0.03677864  0.53915417 -0.24571387 -0.25241166]\n",
      " [ 0.          0.          0.         -0.05097623]]\n",
      "SHAP values per classe 222: [[-1.23041277e-01  1.84653980e-02  8.92065783e-02  1.44604478e-02]\n",
      " [-1.25613440e-02  7.46836439e-05  8.24798645e-03  1.38030547e-02]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [-6.84045875e-03 -1.40128945e-01  1.09604945e-01  2.79555658e-02]\n",
      " [-1.97783611e-02 -7.16582404e-02  8.31993809e-02  0.00000000e+00]]\n",
      "SHAP values per classe 223: [[-0.13298582  0.01902119  0.          0.        ]\n",
      " [ 0.         -0.05553904  0.04254682  0.00622407]\n",
      " [-0.036414    0.03329217  0.          0.01317937]\n",
      " [ 0.          0.14092742 -0.12123188 -0.03244526]\n",
      " [ 0.          0.          0.          0.04955385]]\n",
      "SHAP values per classe 224: [[ 4.76418289e-01 -2.42421658e-01 -1.07408080e-01 -1.08443687e-01]\n",
      " [ 0.00000000e+00  7.85090479e-03  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 6.58697758e-02 -1.02192069e-01  0.00000000e+00  0.00000000e+00]\n",
      " [ 3.12551833e-02 -5.06112804e-02  0.00000000e+00 -4.45602287e-04]]\n",
      "SHAP values per classe 225: [[-0.11145825  0.09056468  0.02622736  0.        ]\n",
      " [-0.00742243  0.00531317 -0.0358356   0.03347927]\n",
      " [-0.02745828  0.          0.          0.00990941]\n",
      " [-0.05215874  0.34858418 -0.1604953  -0.14097188]\n",
      " [-0.02090022  0.11196301 -0.09706961  0.01777139]]\n",
      "SHAP values per classe 226: [[-0.10443706 -0.04135799  0.          0.        ]\n",
      " [-0.00871809  0.          0.          0.01554685]\n",
      " [ 0.          0.01429034  0.          0.        ]\n",
      " [ 0.         -0.12234289  0.07626737  0.        ]\n",
      " [ 0.          0.          0.16609234  0.        ]]\n",
      "SHAP values per classe 227: [[-0.05561069  0.          0.12111614  0.        ]\n",
      " [-0.03219715  0.00480657  0.07652768  0.        ]\n",
      " [-0.02549096  0.          0.          0.0058061 ]\n",
      " [ 0.         -0.07587003  0.13595284  0.        ]\n",
      " [ 0.         -0.0369138   0.         -0.07159444]]\n",
      "SHAP values per classe 228: [[-0.1110397   0.00893682  0.          0.        ]\n",
      " [-0.00542046  0.          0.          0.        ]\n",
      " [-0.0199596   0.04605803 -0.02175404 -0.01609717]\n",
      " [-0.01335725  0.4308409  -0.12883412 -0.06924949]\n",
      " [-0.02180385  0.0359291  -0.08066687  0.        ]]\n",
      "SHAP values per classe 229: [[-0.07525441  0.01019623  0.03035395  0.        ]\n",
      " [-0.02066778  0.01243752  0.          0.        ]\n",
      " [-0.00541566  0.00139341  0.          0.        ]\n",
      " [-0.06096913  0.63837221 -0.34984669 -0.20856976]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 230: [[-0.1187894   0.          0.07576288  0.0315142 ]\n",
      " [-0.01211322 -0.01201956  0.02795185  0.        ]\n",
      " [-0.00690306  0.          0.          0.00454269]\n",
      " [ 0.         -0.12989832  0.1176168   0.00923243]\n",
      " [ 0.         -0.05102169  0.04549765  0.        ]]\n",
      "SHAP values per classe 231: [[-0.1310004  -0.02249189  0.08941668  0.06175786]\n",
      " [-0.0226343  -0.06810109  0.          0.0616252 ]\n",
      " [-0.01647564  0.01736987 -0.03246448  0.        ]\n",
      " [-0.00317278 -0.03943182  0.          0.04494193]\n",
      " [ 0.00478587  0.          0.          0.        ]]\n",
      "SHAP values per classe 232: [[-0.08190786  0.          0.02662905  0.0387798 ]\n",
      " [-0.01884484 -0.06186119  0.         -0.00370379]\n",
      " [ 0.         -0.01358905  0.          0.02518154]\n",
      " [-0.00575766 -0.0843866   0.0413544   0.02187012]\n",
      " [ 0.         -0.02071909  0.01883645  0.        ]]\n",
      "SHAP values per classe 233: [[ 0.2042119   0.         -0.14304328 -0.03437502]\n",
      " [ 0.          0.00269583  0.          0.        ]\n",
      " [ 0.          0.          0.         -0.03788548]\n",
      " [ 0.06940715 -0.11224868  0.03612865  0.        ]\n",
      " [ 0.16946408 -0.13658824  0.         -0.03323403]]\n",
      "SHAP values per classe 234: [[ 0.2385383  -0.01102372 -0.06134711 -0.1011837 ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.00554444 -0.00814987  0.         -0.00200746]\n",
      " [ 0.07042954 -0.1171329   0.          0.        ]\n",
      " [ 0.00630842 -0.03024404  0.          0.        ]]\n",
      "SHAP values per classe 235: [[-0.1395287  -0.02132161  0.17281242  0.        ]\n",
      " [-0.01595826  0.00196224  0.01115164  0.01913177]\n",
      " [-0.03534613  0.          0.01917638  0.        ]\n",
      " [ 0.00147874 -0.08225939  0.10032193  0.        ]\n",
      " [-0.02676739 -0.1035061   0.08026716  0.        ]]\n",
      "SHAP values per classe 236: [[ 0.29861096 -0.09851242 -0.02544464 -0.1499945 ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.13705965 -0.06087327  0.10182405 -0.13666321]\n",
      " [ 0.         -0.05295015  0.15359757 -0.00855595]\n",
      " [ 0.         -0.01972732  0.02026288  0.        ]]\n",
      "SHAP values per classe 237: [[ 0.71952982 -0.17239754 -0.26991889 -0.24895393]\n",
      " [-0.00422372  0.00174922  0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.02276722 -0.05851936  0.          0.        ]\n",
      " [ 0.         -0.02011618  0.          0.        ]]\n",
      "SHAP values per classe 238: [[-0.0611      0.04479543  0.         -0.01849445]\n",
      " [-0.02390807  0.          0.          0.01740341]\n",
      " [-0.01938549  0.02561682  0.          0.01703093]\n",
      " [-0.08788266  0.328448   -0.14389373 -0.07667618]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 239: [[ 0.          0.01199398 -0.03496467  0.        ]\n",
      " [-0.00718098  0.01119413  0.          0.        ]\n",
      " [-0.04908765  0.02989827  0.00090631  0.        ]\n",
      " [-0.17784103  0.40625347 -0.13334836 -0.11361518]\n",
      " [ 0.          0.          0.01710823  0.        ]]\n",
      "SHAP values per classe 240: [[-0.08089307  0.          0.          0.08617726]\n",
      " [-0.01840218  0.          0.          0.        ]\n",
      " [-0.00495557  0.          0.          0.04000858]\n",
      " [ 0.         -0.07953607  0.05385477  0.02026945]\n",
      " [ 0.         -0.02473001  0.          0.        ]]\n",
      "SHAP values per classe 241: [[-0.10314211  0.07991361  0.          0.04002447]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.00843554  0.          0.          0.        ]\n",
      " [-0.04097736  0.60965074 -0.31392295 -0.21846852]\n",
      " [-0.0144313   0.          0.          0.        ]]\n",
      "SHAP values per classe 242: [[ 0.23611905  0.06226434 -0.14324151 -0.08737989]\n",
      " [ 0.          0.00297891  0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.04518211 -0.11721181  0.04784513 -0.0234755 ]\n",
      " [ 0.04631108 -0.0474252   0.          0.        ]]\n",
      "SHAP values per classe 243: [[ 5.43321130e-01 -1.19429492e-01 -2.64548337e-01 -1.63449662e-01]\n",
      " [ 5.25964505e-02  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [-5.07830280e-02  0.00000000e+00  0.00000000e+00 -4.22855059e-02]\n",
      " [ 2.05700078e-01 -1.01223741e-01  0.00000000e+00  4.81762161e-04]\n",
      " [ 8.63904208e-02 -1.95823671e-02  0.00000000e+00  0.00000000e+00]]\n",
      "SHAP values per classe 244: [[-0.11272649  0.05932558  0.03044788  0.        ]\n",
      " [-0.01184462  0.          0.          0.        ]\n",
      " [-0.01804592  0.          0.          0.        ]\n",
      " [ 0.00167416  0.          0.03570182  0.        ]\n",
      " [-0.02140759  0.18839545 -0.24640257  0.        ]]\n",
      "SHAP values per classe 245: [[-0.09980976  0.          0.11879092  0.00886843]\n",
      " [-0.01093669  0.          0.00051563  0.        ]\n",
      " [-0.01408068  0.          0.          0.        ]\n",
      " [ 0.         -0.07285911  0.0618188   0.00882579]\n",
      " [-0.00443569 -0.01887134  0.02131064  0.        ]]\n",
      "SHAP values per classe 246: [[-0.07603471  0.0027793   0.07676954  0.        ]\n",
      " [-0.00974923  0.          0.          0.        ]\n",
      " [-0.05167423  0.          0.         -0.02048859]\n",
      " [ 0.         -0.07771315  0.06488924  0.        ]\n",
      " [ 0.01458577 -0.01309094  0.02076536  0.        ]]\n",
      "SHAP values per classe 247: [[-0.12675538  0.          0.13567482 -0.03546654]\n",
      " [-0.00820697  0.          0.          0.        ]\n",
      " [-0.00424132  0.          0.          0.        ]\n",
      " [-0.03088813  0.46976777 -0.4015628  -0.04728171]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 248: [[-0.08657539  0.          0.          0.04360392]\n",
      " [ 0.          0.          0.00736325  0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.05765218 -0.04445725  0.05686826]\n",
      " [ 0.         -0.0101904   0.          0.02509248]]\n",
      "SHAP values per classe 249: [[-0.066561    0.          0.          0.07098525]\n",
      " [-0.01255161 -0.00827756  0.          0.        ]\n",
      " [ 0.01136333  0.          0.          0.        ]\n",
      " [-0.0037954  -0.05290073  0.04681502  0.00791437]\n",
      " [-0.03851308 -0.05557793  0.04521126  0.        ]]\n",
      "SHAP values per classe 250: [[-0.06267743  0.02808428  0.02783268  0.        ]\n",
      " [-0.00171173  0.          0.0038363   0.        ]\n",
      " [-0.0323261   0.10186732  0.         -0.03967409]\n",
      " [-0.01345159  0.12329574 -0.0341744  -0.06889719]\n",
      " [-0.01913072  0.02274835 -0.08345494  0.02129677]]\n",
      "SHAP values per classe 251: [[-0.14045811  0.11900364 -0.03482642  0.        ]\n",
      " [-0.01038881  0.          0.          0.        ]\n",
      " [-0.0182257   0.03274192 -0.00532851  0.        ]\n",
      " [ 0.          0.          0.04918494  0.        ]\n",
      " [-0.02246017  0.25496386 -0.21487647  0.07109114]]\n",
      "SHAP values per classe 252: [[-0.15457029  0.04716936  0.10979342  0.        ]\n",
      " [-0.02000986  0.04803268  0.00800477 -0.01089467]\n",
      " [-0.01310753 -0.04212159  0.02503166  0.        ]\n",
      " [ 0.01259728  0.          0.          0.        ]\n",
      " [ 0.         -0.02878546  0.03774401  0.        ]]\n",
      "SHAP values per classe 253: [[-0.0851079  -0.01634752  0.06386901  0.        ]\n",
      " [-0.00786881 -0.04332346  0.04169941  0.        ]\n",
      " [-0.04926956  0.08595931 -0.04553251  0.        ]\n",
      " [-0.03826083  0.41965176 -0.10187457 -0.28179707]\n",
      " [-0.00644091  0.          0.          0.        ]]\n",
      "SHAP values per classe 254: [[-1.20876603e-01  0.00000000e+00  6.22901634e-02  5.23765879e-02]\n",
      " [-1.20134420e-02 -4.95007477e-03  0.00000000e+00  1.06404522e-02]\n",
      " [-9.87298064e-03 -1.21494860e-02  0.00000000e+00  1.52054019e-02]\n",
      " [-1.43628432e-02 -1.77291001e-01  1.08839488e-01  4.24285887e-02]\n",
      " [ 4.14263578e-03  0.00000000e+00 -6.19062745e-05  9.74090873e-03]]\n",
      "SHAP values per classe 255: [[-0.1269256  -0.02704478  0.04899329  0.02628958]\n",
      " [-0.00714945  0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.01924384]\n",
      " [ 0.         -0.03968331  0.          0.03445843]\n",
      " [ 0.         -0.01592157  0.          0.02756955]]\n",
      "SHAP values per classe 256: [[-0.0646211   0.01226578  0.02133711  0.01984388]\n",
      " [ 0.         -0.00963542  0.02685768  0.        ]\n",
      " [ 0.          0.         -0.01468941  0.02443236]\n",
      " [ 0.         -0.04494503  0.04470897  0.        ]\n",
      " [-0.01999937  0.          0.          0.05057928]]\n",
      "SHAP values per classe 257: [[-0.04661365  0.04639458  0.04613987 -0.01634743]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.25926895  0.          0.27150277]\n",
      " [ 0.         -0.19722269  0.          0.        ]]\n",
      "SHAP values per classe 258: [[-4.50407480e-02 -4.05456096e-02  7.06250682e-02  0.00000000e+00]\n",
      " [ 0.00000000e+00 -9.60783841e-02  0.00000000e+00 -3.25103946e-02]\n",
      " [ 0.00000000e+00  1.09722046e-04  0.00000000e+00  0.00000000e+00]\n",
      " [-1.16481983e-02  0.00000000e+00 -1.13923194e-01 -1.61806806e-01]\n",
      " [-1.90101963e-02  1.65396501e-01 -4.54493798e-02  0.00000000e+00]]\n",
      "SHAP values per classe 259: [[-0.10286458  0.02291016  0.11182394 -0.03167575]\n",
      " [-0.0177783   0.          0.08372086 -0.07357642]\n",
      " [-0.01309708  0.         -0.03384483  0.02422282]\n",
      " [ 0.         -0.09267548  0.11535426  0.        ]\n",
      " [-0.00546726 -0.0469004   0.06215832  0.01397618]]\n",
      "SHAP values per classe 260: [[-0.15091908 -0.04837642  0.          0.        ]\n",
      " [ 0.         -0.00388657  0.         -0.00923173]\n",
      " [-0.00870076  0.          0.          0.02999099]\n",
      " [ 0.         -0.14713467  0.04480808  0.07935244]\n",
      " [ 0.          0.          0.          0.01329077]]\n",
      "SHAP values per classe 261: [[-0.09372008  0.          0.          0.05782849]\n",
      " [-0.00484663  0.          0.          0.01340994]\n",
      " [-0.00991238 -0.00719876  0.09808765  0.        ]\n",
      " [-0.00049942 -0.13851418  0.13769046  0.        ]\n",
      " [ 0.         -0.03762026  0.0594376  -0.01463621]]\n",
      "SHAP values per classe 262: [[-0.06107345  0.01077962  0.          0.        ]\n",
      " [-0.09129622 -0.08969399  0.40027168 -0.14855837]\n",
      " [-0.00208372  0.         -0.04483836  0.        ]\n",
      " [ 0.         -0.02352704  0.11293116  0.00115275]\n",
      " [-0.00153348 -0.05812456  0.10285444  0.        ]]\n",
      "SHAP values per classe 263: [[-0.10428215  0.08669356  0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.02121487  0.00286486  0.          0.        ]\n",
      " [-0.03176728  0.22620309 -0.09071189 -0.06708422]\n",
      " [-0.03938545  0.22086697 -0.14670078 -0.02937435]]\n",
      "SHAP values per classe 264: [[-0.10875126  0.08140667  0.          0.        ]\n",
      " [ 0.          0.          0.03694066 -0.00300301]\n",
      " [ 0.01333262  0.          0.06933972 -0.07342945]\n",
      " [-0.00602735  0.12583235 -0.07699944 -0.00954469]\n",
      " [-0.05586105  0.24787268 -0.1636512   0.        ]]\n",
      "SHAP values per classe 265: [[-0.12925213 -0.02212002  0.05757689  0.05571904]\n",
      " [-0.00688977  0.          0.          0.        ]\n",
      " [ 0.         -0.0112043   0.          0.00470947]\n",
      " [ 0.         -0.10943831  0.06787345  0.03060059]\n",
      " [ 0.         -0.02935177  0.02735717  0.        ]]\n",
      "SHAP values per classe 266: [[ 0.54197023 -0.06251611 -0.21245684 -0.15966801]\n",
      " [ 0.          0.17926832  0.          0.        ]\n",
      " [ 0.01884623 -0.02004635 -0.0445703   0.        ]\n",
      " [ 0.06291731  0.          0.          0.        ]\n",
      " [ 0.01274962  0.10474493  0.          0.        ]]\n",
      "SHAP values per classe 267: [[-0.02914892 -0.10360958  0.          0.32934112]\n",
      " [-0.00611304  0.          0.          0.00612685]\n",
      " [ 0.         -0.01402143  0.06923853  0.        ]\n",
      " [ 0.         -0.02529208  0.         -0.0551117 ]\n",
      " [ 0.          0.          0.         -0.05628115]]\n",
      "SHAP values per classe 268: [[-0.10777079  0.          0.03763025  0.06165033]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.00277605 -0.03514435  0.04009533  0.        ]\n",
      " [ 0.          0.         -0.01722868  0.        ]]\n",
      "SHAP values per classe 269: [[ 0.01033891  0.05415695  0.         -0.03986576]\n",
      " [ 0.13294171  0.         -0.0268847  -0.0486517 ]\n",
      " [ 0.          0.07903075 -0.06529682  0.        ]\n",
      " [-0.2361774   0.61069384 -0.25484244 -0.13627873]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 270: [[-0.1020256   0.          0.08583042 -0.00200709]\n",
      " [-0.01432145  0.          0.00437727  0.        ]\n",
      " [ 0.          0.          0.00723534  0.00475275]\n",
      " [ 0.         -0.10171159  0.10091579  0.        ]\n",
      " [ 0.         -0.07844811  0.07027743  0.        ]]\n",
      "SHAP values per classe 271: [[ 0.32082485 -0.1359748  -0.1745794  -0.08394482]\n",
      " [ 0.          0.13713358  0.          0.        ]\n",
      " [ 0.02162427  0.          0.         -0.00565487]\n",
      " [ 0.08973335 -0.31766431  0.          0.        ]\n",
      " [ 0.05954233 -0.07937829  0.          0.0038534 ]]\n",
      "SHAP values per classe 272: [[-0.06029863  0.          0.          0.        ]\n",
      " [ 0.03963197  0.          0.          0.        ]\n",
      " [-0.01074315 -0.00479379  0.          0.        ]\n",
      " [ 0.         -0.07863075  0.08166013  0.        ]\n",
      " [ 0.         -0.0224013   0.06999189  0.        ]]\n",
      "SHAP values per classe 273: [[-0.10110509  0.04331852  0.04831549  0.        ]\n",
      " [-0.00980407  0.          0.          0.        ]\n",
      " [-0.00477391  0.          0.          0.        ]\n",
      " [-0.08416292  0.5513702  -0.29267981 -0.16656879]\n",
      " [ 0.0021299   0.          0.          0.        ]]\n",
      "SHAP values per classe 274: [[ 0.35865303 -0.02751087 -0.16083662 -0.10567575]\n",
      " [ 0.          0.          0.03126341  0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.06000025 -0.12201276  0.04636389  0.01358618]\n",
      " [ 0.         -0.07250429  0.          0.        ]]\n",
      "SHAP values per classe 275: [[-0.14618957  0.03253585  0.04679077  0.04815855]\n",
      " [-0.01498086  0.         -0.01162708  0.02060774]\n",
      " [ 0.          0.          0.          0.04201454]\n",
      " [-0.00950827 -0.18033172  0.08239291  0.08278992]\n",
      " [ 0.0013239  -0.02226536  0.01763864  0.        ]]\n",
      "SHAP values per classe 276: [[-0.11610299 -0.00073545  0.10068756  0.03771343]\n",
      " [-0.01013222  0.          0.          0.        ]\n",
      " [-0.04196311 -0.02217117  0.00686569  0.        ]\n",
      " [ 0.         -0.14829754  0.05725038  0.03335897]\n",
      " [ 0.         -0.05333055  0.02373043  0.        ]]\n",
      "SHAP values per classe 277: [[ 0.02461397 -0.01935131 -0.02605024 -0.04635684]\n",
      " [-0.13874257 -0.21590609  0.         -0.11694219]\n",
      " [ 0.00582633 -0.00276842  0.         -0.03149614]\n",
      " [ 0.04985661 -0.08034185 -0.02949182  0.        ]\n",
      " [-0.29146164  0.          0.          0.        ]]\n",
      "SHAP values per classe 278: [[ 0.44000472 -0.03037414 -0.25889991 -0.12502041]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.         -0.00396464]\n",
      " [ 0.03159798 -0.12329723  0.          0.        ]\n",
      " [ 0.04469083 -0.04798172  0.          0.        ]]\n",
      "SHAP values per classe 279: [[-0.13177045  0.          0.05672313  0.06523723]\n",
      " [-0.01573029 -0.00875371  0.02104517  0.01108635]\n",
      " [-0.01213036  0.          0.          0.01184379]\n",
      " [-0.02489799 -0.14941537  0.09153957  0.05791793]\n",
      " [ 0.01261825  0.         -0.14688766  0.1347135 ]]\n",
      "SHAP values per classe 280: [[-0.03996898 -0.04538858  0.          0.02355642]\n",
      " [ 0.          0.03162253  0.          0.        ]\n",
      " [-0.01111343  0.          0.          0.        ]\n",
      " [ 0.         -0.04171559  0.          0.01701607]\n",
      " [ 0.         -0.01267572  0.          0.        ]]\n",
      "SHAP values per classe 281: [[-0.11293914  0.017851    0.08188412  0.        ]\n",
      " [ 0.         -0.0550006   0.07518444  0.        ]\n",
      " [ 0.         -0.00149227  0.00479638  0.        ]\n",
      " [ 0.         -0.07837617  0.0673925   0.        ]\n",
      " [ 0.         -0.02630883  0.00293479  0.        ]]\n",
      "SHAP values per classe 282: [[ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.32388763]\n",
      " [-0.06723386  0.          0.          0.06587804]\n",
      " [ 0.         -0.03993115  0.03844982  0.        ]\n",
      " [ 0.         -0.01399137  0.          0.        ]]\n",
      "SHAP values per classe 283: [[ 0.          0.          0.         -0.05542855]\n",
      " [ 0.         -0.04213377  0.04482983  0.        ]\n",
      " [ 0.         -0.02976604  0.13365948 -0.06181153]\n",
      " [-0.04900183 -0.09989216  0.          0.0744739 ]\n",
      " [-0.14195597 -0.04464033  0.32780154 -0.08746279]]\n",
      "SHAP values per classe 284: [[ 0.71607044 -0.29837669 -0.22103382 -0.23013016]\n",
      " [ 0.          0.         -0.02043165  0.        ]\n",
      " [ 0.         -0.06995038  0.          0.        ]\n",
      " [ 0.02305575 -0.16309505  0.          0.        ]\n",
      " [ 0.00804026  0.          0.          0.        ]]\n",
      "SHAP values per classe 285: [[-0.0526093   0.          0.02852283  0.        ]\n",
      " [-0.02449892  0.          0.          0.        ]\n",
      " [-0.02772989  0.         -0.06350161  0.06019203]\n",
      " [ 0.         -0.05140282  0.03705752  0.01182589]\n",
      " [ 0.          0.          0.01711667  0.00657318]]\n",
      "SHAP values per classe 286: [[-0.13367144  0.16487055  0.          0.        ]\n",
      " [-0.0026836   0.          0.          0.        ]\n",
      " [-0.00971834  0.          0.          0.        ]\n",
      " [-0.03642698  0.40902438 -0.2662262  -0.11368741]\n",
      " [ 0.          0.         -0.02149861  0.        ]]\n",
      "SHAP values per classe 287: [[-0.13073336  0.          0.0410624   0.03995594]\n",
      " [-0.01009507  0.00291285  0.          0.02366782]\n",
      " [-0.00480576  0.          0.          0.02541579]\n",
      " [ 0.         -0.13403686  0.07423739  0.0143592 ]\n",
      " [-0.00492228 -0.03876534  0.          0.06211041]]\n",
      "SHAP values per classe 288: [[ 0.3875736  -0.20230348 -0.15303468 -0.04518972]\n",
      " [ 0.         -0.01394476  0.          0.        ]\n",
      " [ 0.01489172 -0.00514948  0.          0.00787484]\n",
      " [ 0.14094355 -0.13811218  0.          0.        ]\n",
      " [ 0.         -0.09757466  0.          0.        ]]\n",
      "SHAP values per classe 289: [[-0.13419116 -0.10399848  0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.00028443  0.00133289  0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.07129689  0.08882392  0.        ]]\n",
      "SHAP values per classe 290: [[-0.12111444  0.02420446  0.06193744  0.        ]\n",
      " [-0.00945087  0.04688038  0.         -0.05945411]\n",
      " [-0.0117263   0.00615835 -0.024188    0.        ]\n",
      " [ 0.          0.          0.02888534 -0.0177289 ]\n",
      " [-0.02638564  0.32905074 -0.33017396  0.02615788]]\n",
      "SHAP values per classe 291: [[ 0.31911539 -0.1117653  -0.05733031 -0.15675569]\n",
      " [ 0.39180766 -0.0555414  -0.2437767  -0.06839064]\n",
      " [ 0.          0.01401126  0.          0.        ]\n",
      " [ 0.         -0.05013675  0.02039656  0.        ]\n",
      " [ 0.02649605 -0.02353098  0.          0.        ]]\n",
      "SHAP values per classe 292: [[-0.07518263  0.0306239   0.          0.        ]\n",
      " [-0.00349587  0.          0.          0.        ]\n",
      " [ 0.          0.          0.00505921  0.        ]\n",
      " [-0.11285518  0.70187189 -0.3039327  -0.24112331]\n",
      " [ 0.         -0.01849698  0.          0.        ]]\n",
      "SHAP values per classe 293: [[-0.09812953  0.0670751   0.          0.        ]\n",
      " [-0.00638122  0.          0.          0.        ]\n",
      " [-0.03358484  0.16916958  0.         -0.08337326]\n",
      " [ 0.          0.          0.          0.00499567]\n",
      " [-0.02232115  0.04184594 -0.05200823  0.02381764]]\n",
      "SHAP values per classe 294: [[-0.11075205  0.01781836  0.02733795  0.06474454]\n",
      " [-0.00806461  0.          0.          0.01277292]\n",
      " [ 0.          0.00051892 -0.02090131  0.02326728]\n",
      " [ 0.         -0.1320982   0.10284209  0.        ]\n",
      " [ 0.00270639 -0.0401379   0.03719263  0.        ]]\n",
      "SHAP values per classe 295: [[-0.11282243  0.03652145  0.05607839  0.        ]\n",
      " [-0.00946125  0.00133185  0.          0.        ]\n",
      " [-0.01360614  0.00847826  0.          0.        ]\n",
      " [-0.06820185  0.48581845 -0.28109123 -0.14410996]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 296: [[-0.07859233 -0.01192074  0.          0.04778452]\n",
      " [ 0.          0.          0.          0.01248711]\n",
      " [-0.00410092  0.         -0.02122771  0.03180141]\n",
      " [ 0.         -0.05785603  0.02763643  0.02359542]\n",
      " [ 0.         -0.0316129   0.04642572  0.        ]]\n",
      "SHAP values per classe 297: [[-0.10523843  0.06707185  0.03407254  0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.00929162  0.00927652  0.          0.        ]\n",
      " [-0.03506827  0.56166639 -0.35235875 -0.14983347]\n",
      " [ 0.00400813 -0.01504538  0.          0.        ]]\n",
      "SHAP values per classe 298: [[-0.08538859  0.03362548  0.         -0.02599069]\n",
      " [-0.00903975  0.          0.          0.        ]\n",
      " [-0.0089025   0.0084028  -0.01979396  0.        ]\n",
      " [-0.0316345   0.34841616 -0.24488824 -0.07946707]\n",
      " [ 0.         -0.01232755  0.          0.        ]]\n",
      "SHAP values per classe 299: [[-0.15008055  0.05789374  0.14920369  0.        ]\n",
      " [-0.01203349  0.          0.          0.02503827]\n",
      " [-0.02178022  0.13129881  0.03912771 -0.0315831 ]\n",
      " [ 0.         -0.23800737  0.10713082  0.01579566]\n",
      " [ 0.         -0.17210938  0.02221822  0.02142847]]\n",
      "SHAP values per classe 300: [[-0.10794476  0.          0.03406535  0.06357193]\n",
      " [-0.00159679 -0.07269891  0.          0.08916341]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.0592717   0.04118479  0.01834331]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 301: [[-0.12418613  0.00850675  0.02915469  0.        ]\n",
      " [ 0.          0.          0.          0.03599734]\n",
      " [-0.02160722  0.01829947 -0.02345746 -0.02142061]\n",
      " [-0.02759083  0.19909761 -0.14458747 -0.02087544]\n",
      " [-0.0110163   0.16334231 -0.08968057  0.        ]]\n",
      "SHAP values per classe 302: [[ 0.36655367 -0.05276872 -0.16947646 -0.08863213]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.         -0.02804508  0.00326675]\n",
      " [ 0.14529649 -0.13760358  0.00700943  0.        ]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP GED: 11.470588235294118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training del detector...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib/python3.9/site-packages/albumentations/core/bbox_utils.py:476: RuntimeWarning: invalid value encountered in divide\n",
      "  & (clipped_box_areas / denormalized_box_areas >= min_visibility - epsilon)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint salvato per l'epoca 11.\n",
      "------------------\n",
      "Epoch 13/150\n",
      "Inference completata\n",
      "Load .json metadata:  ./tmp/train/B_20181212_110313.json\n",
      "Load .json metadata:  ./tmp/train/B_5bed71eae40c4.json\n",
      "Load .json metadata:  ./tmp/train/B_20181212_110321.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_mihrab_mezquita_cordoba.json\n",
      "Load .json metadata:  ./tmp/train/B_5bad4cbc18c44.json\n",
      "Load .json metadata:  ./tmp/train/R_5c1f82413637d.json\n",
      "Load .json metadata:  ./tmp/train/G_5c67d991a4cf7.json\n",
      "Load .json metadata:  ./tmp/train/B_5dd7d6e26f601.json\n",
      "Load .json metadata:  ./tmp/train/M_alcazaba_malaga3.json\n",
      "Load .json metadata:  ./tmp/train/G_casa_bailio_cordoba.json\n",
      "Load .json metadata:  ./tmp/train/G_5babc82fc022f.json\n",
      "Load .json metadata:  ./tmp/train/M_5e4fb912bf15b.json\n",
      "Load .json metadata:  ./tmp/train/R_5c75195fbb8f2.json\n",
      "Load .json metadata:  ./tmp/train/G_5bb8f33edfa1f.json\n",
      "Load .json metadata:  ./tmp/train/M_5bb0d93bcd653.json\n",
      "Load .json metadata:  ./tmp/train/B_5c15322219e6f.json\n",
      "Load .json metadata:  ./tmp/train/B_facultad_derecho_granada2.json\n",
      "Load .json metadata:  ./tmp/train/M_patio_yeso_reales_alcazares_sevilla3.json\n",
      "Load .json metadata:  ./tmp/train/B_iglesia_caridad_sevilla2.json\n",
      "Load .json metadata:  ./tmp/train/M_20181212_112649.json\n",
      "Load .json metadata:  ./tmp/train/R_ayuntamiento_baeza3.json\n",
      "Load .json metadata:  ./tmp/train/R_5bc0b3ee639ce.json\n",
      "Load .json metadata:  ./tmp/train/B_convento_siervas_de_maria_granada.json\n",
      "Load .json metadata:  ./tmp/train/B_casa_almirante_cadiz2.json\n",
      "Load .json metadata:  ./tmp/train/G_20181212_105119.json\n",
      "Load .json metadata:  ./tmp/train/G_catedral_leon12.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc76ea8caf7b.json\n",
      "Load .json metadata:  ./tmp/train/M_medina_azahara3.json\n",
      "Load .json metadata:  ./tmp/train/G_5baeaa86ac71e.json\n",
      "Load .json metadata:  ./tmp/train/B_catedral_granada4.json\n",
      "Load .json metadata:  ./tmp/train/M_5bae5bf050e24.json\n",
      "Load .json metadata:  ./tmp/train/M_5baf14eb92e6d.json\n",
      "Load .json metadata:  ./tmp/train/B_5c80ebc6ddf27.json\n",
      "Load .json metadata:  ./tmp/train/B_iglesia_gracia_granada.json\n",
      "Load .json metadata:  ./tmp/train/G_iglesia_san_nicolas_ubeda4.json\n",
      "Load .json metadata:  ./tmp/train/R_5bf7c972311d4.json\n",
      "Load .json metadata:  ./tmp/train/M_5bec1e4b72f12.json\n",
      "Load .json metadata:  ./tmp/train/B_iglesia_caridad_sevilla5.json\n",
      "Load .json metadata:  ./tmp/train/M_5bd579c5023a7.json\n",
      "Load .json metadata:  ./tmp/train/R_5bb5f3109fda8.json\n",
      "Load .json metadata:  ./tmp/train/B_santos_justo_pastor_granada8.json\n",
      "Load .json metadata:  ./tmp/train/G_casa_bailio_cordoba2.json\n",
      "Load .json metadata:  ./tmp/train/B_iglesia_san_jeronimo_granada3.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_del_vino_granada6.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_de_las_pesas_granada4.json\n",
      "Load .json metadata:  ./tmp/train/M_5bec1e6a04058.json\n",
      "Load .json metadata:  ./tmp/train/M_5de6b189c985e.json\n",
      "Load .json metadata:  ./tmp/train/B_museo_bellas_artes_sevilla6.json\n",
      "Load .json metadata:  ./tmp/train/M_5bae5eef7467f.json\n",
      "Load .json metadata:  ./tmp/train/M_20181212_115504.json\n",
      "Load .json metadata:  ./tmp/train/R_puerta_puente_cordoba15.json\n",
      "Load .json metadata:  ./tmp/train/B_5baff8c138f48.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc0ca38b7006.json\n",
      "Load .json metadata:  ./tmp/train/G_5cadb7eb3a84a.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_monaita_granada6.json\n",
      "Load .json metadata:  ./tmp/train/B_5bdb2454edef4.json\n",
      "Load .json metadata:  ./tmp/train/G_catedral_leon10.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_san_isidro_mezquita_cordoba5.json\n",
      "Load .json metadata:  ./tmp/train/B_5bebfefce3f27.json\n",
      "Load .json metadata:  ./tmp/train/G_5b8ecc4c3cde4.json\n",
      "Load .json metadata:  ./tmp/train/G_5baf18213b6f1.json\n",
      "Load .json metadata:  ./tmp/train/G_iglesia_santa_maría_del_pi_barcelona3.json\n",
      "Load .json metadata:  ./tmp/train/R_casa_cabildo_jerez6.json\n",
      "Load .json metadata:  ./tmp/train/B_5c48452e4af47.json\n",
      "Load .json metadata:  ./tmp/train/M_5d99bad3a10f2.json\n",
      "Load .json metadata:  ./tmp/train/R_puerta_puente_cordoba4.json\n",
      "Load .json metadata:  ./tmp/train/R_plaza_santa_teresa_ubeda3.json\n",
      "Load .json metadata:  ./tmp/train/B_casa_marqueses_de_cartagena_granada4.json\n",
      "Load .json metadata:  ./tmp/train/B_colegio_bartolome_santiago_granada.json\n",
      "Load .json metadata:  ./tmp/train/G_5b8d77afb94e9.json\n",
      "Load .json metadata:  ./tmp/train/R_5bd6baf8e455c.json\n",
      "Load .json metadata:  ./tmp/train/B_basilica_angustias_granada3.json\n",
      "Load .json metadata:  ./tmp/train/B_5bacbbeed360e.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_monaita_granada5.json\n",
      "Load .json metadata:  ./tmp/train/B_casa-mariana_pineda_granada.json\n",
      "Load .json metadata:  ./tmp/train/R_5bdefaf7351c6.json\n",
      "Load .json metadata:  ./tmp/train/R_palacio_cadenas_ubeda.json\n",
      "Load .json metadata:  ./tmp/train/G_hospital_san_sebastian_cordoba9.json\n",
      "Load .json metadata:  ./tmp/train/G_torre_fadrique2.json\n",
      "Load .json metadata:  ./tmp/train/G_convento_clarisas_palencia4.json\n",
      "Load .json metadata:  ./tmp/train/M_medina_azahara23.json\n",
      "Load .json metadata:  ./tmp/train/G_casa_abrantes_granada6.json\n",
      "Load .json metadata:  ./tmp/train/B_catedral_guadix2.json\n",
      "Load .json metadata:  ./tmp/train/B_5c878e7d3d3f0.json\n",
      "Load .json metadata:  ./tmp/train/G_5de139e53bea1.json\n",
      "Load .json metadata:  ./tmp/train/M_dintel_adovelado5.json\n",
      "Load .json metadata:  ./tmp/train/B_san_felipe_neri_baeza.json\n",
      "Load .json metadata:  ./tmp/train/M_5bafb615991d4.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc765746e381.json\n",
      "Load .json metadata:  ./tmp/train/B_5c14f6b287d17.json\n",
      "Load .json metadata:  ./tmp/train/G_5c62923184bbc.json\n",
      "Load .json metadata:  ./tmp/train/B_casa_cadenas_cadiz3.json\n",
      "Load .json metadata:  ./tmp/train/G_casa_zafra_granada.json\n",
      "Load .json metadata:  ./tmp/train/B_iglesia_caridad_sevilla6.json\n",
      "Load .json metadata:  ./tmp/train/B_5bb0aaee9afc9.json\n",
      "Load .json metadata:  ./tmp/train/B_5dd8f69aee967.json\n",
      "Load .json metadata:  ./tmp/train/M_5c38860a8e338.json\n",
      "Load .json metadata:  ./tmp/train/R_5bb35143c8292.json\n",
      "Load .json metadata:  ./tmp/train/R_20181212_110343.json\n",
      "Load .json metadata:  ./tmp/train/M_5bbe3f16a2771.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc7645ea64dc.json\n",
      "Load .json metadata:  ./tmp/train/G_puerta_apostoles_catedra_valencia3.json\n",
      "Load .json metadata:  ./tmp/train/M_20181212_115516.json\n",
      "Load .json metadata:  ./tmp/train/B_casa_museo_sefardi_granada2.json\n",
      "Load .json metadata:  ./tmp/train/M_5defb57b27d8b.json\n",
      "Load .json metadata:  ./tmp/train/R_5c07fc9b36ec9.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_monaita_granada2.json\n",
      "Load .json metadata:  ./tmp/train/B_palacio_quemadas_cordoba2.json\n",
      "Load .json metadata:  ./tmp/train/R_iglesia_guadahortuna3.json\n",
      "Load .json metadata:  ./tmp/train/M_5e4fb8674b6b0.json\n",
      "Load .json metadata:  ./tmp/train/M_corral_carbon_granada4.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_del_vino_granada12.json\n",
      "Load .json metadata:  ./tmp/train/R_casa_lonja_sevilla_patio.json\n",
      "Load .json metadata:  ./tmp/train/G_puerta_apostoles_catedra_valencia5.json\n",
      "Load .json metadata:  ./tmp/train/G_iglesia_san_nicolas_ubeda2.json\n",
      "Load .json metadata:  ./tmp/train/B_5ce90d44c81b5.json\n",
      "Load .json metadata:  ./tmp/train/M_medina_azahara16.json\n",
      "Load .json metadata:  ./tmp/train/M_5db2c2a620a94.json\n",
      "Load .json metadata:  ./tmp/train/R_san_pedro_cordoba6.json\n",
      "Load .json metadata:  ./tmp/train/R_5bc601592c5ae.json\n",
      "Load .json metadata:  ./tmp/train/B_iglesia_san_juan_de_dios_granada.json\n",
      "Load .json metadata:  ./tmp/train/B_5c4c5d588f969.json\n",
      "Load .json metadata:  ./tmp/train/G_catedral_burgos11.json\n",
      "Load .json metadata:  ./tmp/train/R_5bae51ba6d784.json\n",
      "Load .json metadata:  ./tmp/train/M_5bd35122f11d2.json\n",
      "Load .json metadata:  ./tmp/train/B_5d9e1bfaeb1b0.json\n",
      "Load .json metadata:  ./tmp/train/M_5db2e7f92118d.json\n",
      "Load .json metadata:  ./tmp/train/G_puerta_apostoles_catedra_valencia7.json\n",
      "Load .json metadata:  ./tmp/train/R_5bc2c464cce14.json\n",
      "Load .json metadata:  ./tmp/train/R_iglesia_salvador_ubeda3.json\n",
      "Load .json metadata:  ./tmp/train/M_5bdec6139317d.json\n",
      "Load .json metadata:  ./tmp/train/B_5bbb3a49e5e1d.json\n",
      "Load .json metadata:  ./tmp/train/B_5d98e54e59775.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_elvira_granada3.json\n",
      "Load .json metadata:  ./tmp/train/G_puerta_apostoles_catedral_valencia.json\n",
      "Load .json metadata:  ./tmp/train/B_5c7be6a013c47.json\n",
      "Load .json metadata:  ./tmp/train/M_5bba4d3b86c50.json\n",
      "Load .json metadata:  ./tmp/train/R_5bc4cf3b20c2e.json\n",
      "Load .json metadata:  ./tmp/train/G_iglesia_san_pablo_ubeda5.json\n",
      "Load .json metadata:  ./tmp/train/B_convento_esclavas_puerto_santa_maria.json\n",
      "Load .json metadata:  ./tmp/train/B_5da39ec706056.json\n",
      "Load .json metadata:  ./tmp/train/M_medina_azahara5.json\n",
      "Load .json metadata:  ./tmp/train/G_catedral_burgos9.json\n",
      "Load .json metadata:  ./tmp/train/G_iglesia_san_pablo_ubeda8.json\n",
      "Load .json metadata:  ./tmp/train/R_carcel_martos5.json\n",
      "Load .json metadata:  ./tmp/train/M_5e4fb7d4eb466.json\n",
      "Load .json metadata:  ./tmp/train/G_5cb4506788a6c.json\n",
      "Load .json metadata:  ./tmp/train/G_casa_inquisicion_alhama.json\n",
      "Load .json metadata:  ./tmp/train/B_chancilleria_granada5.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc4cdf0585e4.json\n",
      "Load .json metadata:  ./tmp/train/M_20181212_145543.json\n",
      "Load .json metadata:  ./tmp/train/G_alcazaba-almeria.json\n",
      "Load .json metadata:  ./tmp/train/R_casa_cabildo_jerez5.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc76500a43e5.json\n",
      "Load .json metadata:  ./tmp/train/R_5bcaed60a57a5.json\n",
      "Load .json metadata:  ./tmp/train/M_dintel_adovelado4.json\n",
      "Load .json metadata:  ./tmp/train/B_5bae520c3096f.json\n",
      "Load .json metadata:  ./tmp/train/M_patio_yeso_reales_alcazares_sevilla4.json\n",
      "Load .json metadata:  ./tmp/train/G_monasterio_concepcion_granada4.json\n",
      "Load .json metadata:  ./tmp/train/G_catedral_leon8.json\n",
      "Load .json metadata:  ./tmp/train/R_5bae6379a7219.json\n",
      "Load .json metadata:  ./tmp/train/B_5d90ba3786f84.json\n",
      "Load .json metadata:  ./tmp/train/B_5bacbc2c46129.json\n",
      "Load .json metadata:  ./tmp/train/G_5d853bf14c54f.json\n",
      "Load .json metadata:  ./tmp/train/M_aljibe_san_miguel_bajo.json\n",
      "Load .json metadata:  ./tmp/train/M_5bb0a6a0a9219.json\n",
      "Load .json metadata:  ./tmp/train/M_alcazaba_malaga2.json\n",
      "Load .json metadata:  ./tmp/train/R_5da5cd3e7a1ca.json\n",
      "Load .json metadata:  ./tmp/train/B_5baff87c5d061.json\n",
      "Load .json metadata:  ./tmp/train/B_5bd34562c7157.json\n",
      "Load .json metadata:  ./tmp/train/G_palacio_jabalquinto_baeza13.json\n",
      "Load .json metadata:  ./tmp/train/G_5bac8c5becc42.json\n",
      "Load .json metadata:  ./tmp/train/B_5c191ae226d3d.json\n",
      "Load .json metadata:  ./tmp/train/B_palacio_quemadas_cordoba3.json\n",
      "Load .json metadata:  ./tmp/train/G_5cf2f7b8bb83b.json\n",
      "Load .json metadata:  ./tmp/train/M_5e4fd06f4005c.json\n",
      "Load .json metadata:  ./tmp/train/G_hospital_san_sebastian_cordoba4.json\n",
      "Load .json metadata:  ./tmp/train/M_medina_azahara22.json\n",
      "Load .json metadata:  ./tmp/train/R_puerta_puente_cordoba16.json\n",
      "Load .json metadata:  ./tmp/train/R_5bb897329f5cd.json\n",
      "Load .json metadata:  ./tmp/train/R_5bb90da49c913.json\n",
      "Load .json metadata:  ./tmp/train/B_5c13837ca48df.json\n",
      "Load .json metadata:  ./tmp/train/G_catedral_sevilla6.json\n",
      "Load .json metadata:  ./tmp/train/M_5bf678c169e06.json\n",
      "Load .json metadata:  ./tmp/train/B_5cadbcbc0e666.json\n",
      "Load .json metadata:  ./tmp/train/M_5bcaecccd162f.json\n",
      "Load .json metadata:  ./tmp/train/G_catedral_leon2.json\n",
      "Load .json metadata:  ./tmp/train/B_5df7681a6a1d3.json\n",
      "Load .json metadata:  ./tmp/train/M_alminar_san_jose_granada6.json\n",
      "Load .json metadata:  ./tmp/train/M_20181212_115543.json\n",
      "Load .json metadata:  ./tmp/train/B_santos_justo_pastor_granada3.json\n",
      "Load .json metadata:  ./tmp/train/R_5c1914b7dafda.json\n",
      "Load .json metadata:  ./tmp/train/M_5dd41d557867b.json\n",
      "Load .json metadata:  ./tmp/train/M_5c879cd0ed2cc.json\n",
      "Load .json metadata:  ./tmp/train/R_puerta_puente_cordoba10.json\n",
      "Load .json metadata:  ./tmp/train/G_puerta_bautismo_catedral_sevilla9.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_justicia_granada2.json\n",
      "Load .json metadata:  ./tmp/train/M_5bdedf6d54d29.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_justicia_granada.json\n",
      "Load .json metadata:  ./tmp/train/R_carcel_martos3.json\n",
      "Load .json metadata:  ./tmp/train/R_5c1903a4925ea.json\n",
      "Load .json metadata:  ./tmp/train/B_colegio_san_telmo_sevilla6.json\n",
      "Load .json metadata:  ./tmp/train/G_5d3da546e111e.json\n",
      "Load .json metadata:  ./tmp/train/G_casa_zafra_granada5.json\n",
      "Load .json metadata:  ./tmp/train/G_catedral_toledo2.json\n",
      "Load .json metadata:  ./tmp/train/R_5df9f2036b740.json\n",
      "Load .json metadata:  ./tmp/train/G_5de134de77277.json\n",
      "Load .json metadata:  ./tmp/train/B_convento_magdalena_granada.json\n",
      "Load .json metadata:  ./tmp/train/G_5cc07126bd06d.json\n",
      "Load .json metadata:  ./tmp/train/R_5bb350a2e289a.json\n",
      "Load .json metadata:  ./tmp/train/B_5c4065a551b5d.json\n",
      "Load .json metadata:  ./tmp/train/B_5bd07567077f8.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_elvira_granada2.json\n",
      "Load .json metadata:  ./tmp/train/R_casa_torres_ubeda3.json\n",
      "Load .json metadata:  ./tmp/train/G_catedral_burgos.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc0c8c89fd21.json\n",
      "Load .json metadata:  ./tmp/train/G_casa_abrantes_granada4.json\n",
      "Load .json metadata:  ./tmp/train/M_5db2c2d58820d.json\n",
      "Load .json metadata:  ./tmp/train/B_5ce8393752ba0.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc7645dbbec1.json\n",
      "Load .json metadata:  ./tmp/train/R_iglesia_san_andres.json\n",
      "Load .json metadata:  ./tmp/train/B_chancilleria_granada14.json\n",
      "Load .json metadata:  ./tmp/train/G_palacio_jabalquinto_baeza11.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_monaita_granada.json\n",
      "Load .json metadata:  ./tmp/train/G_5bc1d52645376.json\n",
      "Load .json metadata:  ./tmp/train/R_5c9d17dc28b0e.json\n",
      "Load .json metadata:  ./tmp/train/M_alminar_san_jose_granada4.json\n",
      "Load .json metadata:  ./tmp/train/M_corral_carbon_granada2.json\n",
      "Load .json metadata:  ./tmp/train/G_puerta_apostoles_catedra_valencia2.json\n",
      "Load .json metadata:  ./tmp/train/R_puerta_puente_cordoba5.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc765017d63d.json\n",
      "Load .json metadata:  ./tmp/train/G_casa_abrantes_granada7.json\n",
      "Load .json metadata:  ./tmp/train/R_5bf67925573b1.json\n",
      "Load .json metadata:  ./tmp/train/B_casa_almirante_cadiz5.json\n",
      "Load .json metadata:  ./tmp/train/B_palacio_quemadas_cordoba.json\n",
      "Load .json metadata:  ./tmp/train/G_palacio_jabalquinto_baeza2.json\n",
      "Load .json metadata:  ./tmp/train/B_5bb0b452a19f9.json\n",
      "Load .json metadata:  ./tmp/train/G_catedral_leon6.json\n",
      "Load .json metadata:  ./tmp/train/R_ayuntamiento_baeza13.json\n",
      "Load .json metadata:  ./tmp/train/B_palacio_ansoti_granada9.json\n",
      "Load .json metadata:  ./tmp/train/B_5b8a5bebf2b05.json\n",
      "Load .json metadata:  ./tmp/train/M_20181212_145535.json\n",
      "Load .json metadata:  ./tmp/train/R_palacio_cadenas_ubeda6.json\n",
      "Load .json metadata:  ./tmp/train/G_5d9f62eb395ce.json\n",
      "Load .json metadata:  ./tmp/train/M_5c879cb97a78b.json\n",
      "Load .json metadata:  ./tmp/train/G_hospital_san_sebastian_cordoba3.json\n",
      "Load .json metadata:  ./tmp/train/G_torre_fadrique.json\n",
      "Load .json metadata:  ./tmp/train/G_5cc07109e57de.json\n",
      "Load .json metadata:  ./tmp/train/G_5c4838d6e0fd8.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc8b5000bde2.json\n",
      "Load .json metadata:  ./tmp/train/B_iglesia_angustias_granada2.json\n",
      "Load .json metadata:  ./tmp/train/M_medina_azahara32.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc765338c390.json\n",
      "Load .json metadata:  ./tmp/train/M_5cad9cd45d2e9.json\n",
      "Load .json metadata:  ./tmp/train/G_5bb28d496a53a.json\n",
      "Load .json metadata:  ./tmp/train/M_medina_azahara28.json\n",
      "Load .json metadata:  ./tmp/train/B_5baf982ee2bfd.json\n",
      "Load .json metadata:  ./tmp/train/M_5d31db347e7fe.json\n",
      "Load .json metadata:  ./tmp/train/B_5e3ec0560f9a0.json\n",
      "Load .json metadata:  ./tmp/train/G_5c13847fdc587.json\n",
      "Load .json metadata:  ./tmp/train/B_casa_almirante_cadiz3.json\n",
      "Load .json metadata:  ./tmp/train/G_iglesia_san_pablo_ubeda7.json\n",
      "Load .json metadata:  ./tmp/train/R_5bb78e09c8a9a.json\n",
      "Load .json metadata:  ./tmp/train/B_IMG_0357.json\n",
      "Load .json metadata:  ./tmp/train/R_5c7134cd2811e.json\n",
      "Load .json metadata:  ./tmp/train/M_5d9dcd1b591de.json\n",
      "Load .json metadata:  ./tmp/train/B_catedral_jaen3.json\n",
      "Load .json metadata:  ./tmp/train/R_iglesia_san_cecilio_granada5.json\n",
      "Load .json metadata:  ./tmp/train/R_palacio_carlos_v_granada18.json\n",
      "Load .json metadata:  ./tmp/train/B_compas_convento_santa_isabel_granada3.json\n",
      "Load .json metadata:  ./tmp/train/G_casa_abrantes_granada3.json\n",
      "Load .json metadata:  ./tmp/train/B_casa_museo_sefardi_granada.json\n",
      "Load .json metadata:  ./tmp/train/B_5df11afa505fc.json\n",
      "Load .json metadata:  ./tmp/train/G_iglesia_sabiote.json\n",
      "Load .json metadata:  ./tmp/train/M_5dd41b35bc692.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc75ff931f5d.json\n",
      "Load .json metadata:  ./tmp/train/B_iglesia_san_pedro_pablo_granada3.json\n",
      "Load .json metadata:  ./tmp/train/M_5bbcca54787e1.json\n",
      "Load .json metadata:  ./tmp/train/M_5bec3b41cead0.json\n",
      "Load .json metadata:  ./tmp/train/B_convento_carmelitas_descalzas_granada4.json\n",
      "Load .json metadata:  ./tmp/train/R_iglesia_asuncion_jodar.json\n",
      "Load .json metadata:  ./tmp/train/G_monasterio_concepcion_granada3.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc75fefdc08e.json\n",
      "Load .json metadata:  ./tmp/train/B_5baf578813fe8.json\n",
      "Load .json metadata:  ./tmp/train/B_5be5b11d168b4.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc75e0d6a8e0.json\n",
      "Load .json metadata:  ./tmp/train/G_iglesia_sabiote5.json\n",
      "Load .json metadata:  ./tmp/train/B_5bacb65418a73.json\n",
      "Load .json metadata:  ./tmp/train/B_casa_marqueses_caicedo_granada.json\n",
      "Load .json metadata:  ./tmp/train/R_iglesia_anunciacion_sevilla.json\n",
      "Load .json metadata:  ./tmp/train/B_5bb0a2afa286c.json\n",
      "Load .json metadata:  ./tmp/train/M_20181212_113410.json\n",
      "Load .json metadata:  ./tmp/train/G_catedral_burgos10.json\n",
      "Load .json metadata:  ./tmp/train/G_catedral_leon3.json\n",
      "Load .json metadata:  ./tmp/train/M_5bec3b6fce57a.json\n",
      "Load .json metadata:  ./tmp/train/R_iglesia_guadahortuna2.json\n",
      "Load .json metadata:  ./tmp/train/M_5d99bc04097a3.json\n",
      "Load .json metadata:  ./tmp/train/B_catedral_granada6.json\n",
      "Load .json metadata:  ./tmp/train/G_5bdf14be71c61.json\n",
      "Load .json metadata:  ./tmp/train/B_IMG_0330.json\n",
      "Load .json metadata:  ./tmp/train/M_5baf1bc3da161.json\n",
      "Load .json metadata:  ./tmp/train/R_iglesia_del_sagrario_jaen2.json\n",
      "Load .json metadata:  ./tmp/train/M_alminar_san_jose_granada3.json\n",
      "Load .json metadata:  ./tmp/train/G_iglesia_san_pablo_ubeda4.json\n",
      "Load .json metadata:  ./tmp/train/M_5c7bc23b3c8df.json\n",
      "Load .json metadata:  ./tmp/train/R_5bf817556125f.json\n",
      "Load .json metadata:  ./tmp/train/R_palacio_carlos_v_granada2.json\n",
      "Load .json metadata:  ./tmp/train/B_5ddba404ec262.json\n",
      "Load .json metadata:  ./tmp/train/B_5bd33eb67044c.json\n",
      "Load .json metadata:  ./tmp/train/B_5bb5f3dfac1c3.json\n",
      "Load .json metadata:  ./tmp/train/G_casa_zafra_granada3.json\n",
      "Load .json metadata:  ./tmp/train/M_medina_azahara34.json\n",
      "Load .json metadata:  ./tmp/train/G_capilla_real_granada3.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_de_las_pesas_granada5.json\n",
      "Load .json metadata:  ./tmp/train/G_5bcaece80705a.json\n",
      "Load .json metadata:  ./tmp/train/R_iglesia_san_jeronimo_granada.json\n",
      "Load .json metadata:  ./tmp/train/B_5bad4af6cbe6a.json\n",
      "Load .json metadata:  ./tmp/train/G_5da5cf2a09f80.json\n",
      "Load .json metadata:  ./tmp/train/R_5bf817543af18.json\n",
      "Load .json metadata:  ./tmp/train/B_palacio_ansoti2.json\n",
      "Load .json metadata:  ./tmp/train/B_casa_marqueses_caicedo_granada2.json\n",
      "Load .json metadata:  ./tmp/train/R_5bd575da84afe.json\n",
      "Load .json metadata:  ./tmp/train/R_iglesia_del_sagrario_jaen.json\n",
      "Load .json metadata:  ./tmp/train/B_convento_carmelitas_descalzas_granada6.json\n",
      "Load .json metadata:  ./tmp/train/G_5da6fe91a1b08.json\n",
      "Load .json metadata:  ./tmp/train/M_5c82f4cdc538e.json\n",
      "Load .json metadata:  ./tmp/train/R_puerta_puente_cordoba13.json\n",
      "Load .json metadata:  ./tmp/train/M_5bdee1652730b.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc7649e7f853.json\n",
      "Load .json metadata:  ./tmp/train/M_5db444d933327.json\n",
      "Load .json metadata:  ./tmp/train/G_catedral_burgos8.json\n",
      "Load .json metadata:  ./tmp/train/M_medina_azahara8.json\n",
      "Load .json metadata:  ./tmp/train/B_san_felipe_neri_baeza2.json\n",
      "Load .json metadata:  ./tmp/train/M_5c45b1d2472c7.json\n",
      "Load .json metadata:  ./tmp/train/M_5b8eceba8b412.json\n",
      "Load .json metadata:  ./tmp/train/G_5db2fc59d9b68.json\n",
      "Load .json metadata:  ./tmp/train/R_5bded6103ee40.json\n",
      "Load .json metadata:  ./tmp/train/B_5bb71c65a6474.json\n",
      "Load .json metadata:  ./tmp/train/B_5cb9a29a5424f.json\n",
      "Load .json metadata:  ./tmp/train/R_5bc9b16bd7277.json\n",
      "Load .json metadata:  ./tmp/train/R_palacio_cadenas_ubeda16.json\n",
      "Load .json metadata:  ./tmp/train/M_medina_azahara6.json\n",
      "Load .json metadata:  ./tmp/train/B_iglesia_caridad_sevilla9.json\n",
      "Load .json metadata:  ./tmp/train/G_5ced8dfa04cf1.json\n",
      "Load .json metadata:  ./tmp/train/R_5bcdbfa0a31fb.json\n",
      "Load .json metadata:  ./tmp/train/R_san_grabiel_loja2.json\n",
      "Load .json metadata:  ./tmp/train/B_iglesia_caridad_sevilla8.json\n",
      "Load .json metadata:  ./tmp/train/B_iglesia_san_francisco_cordoba.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc764f8d06ab.json\n",
      "Load .json metadata:  ./tmp/train/R_colegio_niñas_nobles_granada3.json\n",
      "Load .json metadata:  ./tmp/train/B_5bd354095e856.json\n",
      "Load .json metadata:  ./tmp/train/B_5bdb228d13793.json\n",
      "Load .json metadata:  ./tmp/train/G_5dd41b5a94b5e.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc75e652da1b.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc4d231daaf1.json\n",
      "Load .json metadata:  ./tmp/train/B_5c14f51720f9a.json\n",
      "Load .json metadata:  ./tmp/train/G_5c010d67518b6.json\n",
      "Load .json metadata:  ./tmp/train/M_5bd753b475e1b.json\n",
      "Load .json metadata:  ./tmp/train/G_5bc8af93c364c.json\n",
      "Load .json metadata:  ./tmp/train/B_iglesia_señora_gracia_estepa.json\n",
      "Load .json metadata:  ./tmp/train/G_monasterio_concepcion_granada.json\n",
      "Load .json metadata:  ./tmp/train/B_5c2ba60f43651.json\n",
      "Load .json metadata:  ./tmp/train/B_5bb0b4dfa6fc4.json\n",
      "Load .json metadata:  ./tmp/train/M_5bd3504ad94ce.json\n",
      "Load .json metadata:  ./tmp/train/B_5bccafb89cf2f.json\n",
      "Load .json metadata:  ./tmp/train/M_aljibe_san_miguel_bajo4.json\n",
      "Load .json metadata:  ./tmp/train/G_catedral_leon9.json\n",
      "Load .json metadata:  ./tmp/train/R_convento_santa_clara_ubeda2.json\n",
      "Load .json metadata:  ./tmp/train/G_5b8ecc074657b.json\n",
      "Load .json metadata:  ./tmp/train/R_iglesia_del_sagrario_jaen5.json\n",
      "Load .json metadata:  ./tmp/train/B_5bec3a03c184c.json\n",
      "Load .json metadata:  ./tmp/train/G_5c82f51ed64ae.json\n",
      "Load .json metadata:  ./tmp/train/M_20181212_122859.json\n",
      "Load .json metadata:  ./tmp/train/G_torre_fadrique4.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc764753c2e3.json\n",
      "Load .json metadata:  ./tmp/train/G_5bad4abe0539c.json\n",
      "Load .json metadata:  ./tmp/train/G_puerta_bautismo_catedral_sevilla3.json\n",
      "Load .json metadata:  ./tmp/train/B_5e53b78a07e5e.json\n",
      "Load .json metadata:  ./tmp/train/M_5bacb800b40e1.json\n",
      "Load .json metadata:  ./tmp/train/R_ayuntamiento_baeza5.json\n",
      "Load .json metadata:  ./tmp/train/R_5bd19e2979917.json\n",
      "Load .json metadata:  ./tmp/train/M_5c9d17c407acd.json\n",
      "Load .json metadata:  ./tmp/train/R_ayuntamiento_baeza8.json\n",
      "Load .json metadata:  ./tmp/train/M_5e4fbfcdcf33a.json\n",
      "Load .json metadata:  ./tmp/train/B_chancilleria_granada13.json\n",
      "Load .json metadata:  ./tmp/train/G_iglesia_san_miguel_cordoba2.json\n",
      "Load .json metadata:  ./tmp/train/R_5bb8b808d52c6.json\n",
      "Load .json metadata:  ./tmp/train/R_5bb28db47335d.json\n",
      "Load .json metadata:  ./tmp/train/B_fabrica_tabaco_sevilla8.json\n",
      "Load .json metadata:  ./tmp/train/G_catedral_burgos3.json\n",
      "Load .json metadata:  ./tmp/train/B_5bcdf5e2a5c10.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc306e82d209.json\n",
      "Load .json metadata:  ./tmp/train/G_puerta_bautismo_catedral_sevilla11.json\n",
      "Load .json metadata:  ./tmp/train/G_puerta_bautismo_catedral_sevilla12.json\n",
      "Load .json metadata:  ./tmp/train/B_5cf8001418164.json\n",
      "Load .json metadata:  ./tmp/train/G_5bdf0bf35d6ef.json\n",
      "Load .json metadata:  ./tmp/train/M_20181212_113415.json\n",
      "Load .json metadata:  ./tmp/train/M_5c7026209438f.json\n",
      "Load .json metadata:  ./tmp/train/B_santos_justo_pastor_granada7.json\n",
      "Load .json metadata:  ./tmp/train/M_patio_doncella_reales_alcazares_sevilla13.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc9a5fe2bed8.json\n",
      "Load .json metadata:  ./tmp/train/R_palacio_carlos_v_granada14.json\n",
      "Load .json metadata:  ./tmp/train/M_5bae64dc35949.json\n",
      "Load .json metadata:  ./tmp/train/M_corral_carbon_granada11.json\n",
      "Load .json metadata:  ./tmp/train/B_casa_marqueses_de_cartagena_granada3.json\n",
      "Load .json metadata:  ./tmp/train/B_IMG_0339.json\n",
      "Load .json metadata:  ./tmp/train/B_5b8ecb55cc725.json\n",
      "Load .json metadata:  ./tmp/train/R_5c024c2323973.json\n",
      "Load .json metadata:  ./tmp/train/B_5bf6cf1b04611.json\n",
      "Load .json metadata:  ./tmp/train/B_5c8cdc1b5564c.json\n",
      "Load .json metadata:  ./tmp/train/G_5b8eccf9cacde.json\n",
      "Load .json metadata:  ./tmp/train/B_carmelitas_calzadas_granada.json\n",
      "Load .json metadata:  ./tmp/train/G_5d98cc88e4a26.json\n",
      "Load .json metadata:  ./tmp/train/G_5ccefd1dbdf9e.json\n",
      "Load .json metadata:  ./tmp/train/R_20181212_110248.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc75e8d06c33.json\n",
      "Load .json metadata:  ./tmp/train/B_5be6b71806804.json\n",
      "Load .json metadata:  ./tmp/train/G_hospital_san_sebastian_cordoba7.json\n",
      "Load .json metadata:  ./tmp/train/R_ayuntamiento_sevilla3.json\n",
      "Load .json metadata:  ./tmp/train/B_iglesia_san_pedro_pablo_granada2.json\n",
      "Load .json metadata:  ./tmp/train/B_iglesia_angustias_granada3.json\n",
      "Load .json metadata:  ./tmp/train/R_5bd3450596f60.json\n",
      "Load .json metadata:  ./tmp/train/B_5bae52157ff90.json\n",
      "Load .json metadata:  ./tmp/train/B_5bb4ea3b75f38.json\n",
      "Load .json metadata:  ./tmp/train/R_5c09688c5bd6d.json\n",
      "Load .json metadata:  ./tmp/train/M_5c0bb6ad8a829.json\n",
      "Load .json metadata:  ./tmp/train/R_iglesia_santa_ana_granada.json\n",
      "Load .json metadata:  ./tmp/train/G_5ddab25a85cf9.json\n",
      "Load .json metadata:  ./tmp/train/R_puerta_compas_cartuja_granada.json\n",
      "Load .json metadata:  ./tmp/train/M_medina_azahara27.json\n",
      "Load .json metadata:  ./tmp/train/R_palacio_carlos_v_granada4.json\n",
      "Load .json metadata:  ./tmp/train/M_dintel_adovelado7.json\n",
      "Load .json metadata:  ./tmp/train/R_5de6b1e7a7256.json\n",
      "Load .json metadata:  ./tmp/train/B_5c0a71a53b060.json\n",
      "Load .json metadata:  ./tmp/train/B_catedral_granada7.json\n",
      "Load .json metadata:  ./tmp/train/B_5bddc20b3a228.json\n",
      "Load .json metadata:  ./tmp/train/B_convento_carmelitas_descalzas_granada3.json\n",
      "Load .json metadata:  ./tmp/train/R_5bdd586f9ce77.json\n",
      "Load .json metadata:  ./tmp/train/B_convento_carmelitas_descalzas_granada.json\n",
      "Load .json metadata:  ./tmp/train/R_puerta_perdon_catedral_granada6.json\n",
      "Load .json metadata:  ./tmp/train/B_5bec3a053928b.json\n",
      "Load .json metadata:  ./tmp/train/R_curia_granada.json\n",
      "Load .json metadata:  ./tmp/train/G_5bb2417649091.json\n",
      "Load .json metadata:  ./tmp/train/B_5cadbc893b98b.json\n",
      "Load .json metadata:  ./tmp/train/B_casa_cadenas_cadiz4.json\n",
      "Load .json metadata:  ./tmp/train/B_5da8720703692.json\n",
      "Load .json metadata:  ./tmp/train/M_5bd34f039bd23.json\n",
      "Load .json metadata:  ./tmp/train/B_palacio_mendoza_granada.json\n",
      "Load .json metadata:  ./tmp/train/G_5dd2b36c2d262.json\n",
      "Load .json metadata:  ./tmp/train/G_cathedral.json\n",
      "Load .json metadata:  ./tmp/train/G_puerta_infierno_catedral_toledo3.json\n",
      "Load .json metadata:  ./tmp/train/M_5bec3b4e60282.json\n",
      "Load .json metadata:  ./tmp/train/G_5bc06c2a9953c.json\n",
      "Load .json metadata:  ./tmp/train/R_catedral_santa_maria_sevilla.json\n",
      "Load .json metadata:  ./tmp/train/M_medina_azahara.json\n",
      "Load .json metadata:  ./tmp/train/G_basilica_santa_maria_arcos_frontera4.json\n",
      "Load .json metadata:  ./tmp/train/B_hospital_real_granada.json\n",
      "Load .json metadata:  ./tmp/train/G_hospital_san_sebastian_cordoba10.json\n",
      "Load .json metadata:  ./tmp/train/B_5cb31f11d9127.json\n",
      "Load .json metadata:  ./tmp/train/B_iglesia_san_francisco_cordoba2.json\n",
      "Load .json metadata:  ./tmp/train/G_5c0d0f01f22fb.json\n",
      "Load .json metadata:  ./tmp/train/B_5ddd37fa3005f.json\n",
      "Load .json metadata:  ./tmp/train/M_corral_carbon_granada10.json\n",
      "Load .json metadata:  ./tmp/train/B_5c2c923e98eb3.json\n",
      "Load .json metadata:  ./tmp/train/G_convento_clarisas_palencia.json\n",
      "Load .json metadata:  ./tmp/train/B_facultad_derecho_granada6.json\n",
      "Load .json metadata:  ./tmp/train/M_5bd34e85bb4d0.json\n",
      "Load .json metadata:  ./tmp/train/B_5d90d036cd46d.json\n",
      "Load .json metadata:  ./tmp/train/B_5cadb8073058a.json\n",
      "Load .json metadata:  ./tmp/train/R_5c0a52d721023.json\n",
      "Load .json metadata:  ./tmp/train/G_catedral_sevilla2.json\n",
      "Load .json metadata:  ./tmp/train/R_puerta_puente_cordoba.json\n",
      "Load .json metadata:  ./tmp/train/B_colegio_san_telmo_sevilla4.json\n",
      "Load .json metadata:  ./tmp/train/M_alhambra2.json\n",
      "Load .json metadata:  ./tmp/train/B_hospital_san_juan_de_dios_granada3.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc76e871b47e.json\n",
      "Load .json metadata:  ./tmp/train/B_colegio_san_telmo_sevilla5.json\n",
      "Load .json metadata:  ./tmp/train/G_5cd4510ecd2a1.json\n",
      "Load .json metadata:  ./tmp/train/G_5d98cbcf8b124.json\n",
      "Load .json metadata:  ./tmp/train/G_5d07bb5a78cf0.json\n",
      "Load .json metadata:  ./tmp/train/B_5b8ecac4ebfae.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc4cdce3fab8.json\n",
      "Load .json metadata:  ./tmp/train/G_5bc743ec098e2.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_atarazanas_malaga8.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_atarazanas_malaga4.json\n",
      "Load .json metadata:  ./tmp/train/B_5bacb69c505b0.json\n",
      "Load .json metadata:  ./tmp/train/M_5e4fb9bc9e1ae.json\n",
      "Load .json metadata:  ./tmp/train/G_iglesia_sabiote6.json\n",
      "Load .json metadata:  ./tmp/train/G_5bc76dba8ef2f.json\n",
      "Load .json metadata:  ./tmp/train/R_iglesia_salvador_ubeda4.json\n",
      "Load .json metadata:  ./tmp/train/B_5cf7f31d58a0d.json\n",
      "Load .json metadata:  ./tmp/train/M_medina_azahara19.json\n",
      "Load .json metadata:  ./tmp/train/G_5cb6fbc6f2a4a.json\n",
      "Load .json metadata:  ./tmp/train/G_5bec3a78bce6d.json\n",
      "Load .json metadata:  ./tmp/train/G_5c62926eae2a5.json\n",
      "Load .json metadata:  ./tmp/train/B_5cada1e3cfdea.json\n",
      "Load .json metadata:  ./tmp/train/G_iglesia_nuestra_señora_de_la_o_chipiona2.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc765452f841.json\n",
      "Load .json metadata:  ./tmp/train/R_5bd5a68809887.json\n",
      "Load .json metadata:  ./tmp/train/G_5bec50ea6cb7f.json\n",
      "Load .json metadata:  ./tmp/train/M_medina_azahara18.json\n",
      "Load .json metadata:  ./tmp/train/M_5c879cb402953.json\n",
      "Load .json metadata:  ./tmp/train/G_5d62cfd4039d2.json\n",
      "Load .json metadata:  ./tmp/train/M_medina_azahara20.json\n",
      "Load .json metadata:  ./tmp/train/B_5d6648730c69e.json\n",
      "Load .json metadata:  ./tmp/train/G_20181212_105125.json\n",
      "Load .json metadata:  ./tmp/train/R_iglesia_del_sagrario_jaen3.json\n",
      "Load .json metadata:  ./tmp/train/R_iglesia_salvador_ubeda2.json\n",
      "Load .json metadata:  ./tmp/train/B_20181212_105924.json\n",
      "Load .json metadata:  ./tmp/train/B_santos_justo_pastor_granada6.json\n",
      "Load .json metadata:  ./tmp/train/B_5bb5f605c1f88.json\n",
      "Load .json metadata:  ./tmp/train/M_ermita_sansebastian.json\n",
      "Load .json metadata:  ./tmp/train/M_5be5e804a3167.json\n",
      "Load .json metadata:  ./tmp/train/G_5c877f6795355.json\n",
      "Load .json metadata:  ./tmp/train/G_5cadb87f04f94.json\n",
      "Load .json metadata:  ./tmp/train/G_puerta_bautismo_catedral_sevilla10.json\n",
      "Load .json metadata:  ./tmp/train/B_san_juan_cordoba.json\n",
      "Load .json metadata:  ./tmp/train/B_5d9dcbaf77eae.json\n",
      "Load .json metadata:  ./tmp/train/B_catedral_granada.json\n",
      "Load .json metadata:  ./tmp/train/B_5da5d013f0299.json\n",
      "Load .json metadata:  ./tmp/train/M_5db2e772b2a7e.json\n",
      "Load .json metadata:  ./tmp/train/M_5ced1021171f9.json\n",
      "Load .json metadata:  ./tmp/train/R_santa_maria_antequera4.json\n",
      "Load .json metadata:  ./tmp/train/G_iglesia_san_nicolas_ubeda5.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_elvira_granada4.json\n",
      "Load .json metadata:  ./tmp/train/G_5bdf0bbee1eb6.json\n",
      "Load .json metadata:  ./tmp/train/B_convento_merced_granada.json\n",
      "Load .json metadata:  ./tmp/train/R_5c191267b06b1.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_san_isidro_mezquita_cordoba7.json\n",
      "Load .json metadata:  ./tmp/train/B_20181212_105011.json\n",
      "Load .json metadata:  ./tmp/train/M_20181212_115640.json\n",
      "Load .json metadata:  ./tmp/train/B_5bcaedfc23bdb.json\n",
      "Load .json metadata:  ./tmp/train/M_dintel_adovelado2.json\n",
      "Load .json metadata:  ./tmp/train/G_5bdf0b71aba0a.json\n",
      "Load .json metadata:  ./tmp/train/G_5b8ecbee59495.json\n",
      "Load .json metadata:  ./tmp/train/R_5c4066194de97.json\n",
      "Load .json metadata:  ./tmp/train/M_medina_azahara26.json\n",
      "Load .json metadata:  ./tmp/train/R_5db1cfe3aed90.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_elvira_granada6.json\n",
      "Load .json metadata:  ./tmp/train/B_5d66482a8551f.json\n",
      "Load .json metadata:  ./tmp/train/B_5bb4e71f205dd.json\n",
      "Load .json metadata:  ./tmp/train/R_5bb8b7efe4c9c.json\n",
      "Load .json metadata:  ./tmp/train/B_5bd5754e6f78b.json\n",
      "Load .json metadata:  ./tmp/train/G_5c2f2f40203c3.json\n",
      "Load .json metadata:  ./tmp/train/G_5da4ce32a9cbf.json\n",
      "Load .json metadata:  ./tmp/train/R_ayuntamiento_sevilla6.json\n",
      "Load .json metadata:  ./tmp/train/G_5ddc200ecb1a5.json\n",
      "Load .json metadata:  ./tmp/train/G_catedral_toledo4.json\n",
      "Load .json metadata:  ./tmp/train/G_5bb24276e44cc.json\n",
      "Load .json metadata:  ./tmp/train/B_5bb78d37dd05b.json\n",
      "Load .json metadata:  ./tmp/train/M_patio_doncella_reales_alcazares_sevilla6.json\n",
      "Load .json metadata:  ./tmp/train/G_iglesia_san_miguel_cordoba.json\n",
      "Load .json metadata:  ./tmp/train/R_santa_maria_antequera.json\n",
      "Load .json metadata:  ./tmp/train/M_5bad538f2022e.json\n",
      "Load .json metadata:  ./tmp/train/B_5bded5483c8c8.json\n",
      "Load .json metadata:  ./tmp/train/B_5ce83a2b2d61c.json\n",
      "Load .json metadata:  ./tmp/train/B_5def64aa85fc0.json\n",
      "Load .json metadata:  ./tmp/train/R_ayuntamiento_baeza6.json\n",
      "Load .json metadata:  ./tmp/train/B_5c096afcab1bf.json\n",
      "Load .json metadata:  ./tmp/train/G_san_bartolome_andujar2.json\n",
      "Load .json metadata:  ./tmp/train/M_dintel_adovelado.json\n",
      "Load .json metadata:  ./tmp/train/M_5cad9d871f944.json\n",
      "Load .json metadata:  ./tmp/train/M_5baf14b3d8aec.json\n",
      "Load .json metadata:  ./tmp/train/M_5c1385195448d.json\n",
      "Load .json metadata:  ./tmp/train/G_monasterio_concepcion_granada2.json\n",
      "Load .json metadata:  ./tmp/train/R_5be9a1419232a.json\n",
      "Load .json metadata:  ./tmp/train/G_basilica_santa_maria_arcos_frontera7.json\n",
      "Load .json metadata:  ./tmp/train/B_5c0acbbb675b5.json\n",
      "Load .json metadata:  ./tmp/train/M_corral_carbon_granada6.json\n",
      "Load .json metadata:  ./tmp/train/G_5bc76b1661432.json\n",
      "Load .json metadata:  ./tmp/train/M_corral_carbon_granada7.json\n",
      "Load .json metadata:  ./tmp/train/B_palacio_ansoti4.json\n",
      "Load .json metadata:  ./tmp/train/M_medina_azahara11.json\n",
      "Load .json metadata:  ./tmp/train/R_palacio_carlos_v_granada3.json\n",
      "Load .json metadata:  ./tmp/train/G_5bd3513c8e708.json\n",
      "Load .json metadata:  ./tmp/train/B_colegio_san_fernando_granada.json\n",
      "Load .json metadata:  ./tmp/train/M_5e4fb99bb2bc3.json\n",
      "Load .json metadata:  ./tmp/train/B_IMG_1131.json\n",
      "Load .json metadata:  ./tmp/train/B_5c794e4eb432a.json\n",
      "Load .json metadata:  ./tmp/train/M_5e4fb8cac7644.json\n",
      "Load .json metadata:  ./tmp/train/M_ermita_sansebastian2.json\n",
      "Load .json metadata:  ./tmp/train/B_hospital_real_granada2.json\n",
      "Load .json metadata:  ./tmp/train/B_casa_calle_san_matias_granada2.json\n",
      "Load .json metadata:  ./tmp/train/G_5c67dcd823270.json\n",
      "Load .json metadata:  ./tmp/train/R_5bde0353e3682.json\n",
      "Load .json metadata:  ./tmp/train/R_5bb5f42a2c989.json\n",
      "Load .json metadata:  ./tmp/train/R_5bdef0fa697b6.json\n",
      "Load .json metadata:  ./tmp/train/B_5c3dc13138c7a.json\n",
      "Load .json metadata:  ./tmp/train/G_puerta_bautismo_catedral_sevilla6.json\n",
      "Load .json metadata:  ./tmp/train/B_museo_bellas_artes_sevilla5.json\n",
      "Load .json metadata:  ./tmp/train/B_colegio_bartolome_santiago_granada3.json\n",
      "Load .json metadata:  ./tmp/train/B_san_felipe_neri_baeza8.json\n",
      "Load .json metadata:  ./tmp/train/B_5c2764eb103ed.json\n",
      "Load .json metadata:  ./tmp/train/B_5df7426bc0bff.json\n",
      "Load .json metadata:  ./tmp/train/M_5bbcca84a8516.json\n",
      "Load .json metadata:  ./tmp/train/R_palacio_carlos_v_granada20.json\n",
      "Load .json metadata:  ./tmp/train/B_convento_jesus_nazareno_chiclana2.json\n",
      "Load .json metadata:  ./tmp/train/B_5baff856046e5.json\n",
      "Load .json metadata:  ./tmp/train/G_palacio_jabalquinto_baeza14.json\n",
      "Load .json metadata:  ./tmp/train/M_20181212_115538.json\n",
      "Load .json metadata:  ./tmp/train/R_puerta_puente_cordoba8.json\n",
      "Load .json metadata:  ./tmp/train/B_IMG_0378.json\n",
      "Load .json metadata:  ./tmp/train/G_puerta_bautismo_catedral_sevilla7.json\n",
      "Load .json metadata:  ./tmp/train/G_5c7d00c96fbbb.json\n",
      "Load .json metadata:  ./tmp/train/R_iglesia_san_ildefonso_jaen2.json\n",
      "Load .json metadata:  ./tmp/train/R_5c7d015d64d2e.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_del_vino_granada7.json\n",
      "Load .json metadata:  ./tmp/train/R_5bb90f5617705.json\n",
      "Load .json metadata:  ./tmp/train/B_5bb0a2c4b9b8b.json\n",
      "Load .json metadata:  ./tmp/train/G_puerta_apostoles_catedral_murcia3.json\n",
      "Load .json metadata:  ./tmp/train/G_5d98c684abe28.json\n",
      "Load .json metadata:  ./tmp/train/B_5c484246ab3f1.json\n",
      "Load .json metadata:  ./tmp/train/R_palacio_cadenas_ubeda9.json\n",
      "Load .json metadata:  ./tmp/train/M_patio_doncella_reales_alcazares_sevilla9.json\n",
      "Load .json metadata:  ./tmp/train/M_5bd34f9db3310.json\n",
      "Load .json metadata:  ./tmp/train/B_5c2c947748ce6.json\n",
      "Load .json metadata:  ./tmp/train/B_IMG_1132.json\n",
      "Load .json metadata:  ./tmp/train/B_iglesia_san_anton_granada2.json\n",
      "Load .json metadata:  ./tmp/train/B_casa_calle_san_matias_granada3.json\n",
      "Load .json metadata:  ./tmp/train/G_iglesia_san_pablo_ubeda6.json\n",
      "Load .json metadata:  ./tmp/train/G_5da6fcf439ccd.json\n",
      "Load .json metadata:  ./tmp/train/G_5c0d0d49c0423.json\n",
      "Load .json metadata:  ./tmp/train/B_5c4066fd86767.json\n",
      "Load .json metadata:  ./tmp/train/G_iglesia_san_miguel_cordoba4.json\n",
      "Load .json metadata:  ./tmp/train/R_santa_maria_antequera5.json\n",
      "Load .json metadata:  ./tmp/train/B_5d0e5f2316005.json\n",
      "Load .json metadata:  ./tmp/train/M_5bc745d744106.json\n",
      "Load .json metadata:  ./tmp/train/R_iglesia_san_bartolome.json\n",
      "Load .json metadata:  ./tmp/train/B_5c878f098b516.json\n",
      "Load .json metadata:  ./tmp/train/R_5bd96e97c779b.json\n",
      "Load .json metadata:  ./tmp/train/B_iglesia_san_jeronimo_granada2.json\n",
      "Load .json metadata:  ./tmp/train/R_5bacb84ca1ce0.json\n",
      "Load .json metadata:  ./tmp/train/B_5df95dd4cf94d.json\n",
      "Load .json metadata:  ./tmp/train/R_carcel_martos.json\n",
      "Load .json metadata:  ./tmp/train/G_5d9f61bbc6dc2.json\n",
      "Load .json metadata:  ./tmp/train/G_hospital_san_sebastian_cordoba11.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_del_vino_granada9.json\n",
      "Load .json metadata:  ./tmp/train/M_patio_doncella_reales_alcazares_sevilla11.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_monaita_granada4.json\n",
      "Load .json metadata:  ./tmp/train/R_catedral_puerta_perdon_granada.json\n",
      "Load .json metadata:  ./tmp/train/G_5bb28cf500312.json\n",
      "Load .json metadata:  ./tmp/train/R_5bf7c979ad2be.json\n",
      "Load .json metadata:  ./tmp/train/G_basilica_santa_maria_arcos_frontera2.json\n",
      "Load .json metadata:  ./tmp/train/B_san_felipe_neri_baeza4.json\n",
      "Load .json metadata:  ./tmp/train/R_5bb5f7e3b6c72.json\n",
      "Load .json metadata:  ./tmp/train/R_5d98aefd76ce6.json\n",
      "Load .json metadata:  ./tmp/train/B_IMG_1002.json\n",
      "Load .json metadata:  ./tmp/train/R_palacio_carlos_v_granada17.json\n",
      "Load .json metadata:  ./tmp/train/G_5c0a9e2643692.json\n",
      "Load .json metadata:  ./tmp/train/G_hospital_san_sebastian_cordoba2.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_del_vino_granada10.json\n",
      "Load .json metadata:  ./tmp/train/G_5e5a2e8dc057b.json\n",
      "Load .json metadata:  ./tmp/train/B_hospital_real_granada5.json\n",
      "Load .json metadata:  ./tmp/train/B_chancilleria_granada10.json\n",
      "Load .json metadata:  ./tmp/train/G_catedral_sevilla4.json\n",
      "Load .json metadata:  ./tmp/train/R_5bb0b22d051f2.json\n",
      "Load .json metadata:  ./tmp/train/R_ayuntamiento_sevilla.json\n",
      "Load .json metadata:  ./tmp/train/R_palacio_cadenas_ubeda18.json\n",
      "Load .json metadata:  ./tmp/train/B_5ced7d9be567d.json\n",
      "Load .json metadata:  ./tmp/train/G_pinaculo3.json\n",
      "Load .json metadata:  ./tmp/train/M_medina_azahara30.json\n",
      "Load .json metadata:  ./tmp/train/G_5c877f4185ccc.json\n",
      "Load .json metadata:  ./tmp/train/M_20181212_150121.json\n",
      "Load .json metadata:  ./tmp/train/B_5bae53895ec1c.json\n",
      "Load .json metadata:  ./tmp/train/M_patio_yeso_reales_alcazares_sevilla.json\n",
      "Load .json metadata:  ./tmp/train/M_medina_azahara24.json\n",
      "Load .json metadata:  ./tmp/train/B_iglesia_san_anton_granada3.json\n",
      "Load .json metadata:  ./tmp/train/G_hospital_san_sebastian_cordoba8.json\n",
      "Load .json metadata:  ./tmp/train/G_hospital_san_sebastian_cordoba6.json\n",
      "Load .json metadata:  ./tmp/train/B_5bb1ff537029b.json\n",
      "Load .json metadata:  ./tmp/train/G_5c1799d2dde1a.json\n",
      "Load .json metadata:  ./tmp/train/B_5bdb1d1c42d96.json\n",
      "Load .json metadata:  ./tmp/train/B_catedral_jaen.json\n",
      "Load .json metadata:  ./tmp/train/B_5baf98b804126.json\n",
      "Load .json metadata:  ./tmp/train/R_iglesia_santa_fe_granada.json\n",
      "Load .json metadata:  ./tmp/train/R_5bb0b25a063e4.json\n",
      "Load .json metadata:  ./tmp/train/R_palacio_carlos_v_granada15.json\n",
      "Load .json metadata:  ./tmp/train/B_chancilleria_granada9.json\n",
      "Load .json metadata:  ./tmp/train/R_5c0966aea69f7.json\n",
      "Load .json metadata:  ./tmp/train/B_hospital_rreal_granada2.json\n",
      "Load .json metadata:  ./tmp/train/G_hospital_san_sebastian_cordoba5.json\n",
      "Load .json metadata:  ./tmp/train/R_5bc1abdd2b50a.json\n",
      "Load .json metadata:  ./tmp/train/B_5c12755aad84a.json\n",
      "Load .json metadata:  ./tmp/train/B_5bb7972ad3e16.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc76484d31a1.json\n",
      "Load .json metadata:  ./tmp/train/B_5ddba624afba4.json\n",
      "Load .json metadata:  ./tmp/train/G_5d111a858480b.json\n",
      "Load .json metadata:  ./tmp/train/R_san_pedro_cordoba4.json\n",
      "Load .json metadata:  ./tmp/train/B_san_felipe_neri_baeza3.json\n",
      "Load .json metadata:  ./tmp/train/R_5c48450f3f550.json\n",
      "Load .json metadata:  ./tmp/train/R_5bc76d793e6e7.json\n",
      "Load .json metadata:  ./tmp/train/B_5bba92638b868.json\n",
      "Load .json metadata:  ./tmp/train/G_iglesia_santa_maría_del_pi_barcelona2.json\n",
      "Load .json metadata:  ./tmp/train/B_5bfe9d813c0ca.json\n",
      "Load .json metadata:  ./tmp/train/B_5bb5f69957c0a.json\n",
      "Load .json metadata:  ./tmp/train/M_20181212_150254.json\n",
      "Load .json metadata:  ./tmp/train/R_palacio_carlos_v_granada11.json\n",
      "Load .json metadata:  ./tmp/train/B_5c025913a9ddb.json\n",
      "Load .json metadata:  ./tmp/train/G_5c699dfd45a1a.json\n",
      "Load .json metadata:  ./tmp/train/M_20181212_130014.json\n",
      "Load .json metadata:  ./tmp/train/R_puerta_perdon_catedral_granada4.json\n",
      "Load .json metadata:  ./tmp/train/R_san_pedro_cordoba5.json\n",
      "Load .json metadata:  ./tmp/train/B_iglesia_salvador_sevilla.json\n",
      "Load .json metadata:  ./tmp/train/B_san_felipe_neri_baeza7.json\n",
      "Load .json metadata:  ./tmp/train/M_corral_carbon_granada3.json\n",
      "Load .json metadata:  ./tmp/train/M_5bcc9ce820ba1.json\n",
      "Load .json metadata:  ./tmp/train/G_catedral_leon4.json\n",
      "Load .json metadata:  ./tmp/train/B_5bb1c89ba7002.json\n",
      "Load .json metadata:  ./tmp/train/M_20181212_115637.json\n",
      "Load .json metadata:  ./tmp/train/R_5dfa0add8bffc.json\n",
      "Load .json metadata:  ./tmp/train/R_san_pedro_cordoba3.json\n",
      "Load .json metadata:  ./tmp/train/B_5bd0751729011.json\n",
      "Load .json metadata:  ./tmp/train/G_5bb48060bc6a0.json\n",
      "Load .json metadata:  ./tmp/train/B_facultad_derecho_granada5.json\n",
      "Load .json metadata:  ./tmp/train/G_palacio_jabalquinto_baeza.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_del_vino_granada4.json\n",
      "Load .json metadata:  ./tmp/train/G_5cf2f6096b752.json\n",
      "Load .json metadata:  ./tmp/train/G_5c0d10a4df5cb.json\n",
      "Load .json metadata:  ./tmp/train/B_5cf7e81e4e982.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_del_vino_granada.json\n",
      "Load .json metadata:  ./tmp/train/M_5e4fb8e1009fb.json\n",
      "Load .json metadata:  ./tmp/train/R_5bc6e43c0907f.json\n",
      "Load .json metadata:  ./tmp/train/R_5de0eaa225937.json\n",
      "Load .json metadata:  ./tmp/train/G_catedral_burgos4.json\n",
      "Load .json metadata:  ./tmp/train/R_5bb768f243f4d.json\n",
      "Load .json metadata:  ./tmp/train/M_5d623f48dabcd.json\n",
      "Load .json metadata:  ./tmp/train/B_iglesia_caridad_sevilla3.json\n",
      "Load .json metadata:  ./tmp/train/G_catedral_leon5.json\n",
      "Load .json metadata:  ./tmp/train/R_puerta_perdon_catedral_granada12.json\n",
      "Load .json metadata:  ./tmp/train/M_patio_doncella_reales_alcazares_sevilla8.json\n",
      "Load .json metadata:  ./tmp/train/B_5bec4cccf3ed2.json\n",
      "Load .json metadata:  ./tmp/train/B_5c4841c1ca3e2.json\n",
      "Load .json metadata:  ./tmp/train/G_basilica_santa_maria_arcos_frontera3.json\n",
      "Load .json metadata:  ./tmp/train/G_5d74bc786cba6.json\n",
      "Load .json metadata:  ./tmp/train/G_IMG_1052.json\n",
      "Load .json metadata:  ./tmp/train/G_convento_clarisas_palencia5.json\n",
      "Load .json metadata:  ./tmp/train/G_5c2ca09d347ad.json\n",
      "Load .json metadata:  ./tmp/train/M_5bbcca3f7448f.json\n",
      "Load .json metadata:  ./tmp/train/B_parroquia_mayor_santa_maria_encarnacion_huescar.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_justicia_granada5.json\n",
      "Load .json metadata:  ./tmp/train/M_medina_azahara36.json\n",
      "Load .json metadata:  ./tmp/train/R_iglesia_san_cecilio_granada4.json\n",
      "Load .json metadata:  ./tmp/train/G_palacio_jabalquinto_baeza5.json\n",
      "Load .json metadata:  ./tmp/train/R_5bbe3480002dc.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_san_isidro_mezquita_cordoba3.json\n",
      "Load .json metadata:  ./tmp/train/G_5c0d0de30a8f2.json\n",
      "Load .json metadata:  ./tmp/train/G_casa_abrantes_granada.json\n",
      "Load .json metadata:  ./tmp/train/G_5d98c47b04a88.json\n",
      "Load .json metadata:  ./tmp/train/M_20181212_125945.json\n",
      "Load .json metadata:  ./tmp/train/R_puerta_perdon_catedral_granada2.json\n",
      "Load .json metadata:  ./tmp/train/B_5bae55d7aad09.json\n",
      "Load .json metadata:  ./tmp/train/B_5c80d24a04008.json\n",
      "Load .json metadata:  ./tmp/train/G_5db2a2cad60a2.json\n",
      "Load .json metadata:  ./tmp/train/B_colegio_bartolome_santiago_granada4.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc75f2c9c6a4.json\n",
      "Load .json metadata:  ./tmp/train/R_5bc76d50783ef.json\n",
      "Load .json metadata:  ./tmp/train/M_5bc5c30c3eaf6.json\n",
      "Load .json metadata:  ./tmp/train/B_chancilleria_granada11.json\n",
      "Load .json metadata:  ./tmp/train/G_convento_clarisas_palencia2.json\n",
      "Load .json metadata:  ./tmp/train/R_5bc4d1797c791.json\n",
      "Load .json metadata:  ./tmp/train/B_chancilleria_granada2.json\n",
      "Load .json metadata:  ./tmp/train/R_5d559f8ccff2a.json\n",
      "Load .json metadata:  ./tmp/train/G_5bad41c85ae3d.json\n",
      "Load .json metadata:  ./tmp/train/B_casa_almirante_cadiz.json\n",
      "Load .json metadata:  ./tmp/train/R_puerta_perdon_catedral_granada7.json\n",
      "Load .json metadata:  ./tmp/train/B_basilica_angustias_granada2.json\n",
      "Load .json metadata:  ./tmp/train/R_palacio_cadenas_ubeda10.json\n",
      "Load .json metadata:  ./tmp/train/M_5bd4b5dfc5dd4.json\n",
      "Load .json metadata:  ./tmp/train/M_5c1b60d5c92de.json\n",
      "Load .json metadata:  ./tmp/train/G_palacio_jabalquinto_baeza10.json\n",
      "Load .json metadata:  ./tmp/train/R_san_grabiel_loja3.json\n",
      "Load .json metadata:  ./tmp/train/M_dintel_adovelado6.json\n",
      "Load .json metadata:  ./tmp/train/B_museo_bellas_artes_sevilla3.json\n",
      "Load .json metadata:  ./tmp/train/B_5c0b9bda7349b.json\n",
      "Load .json metadata:  ./tmp/train/B_5c19275826ba9.json\n",
      "Load .json metadata:  ./tmp/train/G_5dac7070aa7e2.json\n",
      "Load .json metadata:  ./tmp/train/G_5bc76e72997a7.json\n",
      "Load .json metadata:  ./tmp/train/G_20181212_105521.json\n",
      "Load .json metadata:  ./tmp/train/B_san_felipe_neri_baeza5.json\n",
      "Load .json metadata:  ./tmp/train/R_ayuntamiento_baeza9.json\n",
      "Load .json metadata:  ./tmp/train/B_5c15224895f85.json\n",
      "Load .json metadata:  ./tmp/train/B_5be5d7c4bb9bb.json\n",
      "Load .json metadata:  ./tmp/train/M_5db2c2e015c8c.json\n",
      "Load .json metadata:  ./tmp/train/R_5bb74d7c3e166.json\n",
      "Load .json metadata:  ./tmp/train/B_5cadabdf51477.json\n",
      "Load .json metadata:  ./tmp/train/G_5c7ba984d24b3.json\n",
      "Load .json metadata:  ./tmp/train/B_5ba898dd6f92c.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_san_isidro_mezquita_cordoba4.json\n",
      "Load .json metadata:  ./tmp/train/M_corral_carbon_granada8.json\n",
      "Load .json metadata:  ./tmp/train/B_chancilleria_granada12.json\n",
      "Load .json metadata:  ./tmp/train/R_5bf437f158eb5.json\n",
      "Load .json metadata:  ./tmp/train/B_iglesia_señora_gracia_estepa3.json\n",
      "Load .json metadata:  ./tmp/train/B_catedral_granada9.json\n",
      "Load .json metadata:  ./tmp/train/R_palacio_carlos_v_granada8.json\n",
      "Load .json metadata:  ./tmp/train/M_20181212_105457.json\n",
      "Load .json metadata:  ./tmp/train/B_casatercia_baena.json\n",
      "Load .json metadata:  ./tmp/train/B_5c17dbfe94db3.json\n",
      "Load .json metadata:  ./tmp/train/B_colegio_san_fernando_granada2.json\n",
      "Load .json metadata:  ./tmp/train/R_ayuntamiento_baeza10.json\n",
      "Load .json metadata:  ./tmp/train/B_casa_conde_gabia_granada.json\n",
      "Load .json metadata:  ./tmp/train/B_colegio_san_telmo_sevilla2.json\n",
      "Load .json metadata:  ./tmp/train/G_5e0b2c3b44d7a.json\n",
      "Load .json metadata:  ./tmp/train/R_palacio_carlos_v_granada16.json\n",
      "Load .json metadata:  ./tmp/train/B_casa_calle_san_matias_granada.json\n",
      "Load .json metadata:  ./tmp/train/R_5c23b9ae08c28.json\n",
      "Load .json metadata:  ./tmp/train/B_5bb8ee994df2a.json\n",
      "Load .json metadata:  ./tmp/train/B_san_juan_dios_antequera2.json\n",
      "Load .json metadata:  ./tmp/train/B_chancilleria_granada15.json\n",
      "Load .json metadata:  ./tmp/train/B_palacio_bibataubin_granada.json\n",
      "Load .json metadata:  ./tmp/train/G_5df0cfe41c9e2.json\n",
      "Load .json metadata:  ./tmp/train/B_hospital_san_juan_de_dios_granada2.json\n",
      "Load .json metadata:  ./tmp/train/M_5bdee0fc89299.json\n",
      "Load .json metadata:  ./tmp/train/R_5bfabb729d3b7.json\n",
      "Load .json metadata:  ./tmp/train/R_5bec3f44c6943.json\n",
      "Load .json metadata:  ./tmp/train/R_5bb602378e74b.json\n",
      "Load .json metadata:  ./tmp/train/R_casa_torres_ubeda5.json\n",
      "Load .json metadata:  ./tmp/train/B_5ced0fbf8575d.json\n",
      "Load .json metadata:  ./tmp/train/B_catedral_granada8.json\n",
      "Load .json metadata:  ./tmp/train/R_palacio_cadenas_ubeda2.json\n",
      "Load .json metadata:  ./tmp/train/R_palacio_carlos_v_granada7.json\n",
      "Load .json metadata:  ./tmp/train/G_puerta_bautismo_catedral_sevilla5.json\n",
      "Load .json metadata:  ./tmp/train/B_convento_jesus_nazareno_chiclana4.json\n",
      "Load .json metadata:  ./tmp/train/R_5c1514396c39f.json\n",
      "Load .json metadata:  ./tmp/train/G_20181212_105032.json\n",
      "Load .json metadata:  ./tmp/train/R_5ce695bde2c12.json\n",
      "Load .json metadata:  ./tmp/train/B_5c4c40ffaee5b.json\n",
      "Load .json metadata:  ./tmp/train/M_5ca46555b8d6f.json\n",
      "Load .json metadata:  ./tmp/train/R_ayuntamiento_baeza12.json\n",
      "Load .json metadata:  ./tmp/train/R_5c0cf59f3c68c.json\n",
      "Load .json metadata:  ./tmp/train/R_5e1b37e6a0cca.json\n",
      "Load .json metadata:  ./tmp/train/M_patio_doncella_reales_alcazares_sevilla4.json\n",
      "Load .json metadata:  ./tmp/train/M_patio_yeso_reales_alcazares_sevilla6.json\n",
      "Load .json metadata:  ./tmp/train/G_puerta_apostoles_catedra_valencia4.json\n",
      "Load .json metadata:  ./tmp/train/G_iglesia_san_miguel_cordoba3.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_visires_mezquita_cordoba.json\n",
      "Load .json metadata:  ./tmp/train/B_5c0d00ee1c0cd.json\n",
      "Load .json metadata:  ./tmp/train/G_iglesia_sabiote3.json\n",
      "Load .json metadata:  ./tmp/train/R_5bfab9bb46da6.json\n",
      "Load .json metadata:  ./tmp/train/M_5bb0a6aa5f6e4.json\n",
      "Load .json metadata:  ./tmp/train/R_san_pedro_cordoba.json\n",
      "Load .json metadata:  ./tmp/train/M_20181212_110915.json\n",
      "Load .json metadata:  ./tmp/train/G_5d9f5b7f5da26.json\n",
      "Load .json metadata:  ./tmp/train/G_5da98678c6c25.json\n",
      "Load .json metadata:  ./tmp/train/R_ayuntamiento_baeza2.json\n",
      "Load .json metadata:  ./tmp/train/B_chancilleria_granada3.json\n",
      "Load .json metadata:  ./tmp/train/B_hospital_rreal_granada.json\n",
      "Load .json metadata:  ./tmp/train/R_5bb79917b8e2f.json\n",
      "Load .json metadata:  ./tmp/train/R_5bc4b222ab8b9.json\n",
      "Load .json metadata:  ./tmp/train/B_5bb727333c120.json\n",
      "Load .json metadata:  ./tmp/train/G_puerta_perdon_catedral_toledo.json\n",
      "Load .json metadata:  ./tmp/train/R_santa_maria_puebla_fadrique.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_justicia_granada4.json\n",
      "Load .json metadata:  ./tmp/train/B_5beff5707aec9.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_atarazanas_malaga.json\n",
      "Load .json metadata:  ./tmp/train/M_aljibe_san_miguel_bajo3.json\n",
      "Load .json metadata:  ./tmp/train/B_casa_almirante_cadiz4.json\n",
      "Load .json metadata:  ./tmp/train/R_iglesia_salvador_ubeda5.json\n",
      "Load .json metadata:  ./tmp/train/B_palacio_ansoti6.json\n",
      "Load .json metadata:  ./tmp/train/G_catedral_sevilla.json\n",
      "Load .json metadata:  ./tmp/train/M_5bccb0f95a19f.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc75ea2043a1.json\n",
      "Load .json metadata:  ./tmp/train/B_5bacbc0c24a80.json\n",
      "Load .json metadata:  ./tmp/train/R_5d559e35666bb.json\n",
      "Load .json metadata:  ./tmp/train/M_5c24c231d82db.json\n",
      "Load .json metadata:  ./tmp/train/R_palacio_carlos_v_granada6.json\n",
      "Load .json metadata:  ./tmp/train/G_5d9dcda7e43c1.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_san_isidro_mezquita_cordoba.json\n",
      "Load .json metadata:  ./tmp/train/R_casa_lonja_sevilla_patio2.json\n",
      "Load .json metadata:  ./tmp/train/G_alcazaba-almeria2.json\n",
      "Load .json metadata:  ./tmp/train/G_5c0d1111d3183.json\n",
      "Load .json metadata:  ./tmp/train/G_5d9f5b784eef2.json\n",
      "Load .json metadata:  ./tmp/train/R_puerta_puente_cordoba2.json\n",
      "Load .json metadata:  ./tmp/train/R_5c23bd0b1c5b3.json\n",
      "Load .json metadata:  ./tmp/train/B_5bfab9d919e44.json\n",
      "Load .json metadata:  ./tmp/train/B_hospital_san_juan_de_dios_granada6.json\n",
      "Load .json metadata:  ./tmp/train/B_5c1913fa4368f.json\n",
      "Load .json metadata:  ./tmp/train/M_5c879cbec00c9.json\n",
      "Load .json metadata:  ./tmp/train/G_puerta_apostoles_catedra_valencia6.json\n",
      "Load .json metadata:  ./tmp/train/B_fabrica_tabaco_sevilla4.json\n",
      "Load .json metadata:  ./tmp/train/R_plaza_santa_teresa_ubeda2.json\n",
      "Load .json metadata:  ./tmp/train/R_palacio_carlos_v_granada13.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc75ddc3d1ba.json\n",
      "Load .json metadata:  ./tmp/train/G_5c2b98e90a715.json\n",
      "Load .json metadata:  ./tmp/train/R_ayuntamiento_sevilla9.json\n",
      "Load .json metadata:  ./tmp/train/M_20181212_112635.json\n",
      "Load .json metadata:  ./tmp/train/B_5bdf15a853ace.json\n",
      "Load .json metadata:  ./tmp/train/M_medina_azahara33.json\n",
      "Load .json metadata:  ./tmp/train/M_20181212_112338.json\n",
      "Load .json metadata:  ./tmp/train/B_5bfabad3ce768.json\n",
      "Load .json metadata:  ./tmp/train/B_5bae53c39b2b7.json\n",
      "Load .json metadata:  ./tmp/train/B_5cd7c70902846.json\n",
      "Load .json metadata:  ./tmp/train/B_5bc75ee5ebe5d.json\n",
      "Load .json metadata:  ./tmp/train/G_santa_maria_del_mar_barcelona2.json\n",
      "Load .json metadata:  ./tmp/train/G_palacio_salcedo2.json\n",
      "Load .json metadata:  ./tmp/train/B_san_felipe_neri_baeza6.json\n",
      "Load .json metadata:  ./tmp/train/B_iglesia_señora_gracia_estepa2.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_mihrab_mezquita_cordoba4.json\n",
      "Load .json metadata:  ./tmp/train/G_5df76902c546e.json\n",
      "Load .json metadata:  ./tmp/train/R_5c261a545bbe2.json\n",
      "Load .json metadata:  ./tmp/train/R_5bcaeef31f64b.json\n",
      "Load .json metadata:  ./tmp/train/B_parroquia_nuestra_señora_de_la_o_chipiona.json\n",
      "Load .json metadata:  ./tmp/train/M_5c700b74d7c96.json\n",
      "Load .json metadata:  ./tmp/train/B_catedral_granada3.json\n",
      "Load .json metadata:  ./tmp/train/M_5c6fda72e1704.json\n",
      "Load .json metadata:  ./tmp/train/G_5c740a02c0dac.json\n",
      "Load .json metadata:  ./tmp/train/R_puerta_puente_cordoba11.json\n",
      "Load .json metadata:  ./tmp/train/B_5cada883c36bc.json\n",
      "Load .json metadata:  ./tmp/train/M_puerta_atarazanas_malaga2.json\n",
      "Load .json metadata:  ./tmp/val/M_5db2c3273aa37.json\n",
      "Load .json metadata:  ./tmp/val/B_casa_marqueses_de_cartagena_granada5.json\n",
      "Load .json metadata:  ./tmp/val/G_5df806400189c.json\n",
      "Load .json metadata:  ./tmp/val/B_5bd0a18e3a7cf.json\n",
      "Load .json metadata:  ./tmp/val/B_5c45af8e61851.json\n",
      "Load .json metadata:  ./tmp/val/B_5c68094c5269c.json\n",
      "Load .json metadata:  ./tmp/val/R_casa_cabildo_jerez8.json\n",
      "Load .json metadata:  ./tmp/val/B_5de179ec7b386.json\n",
      "Load .json metadata:  ./tmp/val/M_patio_doncella_reales_alcazares_sevilla12.json\n",
      "Load .json metadata:  ./tmp/val/B_5d2af2ba74f7c.json\n",
      "Load .json metadata:  ./tmp/val/M_puerta_justicia_granada3.json\n",
      "Load .json metadata:  ./tmp/val/R_iglesia_asuncion_jodar2.json\n",
      "Load .json metadata:  ./tmp/val/G_5b8ecbfc3afd4.json\n",
      "Load .json metadata:  ./tmp/val/R_5db7125d0d87f.json\n",
      "Load .json metadata:  ./tmp/val/B_5c8a449b2672b.json\n",
      "Load .json metadata:  ./tmp/val/B_5bae55f40f890.json\n",
      "Load .json metadata:  ./tmp/val/M_5bc3179bc5bd7.json\n",
      "Load .json metadata:  ./tmp/val/M_5bbcca8260a77.json\n",
      "Load .json metadata:  ./tmp/val/B_hospital_san_juan_de_dios_granada.json\n",
      "Load .json metadata:  ./tmp/val/G_5d3603beb29ee.json\n",
      "Load .json metadata:  ./tmp/val/G_5cadb9254e5bb.json\n",
      "Load .json metadata:  ./tmp/val/R_puerta_puente_cordoba7.json\n",
      "Load .json metadata:  ./tmp/val/G_5bc06c895d7f1.json\n",
      "Load .json metadata:  ./tmp/val/M_5bacf44fbf465.json\n",
      "Load .json metadata:  ./tmp/val/B_5bae63c34ffa2.json\n",
      "Load .json metadata:  ./tmp/val/G_5bad24e5bfd54.json\n",
      "Load .json metadata:  ./tmp/val/R_20181212_114849.json\n",
      "Load .json metadata:  ./tmp/val/B_5d9dc590766ab.json\n",
      "Load .json metadata:  ./tmp/val/M_patio_doncella_reales_alcazares_sevilla7.json\n",
      "Load .json metadata:  ./tmp/val/R_casa_arandas.json\n",
      "Load .json metadata:  ./tmp/val/G_casa_abrantes_granada8.json\n",
      "Load .json metadata:  ./tmp/val/B_catedral_jaen5.json\n",
      "Load .json metadata:  ./tmp/val/B_5c876de809b23.json\n",
      "Load .json metadata:  ./tmp/val/R_5bb78ee318b3f.json\n",
      "Load .json metadata:  ./tmp/val/M_20181212_122208.json\n",
      "Load .json metadata:  ./tmp/val/M_5c45b1ab7eacc.json\n",
      "Load .json metadata:  ./tmp/val/G_5bc4b0000a171.json\n",
      "Load .json metadata:  ./tmp/val/M_puerta_atarazanas_malaga7.json\n",
      "Load .json metadata:  ./tmp/val/R_5be6b690211bf.json\n",
      "Load .json metadata:  ./tmp/val/B_5bad4ad9c95b3.json\n",
      "Load .json metadata:  ./tmp/val/G_convento_clarisas_palencia3.json\n",
      "Load .json metadata:  ./tmp/val/M_puerta_de_las_pesas_granada2.json\n",
      "Load .json metadata:  ./tmp/val/G_5c267e2387828.json\n",
      "Load .json metadata:  ./tmp/val/G_5d9f5d4905e1d.json\n",
      "Load .json metadata:  ./tmp/val/B_5cd6a30c8eeae.json\n",
      "Load .json metadata:  ./tmp/val/R_5d208b11429c6.json\n",
      "Load .json metadata:  ./tmp/val/G_catedral_toledo3.json\n",
      "Load .json metadata:  ./tmp/val/R_5bcc411061ead.json\n",
      "Load .json metadata:  ./tmp/val/M_5e5f7d583c41f.json\n",
      "Load .json metadata:  ./tmp/val/B_5bfabb1a9d451.json\n",
      "Load .json metadata:  ./tmp/val/B_iglesia_san_juan_de_dios_granada2.json\n",
      "Load .json metadata:  ./tmp/val/G_casa_abrantes_granada2.json\n",
      "Load .json metadata:  ./tmp/val/M_puerta_del_vino_granada8.json\n",
      "Load .json metadata:  ./tmp/val/B_5cada2796e206.json\n",
      "Load .json metadata:  ./tmp/val/B_chancilleria_granada7.json\n",
      "Load .json metadata:  ./tmp/val/M_5c2ce172117a7.json\n",
      "Load .json metadata:  ./tmp/val/G_5cc0716275b2e.json\n",
      "Load .json metadata:  ./tmp/val/G_5b8a5fbbcc59f.json\n",
      "Load .json metadata:  ./tmp/val/R_convento_santa_clara_ubeda.json\n",
      "Load .json metadata:  ./tmp/val/G_5d09350c0fda2.json\n",
      "Load .json metadata:  ./tmp/val/M_5bd1dff352ca4.json\n",
      "Load .json metadata:  ./tmp/val/M_5c75185ba9a61.json\n",
      "Load .json metadata:  ./tmp/val/B_palacio_ansoti5.json\n",
      "Load .json metadata:  ./tmp/val/M_5bacb65e7ea39.json\n",
      "Load .json metadata:  ./tmp/val/G_hospital_san_sebastian_cordoba.json\n",
      "Load .json metadata:  ./tmp/val/B_casa_cadenas_cadiz.json\n",
      "Load .json metadata:  ./tmp/val/G_capilla_real_granada4.json\n",
      "Load .json metadata:  ./tmp/val/G_20181212_105134.json\n",
      "Load .json metadata:  ./tmp/val/R_5c60427368d45.json\n",
      "Load .json metadata:  ./tmp/val/G_catedral_toledo.json\n",
      "Load .json metadata:  ./tmp/val/B_5bec4cd58ecc0.json\n",
      "Load .json metadata:  ./tmp/val/B_IMG_0329.json\n",
      "Load .json metadata:  ./tmp/val/G_capilla_real_granada2_2.json\n",
      "Load .json metadata:  ./tmp/val/R_plaza_santa_teresa_ubeda.json\n",
      "Load .json metadata:  ./tmp/val/G_iglesia_san_pablo_ubeda9.json\n",
      "Load .json metadata:  ./tmp/val/B_iglesia_san_juan_de_dios_granada3.json\n",
      "Load .json metadata:  ./tmp/val/R_ayuntamiento_baeza7.json\n",
      "Load .json metadata:  ./tmp/val/G_igl_arcos_frontera.json\n",
      "Load .json metadata:  ./tmp/val/B_5c14f985ec8cb.json\n",
      "Load .json metadata:  ./tmp/val/M_20181212_115509.json\n",
      "Load .json metadata:  ./tmp/val/B_5bc75e93a80c2.json\n",
      "Load .json metadata:  ./tmp/val/B_5bc75f886de87.json\n",
      "Load .json metadata:  ./tmp/val/R_5bfdb2389a627.json\n",
      "Load .json metadata:  ./tmp/val/M_medina_azahara9.json\n",
      "Load .json metadata:  ./tmp/val/M_puerta_monaita_granada3.json\n",
      "Load .json metadata:  ./tmp/val/R_palacio_carlos_v_granada.json\n",
      "Load .json metadata:  ./tmp/val/R_san_pedro_cordoba2.json\n",
      "Load .json metadata:  ./tmp/val/B_5c596ad870071.json\n",
      "Load .json metadata:  ./tmp/val/B_5bcdf776e2630.json\n",
      "Load .json metadata:  ./tmp/val/G_5bec3a72c823a.json\n",
      "Load .json metadata:  ./tmp/val/B_palacio_bibataubin_granada4.json\n",
      "Load .json metadata:  ./tmp/val/G_5c877f504a07b.json\n",
      "Load .json metadata:  ./tmp/val/M_puerta_atarazanas_malaga3.json\n",
      "Load .json metadata:  ./tmp/val/G_puerta_bautismo_catedral_sevilla2.json\n",
      "Load .json metadata:  ./tmp/val/R_casa_torres_ubeda4.json\n",
      "Load .json metadata:  ./tmp/val/G_IMG_0369.json\n",
      "Load .json metadata:  ./tmp/val/M_puerta_de_las_pesas_granada6.json\n",
      "Load .json metadata:  ./tmp/val/R_puerta_perdon_catedral_granada5.json\n",
      "Load .json metadata:  ./tmp/val/M_5c85601a50e23.json\n",
      "Load .json metadata:  ./tmp/val/M_5dd41a8a19a4a.json\n",
      "Load .json metadata:  ./tmp/val/M_medina_azahara10.json\n",
      "Load .json metadata:  ./tmp/val/B_convento_santa_ines_granada2.json\n",
      "Load .json metadata:  ./tmp/val/G_basilica_santa_maria_arcos_frontera.json\n",
      "Load .json metadata:  ./tmp/val/B_5be5b0ed738a7.json\n",
      "Load .json metadata:  ./tmp/val/M_5c9620edef2ff.json\n",
      "Load .json metadata:  ./tmp/val/M_5e4fb97a24480.json\n",
      "Load .json metadata:  ./tmp/val/R_puerta_granada_granada.json\n",
      "Load .json metadata:  ./tmp/val/B_facultad_derecho_granada4.json\n",
      "Load .json metadata:  ./tmp/val/R_colegio_niñas_nobles_granada2.json\n",
      "Load .json metadata:  ./tmp/val/R_5bb733b336220.json\n",
      "Load .json metadata:  ./tmp/val/B_fabrica_tabaco_sevilla2.json\n",
      "Load .json metadata:  ./tmp/val/G_pinaculo4.json\n",
      "Load .json metadata:  ./tmp/val/R_capilla_san_francisco_baeza5.json\n",
      "Load .json metadata:  ./tmp/val/M_medina_azahara35.json\n",
      "Load .json metadata:  ./tmp/val/B_IMG_1004.json\n",
      "Load .json metadata:  ./tmp/val/R_5c15277c84aab.json\n",
      "Load .json metadata:  ./tmp/val/G_5cd8200569568.json\n",
      "Load .json metadata:  ./tmp/val/R_5bdef11ecc329.json\n",
      "Load .json metadata:  ./tmp/val/B_catedral_guadix5.json\n",
      "Load .json metadata:  ./tmp/val/B_5c878f865c701.json\n",
      "Load .json metadata:  ./tmp/val/M_20181212_113400.json\n",
      "Load .json metadata:  ./tmp/val/M_5db079dfc13c7.json\n",
      "Load .json metadata:  ./tmp/val/R_5bb4547e1c1e9.json\n",
      "Load .json metadata:  ./tmp/val/R_5cba22808268e.json\n",
      "Load .json metadata:  ./tmp/val/R_5bc0b4b6c8948.json\n",
      "Load .json metadata:  ./tmp/val/B_fabrica_tabaco_sevilla5.json\n",
      "Load .json metadata:  ./tmp/val/B_5ca466a359d1d.json\n",
      "Load .json metadata:  ./tmp/val/R_5bcaf9bf6194d.json\n",
      "Load .json metadata:  ./tmp/val/B_catedral_granada5.json\n",
      "Load .json metadata:  ./tmp/val/B_5cdeec644d080.json\n",
      "Load .json metadata:  ./tmp/val/B_IMG_1055.json\n",
      "Load .json metadata:  ./tmp/val/M_5e5245bcb4ee4.json\n",
      "Load .json metadata:  ./tmp/val/G_iglesia_san_pablo_ubeda3.json\n",
      "Load .json metadata:  ./tmp/val/M_5bccb200d68f2.json\n",
      "Load .json metadata:  ./tmp/val/M_5da4ceed0c3d9.json\n",
      "Load .json metadata:  ./tmp/val/B_IMG_1054.json\n",
      "Load .json metadata:  ./tmp/val/B_5c878f258d48a.json\n",
      "Load .json metadata:  ./tmp/val/B_catedral_granada10.json\n",
      "Load .json metadata:  ./tmp/val/R_iglesia_salvador_granada.json\n",
      "Load .json metadata:  ./tmp/val/B_5bb7b650342fc.json\n",
      "Load .json metadata:  ./tmp/val/G_5d9dcdcba5a00.json\n",
      "Load .json metadata:  ./tmp/val/B_5c0a71fb016ae.json\n",
      "Load .json metadata:  ./tmp/val/B_IMG_0362.json\n",
      "Load .json metadata:  ./tmp/val/B_5bc75e23a2930.json\n",
      "Load .json metadata:  ./tmp/val/G_casa_abrantes_granada5.json\n",
      "Load .json metadata:  ./tmp/val/B_basilica_angustias_granada5.json\n",
      "Load .json metadata:  ./tmp/val/B_5b8ecb06eab42.json\n",
      "Load .json metadata:  ./tmp/val/R_san_grabiel_loja.json\n",
      "Load .json metadata:  ./tmp/val/B_IMG_0359.json\n",
      "Load .json metadata:  ./tmp/val/R_puerta_perdon_catedral_granada8.json\n",
      "Load .json metadata:  ./tmp/val/R_monasterio_cartuja_granada.json\n",
      "Load .json metadata:  ./tmp/val/R_palacio_cadenas_ubeda13.json\n",
      "Load .json metadata:  ./tmp/val/B_IMG_1034.json\n",
      "Load .json metadata:  ./tmp/val/B_5cd3273f34c66.json\n",
      "Load .json metadata:  ./tmp/val/M_puerta_mihrab_mezquita_cordoba2.json\n",
      "Load .json metadata:  ./tmp/val/G_5d98cad22479c.json\n",
      "Load .json metadata:  ./tmp/val/M_patio_yeso_reales_alcazares_sevilla2.json\n",
      "Load .json metadata:  ./tmp/val/B_5bec3a0558cf5.json\n",
      "Load .json metadata:  ./tmp/val/R_casa_cabildo_jerez3.json\n",
      "Load .json metadata:  ./tmp/val/M_5bd577ad73bb0.json\n",
      "Load .json metadata:  ./tmp/val/G_5ced8f6051d21.json\n",
      "Load .json metadata:  ./tmp/val/B_5bfaba8fb40e3.json\n",
      "Load .json metadata:  ./tmp/val/G_puerta_bautismo_catedral_sevilla8.json\n",
      "Load .json metadata:  ./tmp/val/R_5bb78bd53e5ad.json\n",
      "Load .json metadata:  ./tmp/val/B_5c12759d8cc79.json\n",
      "Load .json metadata:  ./tmp/val/G_5bc76dc28fd08.json\n",
      "Load .json metadata:  ./tmp/val/G_5bc9a11663f9b.json\n",
      "Load .json metadata:  ./tmp/val/B_5e4ed1c6cbdec.json\n",
      "Load .json metadata:  ./tmp/val/G_iglesia_san_pablo_ubeda10.json\n",
      "Load .json metadata:  ./tmp/val/G_5de135380f7c3.json\n",
      "Load .json metadata:  ./tmp/val/M_medina_azahara29.json\n",
      "Load .json metadata:  ./tmp/val/M_5baf1a3f2e94b.json\n",
      "Load .json metadata:  ./tmp/val/M_5d623f17ab783.json\n",
      "Load .json metadata:  ./tmp/val/B_basilica_angustias_granada4.json\n",
      "Load .json metadata:  ./tmp/val/B_catedral_guadix7.json\n",
      "Load .json metadata:  ./tmp/val/R_palacio_carlos_v_granada12.json\n",
      "Load .json metadata:  ./tmp/val/B_chancilleria_granada.json\n",
      "Load .json metadata:  ./tmp/val/G_puerta_apostoles_catedral_murcia6.json\n",
      "Load .json metadata:  ./tmp/val/G_iglesia_sabiote4.json\n",
      "Load .json metadata:  ./tmp/val/B_5d9dd3c5b2f16.json\n",
      "Load .json metadata:  ./tmp/val/G_5bc1aaf94ea6d.json\n",
      "Load .json metadata:  ./tmp/val/B_san_juan_dios_antequera.json\n",
      "Load .json metadata:  ./tmp/val/G_5bc9a70361bff.json\n",
      "Load .json metadata:  ./tmp/val/B_5c1cde9e6260a.json\n",
      "Load .json metadata:  ./tmp/val/M_5de6aa806cbef.json\n",
      "Load .json metadata:  ./tmp/val/B_colegio_san_telmo_sevilla.json\n",
      "Load .json metadata:  ./tmp/val/B_IMG_0358.json\n",
      "Load .json metadata:  ./tmp/val/G_palacio_salcedo.json\n",
      "Load .json metadata:  ./tmp/val/R_5d98bfa797969.json\n",
      "Load .json metadata:  ./tmp/val/R_5bc6037474c90.json\n",
      "Load .json metadata:  ./tmp/val/B_5c62af60bdd94.json\n",
      "Load .json metadata:  ./tmp/val/M_5e51856c4c5d0.json\n",
      "Load .json metadata:  ./tmp/val/G_5bb8e97e9badf.json\n",
      "Load .json metadata:  ./tmp/val/B_5babaafb202cf.json\n",
      "Load .json metadata:  ./tmp/val/R_convento_santa_clara_ubeda4.json\n",
      "Load .json metadata:  ./tmp/val/B_5e0354ada9bdf.json\n",
      "Load .json metadata:  ./tmp/val/B_5cf7f3fe6fcc7.json\n",
      "Load .json metadata:  ./tmp/val/M_medina_azahara4.json\n",
      "Load .json metadata:  ./tmp/val/R_5c15348990691.json\n",
      "Load .json metadata:  ./tmp/val/G_palacio_jabalquinto_baeza9.json\n",
      "Load .json metadata:  ./tmp/val/R_5be5e8d4933d2.json\n",
      "Load .json metadata:  ./tmp/val/R_palacio_carlos_v_granada10.json\n",
      "Load .json metadata:  ./tmp/val/R_5c0aaaa13f0d4.json\n",
      "Load .json metadata:  ./tmp/val/G_5c877f35824a9.json\n",
      "Load .json metadata:  ./tmp/val/G_capilla_real_granada5.json\n",
      "Load .json metadata:  ./tmp/val/G_puerta_apostoles_catedral_murcia.json\n",
      "Load .json metadata:  ./tmp/val/R_puerta_perdon_catedral_granada3.json\n",
      "Load .json metadata:  ./tmp/val/M_puerta_elvira_granada.json\n",
      "Load .json metadata:  ./tmp/val/G_5d9c62a9002f9.json\n",
      "Load .json metadata:  ./tmp/val/M_20181212_150308.json\n",
      "Load .json metadata:  ./tmp/val/R_catedral_santa_maria_sevilla2.json\n",
      "Load .json metadata:  ./tmp/val/G_5dd41c407dad2.json\n",
      "Load .json metadata:  ./tmp/val/B_5dfb6b3ec6d75.json\n",
      "Load .json metadata:  ./tmp/val/G_5c6299b35348d.json\n",
      "Load .json metadata:  ./tmp/val/R_ayuntamiento_sevilla8.json\n",
      "Load .json metadata:  ./tmp/val/R_iglesia_san_cecilio_granada.json\n",
      "Load .json metadata:  ./tmp/val/B_museo_bellas_artes_sevilla4.json\n",
      "Load .json metadata:  ./tmp/val/G_5bc4b0208afce.json\n",
      "Load .json metadata:  ./tmp/val/R_5ce91ca209e93.json\n",
      "Load .json metadata:  ./tmp/val/B_IMG_0340.json\n",
      "Load .json metadata:  ./tmp/val/M_5be567087517e.json\n",
      "Load .json metadata:  ./tmp/val/B_facultad_derecho_granada3.json\n",
      "Load .json metadata:  ./tmp/val/B_palacio_ansoti7.json\n",
      "Load .json metadata:  ./tmp/val/B_5c878f1213e55.json\n",
      "Load .json metadata:  ./tmp/val/B_catedral_guadix.json\n",
      "Load .json metadata:  ./tmp/val/B_5d53cdc09e048.json\n",
      "Load .json metadata:  ./tmp/val/B_iglesia_caridad_sevilla4.json\n",
      "Load .json metadata:  ./tmp/val/M_5bae5ed261c0c.json\n",
      "Load .json metadata:  ./tmp/val/M_5c961ed2964b2.json\n",
      "Load .json metadata:  ./tmp/val/B_casa_marqueses_de_cartagena_granada6.json\n",
      "Load .json metadata:  ./tmp/val/R_iglesia_san_cecilio_granada2.json\n",
      "Load .json metadata:  ./tmp/val/B_casa_monte_de_piedad_granada.json\n",
      "Load .json metadata:  ./tmp/val/G_5c82f5c3c0a67.json\n",
      "Load .json metadata:  ./tmp/val/G_puerta_infierno_catedral_toledo2.json\n",
      "Load .json metadata:  ./tmp/val/M_5c38866fefaad.json\n",
      "Load .json metadata:  ./tmp/val/B_5d9dcbbfc416a.json\n",
      "Load .json metadata:  ./tmp/val/B_5be98c369a004.json\n",
      "Load .json metadata:  ./tmp/val/B_5ba899636f449.json\n",
      "Load .json metadata:  ./tmp/val/B_5c8778ca611a2.json\n",
      "Load .json metadata:  ./tmp/val/B_5bc75e6119173.json\n",
      "Load .json metadata:  ./tmp/val/M_20181212_130052.json\n",
      "Load .json metadata:  ./tmp/val/M_5db2e635ab8ed.json\n",
      "Load .json metadata:  ./tmp/val/R_palacio_carlos_v_granada19.json\n",
      "Load .json metadata:  ./tmp/val/M_puerta_de_las_pesas_granada.json\n",
      "Load .json metadata:  ./tmp/val/M_5bcdf82621374.json\n",
      "Load .json metadata:  ./tmp/val/B_compas_convento_santa_isabel_granada.json\n",
      "Load .json metadata:  ./tmp/val/M_5bad4996b3cf4.json\n",
      "Load .json metadata:  ./tmp/val/M_5db2bfe305c0b.json\n",
      "Load .json metadata:  ./tmp/val/B_5bd0a549b5653.json\n",
      "Load .json metadata:  ./tmp/val/G_puerta_bautismo_catedral_sevilla.json\n",
      "Load .json metadata:  ./tmp/val/M_5d0383b7abaf0.json\n",
      "Load .json metadata:  ./tmp/val/R_iglesia_san_cecilio_granada3.json\n",
      "Load .json metadata:  ./tmp/val/M_5baf19070489a.json\n",
      "Load .json metadata:  ./tmp/val/M_corral_carbon_granada9.json\n",
      "Load .json metadata:  ./tmp/val/B_iglesia_san_basilio_granada.json\n",
      "Load .json metadata:  ./tmp/val/B_casa_cadenas_cadiz2.json\n",
      "Load .json metadata:  ./tmp/val/M_corral_carbon_granada.json\n",
      "Load .json metadata:  ./tmp/val/B_5c80d1f310860.json\n",
      "Load .json metadata:  ./tmp/val/G_5c67d9d394832.json\n",
      "Load .json metadata:  ./tmp/val/R_iglesia_anunciacion_sevilla2.json\n",
      "Load .json metadata:  ./tmp/val/B_iglesia_perpetuo_socorro_granada.json\n",
      "Load .json metadata:  ./tmp/val/G_5d98c6d57f872.json\n",
      "Load .json metadata:  ./tmp/val/B_5bed739fdf02e.json\n",
      "Load .json metadata:  ./tmp/val/B_5cf7e7d0e7106.json\n",
      "Load .json metadata:  ./tmp/val/G_5bc4b2d9006fc.json\n",
      "Load .json metadata:  ./tmp/val/R_catedral_puerta_san_jeronimo_granada.json\n",
      "Load .json metadata:  ./tmp/val/R_palacio_cadenas_ubeda4.json\n",
      "Load .json metadata:  ./tmp/val/M_20181212_112853.json\n",
      "Load .json metadata:  ./tmp/val/R_iglesia_santo_domingo_granada.json\n",
      "Load .json metadata:  ./tmp/val/G_5cadb7f561357.json\n",
      "Load .json metadata:  ./tmp/val/G_5cc07140b8e70.json\n",
      "Load .json metadata:  ./tmp/val/B_5bd2cda2a9579.json\n",
      "Load .json metadata:  ./tmp/val/B_convento_carmelitas_descalzas_granada5.json\n",
      "Load .json metadata:  ./tmp/val/B_basilica_angustias_granada.json\n",
      "Load .json metadata:  ./tmp/val/R_5bd33de5f3fa8.json\n",
      "Load .json metadata:  ./tmp/val/G_puerta_apostoles_catedral_murcia4.json\n",
      "Load .json metadata:  ./tmp/val/B_5bdd80e6ea7c8.json\n",
      "Load .json metadata:  ./tmp/val/G_iglesia_nuestra_señora_de_la_o_chipiona.json\n",
      "Load .json metadata:  ./tmp/val/G_iglesia_santa_maría_del_pi_barcelona.json\n",
      "Load .json metadata:  ./tmp/val/R_5db2c3759cdbd.json\n",
      "Load .json metadata:  ./tmp/val/B_palacio_bibataubin_granada3.json\n",
      "Load .json metadata:  ./tmp/val/G_pinaculo2.json\n",
      "Load .json metadata:  ./tmp/val/G_5c138466132c4.json\n",
      "Load .json metadata:  ./tmp/val/M_patio_doncella_reales_alcazares_sevilla.json\n",
      "Load .json metadata:  ./tmp/val/G_catedral_sevilla3.json\n",
      "Load .json metadata:  ./tmp/val/M_patio_doncella_reales_alcazares_sevilla5.json\n",
      "Load .json metadata:  ./tmp/val/B_5bae4188a9817.json\n",
      "Load .json metadata:  ./tmp/val/M_20181212_150258.json\n",
      "Load .json metadata:  ./tmp/val/G_pinaculo5.json\n",
      "Load .json metadata:  ./tmp/val/B_5bd074b099963.json\n",
      "Load .json metadata:  ./tmp/val/R_5bee96a235a67.json\n",
      "Load .json metadata:  ./tmp/val/M_corralcarbon.json\n",
      "Load .json metadata:  ./tmp/val/R_5bb5f65db689e.json\n",
      "Load .json metadata:  ./tmp/val/R_20181212_110256.json\n",
      "Load .json metadata:  ./tmp/val/B_5bc75e9246655.json\n",
      "Load .json metadata:  ./tmp/val/R_puerta_perdon_catedral_granada.json\n",
      "Load .json metadata:  ./tmp/val/R_palacio_carlos_v_granada9.json\n",
      "Load .json metadata:  ./tmp/val/B_IMG_1135.json\n",
      "Load .json metadata:  ./tmp/val/M_alcazaba_malaga.json\n",
      "Load .json metadata:  ./tmp/val/G_iglesia_san_pablo_ubeda2.json\n",
      "Load .json metadata:  ./tmp/val/G_5cb9a35070358.json\n",
      "Load .json metadata:  ./tmp/val/M_ermita_sansebastian3.json\n",
      "Load .json metadata:  ./tmp/val/G_5d4f11234ab2d.json\n",
      "Training del classificatore...\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib/python3.9/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.3354 - loss: 1.3880\n",
      "Epoch 2/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5885 - loss: 1.0546\n",
      "Epoch 3/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8044 - loss: 0.8263\n",
      "Epoch 4/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8550 - loss: 0.6436\n",
      "Epoch 5/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8908 - loss: 0.5223\n",
      "Epoch 6/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8655 - loss: 0.4569\n",
      "Epoch 7/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9035 - loss: 0.3871\n",
      "Epoch 8/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9166 - loss: 0.3522\n",
      "Epoch 9/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9208 - loss: 0.2968\n",
      "Epoch 10/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9464 - loss: 0.2467\n",
      "Epoch 11/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9417 - loss: 0.2364\n",
      "Epoch 12/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9422 - loss: 0.2177\n",
      "Epoch 13/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9266 - loss: 0.2312\n",
      "Epoch 14/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9259 - loss: 0.2233\n",
      "Epoch 15/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9236 - loss: 0.2084\n",
      "Epoch 16/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9438 - loss: 0.1794\n",
      "Epoch 17/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9308 - loss: 0.1840\n",
      "Epoch 18/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9515 - loss: 0.1580\n",
      "Epoch 19/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9349 - loss: 0.1644\n",
      "Epoch 20/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9408 - loss: 0.1671\n",
      "Epoch 21/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9337 - loss: 0.1714\n",
      "Epoch 22/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9468 - loss: 0.1466\n",
      "Epoch 23/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9296 - loss: 0.1651\n",
      "Epoch 24/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9415 - loss: 0.1470\n",
      "Epoch 25/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9440 - loss: 0.1460\n",
      "Epoch 26/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9453 - loss: 0.1500\n",
      "Epoch 27/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9355 - loss: 0.1635\n",
      "Epoch 28/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9297 - loss: 0.1737\n",
      "Epoch 29/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9346 - loss: 0.1619\n",
      "Epoch 30/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9484 - loss: 0.1352\n",
      "Epoch 31/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9498 - loss: 0.1375\n",
      "Epoch 32/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9487 - loss: 0.1303\n",
      "Epoch 33/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9408 - loss: 0.1417\n",
      "Epoch 34/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9402 - loss: 0.1479\n",
      "Epoch 35/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9501 - loss: 0.1327\n",
      "Epoch 36/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9371 - loss: 0.1568\n",
      "Epoch 37/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9324 - loss: 0.1554\n",
      "Epoch 38/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9508 - loss: 0.1182\n",
      "Epoch 39/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9421 - loss: 0.1361\n",
      "Epoch 40/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9458 - loss: 0.1355\n",
      "Epoch 41/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9360 - loss: 0.1413\n",
      "Epoch 42/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9511 - loss: 0.1217\n",
      "Epoch 43/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9513 - loss: 0.1275\n",
      "Epoch 44/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9452 - loss: 0.1389\n",
      "Epoch 45/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9401 - loss: 0.1379\n",
      "Epoch 46/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9580 - loss: 0.1115\n",
      "Epoch 47/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9453 - loss: 0.1360\n",
      "Epoch 48/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9307 - loss: 0.1686\n",
      "Epoch 49/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9556 - loss: 0.1137\n",
      "Epoch 50/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9519 - loss: 0.1183\n",
      "Epoch 51/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9633 - loss: 0.1110\n",
      "Epoch 52/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9559 - loss: 0.1168\n",
      "Epoch 53/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9525 - loss: 0.1284\n",
      "Epoch 54/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9474 - loss: 0.1278\n",
      "Epoch 55/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9616 - loss: 0.1090\n",
      "Epoch 56/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9503 - loss: 0.1199\n",
      "Epoch 57/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9521 - loss: 0.1213\n",
      "Epoch 58/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9573 - loss: 0.1162\n",
      "Epoch 59/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9551 - loss: 0.1302\n",
      "Epoch 60/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9535 - loss: 0.1104\n",
      "Epoch 61/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9565 - loss: 0.1053\n",
      "Epoch 62/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9586 - loss: 0.1183\n",
      "Epoch 63/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9474 - loss: 0.1176\n",
      "Epoch 64/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9530 - loss: 0.1320\n",
      "Epoch 65/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9598 - loss: 0.1112\n",
      "Epoch 66/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9642 - loss: 0.0995\n",
      "Epoch 67/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9483 - loss: 0.1235\n",
      "Epoch 68/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9539 - loss: 0.1098\n",
      "Epoch 69/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9682 - loss: 0.0897\n",
      "Epoch 70/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9643 - loss: 0.1077\n",
      "Epoch 71/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9461 - loss: 0.1353\n",
      "Epoch 72/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9509 - loss: 0.1234\n",
      "Epoch 73/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9554 - loss: 0.1185\n",
      "Epoch 74/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9541 - loss: 0.1119\n",
      "Epoch 75/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9583 - loss: 0.1014\n",
      "Epoch 76/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9448 - loss: 0.1108\n",
      "Epoch 77/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9445 - loss: 0.1281\n",
      "Epoch 78/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9642 - loss: 0.1068\n",
      "Epoch 79/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9633 - loss: 0.1035\n",
      "Epoch 80/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9433 - loss: 0.1163\n",
      "Epoch 81/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9582 - loss: 0.1142\n",
      "Epoch 82/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9544 - loss: 0.0977\n",
      "Epoch 83/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9581 - loss: 0.1055\n",
      "Epoch 84/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9524 - loss: 0.1091\n",
      "Epoch 85/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9604 - loss: 0.1104\n",
      "Epoch 86/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9498 - loss: 0.1199\n",
      "Epoch 87/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9543 - loss: 0.1061\n",
      "Epoch 88/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9642 - loss: 0.0989\n",
      "Epoch 89/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9589 - loss: 0.1017\n",
      "Epoch 90/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9573 - loss: 0.1067\n",
      "Epoch 91/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9528 - loss: 0.1274\n",
      "Epoch 92/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9661 - loss: 0.0864\n",
      "Epoch 93/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9696 - loss: 0.0860\n",
      "Epoch 94/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9567 - loss: 0.1090\n",
      "Epoch 95/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9681 - loss: 0.0870\n",
      "Epoch 96/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9639 - loss: 0.0906\n",
      "Epoch 97/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9610 - loss: 0.0971\n",
      "Epoch 98/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9670 - loss: 0.0920\n",
      "Epoch 99/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9550 - loss: 0.1098\n",
      "Epoch 100/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9616 - loss: 0.0957\n",
      "Epoch 101/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9625 - loss: 0.0986\n",
      "Epoch 102/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9557 - loss: 0.0979 \n",
      "Epoch 103/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9673 - loss: 0.0911\n",
      "Epoch 104/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9518 - loss: 0.0984\n",
      "Epoch 105/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9578 - loss: 0.0998\n",
      "Epoch 106/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9626 - loss: 0.1078\n",
      "Epoch 107/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9495 - loss: 0.1048\n",
      "Epoch 108/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9570 - loss: 0.0948\n",
      "Epoch 109/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9555 - loss: 0.1103\n",
      "Epoch 110/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9589 - loss: 0.1011\n",
      "Epoch 111/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9491 - loss: 0.1011\n",
      "Epoch 112/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9607 - loss: 0.0977   \n",
      "Epoch 113/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9686 - loss: 0.0831\n",
      "Epoch 114/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9661 - loss: 0.0873\n",
      "Epoch 115/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9752 - loss: 0.0794\n",
      "Epoch 116/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9720 - loss: 0.0870\n",
      "Epoch 117/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9593 - loss: 0.0985\n",
      "Epoch 118/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9659 - loss: 0.0757\n",
      "Epoch 119/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9748 - loss: 0.0811\n",
      "Epoch 120/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9683 - loss: 0.0813\n",
      "Epoch 121/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9567 - loss: 0.1127\n",
      "Epoch 122/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9653 - loss: 0.0863\n",
      "Epoch 123/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9602 - loss: 0.0881\n",
      "Epoch 124/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9671 - loss: 0.0865\n",
      "Epoch 125/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9610 - loss: 0.1000\n",
      "Epoch 126/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9693 - loss: 0.0962\n",
      "Epoch 127/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9575 - loss: 0.1000\n",
      "Epoch 128/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9724 - loss: 0.0857\n",
      "Epoch 129/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9654 - loss: 0.0800\n",
      "Epoch 130/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9722 - loss: 0.0780\n",
      "Epoch 131/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9710 - loss: 0.0845\n",
      "Epoch 132/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9712 - loss: 0.0856\n",
      "Epoch 133/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9704 - loss: 0.0917\n",
      "Epoch 134/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9759 - loss: 0.0826\n",
      "Epoch 135/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9692 - loss: 0.0852\n",
      "Epoch 136/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9633 - loss: 0.0998\n",
      "Epoch 137/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9742 - loss: 0.0728\n",
      "Epoch 138/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9765 - loss: 0.0829\n",
      "Epoch 139/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9776 - loss: 0.0704\n",
      "Epoch 140/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9619 - loss: 0.0951\n",
      "Epoch 141/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9663 - loss: 0.0928\n",
      "Epoch 142/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9639 - loss: 0.0958\n",
      "Epoch 143/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9611 - loss: 0.0901\n",
      "Epoch 144/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9773 - loss: 0.0707\n",
      "Epoch 145/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9668 - loss: 0.0829\n",
      "Epoch 146/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9786 - loss: 0.0753\n",
      "Epoch 147/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9878 - loss: 0.0536\n",
      "Epoch 148/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9675 - loss: 0.0886\n",
      "Epoch 149/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9750 - loss: 0.0727\n",
      "Epoch 150/150\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9580 - loss: 0.0889\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8690 - loss: 0.7418 \n",
      "Loss: 0.7050017714500427, Accuracy: 0.8712871074676514\n",
      "Calcolo degli SHAP values...\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 272 background data samples could cause slower run times. Consider using shap.sample(data, K) or shap.kmeans(data, K) to summarize the background as K samples.\n",
      "  0%|                                                                                                        | 0/303 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▎                                                                                               | 1/303 [00:00<02:20,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.520e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=2.948e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=9.529e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=5.037e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 18 iterations, alpha=3.428e-03, previous alpha=2.762e-03, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      "  1%|▋                                                                                               | 2/303 [00:00<02:19,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▉                                                                                               | 3/303 [00:01<02:18,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=8.089e-04, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 30 iterations, alpha=6.565e-05, previous alpha=6.494e-05, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=6.447e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=3.224e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.486e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=5.215e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 14 iterations, alpha=4.712e-04, previous alpha=4.214e-04, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      "  1%|█▎                                                                                              | 4/303 [00:01<02:18,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▌                                                                                              | 5/303 [00:02<02:18,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▉                                                                                              | 6/303 [00:02<02:17,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|██▏                                                                                             | 7/303 [00:03<02:17,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██▌                                                                                             | 8/303 [00:03<02:16,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██▊                                                                                             | 9/303 [00:04<02:16,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.977e-04, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=1.133e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 17 iterations, alpha=8.375e-05, previous alpha=5.750e-05, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=3.999e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 17 iterations, alpha=3.999e-04, previous alpha=1.797e-04, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.821e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=8.901e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=6.702e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=5.013e-04, with an active set of 16 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "  3%|███▏                                                                                           | 10/303 [00:04<02:16,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 795us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=1.951e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.570e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=1.108e-03, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=4.233e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=2.591e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=4.322e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.652e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=6.877e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 11 iterations, alpha=5.457e-03, previous alpha=4.885e-03, with an active set of 6 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.701e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.079e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=9.592e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=3.942e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=2.228e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=9.311e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=3.811e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=2.201e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=1.268e-03, with an active set of 16 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "  4%|███▍                                                                                           | 11/303 [00:05<02:15,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=3.403e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=7.402e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=2.336e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 18 iterations, alpha=1.882e-03, previous alpha=8.918e-04, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=1.060e-01, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=1.541e-02, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=6.916e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=6.916e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 23 iterations, alpha=6.916e-03, previous alpha=6.281e-03, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=4.181e-03, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=3.348e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=2.638e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.329e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.329e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=6.783e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=3.493e-04, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.760e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.402e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.122e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=4.332e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.521e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=4.259e-06, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=4.249e-06, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "  4%|███▊                                                                                           | 12/303 [00:05<02:14,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|████                                                                                           | 13/303 [00:06<02:14,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████▍                                                                                          | 14/303 [00:06<02:13,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████▋                                                                                          | 15/303 [00:06<02:13,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|█████                                                                                          | 16/303 [00:07<02:13,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|█████▎                                                                                         | 17/303 [00:07<02:12,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|█████▋                                                                                         | 18/303 [00:08<02:11,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=3.031e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=6.626e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=3.938e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=3.932e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=2.606e-03, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=1.688e-03, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=1.212e-03, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=8.729e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=2.808e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=6.528e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.072e-02, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.011e-02, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 14 iterations, alpha=9.282e-03, previous alpha=8.643e-03, with an active set of 9 regressors.\n",
      "  warnings.warn(\n",
      "  6%|█████▉                                                                                         | 19/303 [00:08<02:11,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██████▎                                                                                        | 20/303 [00:09<02:11,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██████▌                                                                                        | 21/303 [00:09<02:11,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=1.634e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=1.176e-03, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=4.109e-04, with an active set of 16 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "  7%|██████▉                                                                                        | 22/303 [00:10<02:10,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|███████▏                                                                                       | 23/303 [00:10<02:09,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|███████▌                                                                                       | 24/303 [00:11<02:09,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|███████▊                                                                                       | 25/303 [00:11<02:08,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 18 iterations, alpha=3.309e-03, previous alpha=9.954e-04, with an active set of 11 regressors.\n",
      "  warnings.warn(\n",
      "  9%|████████▏                                                                                      | 26/303 [00:12<02:08,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|████████▍                                                                                      | 27/303 [00:12<02:07,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|████████▊                                                                                      | 28/303 [00:12<02:07,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█████████                                                                                      | 29/303 [00:13<02:07,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█████████▍                                                                                     | 30/303 [00:13<02:06,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█████████▋                                                                                     | 31/303 [00:14<02:06,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|██████████                                                                                     | 32/303 [00:14<02:05,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|██████████▎                                                                                    | 33/303 [00:15<02:05,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|██████████▋                                                                                    | 34/303 [00:15<02:04,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|██████████▉                                                                                    | 35/303 [00:16<02:04,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|███████████▎                                                                                   | 36/303 [00:16<02:03,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|███████████▌                                                                                   | 37/303 [00:17<02:03,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|███████████▉                                                                                   | 38/303 [00:17<02:02,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.476e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=1.318e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=3.277e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=3.339e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.195e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 11 iterations, alpha=1.150e-03, previous alpha=1.115e-03, with an active set of 10 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=2.634e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=4.879e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 20 iterations, alpha=4.737e-04, previous alpha=4.149e-04, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      " 13%|████████████▏                                                                                  | 39/303 [00:18<02:02,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|████████████▌                                                                                  | 40/303 [00:18<02:01,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=2.699e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.350e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.350e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=5.635e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=5.635e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=2.659e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=2.659e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.761e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 13 iterations, alpha=4.730e-04, previous alpha=1.194e-04, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=5.293e-04, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=3.098e-04, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=3.098e-04, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=2.515e-04, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.249e-04, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=9.686e-05, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=4.201e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=4.201e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=4.339e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=3.336e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=3.336e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.926e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.360e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=8.238e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=5.738e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=3.589e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=2.569e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.721e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.412e-05, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=3.610e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=9.907e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=4.010e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=4.010e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=2.922e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=2.005e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.874e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.305e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.105e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=7.829e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=3.949e-04, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=3.949e-04, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=3.820e-04, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=3.698e-04, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=3.253e-04, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=8.942e-05, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=8.942e-05, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=4.027e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=3.291e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 14%|████████████▊                                                                                  | 41/303 [00:19<02:01,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█████████████▏                                                                                 | 42/303 [00:19<02:00,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█████████████▍                                                                                 | 43/303 [00:19<02:00,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/shap/explainers/_kernel.py:707: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 27 iterations, alpha=9.050e-03, previous alpha=6.702e-04, with an active set of 16 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/shap/explainers/_kernel.py:707: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      " 15%|█████████████▊                                                                                 | 44/303 [00:20<01:59,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.134e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=4.521e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=3.049e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.292e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=8.479e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.540e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 15 iterations, alpha=5.818e-04, previous alpha=7.113e-06, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=6.014e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=3.007e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 15 iterations, alpha=2.554e-03, previous alpha=2.410e-03, with an active set of 10 regressors.\n",
      "  warnings.warn(\n",
      " 15%|██████████████                                                                                 | 45/303 [00:20<01:59,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=8.525e-05, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 12 iterations, alpha=8.525e-05, previous alpha=7.686e-05, with an active set of 11 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=4.247e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=5.390e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=2.332e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=2.324e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 13 iterations, alpha=3.057e-03, previous alpha=2.303e-03, with an active set of 10 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=1.140e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=2.665e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=1.637e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=1.631e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 19 iterations, alpha=1.637e-03, previous alpha=1.010e-03, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=3.584e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.741e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.734e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.639e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=8.153e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=8.153e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 10 iterations, alpha=9.256e-03, previous alpha=8.121e-03, with an active set of 7 regressors.\n",
      "  warnings.warn(\n",
      " 15%|██████████████▍                                                                                | 46/303 [00:21<01:58,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|██████████████▋                                                                                | 47/303 [00:21<01:58,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|███████████████                                                                                | 48/303 [00:22<01:57,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|███████████████▎                                                                               | 49/303 [00:22<01:57,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|███████████████▋                                                                               | 50/303 [00:23<01:56,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|███████████████▉                                                                               | 51/303 [00:23<01:56,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|████████████████▎                                                                              | 52/303 [00:24<01:56,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=6.081e-05, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.097e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=4.398e-06, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=7.742e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=3.293e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.016e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 17 iterations, alpha=6.885e-04, previous alpha=4.413e-04, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=1.151e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=1.113e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=1.842e-06, with an active set of 16 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.275e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.141e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=5.957e-04, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=4.257e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=1.674e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=4.610e-05, with an active set of 16 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 17%|████████████████▌                                                                              | 53/303 [00:24<01:55,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 820us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=8.702e-05, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 29 iterations, alpha=5.816e-06, previous alpha=5.114e-06, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=3.757e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=1.628e-05, with an active set of 16 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.668e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.781e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.562e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=7.681e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=1.439e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.230e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=2.354e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=1.506e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=9.710e-06, with an active set of 16 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 18%|████████████████▉                                                                              | 54/303 [00:25<01:55,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 876us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█████████████████▏                                                                             | 55/303 [00:25<01:55,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█████████████████▌                                                                             | 56/303 [00:25<01:54,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=8.175e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 21 iterations, alpha=9.281e-04, previous alpha=6.505e-04, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=3.088e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=2.837e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.199e-03, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.014e-03, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 15 iterations, alpha=1.141e-03, previous alpha=4.448e-04, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=8.697e-04, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=1.521e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=1.354e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=5.872e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=1.675e-04, with an active set of 16 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 19%|█████████████████▊                                                                             | 57/303 [00:26<01:54,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|██████████████████▏                                                                            | 58/303 [00:26<01:53,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 851us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|██████████████████▍                                                                            | 59/303 [00:27<01:53,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██████████████████▊                                                                            | 60/303 [00:27<01:53,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=2.388e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=3.053e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=1.698e-03, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=1.524e-03, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=1.170e-01, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=1.545e-02, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=1.073e-02, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=3.651e-03, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=4.110e-04, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 20%|███████████████████▏                                                                           | 61/303 [00:28<01:53,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████████████████▍                                                                           | 62/303 [00:28<01:52,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 902us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=2.936e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=2.878e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 21%|███████████████████▊                                                                           | 63/303 [00:29<02:17,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=8.905e-04, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=5.007e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 15 iterations, alpha=5.007e-04, previous alpha=1.801e-04, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=6.101e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=1.067e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=8.729e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=5.613e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 18 iterations, alpha=9.421e-04, previous alpha=5.400e-04, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      " 21%|████████████████████                                                                           | 64/303 [00:30<02:08,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|████████████████████▍                                                                          | 65/303 [00:30<02:02,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=3.109e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.554e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 7 iterations, alpha=1.434e-02, previous alpha=1.368e-02, with an active set of 6 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=4.084e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=1.767e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.158e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=9.783e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=8.249e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 10 iterations, alpha=8.936e-03, previous alpha=7.138e-03, with an active set of 9 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=1.214e-01, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=5.213e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=2.545e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 8 iterations, alpha=2.259e-02, previous alpha=2.168e-02, with an active set of 7 regressors.\n",
      "  warnings.warn(\n",
      " 22%|████████████████████▋                                                                          | 66/303 [00:30<01:58,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=6.453e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=5.981e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 17 iterations, alpha=6.374e-05, previous alpha=2.635e-05, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=2.094e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.293e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=4.044e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=2.256e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=6.101e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=4.831e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=3.503e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.337e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=5.077e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=4.390e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 18 iterations, alpha=4.667e-04, previous alpha=2.287e-04, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=6.662e-06, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 22%|█████████████████████                                                                          | 67/303 [00:31<01:55,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=6.951e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=2.757e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.410e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 14 iterations, alpha=8.814e-05, previous alpha=8.814e-05, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=7.679e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 16 iterations, alpha=7.679e-05, previous alpha=5.011e-05, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      " 22%|█████████████████████▎                                                                         | 68/303 [00:31<01:52,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=2.214e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=9.796e-04, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=4.396e-04, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=2.359e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.505e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=7.015e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=3.002e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=3.008e-06, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=6.728e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=4.475e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=3.191e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.549e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.347e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 14 iterations, alpha=1.921e-03, previous alpha=1.310e-03, with an active set of 11 regressors.\n",
      "  warnings.warn(\n",
      " 23%|█████████████████████▋                                                                         | 69/303 [00:32<01:51,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=6.296e-05, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=3.148e-05, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.353e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=5.663e-06, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=4.125e-06, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=1.986e-06, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=2.011e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.424e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=1.670e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=2.166e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.950e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=1.173e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=4.999e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=3.719e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.388e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=4.021e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=2.051e-03, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.970e-03, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=9.513e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=2.841e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=8.573e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=4.317e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 16 iterations, alpha=4.014e-04, previous alpha=1.673e-04, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      " 23%|█████████████████████▉                                                                         | 70/303 [00:32<01:49,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.649e-04, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=3.802e-05, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=2.215e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 18 iterations, alpha=2.209e-05, previous alpha=7.027e-06, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=2.091e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=2.186e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 21 iterations, alpha=2.102e-04, previous alpha=1.405e-04, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.234e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=9.927e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=6.793e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=1.632e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=5.861e-06, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.926e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.604e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 13 iterations, alpha=1.418e-03, previous alpha=1.014e-03, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      " 23%|██████████████████████▎                                                                        | 71/303 [00:33<01:48,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.301e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=4.570e-04, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=3.475e-04, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=1.289e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=5.915e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=2.172e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=8.779e-06, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 24%|██████████████████████▌                                                                        | 72/303 [00:33<01:47,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=3.571e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 10 iterations, alpha=1.742e-02, previous alpha=1.742e-02, with an active set of 7 regressors.\n",
      "  warnings.warn(\n",
      " 24%|██████████████████████▉                                                                        | 73/303 [00:34<01:47,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=8.914e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=1.004e-03, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=1.003e-03, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 24%|███████████████████████▏                                                                       | 74/303 [00:34<01:46,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|███████████████████████▌                                                                       | 75/303 [00:35<01:45,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|███████████████████████▊                                                                       | 76/303 [00:35<01:45,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.724e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=2.270e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=1.664e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 21 iterations, alpha=1.463e-03, previous alpha=1.044e-03, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=3.282e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=2.564e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 20 iterations, alpha=2.561e-03, previous alpha=2.310e-03, with an active set of 11 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=9.101e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=1.024e-02, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=2.870e-03, with an active set of 16 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=4.807e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=8.274e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=7.161e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=5.156e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 11 iterations, alpha=6.399e-03, previous alpha=4.401e-03, with an active set of 10 regressors.\n",
      "  warnings.warn(\n",
      " 25%|████████████████████████▏                                                                      | 77/303 [00:36<01:46,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|████████████████████████▍                                                                      | 78/303 [00:36<01:45,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|████████████████████████▊                                                                      | 79/303 [00:37<01:44,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|█████████████████████████                                                                      | 80/303 [00:37<01:43,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|█████████████████████████▍                                                                     | 81/303 [00:37<01:43,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 18 iterations, alpha=1.267e-04, previous alpha=1.267e-04, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/shap/explainers/_kernel.py:707: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.405e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=1.144e-03, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=6.907e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=9.042e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=3.376e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=2.287e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 10 iterations, alpha=2.557e-03, previous alpha=1.258e-03, with an active set of 9 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=5.785e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=2.688e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 10 iterations, alpha=2.064e-03, previous alpha=1.993e-03, with an active set of 9 regressors.\n",
      "  warnings.warn(\n",
      " 27%|█████████████████████████▋                                                                     | 82/303 [00:38<01:42,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██████████████████████████                                                                     | 83/303 [00:38<01:42,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██████████████████████████▎                                                                    | 84/303 [00:39<01:41,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██████████████████████████▋                                                                    | 85/303 [00:39<01:41,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.656e-03, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=1.053e-03, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=9.938e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 16 iterations, alpha=8.991e-04, previous alpha=8.090e-04, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=2.364e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=1.336e-03, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=1.038e-03, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=3.038e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=2.108e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=2.124e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=2.111e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.636e-03, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 20 iterations, alpha=9.848e-04, previous alpha=9.711e-04, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      " 28%|██████████████████████████▉                                                                    | 86/303 [00:40<01:40,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.045e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=6.447e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=6.188e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=1.752e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=8.736e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 18 iterations, alpha=5.155e-04, previous alpha=8.723e-05, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.278e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=5.125e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=5.108e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=2.489e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=2.312e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 14 iterations, alpha=2.410e-03, previous alpha=1.919e-03, with an active set of 11 regressors.\n",
      "  warnings.warn(\n",
      " 29%|███████████████████████████▎                                                                   | 87/303 [00:40<01:40,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|███████████████████████████▌                                                                   | 88/303 [00:41<01:39,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|███████████████████████████▉                                                                   | 89/303 [00:41<01:39,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=7.433e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=9.043e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=1.609e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=4.655e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=5.333e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=7.038e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 30 iterations, alpha=9.509e-04, previous alpha=9.426e-04, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.416e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=7.068e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=7.030e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 19 iterations, alpha=6.819e-04, previous alpha=8.317e-05, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=6.327e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.515e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=2.368e-03, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=1.939e-03, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 30%|████████████████████████████▏                                                                  | 90/303 [00:42<01:38,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=3.711e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.975e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.855e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 6 iterations, alpha=1.542e-02, previous alpha=1.495e-02, with an active set of 5 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=9.259e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=4.609e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=3.925e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=3.684e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.734e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.610e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 12 iterations, alpha=1.690e-03, previous alpha=1.437e-03, with an active set of 11 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=2.627e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.314e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.298e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 14 iterations, alpha=1.300e-03, previous alpha=5.598e-04, with an active set of 11 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=2.461e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.231e-02, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=3.396e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=3.051e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.236e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=9.802e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 16 iterations, alpha=1.014e-03, previous alpha=4.648e-04, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      " 30%|████████████████████████████▌                                                                  | 91/303 [00:42<01:38,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████████████████████▊                                                                  | 92/303 [00:43<01:37,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/shap/explainers/_kernel.py:707: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      " 31%|█████████████████████████████▏                                                                 | 93/303 [00:43<01:37,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=7.767e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=8.973e-06, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=4.487e-06, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.264e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=8.498e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=9.558e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=7.627e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=1.253e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=2.100e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=2.942e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=2.942e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=1.058e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 31%|█████████████████████████████▍                                                                 | 94/303 [00:43<01:36,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|█████████████████████████████▊                                                                 | 95/303 [00:44<01:36,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|██████████████████████████████                                                                 | 96/303 [00:44<01:36,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|██████████████████████████████▍                                                                | 97/303 [00:45<01:35,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 829us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|██████████████████████████████▋                                                                | 98/303 [00:45<01:35,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███████████████████████████████                                                                | 99/303 [00:46<01:34,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=1.218e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=3.204e-06, with an active set of 16 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=2.239e-04, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.771e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 18 iterations, alpha=1.442e-04, previous alpha=1.142e-04, with an active set of 11 regressors.\n",
      "  warnings.warn(\n",
      " 33%|███████████████████████████████                                                               | 100/303 [00:46<01:34,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███████████████████████████████▎                                                              | 101/303 [00:47<01:34,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=1.860e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=5.775e-05, with an active set of 16 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=6.999e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=4.837e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=4.569e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=2.133e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.610e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 14 iterations, alpha=2.645e-04, previous alpha=1.525e-04, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=4.332e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=4.102e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 16 iterations, alpha=3.535e-04, previous alpha=2.270e-04, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      " 34%|███████████████████████████████▋                                                              | 102/303 [00:47<01:33,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███████████████████████████████▉                                                              | 103/303 [00:48<01:33,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=5.458e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=1.110e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=8.309e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 20 iterations, alpha=5.715e-04, previous alpha=3.349e-04, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=4.975e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=1.074e-03, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=5.351e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 17 iterations, alpha=5.388e-04, previous alpha=2.870e-04, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      " 34%|████████████████████████████████▎                                                             | 104/303 [00:48<01:32,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|████████████████████████████████▌                                                             | 105/303 [00:49<01:32,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.044e-04, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=5.005e-05, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 14 iterations, alpha=2.949e-05, previous alpha=6.773e-06, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=2.491e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.224e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=8.052e-04, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=4.476e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 12 iterations, alpha=4.309e-04, previous alpha=4.098e-04, with an active set of 11 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=7.271e-06, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 17 iterations, alpha=7.271e-06, previous alpha=7.230e-06, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=4.260e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=2.299e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 16 iterations, alpha=2.299e-04, previous alpha=2.068e-04, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      " 35%|████████████████████████████████▉                                                             | 106/303 [00:49<01:31,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|█████████████████████████████████▏                                                            | 107/303 [00:50<01:31,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.151e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=5.757e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=5.585e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 7 iterations, alpha=5.757e-03, previous alpha=5.584e-03, with an active set of 6 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=2.078e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.039e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 13 iterations, alpha=9.244e-04, previous alpha=3.843e-04, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      " 36%|█████████████████████████████████▌                                                            | 108/303 [00:50<01:30,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|█████████████████████████████████▊                                                            | 109/303 [00:50<01:30,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=2.329e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=1.158e-03, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=8.951e-04, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=6.084e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=4.638e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.031e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=5.586e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 16 iterations, alpha=5.586e-05, previous alpha=2.685e-05, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=2.196e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=2.133e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 13 iterations, alpha=1.854e-04, previous alpha=1.677e-04, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      " 36%|██████████████████████████████████▏                                                           | 110/303 [00:51<01:29,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|██████████████████████████████████▍                                                           | 111/303 [00:51<01:29,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|██████████████████████████████████▋                                                           | 112/303 [00:52<01:28,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=2.794e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.397e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=6.986e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 10 iterations, alpha=6.769e-03, previous alpha=5.729e-03, with an active set of 9 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/shap/explainers/_kernel.py:707: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=6.605e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=4.477e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=2.238e-03, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=1.657e-03, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 37%|███████████████████████████████████                                                           | 113/303 [00:52<01:28,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=3.821e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=4.549e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 22 iterations, alpha=4.549e-05, previous alpha=4.534e-05, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=3.617e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.180e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 14 iterations, alpha=3.691e-03, previous alpha=3.641e-03, with an active set of 11 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=9.619e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 19 iterations, alpha=1.481e-02, previous alpha=1.481e-02, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.868e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=8.648e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 10 iterations, alpha=7.410e-04, previous alpha=6.542e-04, with an active set of 9 regressors.\n",
      "  warnings.warn(\n",
      " 38%|███████████████████████████████████▎                                                          | 114/303 [00:53<01:27,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███████████████████████████████████▋                                                          | 115/303 [00:53<01:27,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███████████████████████████████████▉                                                          | 116/303 [00:54<01:26,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|████████████████████████████████████▎                                                         | 117/303 [00:54<01:26,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|████████████████████████████████████▌                                                         | 118/303 [00:55<01:25,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=2.254e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=3.084e-02, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 13 iterations, alpha=1.541e-02, previous alpha=1.541e-02, with an active set of 10 regressors.\n",
      "  warnings.warn(\n",
      " 39%|████████████████████████████████████▉                                                         | 119/303 [00:55<01:25,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=4.595e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=1.112e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=9.799e-04, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 23 iterations, alpha=8.747e-04, previous alpha=5.192e-04, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=3.254e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=2.572e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=2.426e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.046e-03, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 16 iterations, alpha=1.981e-03, previous alpha=4.451e-04, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=9.506e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.282e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 19 iterations, alpha=7.580e-04, previous alpha=7.521e-04, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      " 40%|█████████████████████████████████████▏                                                        | 120/303 [00:56<01:24,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████████████████████████▌                                                        | 121/303 [00:56<01:25,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████████████████████████▊                                                        | 122/303 [00:57<01:25,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=7.973e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 35 iterations, alpha=5.092e-03, previous alpha=3.466e-03, with an active set of 16 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=2.637e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=7.660e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 17 iterations, alpha=3.419e-03, previous alpha=3.384e-03, with an active set of 10 regressors.\n",
      "  warnings.warn(\n",
      " 41%|██████████████████████████████████████▏                                                       | 123/303 [00:57<01:24,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|██████████████████████████████████████▍                                                       | 124/303 [00:57<01:23,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|██████████████████████████████████████▊                                                       | 125/303 [00:58<01:22,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|███████████████████████████████████████                                                       | 126/303 [00:58<01:22,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|███████████████████████████████████████▍                                                      | 127/303 [00:59<01:21,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|███████████████████████████████████████▋                                                      | 128/303 [00:59<01:21,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████████████████████████████████████████                                                      | 129/303 [01:00<01:21,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.263e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=1.391e-04, with an active set of 16 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=2.534e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 15 iterations, alpha=2.224e-04, previous alpha=1.379e-04, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=4.579e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=6.999e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 16 iterations, alpha=2.273e-04, previous alpha=1.680e-04, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=2.416e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=4.608e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=3.605e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 14 iterations, alpha=3.774e-04, previous alpha=2.473e-04, with an active set of 11 regressors.\n",
      "  warnings.warn(\n",
      " 43%|████████████████████████████████████████▎                                                     | 130/303 [01:00<01:20,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=2.821e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=2.314e-03, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=2.079e-03, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=2.889e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=2.042e-05, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=2.100e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=7.603e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 15 iterations, alpha=7.051e-04, previous alpha=4.214e-04, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=3.787e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.347e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=9.155e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=4.254e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 11 iterations, alpha=7.193e-03, previous alpha=2.675e-03, with an active set of 10 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=5.553e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=1.018e-05, with an active set of 16 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 43%|████████████████████████████████████████▋                                                     | 131/303 [01:01<01:20,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=9.474e-05, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=4.737e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=4.681e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 19 iterations, alpha=3.580e-05, previous alpha=3.024e-05, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=7.346e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=1.796e-03, with an active set of 16 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.199e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=3.684e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 11 iterations, alpha=2.557e-03, previous alpha=1.612e-03, with an active set of 10 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=3.995e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=5.327e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=3.370e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=2.868e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 44%|████████████████████████████████████████▉                                                     | 132/303 [01:01<01:19,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|█████████████████████████████████████████▎                                                    | 133/303 [01:02<01:19,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 815us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|█████████████████████████████████████████▌                                                    | 134/303 [01:02<01:19,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|█████████████████████████████████████████▉                                                    | 135/303 [01:03<01:34,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 849us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|██████████████████████████████████████████▏                                                   | 136/303 [01:03<01:29,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|██████████████████████████████████████████▌                                                   | 137/303 [01:04<01:25,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|██████████████████████████████████████████▊                                                   | 138/303 [01:04<01:22,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|███████████████████████████████████████████                                                   | 139/303 [01:05<01:20,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=6.594e-03, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=1.094e-03, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=6.870e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=9.096e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=1.387e-03, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 17 iterations, alpha=1.357e-03, previous alpha=8.626e-04, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=2.801e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=7.445e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=2.953e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 14 iterations, alpha=5.353e-03, previous alpha=1.168e-03, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      " 46%|███████████████████████████████████████████▍                                                  | 140/303 [01:05<01:18,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=6.290e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=2.667e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.972e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=3.146e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 20 iterations, alpha=2.249e-04, previous alpha=1.782e-04, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 18 iterations, alpha=7.601e-04, previous alpha=6.688e-04, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      " 47%|███████████████████████████████████████████▋                                                  | 141/303 [01:06<01:17,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████████████████████████████████████████████                                                  | 142/303 [01:06<01:16,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████████████████████████████████████████████▎                                                 | 143/303 [01:07<01:15,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████████████████████████████████████████████▋                                                 | 144/303 [01:07<01:14,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████████████████████████████████████████████▉                                                 | 145/303 [01:08<01:13,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=7.286e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=3.801e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=1.489e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=3.676e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 16 iterations, alpha=1.446e-04, previous alpha=3.231e-05, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 17 iterations, alpha=8.507e-04, previous alpha=7.729e-04, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/shap/explainers/_kernel.py:707: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      " 48%|█████████████████████████████████████████████▎                                                | 146/303 [01:08<01:13,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|█████████████████████████████████████████████▌                                                | 147/303 [01:08<01:12,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|█████████████████████████████████████████████▉                                                | 148/303 [01:09<01:12,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=6.578e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=4.028e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=3.390e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=1.543e-03, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=1.111e-03, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 18 iterations, alpha=1.855e-03, previous alpha=2.784e-04, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.165e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=3.532e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.013e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=9.007e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=2.627e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=2.168e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=2.948e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=4.881e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=3.831e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=1.520e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=1.499e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 21 iterations, alpha=2.972e-03, previous alpha=1.005e-03, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      " 49%|██████████████████████████████████████████████▏                                               | 149/303 [01:09<01:11,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████████████████████████████▌                                               | 150/303 [01:10<01:11,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=2.496e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 18 iterations, alpha=4.450e-04, previous alpha=4.221e-04, with an active set of 11 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=3.317e-02, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=2.119e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.801e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=8.323e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=6.940e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=1.156e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 24 iterations, alpha=8.839e-04, previous alpha=9.819e-05, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=1.957e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=2.978e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=2.837e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 13 iterations, alpha=2.676e-03, previous alpha=2.441e-03, with an active set of 10 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=6.421e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.499e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=8.066e-04, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 19 iterations, alpha=1.870e-04, previous alpha=7.295e-05, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      " 50%|██████████████████████████████████████████████▊                                               | 151/303 [01:10<01:10,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=1.670e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.858e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=9.292e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=1.563e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 24 iterations, alpha=1.563e-04, previous alpha=1.080e-04, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.247e-02, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.239e-02, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=5.197e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=4.492e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 15 iterations, alpha=6.715e-03, previous alpha=3.143e-03, with an active set of 10 regressors.\n",
      "  warnings.warn(\n",
      " 50%|███████████████████████████████████████████████▏                                              | 152/303 [01:11<01:10,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=5.235e-05, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=6.608e-06, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=5.256e-06, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=6.105e-07, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=2.913e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=7.836e-04, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=3.683e-04, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=2.820e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.399e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=1.313e-05, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=4.811e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=7.283e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=6.863e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 10 iterations, alpha=6.734e-03, previous alpha=5.989e-03, with an active set of 9 regressors.\n",
      "  warnings.warn(\n",
      " 50%|███████████████████████████████████████████████▍                                              | 153/303 [01:11<01:09,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|███████████████████████████████████████████████▊                                              | 154/303 [01:12<01:09,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=2.728e-06, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.578e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=6.734e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 29 iterations, i.e. alpha=5.192e-06, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 51%|████████████████████████████████████████████████                                              | 155/303 [01:12<01:08,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|████████████████████████████████████████████████▍                                             | 156/303 [01:13<01:08,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=4.617e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=7.274e-04, with an active set of 16 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=2.040e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.474e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=4.368e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=4.317e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=3.345e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.608e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.249e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 52%|████████████████████████████████████████████████▋                                             | 157/303 [01:13<01:07,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.966e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.853e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.402e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=6.180e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 16 iterations, alpha=1.026e-04, previous alpha=3.775e-05, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=2.167e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=6.127e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=4.827e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=2.707e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 15 iterations, alpha=4.819e-04, previous alpha=8.252e-05, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=3.256e-05, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=1.115e-05, with an active set of 16 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 52%|█████████████████████████████████████████████████                                             | 158/303 [01:14<01:07,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=4.112e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=5.193e-03, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=5.179e-03, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=2.024e-03, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=2.018e-03, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=4.987e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=4.787e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=4.270e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.776e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=9.604e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=1.699e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 18 iterations, alpha=1.516e-03, previous alpha=1.632e-06, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=4.225e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=3.585e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=6.762e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=3.462e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 18 iterations, alpha=3.540e-04, previous alpha=6.458e-07, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      " 52%|█████████████████████████████████████████████████▎                                            | 159/303 [01:14<01:06,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████████████████████████████████████████████████▋                                            | 160/303 [01:14<01:06,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████████████████████████████████████████████████▉                                            | 161/303 [01:15<01:05,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|██████████████████████████████████████████████████▎                                           | 162/303 [01:15<01:05,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=5.161e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=2.580e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=5.897e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=5.632e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=2.368e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=9.198e-06, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=5.897e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=2.948e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.651e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=9.404e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 15 iterations, alpha=1.163e-03, previous alpha=2.702e-04, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=3.692e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.846e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.749e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=8.449e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.563e-03, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=5.881e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=4.052e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=2.705e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 54%|██████████████████████████████████████████████████▌                                           | 163/303 [01:16<01:05,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|██████████████████████████████████████████████████▉                                           | 164/303 [01:16<01:04,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|███████████████████████████████████████████████████▏                                          | 165/303 [01:17<01:03,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|███████████████████████████████████████████████████▍                                          | 166/303 [01:17<01:03,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|███████████████████████████████████████████████████▊                                          | 167/303 [01:18<01:03,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.149e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=6.076e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=5.384e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.566e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.251e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.138e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 14 iterations, alpha=4.000e-04, previous alpha=6.340e-05, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.803e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.713e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=3.642e-06, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 16 iterations, alpha=1.767e-04, previous alpha=3.460e-06, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      " 55%|████████████████████████████████████████████████████                                          | 168/303 [01:18<01:02,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.162e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=8.529e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=8.529e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=4.265e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 12 iterations, alpha=3.750e-03, previous alpha=3.539e-03, with an active set of 9 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=1.095e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=5.647e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.741e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.588e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 10 iterations, alpha=3.787e-03, previous alpha=1.364e-03, with an active set of 9 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=6.507e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=2.102e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.141e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 18 iterations, alpha=2.045e-03, previous alpha=2.045e-03, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      " 56%|████████████████████████████████████████████████████▍                                         | 169/303 [01:19<01:02,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|████████████████████████████████████████████████████▋                                         | 170/303 [01:19<01:01,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=7.514e-06, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=5.805e-06, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 21 iterations, alpha=7.514e-06, previous alpha=4.620e-06, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      " 56%|█████████████████████████████████████████████████████                                         | 171/303 [01:20<01:01,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████████████████████████████████████████████████████▎                                        | 172/303 [01:20<01:00,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████████████████████████████████████████████████████▋                                        | 173/303 [01:21<01:00,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=2.190e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=3.863e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 14 iterations, alpha=3.754e-03, previous alpha=3.742e-03, with an active set of 11 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=8.185e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=1.218e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 22 iterations, alpha=7.574e-05, previous alpha=4.544e-06, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=3.874e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 23 iterations, alpha=2.520e-03, previous alpha=2.520e-03, with an active set of 16 regressors.\n",
      "  warnings.warn(\n",
      " 57%|█████████████████████████████████████████████████████▉                                        | 174/303 [01:21<01:00,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=7.473e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=1.456e-03, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=9.447e-05, with an active set of 16 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=7.865e-06, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 58%|██████████████████████████████████████████████████████▎                                       | 175/303 [01:21<00:59,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|██████████████████████████████████████████████████████▌                                       | 176/303 [01:22<00:59,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|██████████████████████████████████████████████████████▉                                       | 177/303 [01:22<00:58,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|███████████████████████████████████████████████████████▏                                      | 178/303 [01:23<00:58,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|███████████████████████████████████████████████████████▌                                      | 179/303 [01:23<00:57,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|███████████████████████████████████████████████████████▊                                      | 180/303 [01:24<00:57,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=2.692e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.017e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 6 iterations, alpha=1.017e-02, previous alpha=1.016e-02, with an active set of 5 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=4.539e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 32 iterations, i.e. alpha=2.292e-03, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 34 iterations, alpha=7.751e-05, previous alpha=7.751e-05, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=2.278e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=3.775e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 14 iterations, alpha=3.469e-03, previous alpha=2.723e-03, with an active set of 11 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=6.797e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=2.855e-03, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=2.131e-03, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=1.007e-03, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=9.127e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 60%|████████████████████████████████████████████████████████▏                                     | 181/303 [01:24<00:56,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=6.484e-07, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=5.453e-07, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=6.131e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=7.778e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=3.551e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=3.496e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=1.684e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=9.212e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=3.079e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=4.871e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 28 iterations, alpha=8.226e-05, previous alpha=2.680e-05, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      " 60%|████████████████████████████████████████████████████████▍                                     | 182/303 [01:25<00:56,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|████████████████████████████████████████████████████████▊                                     | 183/303 [01:25<00:55,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=7.955e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 30 iterations, alpha=8.407e-03, previous alpha=2.061e-03, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=7.680e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 17 iterations, alpha=4.585e-05, previous alpha=2.426e-05, with an active set of 16 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=8.673e-03, with an active set of 2 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=2.834e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=2.627e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 9 iterations, alpha=2.636e-03, previous alpha=2.501e-03, with an active set of 8 regressors.\n",
      "  warnings.warn(\n",
      " 61%|█████████████████████████████████████████████████████████                                     | 184/303 [01:26<00:55,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=4.551e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=5.492e-06, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=2.498e-06, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 61%|█████████████████████████████████████████████████████████▍                                    | 185/303 [01:26<00:54,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=5.057e-07, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=1.820e-07, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.659e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=4.735e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=1.620e-04, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=1.381e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=7.352e-06, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 61%|█████████████████████████████████████████████████████████▋                                    | 186/303 [01:27<00:54,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=4.789e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=4.911e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=2.579e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=3.474e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=2.689e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=4.250e-05, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.328e-02, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=9.480e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 29 iterations, alpha=6.337e-04, previous alpha=6.109e-04, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      " 62%|██████████████████████████████████████████████████████████                                    | 187/303 [01:27<00:54,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████████████████████████████████████████████████████████▎                                   | 188/303 [01:28<00:53,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████████████████████████████████████████████████████████▋                                   | 189/303 [01:28<00:52,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████████████████████████████████████████████████████████▉                                   | 190/303 [01:28<00:52,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|███████████████████████████████████████████████████████████▎                                  | 191/303 [01:29<00:51,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|███████████████████████████████████████████████████████████▌                                  | 192/303 [01:29<00:51,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|███████████████████████████████████████████████████████████▊                                  | 193/303 [01:30<00:51,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|████████████████████████████████████████████████████████████▏                                 | 194/303 [01:30<00:50,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=3.036e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 37 iterations, alpha=3.904e-03, previous alpha=1.025e-03, with an active set of 16 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 16 iterations, alpha=9.789e-04, previous alpha=9.153e-04, with an active set of 9 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.257e-02, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 25 iterations, alpha=1.912e-03, previous alpha=1.786e-03, with an active set of 16 regressors.\n",
      "  warnings.warn(\n",
      " 64%|████████████████████████████████████████████████████████████▍                                 | 195/303 [01:31<00:50,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=2.457e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=2.259e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.760e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 9 iterations, alpha=2.023e-03, previous alpha=1.689e-03, with an active set of 8 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=6.285e-06, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 65%|████████████████████████████████████████████████████████████▊                                 | 196/303 [01:31<00:49,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|█████████████████████████████████████████████████████████████                                 | 197/303 [01:32<00:49,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|█████████████████████████████████████████████████████████████▍                                | 198/303 [01:32<00:48,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|█████████████████████████████████████████████████████████████▋                                | 199/303 [01:33<00:48,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████████████████████████████████████████████████████████████                                | 200/303 [01:33<00:47,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████████████████████████████████████████████████████████████▎                               | 201/303 [01:34<00:47,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.811e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=5.447e-04, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=5.341e-04, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=2.533e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 15 iterations, alpha=2.523e-04, previous alpha=2.476e-04, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=3.980e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=7.334e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=3.923e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=3.267e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 18 iterations, alpha=3.808e-03, previous alpha=2.997e-03, with an active set of 11 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=6.511e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=4.318e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 20 iterations, alpha=4.088e-04, previous alpha=1.036e-04, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=2.587e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=1.531e-03, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 23 iterations, alpha=1.476e-03, previous alpha=4.749e-04, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      " 67%|██████████████████████████████████████████████████████████████▋                               | 202/303 [01:34<00:47,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████████████████████████████████████████████████████████████▉                               | 203/303 [01:34<00:46,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|███████████████████████████████████████████████████████████████▎                              | 204/303 [01:35<00:46,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|███████████████████████████████████████████████████████████████▌                              | 205/303 [01:35<00:45,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|███████████████████████████████████████████████████████████████▉                              | 206/303 [01:36<00:45,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|████████████████████████████████████████████████████████████████▏                             | 207/303 [01:36<00:44,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=4.331e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=3.713e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.713e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.586e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=7.900e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 17 iterations, alpha=1.724e-03, previous alpha=5.103e-04, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=5.075e-06, with an active set of 16 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=1.159e-05, with an active set of 16 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 69%|████████████████████████████████████████████████████████████████▌                             | 208/303 [01:37<00:44,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|████████████████████████████████████████████████████████████████▊                             | 209/303 [01:37<00:43,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|█████████████████████████████████████████████████████████████████▏                            | 210/303 [01:38<00:43,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|█████████████████████████████████████████████████████████████████▍                            | 211/303 [01:38<00:42,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=3.999e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.860e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=8.875e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 16 iterations, alpha=8.124e-03, previous alpha=4.103e-03, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.642e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=8.208e-04, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 15 iterations, alpha=6.467e-04, previous alpha=6.140e-04, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=3.774e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=5.830e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=3.860e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=9.546e-06, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 70%|█████████████████████████████████████████████████████████████████▊                            | 212/303 [01:39<00:42,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████████████████████████████████████████                            | 213/303 [01:39<00:41,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=1.505e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=7.527e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=5.887e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=2.442e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.365e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.465e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/shap/explainers/_kernel.py:707: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=2.124e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.025e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=6.190e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=3.095e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.035e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=3.204e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 15 iterations, alpha=2.775e-04, previous alpha=1.727e-05, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/shap/explainers/_kernel.py:707: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      " 71%|██████████████████████████████████████████████████████████████████▍                           | 214/303 [01:40<00:41,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|██████████████████████████████████████████████████████████████████▋                           | 215/303 [01:40<00:40,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.155e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=8.785e-04, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=8.750e-04, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=8.345e-04, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=2.717e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=2.706e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=8.129e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=8.096e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=7.825e-04, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 18 iterations, alpha=1.553e-04, previous alpha=1.245e-04, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=4.050e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 20 iterations, alpha=4.050e-04, previous alpha=4.888e-05, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=6.217e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.092e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=6.033e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=5.266e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=2.287e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=1.531e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=1.286e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=9.457e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 71%|███████████████████████████████████████████████████████████████████                           | 216/303 [01:41<00:40,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████████████████████████████████████████████████████████████████▎                          | 217/303 [01:41<00:39,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████████████████████████████████████████████████████████████████▋                          | 218/303 [01:41<00:39,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=4.819e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=4.819e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=2.410e-02, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.159e-02, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.080e-02, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=5.392e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=2.232e-03, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.684e-03, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.671e-03, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=7.575e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=7.575e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=2.870e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.698e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=4.179e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=2.722e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=7.273e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=7.273e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=4.481e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=3.038e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.233e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=5.267e-04, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=2.171e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.518e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.236e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=8.642e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=3.505e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=3.505e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=3.118e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.407e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.407e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=3.983e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 72%|███████████████████████████████████████████████████████████████████▉                          | 219/303 [01:42<00:39,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|████████████████████████████████████████████████████████████████████▎                         | 220/303 [01:42<00:38,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=7.066e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.495e-03, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.492e-03, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 14 iterations, alpha=1.467e-03, previous alpha=9.438e-04, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=3.255e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=1.144e-06, with an active set of 16 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 73%|████████████████████████████████████████████████████████████████████▌                         | 221/303 [01:43<00:38,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|████████████████████████████████████████████████████████████████████▊                         | 222/303 [01:43<00:37,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|█████████████████████████████████████████████████████████████████████▏                        | 223/303 [01:44<00:37,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|█████████████████████████████████████████████████████████████████████▍                        | 224/303 [01:44<00:36,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|█████████████████████████████████████████████████████████████████████▊                        | 225/303 [01:45<00:36,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|██████████████████████████████████████████████████████████████████████                        | 226/303 [01:45<00:35,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|██████████████████████████████████████████████████████████████████████▍                       | 227/303 [01:46<00:35,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|██████████████████████████████████████████████████████████████████████▋                       | 228/303 [01:46<00:34,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████████████████████████████████████████████████████████████████████                       | 229/303 [01:47<00:34,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████████████████████████████████████████████████████████████████████▎                      | 230/303 [01:47<00:34,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████████████████████████████████████████████████████████████████████▋                      | 231/303 [01:48<00:33,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████████████████████████████████████████████████████████████████████▉                      | 232/303 [01:48<00:33,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|████████████████████████████████████████████████████████████████████████▎                     | 233/303 [01:48<00:32,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=7.382e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=3.575e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=8.499e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=5.861e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=2.211e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=2.044e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 17 iterations, alpha=9.154e-04, previous alpha=4.606e-05, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=2.631e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=2.098e-06, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 18 iterations, alpha=2.098e-06, previous alpha=2.063e-06, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.627e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=1.782e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=1.201e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 77%|████████████████████████████████████████████████████████████████████████▌                     | 234/303 [01:49<00:32,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|████████████████████████████████████████████████████████████████████████▉                     | 235/303 [01:49<00:31,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|█████████████████████████████████████████████████████████████████████████▏                    | 236/303 [01:50<00:31,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|█████████████████████████████████████████████████████████████████████████▌                    | 237/303 [01:50<00:30,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=4.762e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=6.904e-04, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=6.793e-04, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 18 iterations, alpha=4.144e-04, previous alpha=3.331e-04, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=4.543e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 24 iterations, alpha=4.517e-05, previous alpha=4.962e-07, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      " 79%|█████████████████████████████████████████████████████████████████████████▊                    | 238/303 [01:51<00:30,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=4.614e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=4.019e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=1.477e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=1.302e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=2.557e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=2.109e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 79%|██████████████████████████████████████████████████████████████████████████▏                   | 239/303 [01:51<00:29,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|██████████████████████████████████████████████████████████████████████████▍                   | 240/303 [01:52<00:29,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=9.693e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=1.057e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=7.218e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=6.863e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 18 iterations, alpha=6.615e-04, previous alpha=6.026e-04, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=2.919e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.354e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=3.182e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=2.149e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=7.330e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=4.380e-03, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=8.641e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=3.554e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 80%|██████████████████████████████████████████████████████████████████████████▊                   | 241/303 [01:52<00:28,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=5.260e-05, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=2.404e-06, with an active set of 16 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.840e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=3.073e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 22 iterations, alpha=2.828e-03, previous alpha=2.475e-03, with an active set of 11 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.665e-04, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=5.808e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=3.511e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 80%|███████████████████████████████████████████████████████████████████████████                   | 242/303 [01:53<00:28,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████████████████████████████████████████████████████████████████████████▍                  | 243/303 [01:53<00:27,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|███████████████████████████████████████████████████████████████████████████▋                  | 244/303 [01:54<00:27,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████████████████████████████████████████████████████████████████████████                  | 245/303 [01:54<00:26,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████████████████████████████████████████████████████████████████████████▎                 | 246/303 [01:54<00:26,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████████████████████████████████████████████████████████████████████████▋                 | 247/303 [01:55<00:26,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████████████████████████████████████████████████████████████████████████▉                 | 248/303 [01:55<00:25,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|█████████████████████████████████████████████████████████████████████████████▏                | 249/303 [01:56<00:25,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.069e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=4.887e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=2.919e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=1.647e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=4.484e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 18 iterations, alpha=2.986e-04, previous alpha=3.637e-05, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=3.058e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=5.783e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 13 iterations, alpha=5.537e-03, previous alpha=4.076e-03, with an active set of 10 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=3.606e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 21 iterations, alpha=5.351e-03, previous alpha=4.598e-03, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=6.220e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=4.146e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 11 iterations, alpha=3.939e-03, previous alpha=1.324e-03, with an active set of 10 regressors.\n",
      "  warnings.warn(\n",
      " 83%|█████████████████████████████████████████████████████████████████████████████▌                | 250/303 [01:56<00:24,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.172e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=5.861e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=4.836e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=2.259e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 13 iterations, alpha=3.029e-03, previous alpha=1.828e-03, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=2.549e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.260e-02, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=6.204e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 13 iterations, alpha=2.765e-03, previous alpha=2.570e-03, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=8.199e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=4.100e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=2.820e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=2.321e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.601e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.591e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 13 iterations, alpha=2.755e-03, previous alpha=6.928e-04, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=5.350e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=2.675e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 8 iterations, alpha=1.449e-02, previous alpha=1.354e-02, with an active set of 7 regressors.\n",
      "  warnings.warn(\n",
      " 83%|█████████████████████████████████████████████████████████████████████████████▊                | 251/303 [01:57<00:24,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|██████████████████████████████████████████████████████████████████████████████▏               | 252/303 [01:57<00:23,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=3.637e-05, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=2.829e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=2.629e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 15 iterations, alpha=2.147e-05, previous alpha=1.155e-05, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=7.871e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=7.832e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=3.944e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 15 iterations, alpha=6.175e-04, previous alpha=1.798e-04, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=8.224e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=6.693e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 83%|██████████████████████████████████████████████████████████████████████████████▍               | 253/303 [01:58<00:23,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|██████████████████████████████████████████████████████████████████████████████▊               | 254/303 [01:58<00:22,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=5.057e-05, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=4.922e-05, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 19 iterations, alpha=4.922e-05, previous alpha=4.829e-05, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=6.520e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=6.394e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=2.535e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=2.486e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.815e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=1.508e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=1.479e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=3.655e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=2.677e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=2.299e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=5.836e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=5.221e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=2.212e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 18 iterations, alpha=1.872e-04, previous alpha=2.087e-05, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      " 84%|███████████████████████████████████████████████████████████████████████████████               | 255/303 [01:59<00:22,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|███████████████████████████████████████████████████████████████████████████████▍              | 256/303 [01:59<00:21,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|███████████████████████████████████████████████████████████████████████████████▋              | 257/303 [02:00<00:21,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████████████████████████████████████████████████████████████████████████████              | 258/303 [02:00<00:20,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████████████████████████████████████████████████████████████████████████████▎             | 259/303 [02:01<00:20,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████████████████████████████████████████████████████████████████████████████▋             | 260/303 [02:01<00:19,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=9.712e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 8 iterations, alpha=3.730e-03, previous alpha=3.730e-03, with an active set of 7 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=2.889e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 13 iterations, alpha=1.335e-03, previous alpha=1.335e-03, with an active set of 8 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=7.658e-04, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=6.863e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=6.824e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=2.699e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 15 iterations, alpha=6.738e-04, previous alpha=7.290e-05, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=2.828e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 18 iterations, alpha=5.139e-04, previous alpha=4.112e-04, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      " 86%|████████████████████████████████████████████████████████████████████████████████▉             | 261/303 [02:01<00:19,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|█████████████████████████████████████████████████████████████████████████████████▎            | 262/303 [02:02<00:18,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|█████████████████████████████████████████████████████████████████████████████████▌            | 263/303 [02:02<00:18,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 894us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|█████████████████████████████████████████████████████████████████████████████████▉            | 264/303 [02:03<00:18,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|██████████████████████████████████████████████████████████████████████████████████▏           | 265/303 [02:03<00:17,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=2.661e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=2.107e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.189e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=6.346e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 16 iterations, alpha=7.508e-04, previous alpha=5.969e-04, with an active set of 11 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=4.098e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=3.254e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 13 iterations, alpha=1.449e-03, previous alpha=1.125e-03, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.725e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.257e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=1.373e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=4.622e-06, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 88%|██████████████████████████████████████████████████████████████████████████████████▌           | 266/303 [02:04<00:17,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|██████████████████████████████████████████████████████████████████████████████████▊           | 267/303 [02:04<00:16,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|███████████████████████████████████████████████████████████████████████████████████▏          | 268/303 [02:05<00:16,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=8.802e-04, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=3.900e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 15 iterations, alpha=4.902e-04, previous alpha=3.623e-04, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=3.816e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=6.486e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=2.904e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 15 iterations, alpha=5.795e-04, previous alpha=4.828e-05, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.080e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=3.456e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 15 iterations, alpha=2.810e-04, previous alpha=1.333e-04, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      " 89%|███████████████████████████████████████████████████████████████████████████████████▍          | 269/303 [02:05<00:15,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|███████████████████████████████████████████████████████████████████████████████████▊          | 270/303 [02:06<00:15,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████████████████████████████████████████████████████████████████████████████████          | 271/303 [02:06<00:14,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.187e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=3.489e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=2.735e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=1.984e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=5.809e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=3.390e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.635e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=6.900e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=2.711e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=7.327e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=4.789e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=4.377e-07, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=2.791e-07, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 90%|████████████████████████████████████████████████████████████████████████████████████▍         | 272/303 [02:07<00:14,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████████████████████████████████████████████████████████████████████████████████▋         | 273/303 [02:07<00:13,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████████████████████████████████████████████████████████████████████████████████         | 274/303 [02:07<00:13,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████████████████████████████████████████████████████████████████████████████████▎        | 275/303 [02:08<00:13,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 24 iterations, alpha=1.189e-05, previous alpha=1.189e-05, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/shap/explainers/_kernel.py:707: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.863e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.568e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 13 iterations, alpha=7.845e-04, previous alpha=7.228e-04, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      " 91%|█████████████████████████████████████████████████████████████████████████████████████▌        | 276/303 [02:08<00:12,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████████████████████████████████████████████████████████████████████████████████▉        | 277/303 [02:09<00:12,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=1.207e-01, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=7.672e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 9 iterations, alpha=7.672e-03, previous alpha=7.656e-03, with an active set of 8 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=1.932e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=3.680e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 13 iterations, alpha=3.680e-03, previous alpha=3.673e-03, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=2.217e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.405e-02, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 7 iterations, alpha=1.405e-02, previous alpha=1.402e-02, with an active set of 6 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=5.470e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 21 iterations, alpha=8.298e-03, previous alpha=4.784e-03, with an active set of 16 regressors.\n",
      "  warnings.warn(\n",
      " 92%|██████████████████████████████████████████████████████████████████████████████████████▏       | 278/303 [02:09<00:11,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|██████████████████████████████████████████████████████████████████████████████████████▌       | 279/303 [02:10<00:11,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=6.374e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=3.100e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=5.643e-05, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=7.513e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=2.692e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 12 iterations, alpha=2.613e-03, previous alpha=2.610e-03, with an active set of 11 regressors.\n",
      "  warnings.warn(\n",
      " 92%|██████████████████████████████████████████████████████████████████████████████████████▊       | 280/303 [02:10<00:10,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|███████████████████████████████████████████████████████████████████████████████████████▏      | 281/303 [02:11<00:10,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|███████████████████████████████████████████████████████████████████████████████████████▍      | 282/303 [02:11<00:09,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|███████████████████████████████████████████████████████████████████████████████████████▊      | 283/303 [02:12<00:09,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|████████████████████████████████████████████████████████████████████████████████████████      | 284/303 [02:12<00:08,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|████████████████████████████████████████████████████████████████████████████████████████▍     | 285/303 [02:13<00:08,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=8.034e-05, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=6.724e-05, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=2.422e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=2.009e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 19 iterations, alpha=2.141e-05, previous alpha=7.924e-06, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=3.637e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.799e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=2.681e-06, with an active set of 16 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=2.224e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=6.874e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=5.874e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 18 iterations, alpha=3.559e-04, previous alpha=2.264e-04, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.802e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=2.258e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=2.240e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 15 iterations, alpha=1.380e-03, previous alpha=1.118e-03, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      " 94%|████████████████████████████████████████████████████████████████████████████████████████▋     | 286/303 [02:13<00:07,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=1.229e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=6.728e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=7.661e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=5.768e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=4.119e-03, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=4.025e-03, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 21 iterations, alpha=2.742e-03, previous alpha=1.962e-03, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=1.571e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=5.555e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 8 iterations, alpha=4.684e-03, previous alpha=4.366e-03, with an active set of 7 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=3.495e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=4.015e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.989e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 17 iterations, alpha=1.565e-03, previous alpha=1.500e-03, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      " 95%|█████████████████████████████████████████████████████████████████████████████████████████     | 287/303 [02:14<00:07,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████████████████████████████████████████████████████████████████████████████████████▎    | 288/303 [02:14<00:06,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=7.623e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=2.999e-03, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=1.611e-03, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=2.207e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=1.239e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.496e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=8.558e-04, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 19 iterations, alpha=4.670e-04, previous alpha=1.432e-04, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.754e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=6.398e-05, with an active set of 16 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=2.538e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=8.675e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=4.338e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 19 iterations, alpha=2.936e-04, previous alpha=2.546e-04, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      " 95%|█████████████████████████████████████████████████████████████████████████████████████████▋    | 289/303 [02:14<00:06,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=1.482e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=1.482e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=8.468e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=2.314e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=2.773e-06, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=3.979e-02, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=4.713e-04, with an active set of 16 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 96%|█████████████████████████████████████████████████████████████████████████████████████████▉    | 290/303 [02:15<00:06,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|██████████████████████████████████████████████████████████████████████████████████████████▎   | 291/303 [02:16<00:06,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.419e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.966e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.810e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=8.346e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=6.912e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 15 iterations, alpha=1.124e-03, previous alpha=4.429e-04, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=3.158e-04, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=2.960e-05, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=5.173e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=9.871e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=5.148e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=3.431e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 20 iterations, alpha=4.383e-03, previous alpha=2.533e-03, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      " 96%|██████████████████████████████████████████████████████████████████████████████████████████▌   | 292/303 [02:16<00:05,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|██████████████████████████████████████████████████████████████████████████████████████████▉   | 293/303 [02:17<00:05,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|███████████████████████████████████████████████████████████████████████████████████████████▏  | 294/303 [02:17<00:04,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|███████████████████████████████████████████████████████████████████████████████████████████▌  | 295/303 [02:18<00:03,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=6.951e-05, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=5.521e-06, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 18 iterations, alpha=5.521e-06, previous alpha=5.483e-06, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=1.439e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=8.043e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=9.522e-06, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 98%|███████████████████████████████████████████████████████████████████████████████████████████▊  | 296/303 [02:18<00:03,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|████████████████████████████████████████████████████████████████████████████████████████████▏ | 297/303 [02:18<00:02,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=2.197e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.088e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 11 iterations, alpha=6.411e-03, previous alpha=6.023e-03, with an active set of 8 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=4.799e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=5.211e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 16 iterations, alpha=4.975e-03, previous alpha=4.946e-03, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=3.619e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.938e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.793e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=7.578e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=2.240e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=1.511e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 17 iterations, alpha=1.483e-04, previous alpha=5.448e-05, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=1.158e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 98%|████████████████████████████████████████████████████████████████████████████████████████████▍ | 298/303 [02:19<00:02,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=3.113e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=2.810e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.497e-02, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=3.759e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 21 iterations, alpha=2.154e-03, previous alpha=2.083e-03, with an active set of 14 regressors.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=2.116e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.012e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 14 iterations, alpha=8.452e-04, previous alpha=3.074e-04, with an active set of 13 regressors.\n",
      "  warnings.warn(\n",
      " 99%|████████████████████████████████████████████████████████████████████████████████████████████▊ | 299/303 [02:19<00:01,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████████████████████████████████████████████████████████████████████████████████████████ | 300/303 [02:20<00:01,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=9.461e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=3.597e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=1.600e-06, with an active set of 14 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=5.507e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=2.064e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=4.893e-05, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 99%|█████████████████████████████████████████████████████████████████████████████████████████████▍| 301/303 [02:20<00:00,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:725: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=1.282e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/sklearn/linear_model/_least_angle.py:755: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 20 iterations, alpha=1.282e-04, previous alpha=1.236e-04, with an active set of 15 regressors.\n",
      "  warnings.warn(\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████▋| 302/303 [02:21<00:00,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m255/255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████| 303/303 [02:21<00:00,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAP values calcolati.\n",
      "SHAP values per classe 0: [[-0.13835954  0.12031355  0.          0.        ]\n",
      " [-0.00338533  0.01210082 -0.00475813  0.        ]\n",
      " [-0.03334361  0.02633653  0.          0.        ]\n",
      " [-0.03999264  0.25186206 -0.09222849 -0.08212858]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 1: [[-0.08806295  0.02943569 -0.06036968  0.09265575]\n",
      " [-0.00890722  0.          0.          0.        ]\n",
      " [-0.06508922 -0.07105502  0.21061061  0.        ]\n",
      " [ 0.         -0.06466121  0.03179882  0.        ]\n",
      " [ 0.         -0.01589045  0.          0.        ]]\n",
      "SHAP values per classe 2: [[-0.07126073  0.03372392  0.          0.13482955]\n",
      " [ 0.         -0.02512705  0.          0.0225337 ]\n",
      " [-0.00462735  0.00870467  0.          0.        ]\n",
      " [-0.01879892 -0.13315922  0.         -0.04067404]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 3: [[-0.13246851 -0.09591698  0.          0.        ]\n",
      " [-0.0141811   0.          0.          0.        ]\n",
      " [-0.01397973  0.          0.          0.        ]\n",
      " [ 0.         -0.13565832  0.06234867  0.        ]\n",
      " [-0.00382619 -0.02034561  0.          0.        ]]\n",
      "SHAP values per classe 4: [[-0.16111129  0.0462885   0.07492424  0.03423067]\n",
      " [-0.01104543  0.          0.          0.        ]\n",
      " [-0.03168119  0.          0.          0.04821049]\n",
      " [-0.0076996   0.         -0.1143722   0.07802644]\n",
      " [ 0.          0.          0.0184458   0.        ]]\n",
      "SHAP values per classe 5: [[-0.14135454  0.08085195  0.          0.        ]\n",
      " [ 0.          0.          0.         -0.01418225]\n",
      " [-0.03642727  0.01341006  0.         -0.01923288]\n",
      " [-0.02415175  0.4489184  -0.28996782 -0.09623271]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 6: [[-0.10114668  0.02302218  0.          0.06250336]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.06856257  0.03026728  0.03349143]\n",
      " [-0.00428702  0.          0.08837793  0.        ]]\n",
      "SHAP values per classe 7: [[-0.08184614  0.          0.02080374  0.03605745]\n",
      " [ 0.          0.          0.          0.00442638]\n",
      " [-0.00895359 -0.0030704   0.          0.00390145]\n",
      " [ 0.         -0.03665019  0.          0.02585967]\n",
      " [-0.01867318 -0.02225263  0.          0.01707569]]\n",
      "SHAP values per classe 8: [[-0.03637084  0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.00836176 -0.04056983  0.          0.        ]\n",
      " [-0.00660995 -0.02011817  0.01995756  0.        ]\n",
      " [ 0.         -0.04766291  0.17858899 -0.06351697]]\n",
      "SHAP values per classe 9: [[-0.08390362  0.0197157   0.03232691  0.03669736]\n",
      " [ 0.          0.          0.          0.00834915]\n",
      " [-0.00150234  0.          0.01117543  0.        ]\n",
      " [ 0.         -0.04206115  0.03180442  0.        ]\n",
      " [ 0.         -0.01693814  0.          0.04775116]]\n",
      "SHAP values per classe 10: [[-0.13732366  0.          0.01790889  0.06046814]\n",
      " [ 0.          0.00169925  0.          0.        ]\n",
      " [-0.01273144  0.          0.          0.01919766]\n",
      " [ 0.         -0.05723527  0.03014128  0.04375544]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 11: [[-0.10302744  0.          0.          0.00268275]\n",
      " [-0.00628048  0.          0.06371408  0.01366581]\n",
      " [ 0.          0.0104129   0.          0.        ]\n",
      " [ 0.         -0.08629343  0.0700415   0.        ]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 12: [[-0.06488264  0.02940077  0.0378857   0.        ]\n",
      " [ 0.          0.02408276  0.         -0.02405812]\n",
      " [-0.04081464  0.01897257  0.         -0.00631458]\n",
      " [-0.01537633  0.04634869 -0.03421178  0.        ]\n",
      " [-0.0311694   0.          0.          0.        ]]\n",
      "SHAP values per classe 13: [[-0.13899218  0.          0.14566831  0.        ]\n",
      " [-0.01131933  0.00081347  0.          0.        ]\n",
      " [-0.02551068  0.0231181   0.          0.        ]\n",
      " [-0.00702659 -0.10368222  0.03080007  0.06901625]\n",
      " [ 0.         -0.05027998  0.          0.05107085]]\n",
      "SHAP values per classe 14: [[-0.0615369   0.          0.08069923 -0.02115343]\n",
      " [-0.00751262  0.          0.          0.        ]\n",
      " [-0.00498057  0.          0.          0.        ]\n",
      " [-0.09712772  0.75563122 -0.43911141 -0.18452228]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 15: [[-0.11403581  0.          0.03976212  0.06088534]\n",
      " [-0.011191    0.          0.          0.        ]\n",
      " [-0.00334047  0.         -0.01099927  0.        ]\n",
      " [ 0.00671247 -0.04405337  0.02761961  0.02909135]\n",
      " [ 0.         -0.03432581  0.01536607  0.00748767]]\n",
      "SHAP values per classe 16: [[ 0.34668974 -0.09795955 -0.05006693 -0.14584716]\n",
      " [ 0.00994448 -0.01770106  0.          0.        ]\n",
      " [ 0.01418356 -0.0342108   0.          0.02162263]\n",
      " [ 0.         -0.0129844   0.          0.        ]\n",
      " [ 0.0300586  -0.03560937  0.          0.        ]]\n",
      "SHAP values per classe 17: [[ 0.58136157 -0.23566418 -0.26499095 -0.04178539]\n",
      " [ 0.02346073 -0.01161398  0.         -0.02766533]\n",
      " [ 0.00857567  0.06484884  0.         -0.0594529 ]\n",
      " [ 0.02579733 -0.07336955  0.03169422  0.        ]\n",
      " [ 0.01216593 -0.03215058  0.02598176  0.        ]]\n",
      "SHAP values per classe 18: [[-0.0890644   0.          0.          0.05675894]\n",
      " [ 0.          0.04191063 -0.05681133 -0.02100595]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.05331608  0.04229227  0.        ]\n",
      " [ 0.          0.          0.01269569  0.        ]]\n",
      "SHAP values per classe 19: [[-0.05963718  0.03803834 -0.02636257  0.04537595]\n",
      " [-0.00343426  0.          0.          0.        ]\n",
      " [ 0.          0.         -0.05472216  0.04756326]\n",
      " [ 0.         -0.07151247  0.          0.07370429]\n",
      " [-0.01983077 -0.00263095  0.          0.        ]]\n",
      "SHAP values per classe 20: [[-0.16125402  0.02058387  0.0994658   0.        ]\n",
      " [ 0.01518584 -0.00567692  0.         -0.0300495 ]\n",
      " [ 0.20074287 -0.05759807  0.         -0.08913167]\n",
      " [-0.00549185 -0.10946909  0.13535849  0.        ]\n",
      " [ 0.18554806 -0.05601731  0.         -0.05910714]]\n",
      "SHAP values per classe 21: [[-0.09417011  0.          0.01989163  0.05409911]\n",
      " [ 0.05260637  0.          0.         -0.03020711]\n",
      " [-0.03627004  0.          0.          0.        ]\n",
      " [ 0.00231397 -0.07191552  0.0312989   0.        ]\n",
      " [ 0.05987076 -0.02584629 -0.04595393  0.        ]]\n",
      "SHAP values per classe 22: [[ 0.19915207  0.         -0.09316701  0.        ]\n",
      " [ 0.08965294  0.          0.         -0.09391785]\n",
      " [ 0.          0.01160773  0.          0.        ]\n",
      " [-0.38023191  0.49448712 -0.06365245 -0.03850332]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 23: [[ 0.          0.03445525  0.          0.        ]\n",
      " [ 0.5218951  -0.1184213  -0.23225532 -0.17606631]\n",
      " [-0.03196356  0.          0.          0.        ]\n",
      " [ 0.05793476 -0.08178817  0.          0.        ]\n",
      " [ 0.02275183 -0.03112741  0.          0.        ]]\n",
      "SHAP values per classe 24: [[-0.13592623  0.          0.09240292  0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.02025355  0.02371998  0.          0.        ]\n",
      " [ 0.00809853  0.          0.          0.        ]\n",
      " [-0.01260085  0.35384506 -0.3141762   0.        ]]\n",
      "SHAP values per classe 25: [[-0.05518542  0.         -0.03747034  0.07104687]\n",
      " [ 0.          0.         -0.00923208  0.01550201]\n",
      " [-0.04581506 -0.02907862  0.10393915  0.        ]\n",
      " [ 0.         -0.12254245  0.          0.0598115 ]\n",
      " [ 0.          0.          0.         -0.22261344]]\n",
      "SHAP values per classe 26: [[-0.12757742  0.06168569  0.03847048  0.01113004]\n",
      " [-0.0418409   0.19966987 -0.05047147 -0.04354132]\n",
      " [-0.02159945  0.          0.         -0.05958579]\n",
      " [-0.00032388 -0.04336761  0.03091297  0.01376538]\n",
      " [-0.03792045  0.31600987 -0.26091603  0.        ]]\n",
      "SHAP values per classe 27: [[-0.1471035  -0.06483158  0.25776443  0.        ]\n",
      " [-0.02328986 -0.00084059  0.06126583 -0.04259734]\n",
      " [-0.02112847  0.          0.01968424  0.        ]\n",
      " [ 0.00677586 -0.07841432  0.05739469  0.        ]\n",
      " [ 0.00371396 -0.03190663  0.03365361  0.        ]]\n",
      "SHAP values per classe 28: [[ 0.61654302 -0.10251413 -0.31082143 -0.13927655]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.03864642 -0.03154283  0.         -0.02405806]\n",
      " [ 0.0299299  -0.06720185  0.          0.        ]\n",
      " [ 0.01355166 -0.02804648  0.          0.        ]]\n",
      "SHAP values per classe 29: [[ 0.40797653 -0.30716061 -0.03448221 -0.08760465]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.06484936 -0.11511624  0.          0.        ]\n",
      " [ 0.05309216 -0.0626251   0.01443201  0.        ]]\n",
      "SHAP values per classe 30: [[ 5.75263288e-01 -2.17224282e-01 -1.48705344e-01 -1.79134759e-01]\n",
      " [ 0.00000000e+00  2.84494243e-02  3.62027365e-04  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.61910069e-02]\n",
      " [ 7.01487992e-02 -8.91200139e-02  0.00000000e+00  3.65830487e-02]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "SHAP values per classe 31: [[ 0.          0.          0.08418054 -0.07638682]\n",
      " [ 0.07655991  0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.06516552  0.04198781  0.        ]\n",
      " [ 0.          0.          0.         -0.06698996]]\n",
      "SHAP values per classe 32: [[-0.09614356  0.          0.05645422  0.02649647]\n",
      " [-0.00984015 -0.0017806   0.03065531 -0.00038361]\n",
      " [-0.00436166  0.          0.          0.        ]\n",
      " [ 0.         -0.0882301   0.08804314  0.        ]\n",
      " [ 0.         -0.08828998  0.12272668  0.        ]]\n",
      "SHAP values per classe 33: [[-0.15618912  0.0532502   0.02693991  0.06994282]\n",
      " [-0.00779501  0.         -0.08186049  0.10400016]\n",
      " [ 0.          0.00252906 -0.03439617  0.03532266]\n",
      " [ 0.         -0.13128235  0.09269355  0.02299669]\n",
      " [-0.01070411 -0.12322647  0.07796526  0.02520019]]\n",
      "SHAP values per classe 34: [[ 0.59145587 -0.07831583 -0.28863246 -0.22223844]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.00304413  0.          0.        ]\n",
      " [ 0.04569638 -0.07014828  0.          0.03597203]\n",
      " [ 0.00961952 -0.03191453  0.          0.        ]]\n",
      "SHAP values per classe 35: [[-0.17053153  0.00527417  0.08825125  0.04538042]\n",
      " [-0.01032059  0.00079569 -0.02067037  0.        ]\n",
      " [-0.01161414  0.          0.          0.        ]\n",
      " [ 0.         -0.09035176  0.0598946   0.07597726]\n",
      " [ 0.         -0.14456487  0.02986587  0.03688245]]\n",
      "SHAP values per classe 36: [[-0.0599863   0.0473285  -0.00483595  0.03824393]\n",
      " [ 0.         -0.02645164 -0.16505     0.15547511]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.05855959  0.          0.03082955]\n",
      " [ 0.         -0.01181557  0.          0.        ]]\n",
      "SHAP values per classe 37: [[-0.13955577  0.10957717  0.          0.        ]\n",
      " [-0.03120968  0.          0.          0.        ]\n",
      " [-0.03615893  0.03279108  0.          0.        ]\n",
      " [ 0.          0.33124066 -0.26468369 -0.05013317]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 38: [[-0.10759034  0.043029    0.02315173  0.01775834]\n",
      " [-0.03934512  0.07368032 -0.03315021  0.        ]\n",
      " [ 0.00453587  0.02659138  0.          0.00046857]\n",
      " [ 0.          0.23120994 -0.07574842 -0.15907041]\n",
      " [-0.02280516  0.         -0.02555448  0.        ]]\n",
      "SHAP values per classe 39: [[-0.1455888   0.          0.05135101  0.08310266]\n",
      " [-0.00845219  0.          0.01463326  0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.06844456  0.0422383   0.03440146]\n",
      " [ 0.         -0.06563987  0.          0.03773599]]\n",
      "SHAP values per classe 40: [[ 0.72173168 -0.2431973  -0.2174745  -0.23801158]\n",
      " [ 0.          0.          0.          0.01388354]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.00623065 -0.02228774  0.          0.        ]]\n",
      "SHAP values per classe 41: [[ 0.5016045  -0.27422942 -0.06059027 -0.13204385]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.04908359 -0.09356966  0.04012659  0.01126066]\n",
      " [ 0.02557101 -0.06740094  0.06034076  0.        ]]\n",
      "SHAP values per classe 42: [[-0.16946961 -0.02907815  0.1183207   0.05622302]\n",
      " [-0.00914667 -0.00443042  0.          0.02760898]\n",
      " [-0.01050169  0.          0.          0.        ]\n",
      " [ 0.         -0.11477684  0.          0.04400425]\n",
      " [ 0.         -0.03505665  0.          0.02006491]]\n",
      "SHAP values per classe 43: [[-0.04388047  0.02242975  0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.032245    0.          0.        ]\n",
      " [ 0.         -0.07679754  0.08370273  0.        ]\n",
      " [ 0.         -0.04009137  0.          0.03453538]]\n",
      "SHAP values per classe 44: [[ 0.38684814 -0.13072586 -0.06708766 -0.16579803]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.21764809 -0.16785683 -0.00987093 -0.04974168]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.         -0.05857154 -0.00245508]]\n",
      "SHAP values per classe 45: [[-0.1266603   0.          0.01836311  0.07391427]\n",
      " [-0.01111047  0.          0.          0.01353814]\n",
      " [-0.00363945  0.          0.          0.        ]\n",
      " [ 0.         -0.09143555  0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 46: [[-0.10915673  0.04098666  0.12290102 -0.02772703]\n",
      " [-0.00866753  0.          0.          0.        ]\n",
      " [-0.01294163  0.          0.          0.        ]\n",
      " [-0.02216464  0.43180602 -0.27395005 -0.10340807]\n",
      " [ 0.          0.          0.          0.0093843 ]]\n",
      "SHAP values per classe 47: [[-0.13429981  0.33996935 -0.13659185 -0.07320713]\n",
      " [-0.00913489  0.          0.         -0.01348462]\n",
      " [-0.01587941  0.          0.          0.        ]\n",
      " [-0.01835097  0.04427376 -0.02743929 -0.0053307 ]\n",
      " [-0.03568781  0.17734749 -0.07828761 -0.04171711]]\n",
      "SHAP values per classe 48: [[-0.13304044  0.10694953  0.          0.        ]\n",
      " [-0.0028611   0.010409    0.          0.        ]\n",
      " [-0.03355373  0.04902609  0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.03598573  0.        ]]\n",
      "SHAP values per classe 49: [[-0.07483784  0.          0.07238341 -0.05130854]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.03988137  0.          0.01827278  0.        ]\n",
      " [ 0.         -0.12097928  0.07631029  0.04084051]\n",
      " [ 0.         -0.04162773  0.          0.        ]]\n",
      "SHAP values per classe 50: [[-0.13805492  0.02838852  0.          0.10157908]\n",
      " [-0.0061962   0.          0.          0.        ]\n",
      " [-0.01997772  0.          0.          0.        ]\n",
      " [ 0.         -0.12054363  0.02804702  0.07598874]\n",
      " [ 0.         -0.02762707  0.          0.02929403]]\n",
      "SHAP values per classe 51: [[-0.15129916  0.          0.16096897 -0.02711714]\n",
      " [-0.01139571  0.          0.01831168  0.01069476]\n",
      " [-0.03670494  0.          0.03468772 -0.00653185]\n",
      " [ 0.         -0.10183596  0.04887566  0.0283699 ]\n",
      " [ 0.         -0.0692872   0.09427388  0.        ]]\n",
      "SHAP values per classe 52: [[-0.12354957  0.02323204  0.09712009  0.        ]\n",
      " [-0.0103688  -0.00137708  0.          0.        ]\n",
      " [-0.01222765  0.03282405  0.          0.        ]\n",
      " [ 0.         -0.15577959  0.19583533  0.        ]\n",
      " [ 0.         -0.0347033   0.          0.        ]]\n",
      "SHAP values per classe 53: [[-0.1184486   0.          0.06648439  0.        ]\n",
      " [-0.01097702  0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.0042382  -0.12038009  0.          0.        ]\n",
      " [ 0.         -0.02883081  0.07599072  0.        ]]\n",
      "SHAP values per classe 54: [[-0.02346264 -0.0273824  -0.05859849  0.1569317 ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.00146768  0.        ]\n",
      " [ 0.         -0.05246611  0.02578804  0.02532762]\n",
      " [-0.04800821  0.          0.          0.        ]]\n",
      "SHAP values per classe 55: [[-0.13944771  0.1119346  -0.01247459  0.        ]\n",
      " [-0.00395769  0.02761006  0.         -0.01115442]\n",
      " [-0.04328262  0.          0.          0.00790112]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.26414024 -0.20121887  0.        ]]\n",
      "SHAP values per classe 56: [[ 0.3280022  -0.27966693  0.         -0.05233377]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.03645742 -0.00520335 -0.00342746]\n",
      " [-0.07491745  0.10890758 -0.03114648 -0.00831117]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 57: [[ 0.50087154 -0.11020791 -0.17700507 -0.17858292]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.15963488 -0.1000981  -0.03628819 -0.02719517]\n",
      " [ 0.0251223  -0.07025221  0.          0.        ]\n",
      " [ 0.         -0.0251774   0.          0.        ]]\n",
      "SHAP values per classe 58: [[-0.15130615  0.08719648  0.13184621 -0.03627114]\n",
      " [-0.01685073  0.          0.          0.        ]\n",
      " [-0.0128215   0.          0.          0.00647311]\n",
      " [ 0.         -0.02835392  0.10800677 -0.06668356]\n",
      " [ 0.         -0.06024794  0.09369476  0.        ]]\n",
      "SHAP values per classe 59: [[-0.13394084 -0.06196992  0.03399081  0.08810445]\n",
      " [-0.01711646  0.          0.          0.01010148]\n",
      " [-0.01403178  0.07933942  0.          0.00049831]\n",
      " [ 0.         -0.07423932  0.          0.0378023 ]\n",
      " [ 0.         -0.06064716  0.          0.03460687]]\n",
      "SHAP values per classe 60: [[-0.15413308  0.          0.          0.35991961]\n",
      " [-0.0118482  -0.00520327  0.          0.04925025]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.09365353 -0.03470016  0.        ]\n",
      " [ 0.         -0.01861728  0.03746414  0.        ]]\n",
      "SHAP values per classe 61: [[-0.17912591  0.02228432  0.07823166  0.07757932]\n",
      " [-0.00821197  0.08384417 -0.04706961  0.02190984]\n",
      " [-0.01641367  0.          0.          0.02104847]\n",
      " [ 0.         -0.10203954  0.01695253  0.10995285]\n",
      " [ 0.         -0.13964087  0.03337699  0.03529631]]\n",
      "SHAP values per classe 62: [[ 0.63924185 -0.31666807 -0.12535542 -0.16744968]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.         -0.00998202]\n",
      " [ 0.02727047 -0.07596608  0.          0.        ]\n",
      " [ 0.          0.         -0.01371089  0.        ]]\n",
      "SHAP values per classe 63: [[-0.03064887  0.          0.02998094 -0.10166936]\n",
      " [ 0.          0.          0.21710993 -0.05560015]\n",
      " [-0.00341174  0.          0.03446333 -0.02390108]\n",
      " [ 0.         -0.03997851  0.05978533  0.        ]\n",
      " [-0.01418389 -0.04174146  0.          0.        ]]\n",
      "SHAP values per classe 64: [[-0.10572795  0.07629587  0.03086029  0.        ]\n",
      " [-0.01061589  0.          0.          0.        ]\n",
      " [-0.0064374   0.          0.          0.        ]\n",
      " [-0.03476919  0.41507178 -0.25913193 -0.16420926]\n",
      " [ 0.          0.08056681 -0.0187839   0.        ]]\n",
      "SHAP values per classe 65: [[-0.03397148 -0.26647964  0.28452664  0.        ]\n",
      " [ 0.          0.10326329 -0.33050567  0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 66: [[-0.1263012   0.02867261  0.          0.09280595]\n",
      " [-0.02851088 -0.02946938  0.01981488  0.01674547]\n",
      " [-0.01028363  0.          0.          0.03114811]\n",
      " [ 0.01938022 -0.12258289  0.05870524  0.02238756]\n",
      " [ 0.          0.          0.01607778  0.        ]]\n",
      "SHAP values per classe 67: [[-0.05647061  0.0088144   0.09036625 -0.03362358]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.01624651  0.          0.04385352  0.        ]\n",
      " [ 0.0235663  -0.12557915  0.05974019  0.0455475 ]\n",
      " [ 0.         -0.07097141  0.04817352  0.00895126]]\n",
      "SHAP values per classe 68: [[-0.12391389  0.03765042  0.01880611  0.04732755]\n",
      " [-0.00885218  0.          0.          0.04956569]\n",
      " [-0.046911    0.          0.10399092  0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.         -0.02800501 -0.06222751]]\n",
      "SHAP values per classe 69: [[-0.15812524 -0.06857299  0.          0.        ]\n",
      " [ 0.         -0.01101825  0.11283843 -0.14429654]\n",
      " [-0.00857504  0.          0.0078652   0.        ]\n",
      " [ 0.          0.          0.23430568  0.        ]\n",
      " [ 0.          0.          0.          0.00950238]]\n",
      "SHAP values per classe 70: [[-0.13079666 -0.01920056  0.06728371  0.        ]\n",
      " [-0.00785003  0.          0.          0.06474587]\n",
      " [ 0.          0.         -0.01938385  0.01545096]\n",
      " [ 0.         -0.06135482  0.          0.02179741]\n",
      " [ 0.         -0.02264666  0.          0.        ]]\n",
      "SHAP values per classe 71: [[ 0.02493117 -0.01506319  0.03699703 -0.05313421]\n",
      " [ 0.         -0.02133463 -0.03430734  0.        ]\n",
      " [ 0.          0.          0.          0.06214734]\n",
      " [ 0.00126396 -0.06588729  0.02569264  0.01347381]\n",
      " [ 0.06393599 -0.03487406 -0.04749904  0.        ]]\n",
      "SHAP values per classe 72: [[ 0.5168467  -0.22385174 -0.08959045 -0.12582704]\n",
      " [-0.00465286  0.         -0.03625891  0.        ]\n",
      " [ 0.          0.09488603  0.         -0.05695324]\n",
      " [ 0.04049956 -0.04915324  0.          0.03447306]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 73: [[-0.14098643  0.03048786  0.16048564  0.        ]\n",
      " [ 0.         -0.00063166  0.05010639 -0.03857954]\n",
      " [ 0.13877321 -0.07302763 -0.01661779 -0.11905183]\n",
      " [ 0.         -0.08109411  0.12832728  0.01203368]\n",
      " [-0.03065316 -0.09191077  0.          0.04041914]]\n",
      "SHAP values per classe 74: [[-0.06728998  0.12161686 -0.09635296  0.        ]\n",
      " [ 0.         -0.00364859  0.01301782  0.        ]\n",
      " [ 0.          0.00912851 -0.01198319  0.        ]\n",
      " [-0.02011332 -0.19769931  0.29654782  0.        ]\n",
      " [ 0.         -0.00255215 -0.05127859  0.        ]]\n",
      "SHAP values per classe 75: [[-0.10437295  0.07834225  0.         -0.0164076 ]\n",
      " [-0.00593368  0.01138997  0.          0.        ]\n",
      " [-0.00818042 -0.02926481  0.          0.        ]\n",
      " [-0.07152779  0.23064256 -0.07954022 -0.06014156]\n",
      " [-0.02314361  0.22566803 -0.13965553 -0.09747515]]\n",
      "SHAP values per classe 76: [[-0.08612854  0.          0.06493997  0.        ]\n",
      " [ 0.          0.          0.02766781  0.04482492]\n",
      " [ 0.         -0.01054212  0.          0.        ]\n",
      " [ 0.         -0.04817642  0.          0.        ]\n",
      " [-0.00996983 -0.06841058  0.28794057 -0.17533337]]\n",
      "SHAP values per classe 77: [[-0.11449848  0.05224623  0.          0.05842629]\n",
      " [ 0.02360193  0.          0.          0.        ]\n",
      " [-0.05252162  0.          0.          0.        ]\n",
      " [ 0.         -0.08281128  0.13177793  0.        ]\n",
      " [ 0.         -0.04455309  0.          0.00314709]]\n",
      "SHAP values per classe 78: [[-1.02842504e-01  0.00000000e+00  5.23438793e-02  3.23378230e-02]\n",
      " [-4.23290526e-03  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [-3.51595056e-03  0.00000000e+00 -9.83858693e-05  0.00000000e+00]\n",
      " [ 0.00000000e+00 -7.05560782e-02  0.00000000e+00  2.99804854e-02]\n",
      " [ 0.00000000e+00 -1.59942304e-02  0.00000000e+00  0.00000000e+00]]\n",
      "SHAP values per classe 79: [[-0.11996199  0.03602924  0.0698203   0.        ]\n",
      " [-0.0105926  -0.00252487  0.00811699  0.        ]\n",
      " [-0.01429262  0.          0.          0.        ]\n",
      " [ 0.         -0.12291298  0.10846987  0.        ]\n",
      " [ 0.         -0.05411877  0.04532562  0.        ]]\n",
      "SHAP values per classe 80: [[-0.10231303  0.          0.          0.10282935]\n",
      " [-0.01762941  0.          0.          0.        ]\n",
      " [-0.0149798   0.          0.          0.        ]\n",
      " [ 0.02013305 -0.07792059  0.          0.07809882]\n",
      " [-0.02423491 -0.05833888  0.          0.01976948]]\n",
      "SHAP values per classe 81: [[-0.14226342  0.          0.09823689  0.02756386]\n",
      " [-0.02271967  0.          0.          0.        ]\n",
      " [-0.00241794  0.          0.          0.        ]\n",
      " [ 0.0142674  -0.08606905  0.01315912  0.        ]\n",
      " [ 0.         -0.03226776  0.00810607  0.03867754]]\n",
      "SHAP values per classe 82: [[-0.17075434  0.03305678  0.12406961  0.02185635]\n",
      " [ 0.          0.          0.01655315  0.        ]\n",
      " [ 0.          0.0036674   0.03118365 -0.00636475]\n",
      " [ 0.0120515  -0.1348084   0.10521429  0.00068977]\n",
      " [ 0.         -0.11232028  0.0876566   0.        ]]\n",
      "SHAP values per classe 83: [[-0.07945166  0.          0.          0.        ]\n",
      " [-0.01150782 -0.00570575 -0.01957144  0.14190184]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.01433087  0.          0.          0.04591695]\n",
      " [ 0.         -0.12448954  0.          0.31649186]]\n",
      "SHAP values per classe 84: [[ 0.05440097  0.00446782 -0.12174907  0.        ]\n",
      " [ 0.          0.          0.          0.023174  ]\n",
      " [ 0.34497003 -0.12170776  0.         -0.19427811]\n",
      " [ 0.02959562 -0.07044827  0.          0.01037003]\n",
      " [ 0.         -0.07106523  0.          0.        ]]\n",
      "SHAP values per classe 85: [[ 0.28690316 -0.07232403 -0.13585932 -0.09739066]\n",
      " [-0.07449814  0.          0.03159259  0.01692067]\n",
      " [ 0.04365623 -0.05554906  0.         -0.02614036]\n",
      " [ 0.03082232 -0.06227472  0.03128206  0.01638109]\n",
      " [ 0.07508162  0.         -0.02306886  0.00126959]]\n",
      "SHAP values per classe 86: [[-0.16521556  0.11578999  0.03323074  0.01706676]\n",
      " [-0.00305967  0.          0.01634066 -0.01148493]\n",
      " [-0.02396129  0.12631591  0.          0.        ]\n",
      " [ 0.          0.          0.10558099  0.06181398]\n",
      " [ 0.         -0.08127626  0.04060487  0.04309998]]\n",
      "SHAP values per classe 87: [[ 0.29654292 -0.09507087 -0.06329828 -0.13700742]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.12321798 -0.06778401  0.         -0.03068804]\n",
      " [ 0.2518443  -0.04493962 -0.11536424 -0.04672327]\n",
      " [ 0.         -0.02011479  0.          0.        ]]\n",
      "SHAP values per classe 88: [[-0.14564947  0.03976478  0.01990558  0.        ]\n",
      " [-0.01506465 -0.07383857  0.          0.10410121]\n",
      " [ 0.00711737 -0.03746978  0.          0.        ]\n",
      " [-0.00150375 -0.10152162  0.05749427  0.05092194]\n",
      " [ 0.00197003 -0.03022729  0.01014679  0.        ]]\n",
      "SHAP values per classe 89: [[-0.12521766  0.09805364  0.01776634  0.        ]\n",
      " [-0.00091898  0.05849625 -0.03490304  0.00563874]\n",
      " [-0.01352911 -0.00270331  0.          0.        ]\n",
      " [-0.06440206  0.34819178 -0.18874871 -0.07586809]\n",
      " [-0.00403489  0.18732287 -0.04663844 -0.13092465]]\n",
      "SHAP values per classe 90: [[-0.08312998 -0.05454828  0.          0.14550949]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.0059491  -0.01008427  0.03290074]\n",
      " [ 0.         -0.02273856  0.          0.07055951]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 91: [[-0.06254457 -0.03089847  0.          0.03276248]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.00333916 -0.00647621  0.          0.        ]\n",
      " [ 0.         -0.0579897   0.05949303  0.03487832]\n",
      " [-0.00219677 -0.03157412  0.08194406 -0.04919009]]\n",
      "SHAP values per classe 92: [[-0.16048547  0.          0.00588348  0.01376693]\n",
      " [-0.00907103  0.          0.          0.02073897]\n",
      " [ 0.         -0.00814081  0.          0.        ]\n",
      " [ 0.         -0.09143562  0.03406128  0.03521955]\n",
      " [-0.00425876  0.          0.          0.012838  ]]\n",
      "SHAP values per classe 93: [[ 0.66133882 -0.38043137 -0.09784265 -0.17468059]\n",
      " [ 0.          0.17462755 -0.0845099   0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.03258015 -0.05587674  0.          0.00978565]\n",
      " [ 0.04287822  0.         -0.01096561  0.        ]]\n",
      "SHAP values per classe 94: [[-0.08615384  0.09156339  0.          0.        ]\n",
      " [-0.03495477  0.          0.01226546  0.        ]\n",
      " [-0.01727336  0.02781718  0.          0.        ]\n",
      " [-0.07655699  0.5115213  -0.23772202 -0.21510146]\n",
      " [ 0.02715625  0.          0.          0.        ]]\n",
      "SHAP values per classe 95: [[ 0.63672374 -0.19396889 -0.18815811 -0.2397806 ]\n",
      " [ 0.          0.02018717  0.          0.        ]\n",
      " [ 0.         -0.02021225  0.          0.        ]\n",
      " [ 0.02374738 -0.07094934  0.          0.        ]\n",
      " [ 0.02291871 -0.02742088  0.          0.        ]]\n",
      "SHAP values per classe 96: [[ 0.6385675  -0.1792085  -0.22763235 -0.20560067]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.02146888 -0.06779083  0.03193603  0.        ]\n",
      " [ 0.00795808 -0.02716059  0.01122913  0.        ]]\n",
      "SHAP values per classe 97: [[-0.16583189  0.12009747  0.          0.01324122]\n",
      " [-0.01078387  0.          0.          0.        ]\n",
      " [-0.02835188  0.05356816 -0.05718374  0.01199377]\n",
      " [ 0.          0.          0.          0.01878345]\n",
      " [ 0.          0.         -0.06279336  0.03071965]]\n",
      "SHAP values per classe 98: [[-0.08471818  0.07071937  0.         -0.00363709]\n",
      " [ 0.          0.          0.02188431  0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.07741413  0.7232967  -0.44745629 -0.17752557]\n",
      " [ 0.         -0.00872915  0.          0.        ]]\n",
      "SHAP values per classe 99: [[-0.149748    0.          0.07554399  0.04695337]\n",
      " [-0.01619547  0.          0.          0.00728261]\n",
      " [-0.0412988   0.          0.0309043   0.        ]\n",
      " [ 0.01422446 -0.13532963  0.07281085  0.03655206]\n",
      " [ 0.         -0.06001633  0.02392387  0.04442482]]\n",
      "SHAP values per classe 100: [[-0.16269798  0.05978906  0.20946174 -0.16321372]\n",
      " [-0.00604901 -0.00256948 -0.13685599  0.17853833]\n",
      " [-0.02263553  0.01974411 -0.15257555  0.22237931]\n",
      " [ 0.00771343 -0.1094244   0.25670404 -0.22699357]\n",
      " [-0.00217051 -0.0272263   0.20147612 -0.20142577]]\n",
      "SHAP values per classe 101: [[-1.49692709e-01  1.27516784e-01  5.74695703e-02 -2.87226618e-04]\n",
      " [-8.17081760e-03  1.67404143e-02  0.00000000e+00  0.00000000e+00]\n",
      " [-2.61819020e-02  2.49590835e-02  0.00000000e+00  0.00000000e+00]\n",
      " [-2.90010744e-02  3.62531336e-01 -2.56410248e-01 -6.27615181e-02]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "SHAP values per classe 102: [[ 0.24901696 -0.0436725  -0.0983656  -0.11952501]\n",
      " [ 0.0471756  -0.0349873   0.          0.        ]\n",
      " [ 0.0957841  -0.05010517  0.         -0.05289589]\n",
      " [ 0.         -0.07309672  0.          0.        ]\n",
      " [ 0.04036514 -0.0247     -0.00998629  0.        ]]\n",
      "SHAP values per classe 103: [[ 0.          0.          0.         -0.01295495]\n",
      " [ 0.30027379 -0.1187906  -0.01098723 -0.14191416]\n",
      " [ 0.          0.03211494 -0.00962362  0.        ]\n",
      " [-0.38722056  0.57317406 -0.08648424 -0.06188539]\n",
      " [-0.08786152  0.11612493  0.          0.        ]]\n",
      "SHAP values per classe 104: [[ 0.          0.07386682  0.         -0.09647237]\n",
      " [-0.02126846  0.01189976  0.         -0.00736816]\n",
      " [-0.06336765  0.04066038 -0.00153118  0.        ]\n",
      " [-0.15172744  0.4309456  -0.16068117 -0.08794201]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 105: [[-0.10029159  0.07217587  0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.05509462  0.          0.          0.        ]\n",
      " [-0.05176291  0.67230299 -0.35258055 -0.18702735]\n",
      " [ 0.         -0.0293762   0.          0.        ]]\n",
      "SHAP values per classe 106: [[-0.08901487  0.03558973  0.          0.07559825]\n",
      " [-0.01607826  0.00988753  0.          0.        ]\n",
      " [-0.03119753  0.          0.         -0.03669562]\n",
      " [ 0.          0.          0.          0.05360208]\n",
      " [ 0.         -0.05765422  0.          0.        ]]\n",
      "SHAP values per classe 107: [[-0.14379066  0.          0.          0.05354738]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.03292375]\n",
      " [ 0.         -0.06688042  0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 108: [[-0.10070336  0.04748     0.          0.        ]\n",
      " [-0.01006295  0.014214    0.          0.        ]\n",
      " [-0.01720759  0.0172738   0.          0.        ]\n",
      " [-0.01887493  0.03685962 -0.01546621  0.        ]\n",
      " [-0.02625942  0.05494845 -0.05896612  0.        ]]\n",
      "SHAP values per classe 109: [[ 0.582902   -0.18520068 -0.14249837 -0.21218747]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.07843664  0.05599582  0.        ]\n",
      " [ 0.02423575 -0.06243706  0.          0.        ]]\n",
      "SHAP values per classe 110: [[-0.15176825 -0.01625286  0.          0.17314896]\n",
      " [ 0.          0.10603683  0.05958594 -0.05802316]\n",
      " [-0.01897455 -0.01646109 -0.06122012  0.15001775]\n",
      " [ 0.         -0.05388961  0.00494399  0.        ]\n",
      " [-0.00119699 -0.03835542  0.04798814  0.        ]]\n",
      "SHAP values per classe 111: [[-0.05405152  0.          0.          0.02792294]\n",
      " [-0.01128903  0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.08292461  0.         -0.00308868]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 112: [[ 0.11678184  0.          0.08225472 -0.107097  ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.01684536 -0.0108502 ]\n",
      " [ 0.         -0.06916346  0.13431436  0.        ]\n",
      " [ 0.         -0.05003053  0.          0.        ]]\n",
      "SHAP values per classe 113: [[-0.13238191  0.04453695  0.06606849 -0.00226706]\n",
      " [ 0.         -0.10789606  0.07615625  0.07901567]\n",
      " [-0.01590656  0.          0.          0.03580557]\n",
      " [-0.01373364  0.          0.          0.        ]\n",
      " [-0.00716898 -0.04005387  0.05741961  0.        ]]\n",
      "SHAP values per classe 114: [[-0.16766593 -0.00839046  0.09116153  0.04383846]\n",
      " [-0.02511245  0.          0.          0.01267246]\n",
      " [-0.00342508 -0.01155087  0.          0.0182854 ]\n",
      " [ 0.05685983 -0.07442269  0.02350519  0.05084682]\n",
      " [ 0.0635023  -0.00148659  0.          0.        ]]\n",
      "SHAP values per classe 115: [[-0.12824592  0.01309659  0.09243961  0.        ]\n",
      " [-0.00225233  0.          0.00990147  0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.10168933  0.08223371  0.        ]\n",
      " [ 0.         -0.06872528  0.07843569  0.        ]]\n",
      "SHAP values per classe 116: [[ 0.27400965 -0.04695163 -0.15163567 -0.11460005]\n",
      " [ 0.31382259  0.         -0.03991572  0.        ]\n",
      " [ 0.03902312 -0.04015431  0.         -0.05235201]\n",
      " [ 0.01902085 -0.06403932  0.          0.        ]\n",
      " [ 0.00486849 -0.02121714  0.          0.        ]]\n",
      "SHAP values per classe 117: [[-0.04070003  0.          0.          0.03272501]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.02301018  0.2157946  -0.26031374]\n",
      " [-0.00415302  0.          0.          0.        ]]\n",
      "SHAP values per classe 118: [[-0.10537286  0.          0.          0.        ]\n",
      " [ 0.          0.          0.11700819  0.        ]\n",
      " [-0.00977888  0.          0.          0.        ]\n",
      " [ 0.         -0.09005563  0.09614987 -0.02129438]\n",
      " [ 0.          0.          0.06615437 -0.04198567]]\n",
      "SHAP values per classe 119: [[-0.13802122  0.02481489  0.01341848  0.07700843]\n",
      " [-0.01328902  0.          0.          0.00844571]\n",
      " [-0.01777277 -0.00493456  0.02115152  0.01893108]\n",
      " [-0.00547938 -0.1433591   0.05997639  0.07204541]\n",
      " [-0.00880855 -0.04123487  0.          0.01466757]]\n",
      "SHAP values per classe 120: [[-0.10439227  0.02519598  0.17440387 -0.0836054 ]\n",
      " [-0.00721005  0.          0.          0.        ]\n",
      " [-0.01489462 -0.00322036  0.          0.03909032]\n",
      " [-0.01614799 -0.19911328  0.04837509  0.027398  ]\n",
      " [ 0.         -0.03170086  0.06172538 -0.02917844]]\n",
      "SHAP values per classe 121: [[-0.10219263 -0.01436566  0.04910785  0.03404835]\n",
      " [-0.01405827  0.          0.          0.02060118]\n",
      " [-0.00620237  0.          0.          0.02175372]\n",
      " [ 0.         -0.10691358 -0.02188166  0.13783838]\n",
      " [ 0.         -0.0186004   0.          0.02319218]]\n",
      "SHAP values per classe 122: [[ 0.39239863 -0.13769641 -0.13401644 -0.10594303]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.071834    0.03729173  0.          0.        ]\n",
      " [ 0.         -0.0356918   0.          0.        ]\n",
      " [ 0.04480925 -0.06626068  0.021974    0.        ]]\n",
      "SHAP values per classe 123: [[-0.09682736  0.          0.01303093  0.04473546]\n",
      " [-0.00623447  0.          0.04680293  0.        ]\n",
      " [-0.01115299  0.          0.          0.        ]\n",
      " [ 0.         -0.02553579  0.04727201  0.02259628]\n",
      " [ 0.         -0.1156971   0.          0.01546204]]\n",
      "SHAP values per classe 124: [[ 0.17491877  0.          0.         -0.05227523]\n",
      " [ 0.         -0.02014427 -0.03350545 -0.00761229]\n",
      " [ 0.          0.0070855  -0.01699089  0.        ]\n",
      " [ 0.11680592 -0.17660872  0.          0.        ]\n",
      " [ 0.00650093 -0.07460149 -0.00495503  0.01886645]]\n",
      "SHAP values per classe 125: [[ 0.28569175 -0.0989236  -0.06148952 -0.13479328]\n",
      " [ 0.          0.         -0.00237667  0.        ]\n",
      " [ 0.0565028  -0.03180745  0.         -0.02407186]\n",
      " [ 0.         -0.03918985  0.          0.        ]\n",
      " [ 0.02258564 -0.039429    0.          0.        ]]\n",
      "SHAP values per classe 126: [[-0.1101066   0.04460557  0.          0.        ]\n",
      " [-0.00593999  0.          0.         -0.01721895]\n",
      " [-0.01908257  0.01397108  0.          0.01675398]\n",
      " [-0.03997701  0.43375665 -0.18427829 -0.15322687]\n",
      " [-0.03239235  0.14548523 -0.09378516  0.        ]]\n",
      "SHAP values per classe 127: [[-0.10821625  0.          0.03891442  0.06402969]\n",
      " [ 0.         -0.01472779  0.03889686  0.        ]\n",
      " [-0.00716059  0.          0.          0.        ]\n",
      " [ 0.         -0.0600478   0.          0.04386175]\n",
      " [ 0.         -0.00688953  0.          0.        ]]\n",
      "SHAP values per classe 128: [[ 0.27338022 -0.10992538 -0.03768401 -0.16576213]\n",
      " [ 0.14740119  0.         -0.19508531  0.        ]\n",
      " [ 0.         -0.08638842  0.         -0.0300346 ]\n",
      " [-0.11732456 -0.04876402  0.19436231  0.        ]\n",
      " [ 0.17053725  0.          0.          0.        ]]\n",
      "SHAP values per classe 129: [[ 0.69407226 -0.23703398 -0.14135522 -0.2859758 ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.01931224  0.          0.          0.        ]\n",
      " [ 0.         -0.05890643  0.0542976   0.        ]\n",
      " [ 0.         -0.02980717  0.          0.        ]]\n",
      "SHAP values per classe 130: [[ 0.30773232 -0.09454432 -0.07442917 -0.11242008]\n",
      " [ 0.08453007 -0.04749519  0.          0.        ]\n",
      " [ 0.08207404 -0.05712318 -0.0009316  -0.0299356 ]\n",
      " [ 0.07153405 -0.17819888  0.02286875  0.        ]\n",
      " [ 0.          0.06063126  0.02264014  0.        ]]\n",
      "SHAP values per classe 131: [[-0.06785318  0.          0.          0.        ]\n",
      " [-0.00612993  0.18010798 -0.03918544 -0.05987509]\n",
      " [ 0.          0.          0.          0.00278722]\n",
      " [-0.01607367  0.18410273 -0.04616147 -0.09595531]\n",
      " [-0.02239789 -0.04057394  0.          0.        ]]\n",
      "SHAP values per classe 132: [[-0.06175698  0.         -0.07995747  0.15841237]\n",
      " [ 0.         -0.03182785  0.          0.05277722]\n",
      " [ 0.          0.         -0.01776763  0.01010097]\n",
      " [ 0.         -0.0524332   0.03371342  0.00536581]\n",
      " [-0.01225803 -0.01621512 -0.02396453  0.06391624]]\n",
      "SHAP values per classe 133: [[-0.13158506  0.03352144  0.08859294  0.01046935]\n",
      " [-0.011356   -0.00138861  0.          0.00826562]\n",
      " [-0.02365788  0.02534858  0.          0.01805917]\n",
      " [ 0.         -0.08215799  0.10826163  0.        ]\n",
      " [ 0.         -0.03086935  0.06380361 -0.02460592]]\n",
      "SHAP values per classe 134: [[-0.10821472  0.01576277  0.13552265 -0.03317508]\n",
      " [ 0.          0.          0.03885992  0.        ]\n",
      " [-0.0286085   0.          0.11978159 -0.08690424]\n",
      " [ 0.         -0.12322295  0.07058803  0.        ]\n",
      " [ 0.         -0.05524536  0.04353069  0.        ]]\n",
      "SHAP values per classe 135: [[-0.13362385  0.12265631  0.00295891  0.        ]\n",
      " [ 0.          0.          0.08984263 -0.01637576]\n",
      " [-0.01305724  0.02674548 -0.00734855  0.        ]\n",
      " [-0.0317188   0.33471875 -0.29044423 -0.03937423]\n",
      " [-0.02289406  0.06667935 -0.05021106  0.        ]]\n",
      "SHAP values per classe 136: [[ 0.          0.01333191  0.03069697 -0.0769237 ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.0264215   0.02394865  0.          0.03439418]\n",
      " [-0.0545322   0.51051248 -0.24509752 -0.22941009]\n",
      " [ 0.          0.          0.         -0.02866674]]\n",
      "SHAP values per classe 137: [[ 0.24984982 -0.02925292 -0.06449717 -0.05755121]\n",
      " [ 0.          0.          0.         -0.0244776 ]\n",
      " [ 0.         -0.03150743  0.         -0.05342431]\n",
      " [ 0.04416317 -0.11004903  0.          0.        ]\n",
      " [ 0.0696288  -0.15220096  0.          0.        ]]\n",
      "SHAP values per classe 138: [[-0.14670179  0.03185008  0.06404826  0.        ]\n",
      " [-0.01080777  0.          0.          0.        ]\n",
      " [-0.02052961  0.          0.          0.04236679]\n",
      " [ 0.         -0.07193864  0.04528566  0.        ]\n",
      " [-0.01827771 -0.07753805 -0.16303445  0.16250484]]\n",
      "SHAP values per classe 139: [[ 0.31803825 -0.01494256 -0.14954265  0.        ]\n",
      " [ 0.          0.         -0.00486192  0.        ]\n",
      " [ 0.03132016  0.02801741  0.         -0.01113682]\n",
      " [ 0.06739675 -0.14211986  0.          0.        ]\n",
      " [ 0.05369097 -0.06829886  0.          0.        ]]\n",
      "SHAP values per classe 140: [[ 0.38099278 -0.16661037 -0.12286898 -0.10897475]\n",
      " [ 0.          0.0527243   0.          0.        ]\n",
      " [ 0.06368197  0.          0.         -0.03118936]\n",
      " [-0.02241166 -0.08296292  0.          0.02907852]\n",
      " [ 0.06332424 -0.10096309  0.          0.        ]]\n",
      "SHAP values per classe 141: [[ 0.34899385 -0.23862292 -0.02499169 -0.07287345]\n",
      " [ 0.00812591  0.04471989  0.          0.01410834]\n",
      " [ 0.0771718  -0.16405555  0.          0.        ]\n",
      " [ 0.01441212 -0.0868511   0.04799226  0.03377445]\n",
      " [ 0.06625927 -0.09131056  0.          0.00187888]]\n",
      "SHAP values per classe 142: [[-0.12762831  0.0317269   0.10613937  0.        ]\n",
      " [-0.01103075  0.          0.          0.        ]\n",
      " [-0.03901498  0.02305848  0.          0.        ]\n",
      " [-0.01896451 -0.05736319  0.01589309  0.        ]\n",
      " [ 0.00196449 -0.02545044  0.02616438 -0.0096647 ]]\n",
      "SHAP values per classe 143: [[ 0.29623241 -0.03344168 -0.0918611  -0.16000958]\n",
      " [ 0.         -0.00944371  0.          0.        ]\n",
      " [ 0.          0.01590601  0.          0.        ]\n",
      " [ 0.00587313 -0.13109139  0.          0.07272133]\n",
      " [ 0.         -0.07855222  0.          0.07816677]]\n",
      "SHAP values per classe 144: [[ 0.54828722 -0.16840247 -0.13250563 -0.14797593]\n",
      " [ 0.01573676 -0.0114227   0.          0.        ]\n",
      " [ 0.0522522  -0.04222514  0.         -0.03129733]\n",
      " [ 0.          0.         -0.03015892  0.        ]\n",
      " [ 0.         -0.01942886  0.          0.        ]]\n",
      "SHAP values per classe 145: [[-0.14792296 -0.00417564  0.13052221  0.        ]\n",
      " [ 0.          0.          0.08205369 -0.12770693]\n",
      " [-0.02121693  0.          0.02422305  0.        ]\n",
      " [ 0.         -0.08472033  0.03848525  0.03037794]\n",
      " [ 0.         -0.02661686  0.030854   -0.00131054]]\n",
      "SHAP values per classe 146: [[ 0.18697405 -0.0227168  -0.10834362 -0.07371563]\n",
      " [-0.10106428  0.          0.          0.0304184 ]\n",
      " [ 0.23082313 -0.10127388 -0.04259191 -0.06847915]\n",
      " [ 0.04269707 -0.06485542  0.          0.00804511]\n",
      " [ 0.09841272 -0.05206087  0.         -0.02332672]]\n",
      "SHAP values per classe 147: [[-0.11221514  0.02107025  0.11053622 -0.00559673]\n",
      " [-0.00688592  0.          0.          0.        ]\n",
      " [-0.01645522  0.          0.01916726  0.        ]\n",
      " [ 0.         -0.10292635  0.13775639  0.        ]\n",
      " [-0.06209746 -0.12157107  0.09827566  0.        ]]\n",
      "SHAP values per classe 148: [[ 0.38127724 -0.26705593 -0.04715896 -0.06758451]\n",
      " [ 0.          0.1169883   0.         -0.01648868]\n",
      " [ 0.07487791  0.          0.          0.        ]\n",
      " [ 0.07756777 -0.16787671  0.05682873  0.02446596]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 149: [[-0.046358   -0.01481783  0.12059774 -0.02510461]\n",
      " [ 0.04321383 -0.02210284  0.         -0.06211665]\n",
      " [ 0.         -0.01628661  0.         -0.03370042]\n",
      " [ 0.         -0.07636677  0.07278627  0.        ]\n",
      " [ 0.         -0.02469382  0.04721265  0.        ]]\n",
      "SHAP values per classe 150: [[-0.12985014  0.12701874  0.          0.        ]\n",
      " [-0.00644996  0.          0.          0.        ]\n",
      " [-0.0267168   0.          0.          0.        ]\n",
      " [-0.04709778  0.28174306 -0.16942043 -0.06000214]\n",
      " [ 0.          0.07830411 -0.08597422 -0.02653376]]\n",
      "SHAP values per classe 151: [[-0.08405294  0.          0.          0.03276536]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.0076472 ]\n",
      " [ 0.         -0.06204955  0.02216349  0.02409178]\n",
      " [ 0.          0.          0.05079085  0.        ]]\n",
      "SHAP values per classe 152: [[-0.12757975  0.          0.06685017 -0.04620793]\n",
      " [-0.01019551  0.004927    0.          0.01389558]\n",
      " [-0.01233411  0.         -0.00122784  0.00985566]\n",
      " [ 0.00372936 -0.13463423  0.07136965  0.03595507]\n",
      " [ 0.00196494 -0.03748818  0.05965131 -0.02220013]]\n",
      "SHAP values per classe 153: [[-0.12032007  0.17299099  0.         -0.07538585]\n",
      " [-0.01916242  0.02548593  0.          0.        ]\n",
      " [-0.0214172   0.0136302   0.          0.        ]\n",
      " [-0.02370146  0.08994319 -0.03984669 -0.00363849]\n",
      " [-0.02191537  0.04947931 -0.04365535  0.01808158]]\n",
      "SHAP values per classe 154: [[-0.13012817  0.09768623  0.01447715  0.        ]\n",
      " [-0.00696685  0.00487249  0.          0.        ]\n",
      " [-0.0302531   0.          0.          0.01161456]\n",
      " [-0.04277802  0.32979532 -0.16366772 -0.13666813]\n",
      " [-0.01202889  0.05395879 -0.06962911  0.        ]]\n",
      "SHAP values per classe 155: [[ 0.1153372   0.          0.         -0.09182781]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.0002068   0.          0.         -0.03670207]\n",
      " [-0.02230971  0.19992414 -0.07288378  0.        ]\n",
      " [ 0.          0.          0.         -0.00473115]]\n",
      "SHAP values per classe 156: [[ 0.37019748 -0.1607325  -0.1388116  -0.12799302]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.08356107 -0.11115093  0.          0.        ]\n",
      " [ 0.14201132  0.          0.06466592  0.        ]]\n",
      "SHAP values per classe 157: [[-0.13346263 -0.04366655  0.          0.        ]\n",
      " [-0.00601753  0.          0.          0.        ]\n",
      " [ 0.          0.00017196  0.          0.        ]\n",
      " [ 0.         -0.07144057  0.          0.03444666]\n",
      " [ 0.         -0.024896    0.          0.        ]]\n",
      "SHAP values per classe 158: [[ 0.46837001 -0.0431181  -0.29304016 -0.105775  ]\n",
      " [ 0.          0.13899325  0.          0.        ]\n",
      " [ 0.04910448  0.          0.03619329 -0.03764702]\n",
      " [ 0.0569752  -0.10509112  0.          0.        ]\n",
      " [ 0.         -0.05545891  0.          0.01735796]]\n",
      "SHAP values per classe 159: [[-0.09916301  0.08399425  0.          0.        ]\n",
      " [-0.01195391  0.          0.02035552  0.        ]\n",
      " [-0.00585643  0.021476    0.         -0.01488971]\n",
      " [-0.13899572  0.47231834 -0.24811997 -0.08581784]\n",
      " [ 0.          0.          0.02372244  0.        ]]\n",
      "SHAP values per classe 160: [[-0.00719519 -0.00192385  0.04570183 -0.11086089]\n",
      " [-0.00441412  0.          0.01789815  0.00230485]\n",
      " [-0.00853962  0.          0.          0.        ]\n",
      " [ 0.         -0.04336017 -0.01704522  0.        ]\n",
      " [ 0.00183809 -0.02387327  0.          0.0275177 ]]\n",
      "SHAP values per classe 161: [[-0.11974891  0.0214811   0.01584798  0.09538389]\n",
      " [-0.01814635  0.          0.02540451  0.        ]\n",
      " [-0.00565827  0.         -0.00533779  0.03034702]\n",
      " [ 0.         -0.05699714  0.          0.05051755]\n",
      " [-0.01607521  0.          0.          0.        ]]\n",
      "SHAP values per classe 162: [[-0.12758046  0.02918334  0.          0.0951881 ]\n",
      " [ 0.         -0.03531131  0.          0.08874912]\n",
      " [-0.01063798  0.          0.          0.        ]\n",
      " [ 0.00230529 -0.07424474  0.01836268  0.        ]\n",
      " [-0.02512677  0.          0.          0.        ]]\n",
      "SHAP values per classe 163: [[-0.13535201  0.          0.09101813  0.07050097]\n",
      " [-0.00937939  0.          0.          0.02147476]\n",
      " [-0.01128386 -0.00562058  0.         -0.05731248]\n",
      " [ 0.         -0.10808633  0.01668222  0.04598786]\n",
      " [-0.01115405 -0.07655321  0.          0.        ]]\n",
      "SHAP values per classe 164: [[-0.08831971  0.06272217  0.          0.0618253 ]\n",
      " [-0.00670231  0.          0.         -0.01601547]\n",
      " [ 0.          0.01311079  0.          0.        ]\n",
      " [ 0.         -0.06789983  0.03871421  0.01816974]\n",
      " [ 0.         -0.03108231  0.0693752  -0.00976567]]\n",
      "SHAP values per classe 165: [[-0.10052343  0.06089513  0.          0.        ]\n",
      " [ 0.          0.          0.         -0.01037236]\n",
      " [-0.02140406  0.          0.          0.        ]\n",
      " [ 0.          0.00656887 -0.03515725  0.        ]\n",
      " [-0.06241384  0.47884674 -0.28117672 -0.09372142]]\n",
      "SHAP values per classe 166: [[-0.13981869  0.11200351  0.         -0.00268452]\n",
      " [-0.00661166  0.          0.00149382  0.        ]\n",
      " [-0.03919299  0.03643453 -0.00385769  0.        ]\n",
      " [-0.02946727  0.20294826 -0.10601375 -0.00214137]\n",
      " [ 0.          0.         -0.01868459  0.        ]]\n",
      "SHAP values per classe 167: [[-0.11402471  0.14577172  0.          0.        ]\n",
      " [-0.04521565 -0.09112293  0.06697588  0.        ]\n",
      " [-0.0157291   0.05670012  0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.02081989  0.37409393 -0.42533132  0.        ]]\n",
      "SHAP values per classe 168: [[-0.07672784  0.02699062 -0.02411689  0.        ]\n",
      " [-0.00762683  0.          0.         -0.00634951]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.01827509 -0.1212923   0.03208296  0.13522043]\n",
      " [ 0.         -0.02089054  0.01139512  0.        ]]\n",
      "SHAP values per classe 169: [[-0.11458793  0.03273893  0.02379089  0.05910752]\n",
      " [-0.00872197 -0.00127428  0.          0.00833301]\n",
      " [ 0.          0.14767043 -0.13863615  0.        ]\n",
      " [ 0.         -0.21781153  0.17149729  0.03662433]\n",
      " [-0.03808866 -0.17348317  0.15096729  0.05357206]]\n",
      "SHAP values per classe 170: [[-0.12561839  0.08535491  0.          0.        ]\n",
      " [-0.00743162  0.01774727  0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.00126175  0.          0.04110668  0.        ]\n",
      " [-0.04076177  0.54734486 -0.14526866 -0.27196832]]\n",
      "SHAP values per classe 171: [[ 0.49685089 -0.25961931 -0.0332512  -0.17046074]\n",
      " [ 0.0490902   0.0302491   0.0370543  -0.09205353]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.0622965  -0.05205685  0.        ]\n",
      " [ 0.04049771  0.          0.00464455  0.        ]]\n",
      "SHAP values per classe 172: [[ 0.35733396 -0.08708966 -0.10375578 -0.14701741]\n",
      " [-0.04147266  0.05123159  0.          0.        ]\n",
      " [-0.05780693  0.04629847  0.          0.        ]\n",
      " [-0.2325886   0.29692646 -0.04628364 -0.00818215]\n",
      " [ 0.03074834 -0.0564663   0.          0.00682379]]\n",
      "SHAP values per classe 173: [[-0.10667168  0.         -0.02596415  0.04163572]\n",
      " [ 0.04264057  0.          0.          0.        ]\n",
      " [-0.02289644 -0.00538872  0.          0.00096933]\n",
      " [ 0.03560476 -0.03088574  0.02264276  0.        ]\n",
      " [-0.03883257  0.          0.04884848  0.        ]]\n",
      "SHAP values per classe 174: [[-0.16650539  0.02166646  0.          0.0234655 ]\n",
      " [ 0.         -0.03641633 -0.08425613  0.10531638]\n",
      " [-0.02003517 -0.0216445   0.01285077  0.02196909]\n",
      " [ 0.         -0.12536116  0.12107672  0.        ]\n",
      " [ 0.         -0.06056132  0.05633277  0.00345635]]\n",
      "SHAP values per classe 175: [[-0.1348107   0.          0.02403806  0.        ]\n",
      " [-0.0095466   0.          0.         -0.0099296 ]\n",
      " [-0.03255901  0.07705807  0.0536813  -0.03084995]\n",
      " [ 0.         -0.0913095   0.03229053  0.05436666]\n",
      " [-0.01369296  0.06647616 -0.16800157  0.10976511]]\n",
      "SHAP values per classe 176: [[-0.12970715  0.03014879  0.08237717  0.        ]\n",
      " [-0.00644304  0.          0.01684678  0.        ]\n",
      " [-0.02252277  0.00711986  0.01363943  0.        ]\n",
      " [ 0.         -0.13274263  0.10415896  0.        ]\n",
      " [ 0.         -0.02662093  0.04007339  0.        ]]\n",
      "SHAP values per classe 177: [[ 0.50241343 -0.09587043 -0.23721283 -0.16157063]\n",
      " [ 0.          0.          0.04773064  0.        ]\n",
      " [ 0.07026422 -0.05049603  0.         -0.01972327]\n",
      " [ 0.0321841  -0.07056688  0.          0.        ]\n",
      " [ 0.11673582 -0.03762529  0.          0.        ]]\n",
      "SHAP values per classe 178: [[ 0.16054515 -0.01405767 -0.06725158 -0.05780496]\n",
      " [ 0.0239782  -0.01927888 -0.02704624  0.        ]\n",
      " [ 0.11414156 -0.04345831  0.         -0.03141876]\n",
      " [ 0.         -0.03166466  0.07958949  0.01721458]\n",
      " [ 0.02347038 -0.07280677  0.          0.        ]]\n",
      "SHAP values per classe 179: [[-0.08009688  0.          0.03476282  0.        ]\n",
      " [-0.01132953 -0.00800453  0.          0.        ]\n",
      " [-0.01839059 -0.0600456   0.          0.        ]\n",
      " [ 0.         -0.07546245  0.          0.10927259]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 180: [[ 0.          0.         -0.03288493  0.        ]\n",
      " [ 0.          0.          0.11721641  0.        ]\n",
      " [-0.0474005   0.06464205  0.          0.        ]\n",
      " [-0.16772054  0.57735396 -0.1994307  -0.18094102]\n",
      " [ 0.          0.         -0.02263636  0.        ]]\n",
      "SHAP values per classe 181: [[-0.10052685  0.09565457 -0.00331386  0.        ]\n",
      " [ 0.29675742 -0.08565628 -0.10912847 -0.05511406]\n",
      " [-0.03465035  0.0635552   0.          0.        ]\n",
      " [ 0.          0.37936558 -0.26721204 -0.01828858]\n",
      " [ 0.          0.          0.07908705 -0.11642754]]\n",
      "SHAP values per classe 182: [[-0.11404471  0.          0.          0.        ]\n",
      " [-0.00630412  0.          0.          0.        ]\n",
      " [-0.01506786 -0.01225503  0.          0.00317924]\n",
      " [-0.02849751  0.44687114 -0.25464964 -0.07515921]\n",
      " [-0.01246247  0.07238825  0.         -0.0746961 ]]\n",
      "SHAP values per classe 183: [[ 0.40018202 -0.03188367 -0.18074486 -0.17089527]\n",
      " [-0.03930686  0.         -0.02735462  0.        ]\n",
      " [ 0.          0.          0.18811338 -0.13445887]\n",
      " [ 0.         -0.11418671  0.03304534  0.        ]\n",
      " [ 0.         -0.05808433  0.          0.        ]]\n",
      "SHAP values per classe 184: [[-0.13618558  0.06146551  0.          0.        ]\n",
      " [-0.00962013  0.02209962  0.          0.        ]\n",
      " [-0.01413713  0.03336418 -0.06107266  0.        ]\n",
      " [ 0.          0.          0.05076987  0.        ]\n",
      " [-0.04397984  0.33812265 -0.1836097  -0.01657729]]\n",
      "SHAP values per classe 185: [[-0.07901362  0.          0.          0.09112294]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.04934492  0.          0.        ]\n",
      " [ 0.         -0.01039522  0.          0.        ]]\n",
      "SHAP values per classe 186: [[-0.1027618   0.          0.          0.07155104]\n",
      " [-0.00646485  0.          0.          0.01289625]\n",
      " [-0.00547971  0.          0.          0.02873275]\n",
      " [ 0.         -0.0389838   0.          0.        ]\n",
      " [ 0.         -0.01913746  0.          0.        ]]\n",
      "SHAP values per classe 187: [[ 0.35800199 -0.27019427 -0.02485091 -0.07265649]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.10301212  0.          0.        ]\n",
      " [ 0.09867159 -0.11342807  0.02407004  0.        ]\n",
      " [ 0.0450912  -0.06967638  0.          0.00900888]]\n",
      "SHAP values per classe 188: [[-0.12842658  0.          0.          0.0847008 ]\n",
      " [-0.00649793  0.          0.          0.        ]\n",
      " [ 0.         -0.00679591  0.          0.        ]\n",
      " [ 0.         -0.08036468  0.03462239  0.        ]\n",
      " [ 0.         -0.01830776  0.03179367  0.        ]]\n",
      "SHAP values per classe 189: [[-0.16881398  0.04671469  0.05113165  0.05043723]\n",
      " [-0.01258068  0.          0.          0.00738326]\n",
      " [-0.02908689  0.          0.          0.01712333]\n",
      " [ 0.         -0.15605553  0.03083524  0.07731253]\n",
      " [-0.00350462 -0.013235    0.          0.01255002]]\n",
      "SHAP values per classe 190: [[-0.10550091  0.03235489  0.          0.08125619]\n",
      " [-0.01047114  0.          0.          0.        ]\n",
      " [ 0.         -0.03754495  0.04779483  0.        ]\n",
      " [ 0.00488241 -0.06418103  0.02610672  0.0233657 ]\n",
      " [ 0.00196425 -0.01875838  0.          0.        ]]\n",
      "SHAP values per classe 191: [[-0.14576392  0.11358039  0.          0.02468997]\n",
      " [-0.00294111 -0.03053954  0.          0.03267685]\n",
      " [-0.0173241   0.01524659  0.          0.        ]\n",
      " [-0.04364053  0.41256172 -0.21346904 -0.13819007]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 192: [[ 0.3845831  -0.19385505 -0.05225465 -0.09461016]\n",
      " [ 0.          0.         -0.0031488   0.        ]\n",
      " [ 0.00616001 -0.06348305  0.          0.00435885]\n",
      " [ 0.06198548 -0.13134909  0.03387499  0.        ]\n",
      " [ 0.05121619  0.          0.          0.00812182]]\n",
      "SHAP values per classe 193: [[-0.11452375  0.22563507  0.          0.        ]\n",
      " [ 0.          0.00564899  0.          0.        ]\n",
      " [ 0.          0.2667211   0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.03969638  0.33148206 -0.07909281 -0.11841999]]\n",
      "SHAP values per classe 194: [[-0.0506924   0.03015974  0.02619697  0.        ]\n",
      " [ 0.         -0.00722777  0.          0.04893473]\n",
      " [ 0.          0.          0.17890206  0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.04109496 -0.02400495  0.20389033  0.        ]]\n",
      "SHAP values per classe 195: [[-0.13928846 -0.06942548  0.19943333  0.06962077]\n",
      " [-0.00720645  0.          0.          0.        ]\n",
      " [-0.00571553  0.         -0.07151456  0.03278589]\n",
      " [-0.0151151  -0.10652731  0.          0.04975294]\n",
      " [ 0.         -0.02265708  0.          0.02480938]]\n",
      "SHAP values per classe 196: [[ 0.         -0.03167999  0.10316057  0.        ]\n",
      " [ 0.          0.          0.         -0.03104921]\n",
      " [ 0.          0.          0.05619916  0.        ]\n",
      " [ 0.         -0.08109411  0.08612034  0.        ]\n",
      " [ 0.         -0.11295068  0.          0.        ]]\n",
      "SHAP values per classe 197: [[-0.09740252  0.1049698   0.          0.        ]\n",
      " [ 0.40368397 -0.1171881  -0.21940393 -0.08962274]\n",
      " [-0.05611163 -0.01402968  0.          0.        ]\n",
      " [-0.2078825   0.56450089 -0.12417868 -0.04542388]\n",
      " [ 0.          0.07032296  0.          0.        ]]\n",
      "SHAP values per classe 198: [[-0.12680427  0.10089012  0.          0.01419388]\n",
      " [-0.02209746  0.10418898  0.         -0.04974553]\n",
      " [-0.02513428  0.03711325  0.          0.        ]\n",
      " [-0.02284347  0.21228135 -0.15621903 -0.04886274]\n",
      " [-0.01826302  0.06996188 -0.05559745  0.01573388]]\n",
      "SHAP values per classe 199: [[ 0.11014782 -0.02955302  0.         -0.08575771]\n",
      " [ 0.01056797 -0.0032902   0.          0.        ]\n",
      " [ 0.07660536 -0.06029632  0.         -0.04673485]\n",
      " [ 0.         -0.06292763  0.          0.01705023]\n",
      " [ 0.08737316 -0.09624385  0.          0.        ]]\n",
      "SHAP values per classe 200: [[-0.11391699  0.          0.03821182  0.0234855 ]\n",
      " [-0.00941405  0.          0.          0.        ]\n",
      " [-0.01063521  0.          0.          0.01556678]\n",
      " [ 0.         -0.07204951  0.          0.        ]\n",
      " [ 0.         -0.04527298  0.07869669  0.        ]]\n",
      "SHAP values per classe 201: [[-0.16347889 -0.00864561  0.0351765   0.08260287]\n",
      " [ 0.         -0.04678476  0.05639685  0.        ]\n",
      " [-0.01335158  0.00292675  0.          0.01555849]\n",
      " [ 0.         -0.05233072  0.          0.06989223]\n",
      " [ 0.         -0.03080451  0.          0.        ]]\n",
      "SHAP values per classe 202: [[-0.10734896  0.0342215   0.0689254   0.        ]\n",
      " [-0.00349602  0.06573456  0.          0.        ]\n",
      " [-0.00076282  0.071671    0.          0.        ]\n",
      " [ 0.03031738 -0.09470087  0.06168816  0.        ]\n",
      " [ 0.         -0.03290463  0.03946842  0.        ]]\n",
      "SHAP values per classe 203: [[-0.12186159  0.          0.          0.09521054]\n",
      " [-0.0090565  -0.03738293  0.          0.        ]\n",
      " [-0.01104163  0.          0.          0.02787544]\n",
      " [-0.00531656 -0.07070982  0.          0.02870446]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 204: [[-0.12791467  0.00713358  0.0177089   0.06744121]\n",
      " [ 0.          0.01793032  0.01926602  0.        ]\n",
      " [-0.00634536 -0.01485404  0.          0.        ]\n",
      " [-0.0001886   0.          0.02472375  0.        ]\n",
      " [ 0.         -0.02432848  0.          0.        ]]\n",
      "SHAP values per classe 205: [[-0.15794153  0.          0.04478356  0.06104999]\n",
      " [-0.01205094  0.          0.          0.        ]\n",
      " [-0.02641034  0.          0.          0.03103944]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.04397904  0.00619071  0.03371659]]\n",
      "SHAP values per classe 206: [[-0.04384345  0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.01021098  0.          0.          0.        ]\n",
      " [-0.05521058  0.26807298 -0.05641933 -0.12743817]\n",
      " [ 0.          0.07599882 -0.04624338  0.        ]]\n",
      "SHAP values per classe 207: [[-0.15564079  0.03286252  0.04060988  0.04913323]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.0044922   0.          0.        ]\n",
      " [ 0.         -0.02082645  0.          0.        ]\n",
      " [ 0.00593746 -0.02202816  0.          0.        ]]\n",
      "SHAP values per classe 208: [[-0.15185257 -0.03014558  0.20958118 -0.04350837]\n",
      " [-0.0057524  -0.00336456  0.          0.        ]\n",
      " [-0.00955265  0.          0.          0.        ]\n",
      " [-0.00456944 -0.10561489  0.05763986  0.04150797]\n",
      " [ 0.         -0.03571973  0.03658732  0.        ]]\n",
      "SHAP values per classe 209: [[-0.12375262  0.02229208  0.          0.0746699 ]\n",
      " [-0.0048201  -0.00641995  0.00730803 -0.0489652 ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.11186329  0.10789165 -0.02867644]\n",
      " [-0.00104003 -0.02125842  0.03207453  0.        ]]\n",
      "SHAP values per classe 210: [[-0.09325519  0.          0.          0.04358071]\n",
      " [-0.0134919   0.          0.          0.        ]\n",
      " [-0.01243819 -0.01923059  0.          0.0207316 ]\n",
      " [ 0.         -0.05829833  0.          0.03602862]\n",
      " [ 0.         -0.03094643  0.          0.01338911]]\n",
      "SHAP values per classe 211: [[-0.12323935  0.          0.          0.01265037]\n",
      " [-0.00626951  0.          0.          0.        ]\n",
      " [-0.01845787  0.          0.03009786  0.0589358 ]\n",
      " [-0.06488401  0.35346347 -0.23702076 -0.13193745]\n",
      " [ 0.          0.          0.01535188  0.00230739]]\n",
      "SHAP values per classe 212: [[-0.13620815  0.03309871  0.00508533  0.08592099]\n",
      " [ 0.         -0.02829891  0.          0.02461927]\n",
      " [-0.01498094  0.          0.          0.01801305]\n",
      " [-0.01258921 -0.05156069  0.04271896  0.03252893]\n",
      " [-0.01005332  0.          0.02140879  0.        ]]\n",
      "SHAP values per classe 213: [[ 0.          0.          0.          0.        ]\n",
      " [-0.01232815  0.          0.          0.        ]\n",
      " [-0.03392361  0.          0.02949681  0.01678314]\n",
      " [ 0.         -0.13528092  0.10101389  0.03207676]\n",
      " [ 0.          0.          0.00337283  0.        ]]\n",
      "SHAP values per classe 214: [[-0.12261595  0.09866604  0.          0.        ]\n",
      " [-0.00681696  0.02208253  0.          0.        ]\n",
      " [-0.01628404  0.01249696  0.          0.        ]\n",
      " [-0.05360665  0.48590633 -0.23045281 -0.14290384]\n",
      " [ 0.01981006  0.          0.         -0.00972129]]\n",
      "SHAP values per classe 215: [[-0.08492773  0.          0.09087804  0.        ]\n",
      " [-0.0116558   0.          0.02376059  0.        ]\n",
      " [ 0.         -0.02127658  0.          0.        ]\n",
      " [-0.02663976 -0.11729044  0.1846421   0.        ]\n",
      " [-0.00040946 -0.04411426  0.04766018  0.        ]]\n",
      "SHAP values per classe 216: [[-0.11476405  0.03421126  0.05543859  0.04053069]\n",
      " [-0.00791625  0.00104723  0.          0.        ]\n",
      " [-0.00477943 -0.0010724  -0.02540745  0.04169621]\n",
      " [-0.00337118 -0.0716701   0.1183432   0.        ]\n",
      " [-0.00470224 -0.00938936 -0.06701774  0.1050734 ]]\n",
      "SHAP values per classe 217: [[-0.11822841  0.          0.06280679  0.02809596]\n",
      " [-0.00755016  0.          0.          0.        ]\n",
      " [-0.02000839  0.          0.          0.02832714]\n",
      " [ 0.         -0.07504105  0.00995569  0.04704375]\n",
      " [ 0.          0.          0.          0.04668483]]\n",
      "SHAP values per classe 218: [[ 0.31478024 -0.02283352 -0.1618038  -0.08577789]\n",
      " [ 0.          0.01345179  0.          0.        ]\n",
      " [ 0.11105712  0.          0.          0.        ]\n",
      " [ 0.         -0.09916535  0.          0.        ]\n",
      " [ 0.          0.          0.01731968  0.        ]]\n",
      "SHAP values per classe 219: [[-0.15455694  0.          0.04786807  0.07656081]\n",
      " [-0.01009211  0.          0.          0.        ]\n",
      " [ 0.          0.          0.00653929  0.00820173]\n",
      " [ 0.         -0.0623965   0.          0.03976589]\n",
      " [ 0.         -0.02131405  0.01608257  0.00612174]]\n",
      "SHAP values per classe 220: [[-0.09217158  0.          0.01216432  0.04106487]\n",
      " [-0.00922156  0.          0.00291065  0.        ]\n",
      " [-0.01809838  0.          0.          0.        ]\n",
      " [ 0.         -0.06581316  0.03471697  0.02886925]\n",
      " [ 0.          0.          0.01119556  0.        ]]\n",
      "SHAP values per classe 221: [[-0.13440542  0.09461213  0.          0.        ]\n",
      " [ 0.          0.01278399  0.         -0.05346866]\n",
      " [-0.01359939  0.          0.          0.03036512]\n",
      " [-0.03581916  0.55245372 -0.33302826 -0.15718996]\n",
      " [ 0.          0.          0.          0.00503941]]\n",
      "SHAP values per classe 222: [[-0.12537182  0.          0.08739594  0.        ]\n",
      " [-0.01784955  0.          0.          0.        ]\n",
      " [ 0.00023497  0.          0.          0.        ]\n",
      " [ 0.         -0.13990933  0.05297837  0.        ]\n",
      " [ 0.         -0.02847197  0.05659387  0.        ]]\n",
      "SHAP values per classe 223: [[-0.1557529   0.06700632  0.04697408  0.02242497]\n",
      " [-0.00886521  0.01770485  0.          0.        ]\n",
      " [-0.03466342  0.05865406  0.          0.        ]\n",
      " [ 0.          0.18528706 -0.13991814 -0.01491738]\n",
      " [ 0.          0.          0.03514729  0.        ]]\n",
      "SHAP values per classe 224: [[ 0.47183363 -0.20522761 -0.07688868 -0.15351939]\n",
      " [ 0.          0.          0.          0.02027719]\n",
      " [ 0.          0.1100023  -0.13334458  0.        ]\n",
      " [ 0.05578212 -0.10279623  0.          0.01381646]\n",
      " [ 0.06502718 -0.05594572  0.          0.        ]]\n",
      "SHAP values per classe 225: [[-0.12912135  0.13494742  0.         -0.00661433]\n",
      " [-0.01125359  0.00440148  0.         -0.00486447]\n",
      " [-0.04084331  0.05510657 -0.03823103  0.02963582]\n",
      " [-0.0271591   0.24895748 -0.11343081 -0.09603586]\n",
      " [-0.01968062  0.03294623 -0.01482321  0.        ]]\n",
      "SHAP values per classe 226: [[-0.07666522  0.          0.17955057 -0.09541961]\n",
      " [-0.00594142  0.         -0.00737762  0.01356044]\n",
      " [-0.02542548  0.          0.          0.        ]\n",
      " [ 0.0022276  -0.09029883  0.09548567  0.        ]\n",
      " [-0.03956558 -0.06249579 -0.06035756  0.13060776]]\n",
      "SHAP values per classe 227: [[-0.07191148  0.00463377  0.11159765 -0.0490641 ]\n",
      " [ 0.          0.02734464  0.          0.        ]\n",
      " [-0.04018909  0.0008259   0.02714972  0.        ]\n",
      " [ 0.         -0.12832201  0.06710378  0.04635839]\n",
      " [ 0.         -0.0711767   0.02126433  0.02279613]]\n",
      "SHAP values per classe 228: [[-0.12119184  0.06945482  0.          0.0296898 ]\n",
      " [-0.0234072   0.1550062  -0.04529283  0.        ]\n",
      " [-0.03291916 -0.01964719  0.          0.        ]\n",
      " [ 0.00458885  0.23109075 -0.15794401 -0.11763115]\n",
      " [-0.03019884  0.13097418 -0.03835535 -0.00960935]]\n",
      "SHAP values per classe 229: [[-0.08843913  0.06122636  0.          0.        ]\n",
      " [ 0.          0.0114095   0.          0.        ]\n",
      " [-0.0068244  -0.10007567  0.          0.        ]\n",
      " [-0.11313873  0.56631382 -0.21776292 -0.1403039 ]\n",
      " [ 0.         -0.02945354  0.          0.        ]]\n",
      "SHAP values per classe 230: [[-0.14351071  0.          0.05077544  0.00297979]\n",
      " [-0.01300837  0.          0.          0.01608841]\n",
      " [-0.01841342  0.          0.          0.00164013]\n",
      " [ 0.         -0.1245079   0.08123564  0.01792408]\n",
      " [ 0.         -0.03686013  0.11696601  0.        ]]\n",
      "SHAP values per classe 231: [[-0.12915385  0.0291115   0.02422784  0.07446012]\n",
      " [-0.00826268 -0.02192349  0.          0.        ]\n",
      " [-0.00905212  0.          0.          0.        ]\n",
      " [ 0.         -0.11961285  0.06232466  0.02929721]\n",
      " [ 0.          0.          0.          0.02370636]]\n",
      "SHAP values per classe 232: [[-0.132451    0.          0.06125561  0.04395415]\n",
      " [ 0.          0.0569261  -0.05067103  0.        ]\n",
      " [-0.00689634  0.00267373  0.          0.        ]\n",
      " [ 0.         -0.06628249  0.0684728   0.01430012]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 233: [[ 0.25926839 -0.02628644 -0.14888925 -0.05349159]\n",
      " [ 0.         -0.00844187  0.          0.        ]\n",
      " [ 0.03645864 -0.04083211  0.         -0.01474601]\n",
      " [ 0.1796559  -0.17570581  0.         -0.04473272]\n",
      " [ 0.02086178 -0.03083218  0.          0.        ]]\n",
      "SHAP values per classe 234: [[ 0.31380282 -0.05714592 -0.14558443 -0.11893386]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.         -0.00902385  0.        ]\n",
      " [-0.00887003 -0.05644762  0.          0.        ]\n",
      " [ 0.04726849 -0.06547379  0.          0.        ]]\n",
      "SHAP values per classe 235: [[-0.11166971  0.02824233  0.11717623  0.        ]\n",
      " [-0.01288402  0.          0.          0.05979684]\n",
      " [-0.0315931   0.          0.          0.        ]\n",
      " [ 0.         -0.09689305  0.09340257  0.        ]\n",
      " [-0.04304714 -0.13865405  0.03941212  0.08243659]]\n",
      "SHAP values per classe 236: [[ 0.3727059  -0.0860964  -0.12549696 -0.15099793]\n",
      " [ 0.         -0.00455332  0.01338239  0.        ]\n",
      " [ 0.19312589 -0.08209176 -0.02160944 -0.06563428]\n",
      " [ 0.         -0.05335821  0.04311259  0.        ]\n",
      " [ 0.         -0.02845895  0.          0.        ]]\n",
      "SHAP values per classe 237: [[ 0.70299179 -0.27063927 -0.17397256 -0.19848437]\n",
      " [ 0.          0.04802142  0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.00615033 -0.11008111  0.04104448  0.        ]\n",
      " [ 0.01100015  0.          0.          0.        ]]\n",
      "SHAP values per classe 238: [[-0.07138756  0.11395843  0.         -0.03636565]\n",
      " [ 0.          0.00260479  0.          0.00652513]\n",
      " [-0.04929801  0.05387501  0.          0.        ]\n",
      " [-0.0312949   0.22415572 -0.08096791 -0.08227558]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 239: [[ 0.          0.          0.         -0.03103684]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.04799229 -0.01226952  0.        ]\n",
      " [-0.30705259  0.44832525 -0.0425335  -0.02923508]\n",
      " [ 0.          0.          0.01486566  0.        ]]\n",
      "SHAP values per classe 240: [[-0.07695675 -0.01129891  0.          0.18906107]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.01340544  0.          0.          0.        ]\n",
      " [ 0.         -0.06614955  0.02613697  0.        ]\n",
      " [ 0.         -0.01879125  0.          0.        ]]\n",
      "SHAP values per classe 241: [[-0.11729838  0.05194551  0.02854505  0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.01516868  0.          0.         -0.00488932]\n",
      " [-0.06843641  0.61503252 -0.34853914 -0.16492388]\n",
      " [-0.00661744  0.          0.          0.        ]]\n",
      "SHAP values per classe 242: [[ 0.30802296 -0.05053369 -0.10484099 -0.13253668]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.01641964 -0.05602888  0.          0.01419758]\n",
      " [ 0.06850351 -0.07444348  0.0361961   0.        ]\n",
      " [ 0.1021634  -0.11318241  0.          0.        ]]\n",
      "SHAP values per classe 243: [[ 0.56594307 -0.13562817 -0.23344784 -0.18664833]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.02045758 -0.01294275  0.          0.        ]\n",
      " [ 0.01671929 -0.06298645  0.          0.        ]\n",
      " [ 0.03460418 -0.02870654  0.          0.        ]]\n",
      "SHAP values per classe 244: [[-0.1256511   0.1231075  -0.01566786  0.        ]\n",
      " [-0.00267776  0.         -0.00093396  0.        ]\n",
      " [-0.02051197  0.          0.          0.        ]\n",
      " [ 0.          0.          0.02482448  0.        ]\n",
      " [-0.02529509  0.25059066 -0.0932537  -0.09879582]]\n",
      "SHAP values per classe 245: [[-0.11260786  0.          0.02818431  0.07752071]\n",
      " [-0.00819476  0.0235531   0.          0.        ]\n",
      " [ 0.         -0.0238613   0.03024897  0.        ]\n",
      " [ 0.         -0.12505552  0.09947066  0.01244387]\n",
      " [-0.02855967 -0.03056205  0.06546408  0.        ]]\n",
      "SHAP values per classe 246: [[-0.20249255  0.02603893  0.15659317 -0.05783987]\n",
      " [ 0.06618473  0.         -0.04578991  0.        ]\n",
      " [-0.08136247 -0.00114791  0.06024827  0.        ]\n",
      " [-0.04161258 -0.08760527  0.07927657  0.        ]\n",
      " [-0.01070895 -0.06104862  0.075439   -0.00858254]]\n",
      "SHAP values per classe 247: [[-0.12251213  0.11894789  0.          0.        ]\n",
      " [-0.00614251  0.          0.          0.        ]\n",
      " [-0.04355742  0.01090959  0.          0.        ]\n",
      " [-0.03541136  0.31839765 -0.20715304 -0.03072809]\n",
      " [-0.00180388  0.          0.00515824  0.        ]]\n",
      "SHAP values per classe 248: [[-0.06548609  0.          0.04592445  0.        ]\n",
      " [-0.01369989  0.          0.          0.        ]\n",
      " [-0.03119933 -0.00376519  0.          0.05364336]\n",
      " [ 0.         -0.0583988   0.0393061   0.01138908]\n",
      " [ 0.         -0.01332336  0.06218193  0.        ]]\n",
      "SHAP values per classe 249: [[-0.0912623   0.          0.0830274   0.        ]\n",
      " [ 0.         -0.01840137  0.         -0.05832308]\n",
      " [-0.0070012   0.          0.02146643  0.        ]\n",
      " [ 0.         -0.06497454  0.06489364  0.        ]\n",
      " [-0.01183129  0.          0.15848099  0.        ]]\n",
      "SHAP values per classe 250: [[-0.06903082  0.04957982  0.          0.01160726]\n",
      " [-0.02755815  0.31308057 -0.05936854 -0.06329729]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.01863898  0.11135536  0.          0.        ]\n",
      " [ 0.          0.         -0.04479964  0.        ]]\n",
      "SHAP values per classe 251: [[-0.13285398  0.03490771  0.05731563  0.        ]\n",
      " [-0.00378671  0.          0.          0.        ]\n",
      " [-0.02620223  0.          0.          0.        ]\n",
      " [ 0.         -0.04571283  0.          0.00317076]\n",
      " [-0.01828185  0.25277756 -0.2561572   0.03249388]]\n",
      "SHAP values per classe 252: [[-0.17413587  0.0328103   0.045327    0.0525534 ]\n",
      " [-0.00871419 -0.0154477   0.          0.00772018]\n",
      " [-0.01909722 -0.03689803  0.03264791  0.        ]\n",
      " [ 0.          0.          0.          0.05232457]\n",
      " [ 0.         -0.0895411   0.06671599  0.00567784]]\n",
      "SHAP values per classe 253: [[-0.130042    0.02972288  0.07601035  0.00786752]\n",
      " [-0.00457513  0.02474892  0.          0.        ]\n",
      " [-0.01820458  0.          0.          0.        ]\n",
      " [-0.05275587  0.35572182 -0.10639111 -0.20538527]\n",
      " [ 0.          0.0393082  -0.0581943   0.        ]]\n",
      "SHAP values per classe 254: [[-0.12283056  0.02866263  0.02920127  0.06417372]\n",
      " [-0.01819036  0.          0.          0.00868259]\n",
      " [-0.01289807  0.01807741  0.          0.        ]\n",
      " [ 0.         -0.08534476  0.05117872  0.03969076]\n",
      " [ 0.         -0.06057435  0.02550594  0.        ]]\n",
      "SHAP values per classe 255: [[-0.07744486  0.          0.03168984  0.0214212 ]\n",
      " [-0.00447526  0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.06281718  0.01751953  0.02024385]\n",
      " [ 0.         -0.03747335  0.          0.        ]]\n",
      "SHAP values per classe 256: [[-0.09054728  0.          0.01755351  0.03459181]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.         -0.00466795  0.        ]\n",
      " [-0.00058103 -0.07778658  0.05817556  0.01752379]\n",
      " [-0.0249265   0.          0.          0.05298438]]\n",
      "SHAP values per classe 257: [[-0.02175939  0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.1423216 ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.05073778  0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 258: [[-0.02937717  0.          0.          0.        ]\n",
      " [ 0.02576829  0.          0.03545754 -0.06813846]\n",
      " [ 0.          0.1071598  -0.05246312 -0.07291601]\n",
      " [-0.03121841  0.21088067 -0.04146255 -0.09044399]\n",
      " [-0.00515182  0.02058548 -0.02473584  0.        ]]\n",
      "SHAP values per classe 259: [[-0.11943208  0.02904432  0.18550902 -0.09696608]\n",
      " [ 0.          0.          0.15733664 -0.21438733]\n",
      " [-0.02053553  0.          0.          0.        ]\n",
      " [-0.00384775 -0.16733466 -0.00296464  0.04471615]\n",
      " [ 0.         -0.031763    0.07960151 -0.05837045]]\n",
      "SHAP values per classe 260: [[-0.12557177  0.03451336  0.0094552   0.08717201]\n",
      " [-0.01113762  0.          0.          0.        ]\n",
      " [-0.03517174  0.          0.05536744  0.01248808]\n",
      " [ 0.         -0.0369193   0.          0.05496733]\n",
      " [ 0.00333074  0.08382291  0.          0.        ]]\n",
      "SHAP values per classe 261: [[-0.0966061   0.02449265  0.0564614   0.01960286]\n",
      " [ 0.          0.          0.00657939  0.        ]\n",
      " [ 0.          0.01159976  0.          0.        ]\n",
      " [-0.01053162 -0.17656008  0.08868191  0.10704973]\n",
      " [ 0.         -0.07666727  0.10097623  0.        ]]\n",
      "SHAP values per classe 262: [[-0.10153666  0.034046    0.06054456  0.        ]\n",
      " [ 0.          0.13892868 -0.08106129 -0.04328106]\n",
      " [-0.02021204 -0.03311949  0.06155344  0.        ]\n",
      " [ 0.         -0.04036152  0.02963927  0.        ]\n",
      " [-0.02663221 -0.12156121  0.16232533  0.        ]]\n",
      "SHAP values per classe 263: [[-0.12496569  0.06928807  0.          0.        ]\n",
      " [ 0.          0.03155261 -0.01886078  0.        ]\n",
      " [-0.01460263  0.01386588  0.          0.        ]\n",
      " [-0.03449692  0.39277461 -0.15276626 -0.11615353]\n",
      " [-0.02151913  0.05243573 -0.04648726  0.        ]]\n",
      "SHAP values per classe 264: [[-0.17364637  0.14653181  0.01839406  0.01054406]\n",
      " [-0.01314967  0.          0.          0.        ]\n",
      " [ 0.09424733  0.          0.         -0.00967649]\n",
      " [ 0.05730718  0.02366662 -0.10056835 -0.0388447 ]\n",
      " [-0.17753565  0.30310355 -0.10535905  0.        ]]\n",
      "SHAP values per classe 265: [[-0.15581853  0.03197043  0.          0.08960083]\n",
      " [-0.01827857 -0.00713116  0.          0.        ]\n",
      " [ 0.          0.          0.00041993  0.        ]\n",
      " [ 0.00542423 -0.07447018  0.02938981  0.02694288]\n",
      " [-0.01824179 -0.03770286  0.06614202  0.        ]]\n",
      "SHAP values per classe 266: [[ 0.56357857 -0.13401701 -0.14090661 -0.15465393]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.00781032 -0.0193604   0.        ]\n",
      " [ 0.0883059  -0.10333222  0.          0.01700885]\n",
      " [ 0.         -0.03569314  0.          0.        ]]\n",
      "SHAP values per classe 267: [[-0.06742458  0.          0.          0.01730614]\n",
      " [-0.00938005  0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.02762921  0.          0.        ]\n",
      " [-0.00475283 -0.01345221  0.04651504  0.        ]]\n",
      "SHAP values per classe 268: [[-0.13071746  0.03419862  0.          0.07195577]\n",
      " [-0.02725175  0.03756694  0.          0.        ]\n",
      " [-0.02125052  0.          0.          0.        ]\n",
      " [ 0.         -0.07186506  0.04368232  0.03922678]\n",
      " [ 0.          0.1524376   0.          0.        ]]\n",
      "SHAP values per classe 269: [[-0.09255715  0.09453903  0.          0.        ]\n",
      " [ 0.01180504  0.          0.02981515 -0.02702899]\n",
      " [ 0.          0.01418967  0.          0.        ]\n",
      " [-0.21029843  0.56114576 -0.13818223 -0.14220368]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 270: [[-0.14814729  0.          0.09289375  0.        ]\n",
      " [-0.01204423  0.          0.02025837  0.        ]\n",
      " [-0.01577266  0.01423686  0.          0.        ]\n",
      " [ 0.         -0.06707455  0.07321303  0.        ]\n",
      " [ 0.         -0.03296954  0.01318289  0.        ]]\n",
      "SHAP values per classe 271: [[ 0.39547783 -0.20538228 -0.0660904  -0.08719875]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.08601914  0.          0.        ]\n",
      " [ 0.07876445 -0.1283325   0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 272: [[-0.11073628  0.         -0.13677541  0.14690834]\n",
      " [-0.01003282  0.          0.08137307  0.        ]\n",
      " [-0.00577604  0.         -0.02708615  0.        ]\n",
      " [-0.00760094 -0.06354667  0.33786477 -0.28813979]\n",
      " [-0.00284884 -0.01724341  0.          0.        ]]\n",
      "SHAP values per classe 273: [[-0.12334107  0.0256817   0.          0.02764047]\n",
      " [-0.00698928  0.          0.         -0.02022724]\n",
      " [-0.01410312  0.          0.01037957  0.02634889]\n",
      " [-0.03860684  0.3497186  -0.27372137 -0.1290332 ]\n",
      " [-0.02061052  0.          0.          0.        ]]\n",
      "SHAP values per classe 274: [[ 0.32091483 -0.07343185 -0.10114157 -0.1497364 ]\n",
      " [ 0.02077209  0.          0.          0.01842125]\n",
      " [ 0.          0.01128653  0.          0.        ]\n",
      " [ 0.07955809 -0.12068376  0.0231196   0.        ]\n",
      " [ 0.03865218 -0.0615943   0.          0.01380953]]\n",
      "SHAP values per classe 275: [[-0.12795173  0.024199    0.          0.11071602]\n",
      " [-0.0111989   0.          0.          0.01452098]\n",
      " [-0.05309175  0.03433793  0.          0.01856653]\n",
      " [ 0.00444695 -0.16338961  0.05880898  0.0462825 ]\n",
      " [ 0.          0.04536347  0.          0.01630807]]\n",
      "SHAP values per classe 276: [[-0.16805555  0.03168136  0.03744725  0.09374778]\n",
      " [-0.00648698  0.01746309 -0.08638774  0.08759066]\n",
      " [-0.01705786  0.          0.          0.01354913]\n",
      " [ 0.         -0.16353541  0.11058173  0.00659194]\n",
      " [ 0.         -0.06008038  0.          0.06986154]]\n",
      "SHAP values per classe 277: [[ 0.          0.          0.         -0.04103368]\n",
      " [ 0.44854695 -0.06461727 -0.22352357 -0.12784058]\n",
      " [ 0.         -0.00595547  0.         -0.00471354]\n",
      " [ 0.         -0.02549234  0.          0.        ]\n",
      " [ 0.         -0.02797651  0.          0.        ]]\n",
      "SHAP values per classe 278: [[ 0.40863716 -0.09257325 -0.12288016 -0.16138975]\n",
      " [ 0.         -0.01578199  0.          0.        ]\n",
      " [ 0.          0.01075393 -0.00496561  0.        ]\n",
      " [ 0.05015774 -0.10595394  0.          0.00807956]\n",
      " [ 0.04517582 -0.05169026  0.          0.00462875]]\n",
      "SHAP values per classe 279: [[-0.15559831  0.02939488  0.04493543  0.03202905]\n",
      " [-0.01213268  0.          0.          0.        ]\n",
      " [-0.01900102  0.01686132  0.          0.        ]\n",
      " [-0.00775055 -0.13104624  0.          0.08571897]\n",
      " [ 0.00398398  0.          0.          0.        ]]\n",
      "SHAP values per classe 280: [[-0.05841621  0.          0.00885818  0.        ]\n",
      " [-0.0175027  -0.03273799  0.          0.        ]\n",
      " [ 0.          0.          0.          0.02585108]\n",
      " [ 0.         -0.03666403  0.          0.00970358]\n",
      " [ 0.          0.          0.          0.01255138]]\n",
      "SHAP values per classe 281: [[-0.12700463  0.01731363  0.07879277  0.01216808]\n",
      " [-0.00975557 -0.00377318  0.00708154  0.        ]\n",
      " [ 0.          0.         -0.06727871  0.        ]\n",
      " [ 0.         -0.10533298  0.09711932  0.01275146]\n",
      " [-0.04851083 -0.04782931  0.16297504  0.        ]]\n",
      "SHAP values per classe 282: [[-0.0718856   0.          0.          0.07472826]\n",
      " [-0.00868197  0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.04117988  0.          0.02082106]\n",
      " [ 0.         -0.01197809  0.          0.        ]]\n",
      "SHAP values per classe 283: [[ 0.05461762 -0.00496392  0.03073739 -0.10996134]\n",
      " [ 0.02704196 -0.02922457  0.03034901 -0.05133973]\n",
      " [ 0.          0.          0.         -0.00467941]\n",
      " [ 0.         -0.0829097   0.07982228  0.01063483]\n",
      " [ 0.         -0.0208228   0.          0.        ]]\n",
      "SHAP values per classe 284: [[ 0.68456722 -0.29096793 -0.17265633 -0.2097948 ]\n",
      " [ 0.         -0.06218229  0.03994567  0.        ]\n",
      " [ 0.          0.07646722 -0.04517314  0.        ]\n",
      " [ 0.02296904 -0.11442727  0.04521583  0.        ]\n",
      " [ 0.01689155  0.          0.         -0.01041397]]\n",
      "SHAP values per classe 285: [[-0.0668164   0.03457362  0.          0.        ]\n",
      " [-0.01090244  0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.0549155   0.          0.03446468]\n",
      " [ 0.         -0.0239566   0.          0.        ]]\n",
      "SHAP values per classe 286: [[-0.12253196  0.12048638  0.          0.        ]\n",
      " [ 0.          0.01881672 -0.00113578  0.        ]\n",
      " [ 0.          0.01972911  0.         -0.00456889]\n",
      " [-0.06530002  0.34589269 -0.21096243 -0.07393292]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "SHAP values per classe 287: [[-0.18091239  0.          0.06989721  0.07339021]\n",
      " [-0.01128738  0.          0.          0.01549122]\n",
      " [ 0.05630965  0.          0.          0.        ]\n",
      " [ 0.00999342 -0.09936607  0.          0.10883679]\n",
      " [ 0.05266557 -0.00437806 -0.00834679  0.        ]]\n",
      "SHAP values per classe 288: [[ 0.35385067 -0.13924702 -0.07524912 -0.09427075]\n",
      " [ 0.          0.03220368  0.         -0.04145125]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.10281788 -0.12231413  0.          0.        ]\n",
      " [ 0.06134949 -0.05573738  0.          0.01513573]]\n",
      "SHAP values per classe 289: [[-0.11899936  0.03389134  0.06582151  0.        ]\n",
      " [-0.01698717 -0.03972759  0.02871925 -0.01206503]\n",
      " [ 0.          0.          0.          0.0043513 ]\n",
      " [ 0.         -0.0966357   0.07075564  0.01952585]\n",
      " [ 0.         -0.02703316  0.03006286 -0.03171853]]\n",
      "SHAP values per classe 290: [[-0.15300074  0.          0.          0.05592409]\n",
      " [-0.00744755  0.          0.01997362  0.        ]\n",
      " [-0.02085563  0.          0.          0.        ]\n",
      " [ 0.         -0.05068814  0.02324629  0.02760346]\n",
      " [-0.02195225  0.32490016 -0.32998149  0.        ]]\n",
      "SHAP values per classe 291: [[ 0.28843879 -0.07777816 -0.04512745 -0.1488769 ]\n",
      " [ 0.36440061 -0.07982666 -0.21859886 -0.0748201 ]\n",
      " [ 0.          0.          0.01832279  0.00801756]\n",
      " [ 0.08162799 -0.04794497 -0.01006223  0.        ]\n",
      " [ 0.         -0.0157077   0.00207505  0.        ]]\n",
      "SHAP values per classe 292: [[-0.10521782  0.05492714  0.03342054  0.0094524 ]\n",
      " [-0.00574094  0.          0.          0.        ]\n",
      " [-0.01125237  0.          0.         -0.01145157]\n",
      " [-0.0825113   0.68227082 -0.34629996 -0.2512228 ]\n",
      " [ 0.         -0.03257781  0.01291568  0.        ]]\n",
      "SHAP values per classe 293: [[-0.10054721  0.11369197  0.          0.        ]\n",
      " [-0.01274169  0.          0.          0.        ]\n",
      " [-0.01475877  0.          0.03953012  0.        ]\n",
      " [ 0.          0.         -0.03186463  0.        ]\n",
      " [-0.02419551  0.12222859 -0.08649634  0.        ]]\n",
      "SHAP values per classe 294: [[-0.16922659 -0.12131859  0.11579889  0.17739806]\n",
      " [-0.01124469  0.03176757  0.07415561 -0.11260691]\n",
      " [-0.01002369  0.11056297  0.          0.        ]\n",
      " [ 0.         -0.09831978  0.08123896  0.01751025]\n",
      " [ 0.         -0.02251393  0.          0.        ]]\n",
      "SHAP values per classe 295: [[-0.12984584  0.0859364   0.01477992  0.        ]\n",
      " [-0.0066908   0.          0.          0.        ]\n",
      " [-0.01625257  0.          0.          0.        ]\n",
      " [-0.03582414  0.45911431 -0.24726912 -0.16497338]\n",
      " [ 0.          0.          0.02012736  0.        ]]\n",
      "SHAP values per classe 296: [[-0.07504457  0.         -0.07587755  0.11684021]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.06514331  0.          0.0500512 ]\n",
      " [ 0.         -0.01298126  0.          0.        ]]\n",
      "SHAP values per classe 297: [[-0.11538682  0.03891039  0.0254633   0.        ]\n",
      " [-0.03057923  0.          0.         -0.01437367]\n",
      " [ 0.          0.04878188  0.          0.        ]\n",
      " [-0.03924719  0.45721228 -0.30089639 -0.11514238]\n",
      " [ 0.          0.          0.          0.00512645]]\n",
      "SHAP values per classe 298: [[-0.16067287  0.04897032  0.09677001 -0.00920457]\n",
      " [-0.00896128  0.          0.          0.        ]\n",
      " [-0.01433748  0.          0.          0.        ]\n",
      " [-0.02971971  0.46141514 -0.36906828 -0.04757616]\n",
      " [ 0.          0.0164079   0.          0.        ]]\n",
      "SHAP values per classe 299: [[-0.16121719  0.03490383  0.09918286  0.03832259]\n",
      " [-0.00971106 -0.09263821  0.          0.06390633]\n",
      " [-0.03294078  0.          0.02592598  0.0234934 ]\n",
      " [ 0.         -0.13298626  0.10784584  0.02146692]\n",
      " [ 0.         -0.06308345  0.06383187  0.01884073]]\n",
      "SHAP values per classe 300: [[-0.14539732  0.05360517  0.          0.08630803]\n",
      " [ 0.          0.          0.02362643  0.        ]\n",
      " [-0.01178053  0.00136256  0.00245566  0.        ]\n",
      " [ 0.         -0.11163977  0.0365646   0.0701282 ]\n",
      " [-0.00460095  0.02499862 -0.01143165  0.        ]]\n",
      "SHAP values per classe 301: [[-0.12821533  0.08902714  0.          0.03769105]\n",
      " [ 0.00066548  0.10914679 -0.11351339 -0.01345496]\n",
      " [-0.03003384  0.          0.04696468  0.        ]\n",
      " [-0.01843311  0.20157933 -0.15307189 -0.02414868]\n",
      " [-0.00941193  0.02788613 -0.02194111  0.00099337]]\n",
      "SHAP values per classe 302: [[ 0.27095469 -0.13487173 -0.06354013 -0.03535395]\n",
      " [ 0.          0.          0.00200427  0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.07715082 -0.12727504  0.          0.        ]\n",
      " [ 0.05836264 -0.07498995  0.          0.        ]]\n",
      "SHAP GED: 10.764705882352942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training del detector...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/galessio/jupyter/lib/python3.9/site-packages/albumentations/core/bbox_utils.py:476: RuntimeWarning: invalid value encountered in divide\n",
      "  & (clipped_box_areas / denormalized_box_areas >= min_visibility - epsilon)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint salvato per l'epoca 12.\n",
      "------------------\n",
      "Epoch 14/150\n",
      "10.1321585903083736\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 60\u001b[0m\n\u001b[1;32m     58\u001b[0m detector\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# Inference per la preparazione dei dati\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m \u001b[43mcompute_json_detection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdetector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTMP_TRAIN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m compute_json_detection(detector, val_loader, TMP_VAL, dataset\u001b[38;5;241m=\u001b[39mdata)\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInference completata\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[27], line 15\u001b[0m, in \u001b[0;36mcompute_json_detection\u001b[0;34m(detector, loader, path, dataset)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(loader)):\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(loader)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mloader\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m     16\u001b[0m     results \u001b[38;5;241m=\u001b[39m detector([img])[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     17\u001b[0m     r_b \u001b[38;5;241m=\u001b[39m results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mboxes\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m/orfeo/cephfs/home/dssc/galessio/XAI_Monuments/utils/dataloader.py:141\u001b[0m, in \u001b[0;36mArchitectureDetectionDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    139\u001b[0m xml_name, label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mxml_loc[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mxml_loc[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mcontains(im_name)]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    140\u001b[0m name, folder, shape, target \u001b[38;5;241m=\u001b[39m parseXML(xml_name, SUB_ELEMENTS, idx, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 141\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43mclip\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mpreserve_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform:\n\u001b[1;32m    143\u001b[0m     augmented \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(image\u001b[38;5;241m=\u001b[39mimage, bboxes\u001b[38;5;241m=\u001b[39mtarget[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mboxes\u001b[39m\u001b[38;5;124m'\u001b[39m], labels\u001b[38;5;241m=\u001b[39mtarget[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/skimage/transform/_warps.py:203\u001b[0m, in \u001b[0;36mresize\u001b[0;34m(image, output_shape, order, mode, cval, clip, preserve_range, anti_aliasing, anti_aliasing_sigma)\u001b[0m\n\u001b[1;32m    200\u001b[0m     filtered \u001b[38;5;241m=\u001b[39m image\n\u001b[1;32m    202\u001b[0m zoom_factors \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m factors]\n\u001b[0;32m--> 203\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mndi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzoom\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzoom_factors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mndi_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrid_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m    205\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    207\u001b[0m _clip_warp_output(image, out, mode, cval, clip)\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/orfeo/cephfs/home/dssc/galessio/jupyter/lib64/python3.9/site-packages/scipy/ndimage/_interpolation.py:869\u001b[0m, in \u001b[0;36mzoom\u001b[0;34m(input, zoom, output, order, mode, cval, prefilter, grid_mode)\u001b[0m\n\u001b[1;32m    865\u001b[0m zoom \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39mdivide(zoom_nominator, zoom_div,\n\u001b[1;32m    866\u001b[0m                     out\u001b[38;5;241m=\u001b[39mnumpy\u001b[38;5;241m.\u001b[39mones_like(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39mnumpy\u001b[38;5;241m.\u001b[39mfloat64),\n\u001b[1;32m    867\u001b[0m                     where\u001b[38;5;241m=\u001b[39mzoom_div \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    868\u001b[0m zoom \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39mascontiguousarray(zoom)\n\u001b[0;32m--> 869\u001b[0m \u001b[43m_nd_image\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzoom_shift\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfiltered\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzoom\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnpad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mgrid_mode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Configurazione directory checkpoint\n",
    "CHECKPOINT_DIR = \"./checkpoints2/\"\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "\n",
    "# Funzione per caricare il checkpoint più recente\n",
    "def load_checkpoint():\n",
    "    checkpoints = [f for f in os.listdir(CHECKPOINT_DIR) if f.startswith(\"detector\")]\n",
    "    if checkpoints:\n",
    "        last_checkpoint = max(checkpoints, key=lambda x: int(x.split('_')[2].split('.')[0]))\n",
    "        checkpoint_path = os.path.join(CHECKPOINT_DIR, last_checkpoint)\n",
    "        checkpoint = torch.load(checkpoint_path)\n",
    "        print(f\"Checkpoint caricato: {checkpoint_path}\")\n",
    "        return checkpoint\n",
    "    return None\n",
    "\n",
    "checkpoint = load_checkpoint()\n",
    "start_epoch = checkpoint['epoch'] + 1 if checkpoint else 0\n",
    "\n",
    "# Caricamento del modello e dello stato ottimizzatore\n",
    "if checkpoint:\n",
    "    detector.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "\n",
    "# Funzione per preparare i dati per il classificatore\n",
    "def prepare_data(loader, TMP, dataset):\n",
    "    matrix_metadata = metadata_to_matrix(TMP, \"json\")\n",
    "    names = matrix_metadata[:, -1]\n",
    "    data = np.zeros((len(names), num_archi_features))\n",
    "    labels = np.zeros(len(names))\n",
    "\n",
    "    if dataset == \"MonumenAI\":\n",
    "        for i, name in enumerate(names):\n",
    "            im_name = name[2:-4]\n",
    "            idx = loader.images_loc['path'].str.contains(im_name)\n",
    "            data[idx] = matrix_metadata[i, :num_archi_features]\n",
    "            labels[idx] = matrix_metadata[i, num_archi_features]\n",
    "    elif dataset == \"PascalPart\":\n",
    "        for i, name in enumerate(names):\n",
    "            im_name = os.path.join(PATH_PASCAL + PASCAL_IMG, name.split('_')[1][:-5] + '.jpg')\n",
    "            idx = loader.images_loc.index(im_name)\n",
    "            data[idx] = matrix_metadata[i, :num_archi_features]\n",
    "            labels[idx] = matrix_metadata[i, num_archi_features]\n",
    "\n",
    "    data = data.astype(np.float32)\n",
    "    labels = to_categorical(labels.astype(np.float32).astype(np.int8))\n",
    "    return data, labels\n",
    "\n",
    "# Loop per il training del detector e del classificatore\n",
    "for epoch in range(start_epoch, num_epochs_detection + 1):\n",
    "    print('------------------')\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs_detection}\")\n",
    "\n",
    "    if epoch > 0 or args.resume:\n",
    "        detector.eval()\n",
    "        # Inference per la preparazione dei dati\n",
    "        compute_json_detection(detector, train_loader, TMP_TRAIN, dataset=data)\n",
    "        compute_json_detection(detector, val_loader, TMP_VAL, dataset=data)\n",
    "\n",
    "        print('Inference completata')\n",
    "\n",
    "        # Preparazione dei dati\n",
    "        train_data, train_label = prepare_data(train_loader, TMP_TRAIN, data)\n",
    "        test_data, test_label = prepare_data(val_loader, TMP_VAL, data)\n",
    "\n",
    "        # Classificatore\n",
    "        classificator = keras.Sequential([\n",
    "            keras.layers.Dense(units=n_neurons_classification, activation='relu', input_shape=(num_archi_features,)),\n",
    "            keras.layers.Dense(units=num_styles, activation='softmax')\n",
    "        ])\n",
    "        classificator.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        print(\"Training del classificatore...\")\n",
    "        history = classificator.fit(\n",
    "            train_data, train_label,\n",
    "            batch_size=batch_size_classification,\n",
    "            epochs=num_epochs_classification,\n",
    "            verbose=1\n",
    "        )\n",
    "        loss, accuracy = classificator.evaluate(test_data, test_label, verbose=1)\n",
    "        print(f\"Loss: {loss}, Accuracy: {accuracy}\")\n",
    "\n",
    "        # SHAP Analysis\n",
    "        print(\"Calcolo degli SHAP values...\")\n",
    "        elements = np.random.choice(len(train_data), int(0.3 * len(train_data)), replace=False)\n",
    "        explainer = shap.KernelExplainer(classificator.predict, train_data[elements])\n",
    "\n",
    "        shap_values_test = explainer.shap_values(test_data, nsamples=30)\n",
    "        print(\"SHAP values calcolati.\")\n",
    "        for i, shap_val in enumerate(shap_values_test):\n",
    "            print(f\"SHAP values per classe {i}: {shap_val[:5]}\")  # Stampa i primi valori per debug\n",
    "\n",
    "        d = GED_metric(test_data, shap_values_test, dataset=data)\n",
    "        print(f\"SHAP GED: {d}\")\n",
    "\n",
    "        classificator.save_weights(os.path.join(CHECKPOINT_DIR, f\"classificator_epoch_{epoch}.weights.h5\"))\n",
    "\n",
    "    if epoch < num_epochs_detection:\n",
    "        # Training del detector\n",
    "        detector.train()\n",
    "        print(\"Training del detector...\")\n",
    "        for images, targets in train_loader:\n",
    "            images = [img.to('cuda') for img in images]\n",
    "            targets = [{k: v.to('cuda') for k, v in t.items()} for t in targets]\n",
    "\n",
    "            loss_dict = detector(images, targets)\n",
    "            losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            losses.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        # Salvataggio del checkpoint\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': detector.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "        }, os.path.join(CHECKPOINT_DIR, f\"detector_epoch_{epoch}.pth\"))\n",
    "        print(f\"Checkpoint salvato per l'epoca {epoch}.\")\n",
    "\n",
    "# Valutazione finale\n",
    "if num_epochs_detection == 0:\n",
    "    loss, accuracy = classificator.evaluate(test_data, test_label, verbose=1)\n",
    "    print(f\"Loss finale: {loss}, Accuracy finale: {accuracy}\")\n",
    "\n",
    "    predict_test = classificator.predict(test_data)\n",
    "    prediction = np.argmax(predict_test, axis=1)\n",
    "    true_labels = np.argmax(test_label, axis=1)\n",
    "\n",
    "    cm = confusion_matrix(true_labels, prediction)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=STYLES_HOTONE_ENCODE.keys())\n",
    "    disp.plot(include_values=True, cmap='viridis')\n",
    "    plt.savefig('confmatDeLDECAS.png')\n",
    "\n",
    "    shap_values_test = explainer.shap_values(test_data, nsamples=30)\n",
    "    d = GED_metric(test_data, shap_values_test, dataset=data)\n",
    "    print(f\"Final SHAP GED: {d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597b40a0-acb8-4cce-8152-f5f596ab2e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(TMP_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6277e20d-9f05-4cd7-b6f1-99ae2729eb81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc4e216-dd8a-4547-afea-67f27f620417",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae75c41-ba65-46a2-8c25-91c817c034c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
