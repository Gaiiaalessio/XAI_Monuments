{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "033f27ef-aa1b-4dd3-be12-92054abd3d34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a04bfa74-dce5-410a-b6d3-08c580f968ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2d1187a-6f9f-4a29-a647-4f7fce6a5869",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install numpy --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "411821e2-fb28-419e-b36d-c2d121906079",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install numpy --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf5c261d-9576-4656-b89a-72dfa3eae7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pandas --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9441b8f-02ba-40f9-a9f7-abcb7186b195",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip uninstall pandas -y\n",
    "#!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a454191-94b2-45c0-8389-8a3912ba30d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pycocotools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23f4b6ac-4b2e-4fc3-a5a2-fa499493bd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install \"numpy<2.0.0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7de4bec-868e-40b7-9b50-b77a2936d061",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-06 12:22:09.408899: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-06 12:22:11.490926: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-06 12:22:12.424925: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-06 12:22:12.599188: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-06 12:22:13.657808: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-06 12:23:03.690209: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/orfeo/cephfs/home/dssc/adellasiega/jupyter/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/orfeo/cephfs/home/dssc/adellasiega/jupyter/lib/python3.9/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.21 (you have 1.4.18). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "##Imports\n",
    "import numpy as np \n",
    "import os, sys, argparse, datetime, shutil\n",
    "import torchvision.models as models\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.keras.models import model_from_json\n",
    "from keras.utils import to_categorical\n",
    "import shap \n",
    "import tensorflow as tf\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "\n",
    "#Import from current folder\n",
    "from utils.config import *\n",
    "from utils.dataloader import *\n",
    "from utils.engine import train_one_epoch, evaluate\n",
    "from utils.train import compute_json_detection\n",
    "from utils.coco_utils import get_coco_api_from_dataset\n",
    "from utils.coco_eval import CocoEvaluator\n",
    "from utils.knowledge_graph import compare_shap_and_KG, reduce_shap, GED_metric, get_bbox_weight\n",
    "import utils.utils as uti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29224100-b419-447f-8c72-712a0aafe89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53dfad0d-f080-4b0e-bb6c-db596c1a754c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/usr/lib64/python39.zip',\n",
       " '/usr/lib64/python3.9',\n",
       " '/usr/lib64/python3.9/lib-dynload',\n",
       " '',\n",
       " '/orfeo/cephfs/home/dssc/adellasiega/jupyter/lib64/python3.9/site-packages',\n",
       " '/orfeo/cephfs/home/dssc/adellasiega/jupyter/lib/python3.9/site-packages',\n",
       " '../monumai']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63c3188c-f693-4a16-88c0-4831c62e464d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip uninstall -y numpy tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f68e5d3-ff24-4c2f-8fcc-8ce2d98683fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install numpy==1.24 tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc4742e7-b664-445d-9bb4-864e034634fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Imposta il percorso della directory manualmente\n",
    "os.chdir(os.path.expanduser('~/XAI_Monuments/tools'))\n",
    "notebook_dir = os.getcwd()\n",
    "sys.path.append(notebook_dir)\n",
    "\n",
    "from pickle_tools import *\n",
    "\n",
    "TMP_TRAIN = TMP_PATH + '/train'\n",
    "TMP_VAL = TMP_PATH + '/val'\n",
    "TMP_TEST = TMP_PATH + '/test'\n",
    "\n",
    "os.makedirs(TMP_VAL, exist_ok=True)\n",
    "os.makedirs(TMP_TRAIN, exist_ok=True)\n",
    "os.makedirs(TMP_TEST, exist_ok=True)\n",
    "\n",
    "# Argparse\n",
    "parser = argparse.ArgumentParser(description='Arguments needed to prepare the metadata files')\n",
    "parser.add_argument('--resume', dest='resume', help='Whether or not to resume a training', default=False)\n",
    "parser.add_argument('--path_resume', dest='path_resume', help='Path to the model to load', default='./model/model_monumenai.pth')\n",
    "parser.add_argument('--epoch_classif', dest='epoch_classif', help='Number of epochs to train the classification model', default=150)\n",
    "parser.add_argument('--batch_size', dest='batch_size', help='Batch size to train the classification model', default=64)\n",
    "parser.add_argument('--neuron_classif', dest='neuron_classif', help='Number of neurons in the classification model', default=11)\n",
    "parser.add_argument('--epoch_detection', dest='epoch_detection', help='Number of epochs to train the detection model', default=0)\n",
    "parser.add_argument('--lr', dest='lr', help='Learning rate of the detection model', default=0.0003)\n",
    "parser.add_argument('--stepLR', dest='stepLR', help='Step of the learning rate scheduler', default=9)\n",
    "parser.add_argument('--gammaLR', dest='gammaLR', help='Gamma parameter of the learning rate scheduler', default=0.1)\n",
    "parser.add_argument('--weight', dest='weight', help='Type of weighting', default='None')\n",
    "parser.add_argument('--exp_weights', dest='exp_weights', help='linear or exponential weighting', default='linear')\n",
    "parser.add_argument('--data', dest='data', help='MonumenAI or PascalPart', default='MonumenAI')\n",
    "\n",
    "# Se stai usando un ambiente Jupyter, ignora gli argomenti aggiuntivi\n",
    "if 'ipykernel_launcher' in sys.argv[0]:\n",
    "    sys.argv = sys.argv[:1]\n",
    "\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e5291e6-e84a-4d67-8686-c07fb48c102c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters classification\n",
    "n_neurons_classification = int(args.neuron_classif)\n",
    "num_epochs_classification = int(args.epoch_classif)\n",
    "batch_size_classification = int(args.batch_size)\n",
    "learning_rate_classification = None\n",
    "\n",
    "#Hyperparameters detection\n",
    "args.epoch_detection = 20\n",
    "num_epochs_detection = int(args.epoch_detection)\n",
    "learning_rate_detection = float(args.lr)\n",
    "stepLR = float(args.stepLR)\n",
    "gammaLR = float(args.gammaLR)\n",
    "data = args.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b54b508-69c8-4900-bb43-e0b560bd948a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import sys\n",
    "os.chdir(os.path.expanduser('~/XAI_Monuments/tools'))\n",
    "notebook_dir = os.getcwd()\n",
    "sys.path.append(notebook_dir)\n",
    "if data == 'MonumenAI':\n",
    "    from metadata_tools import *\n",
    "    from monumai.monument import Monument\n",
    "    archi_features = [el for sublist in list(Monument.ELEMENT_DIC.values()) for el in sublist]\n",
    "    styles = FOLDERS_DATA\n",
    "    #Loaders for detection\n",
    "    PATH_DATA = \"../\"+PATH_DATA\n",
    "    train_loader = ArchitectureDetectionDataset(os.path.join(PATH_DATA, 'train.csv'), os.path.join(PATH_DATA, CSV_XML), transform_detection)\n",
    "\n",
    "    if num_epochs_detection != 0:\n",
    "        val_loader = ArchitectureDetectionDataset(os.path.join(PATH_DATA,'val.csv'), os.path.join(PATH_DATA, CSV_XML), transform_detection)\n",
    "    else:\n",
    "        #Actually loading the test set\n",
    "        val_loader = ArchitectureDetectionDataset(os.path.join(PATH_DATA,'val.csv'), os.path.join(PATH_DATA, CSV_XML), transform_detection)\n",
    "        test_loader = ArchitectureDetectionDataset(os.path.join(PATH_DATA,'test.csv'), os.path.join(PATH_DATA, CSV_XML), transform_detection)\n",
    "if data == 'PascalPart':\n",
    "    from tools.metadata_tools_pascal import *\n",
    "    from monumai.pascal import Monument\n",
    "    archi_features = [el for sublist in list(Monument.ELEMENT_DIC.values()) for el in sublist]\n",
    "    styles = list(PASCAL_EL_DIC.keys())\n",
    "    #Loaders for detection\n",
    "    train_loader = PascalDetectionDataset(train_pascal, PATH_PASCAL+PASCAL_IMG,PATH_PASCAL+PASCAL_XML, transform_detection_pascal)\n",
    "    if num_epochs_detection != 0:\n",
    "        val_loader = PascalDetectionDataset(val_pascal, PATH_PASCAL+PASCAL_IMG,PATH_PASCAL+PASCAL_XML, transform_detection_pascal)\n",
    "    else:\n",
    "        #Actually loading the test set\n",
    "        val_loader = PascalDetectionDataset(val_pascal, PATH_PASCAL+PASCAL_IMG,PATH_PASCAL+PASCAL_XML, transform_detection_pascal)\n",
    "        test_loader = PascalDetectionDataset(test_pascal, PATH_PASCAL+PASCAL_IMG,PATH_PASCAL+PASCAL_XML, transform_detection_pascal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6df99016-b966-4058-9702-7df7e78423bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Hyperparameters for detection\n",
    "num_archi_features = len(archi_features)\n",
    "num_classes_detection = num_archi_features + 1  # num_archi_features + background\n",
    "num_styles = len(styles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "93df370e-c64e-4da4-ba64-179bbf062c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/adellasiega/jupyter/lib64/python3.9/site-packages/torchvision/models/_utils.py:135: UserWarning: Using 'weights' as positional parameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) instead.\n",
      "  warnings.warn(\n",
      "/orfeo/cephfs/home/dssc/adellasiega/jupyter/lib64/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "##Build detection model\n",
    "if args.weight == \"bbox_level\":\n",
    "    from utils.pytorch_utils import fasterrcnn_resnet50_fpn_custom\n",
    "    detector = fasterrcnn_resnet50_fpn_custom(True)\n",
    "    in_features = detector.roi_heads.box_predictor.cls_score.in_features\n",
    "    detector.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes_detection)\n",
    "else:\n",
    "    detector = models.detection.fasterrcnn_resnet50_fpn(True)\n",
    "    in_features = detector.roi_heads.box_predictor.cls_score.in_features\n",
    "    detector.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes_detection)\n",
    "\n",
    "if args.exp_weights == 'exponential':\n",
    "    is_exponential = True\n",
    "elif args.exp_weights == 'linear':\n",
    "    is_exponential = False\n",
    "else:\n",
    "    print(\"Unrecognized type of weighting, defaulted to linear\")\n",
    "    is_exponential = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f6791577-e707-4bb1-96ba-5831528d1683",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/adellasiega/jupyter/lib64/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "detector = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "detector.to(device)\n",
    "\n",
    "optimizer = torch.optim.SGD(detector.parameters(), lr=learning_rate_detection, momentum=0.9)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, stepLR, gamma=gammaLR, last_epoch=-1)\n",
    "\n",
    "if args.resume:\n",
    "    detector.load_state_dict(torch.load(args.path_resume, map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "df3ea76c-8fbd-4e1a-b2e6-65238b0937b2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/adellasiega/jupyter/lib64/python3.9/site-packages/torch/nn/modules/conv.py:456: UserWarning: Attempt to open cnn_infer failed: handle=0 error: libcudnn_cnn_infer.so.8: cannot open shared object file: No such file or directory (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:81.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1]  [  0/908]  eta: 3:04:42  lr: 0.000300  loss: 0.4150 (0.4150)  loss_classifier: 0.2434 (0.2434)  loss_box_reg: 0.0744 (0.0744)  loss_objectness: 0.0647 (0.0647)  loss_rpn_box_reg: 0.0325 (0.0325)  time: 12.2055  data: 0.6049  max mem: 943\n",
      "Epoch: [1]  [  2/908]  eta: 1:04:43  lr: 0.000300  loss: 0.4150 (0.6754)  loss_classifier: 0.2434 (0.4076)  loss_box_reg: 0.0744 (0.0934)  loss_objectness: 0.1659 (0.1427)  loss_rpn_box_reg: 0.0325 (0.0317)  time: 4.2867  data: 0.3232  max mem: 1107\n",
      "Epoch: [1]  [  4/908]  eta: 0:40:29  lr: 0.000300  loss: 0.4150 (0.7081)  loss_classifier: 0.2434 (0.4149)  loss_box_reg: 0.0744 (0.1123)  loss_objectness: 0.1659 (0.1409)  loss_rpn_box_reg: 0.0325 (0.0401)  time: 2.6874  data: 0.2784  max mem: 1107\n",
      "------------------\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "70",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m detector\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#Run inference on all data to prepare for classification\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[43mcompute_json_detection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdetector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTMP_TRAIN\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m compute_json_detection(detector, val_loader, TMP_VAL,dataset\u001b[38;5;241m=\u001b[39mdata)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m#If necessary run on test set aswell\u001b[39;00m\n",
      "File \u001b[0;32m/orfeo/cephfs/home/dssc/adellasiega/XAI_Monuments/utils/train.py:129\u001b[0m, in \u001b[0;36mcompute_json_detection\u001b[0;34m(detector, loader, path, dataset)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(r_b)):\n\u001b[1;32m    120\u001b[0m     box \u001b[38;5;241m=\u001b[39m r_b[k]\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m224.\u001b[39m\n\u001b[1;32m    121\u001b[0m     local_result \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    122\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbndbox\u001b[39m\u001b[38;5;124m\"\u001b[39m : {\n\u001b[1;32m    123\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxmin\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m(box[\u001b[38;5;241m0\u001b[39m]),\n\u001b[1;32m    124\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mymin\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m(box[\u001b[38;5;241m1\u001b[39m]),\n\u001b[1;32m    125\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mymax\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m(box[\u001b[38;5;241m3\u001b[39m]),\n\u001b[1;32m    126\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxmax\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m(box[\u001b[38;5;241m2\u001b[39m])\n\u001b[1;32m    127\u001b[0m         },\n\u001b[1;32m    128\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m\"\u001b[39m : \u001b[38;5;28mstr\u001b[39m(scores[k]),\n\u001b[0;32m--> 129\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m\"\u001b[39m : \u001b[43mreverse_dic\u001b[49m\u001b[43m[\u001b[49m\u001b[43mclasses\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    130\u001b[0m     }\n\u001b[1;32m    131\u001b[0m     condensced_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(local_result)\n\u001b[1;32m    132\u001b[0m local_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path,information_about_class[condensced_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrue_label\u001b[39m\u001b[38;5;124m\"\u001b[39m]] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m img_name\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m4\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: 70"
     ]
    }
   ],
   "source": [
    "### Loop ~ Epochs. First epoch is regular detection training\n",
    "for j in range(num_epochs_detection+1):\n",
    "    print('------------------')\n",
    "    print(\"Epoch \" + str(j+1) + '/' + str(num_epochs_detection))\n",
    "    #Detection Hyperparameters\n",
    "    if j > 0 or args.resume:\n",
    "        detector.eval()\n",
    "        #Run inference on all data to prepare for classification\n",
    "        compute_json_detection(detector, train_loader, TMP_TRAIN,dataset=data)\n",
    "        compute_json_detection(detector, val_loader, TMP_VAL,dataset=data)\n",
    "        #If necessary run on test set aswell\n",
    "        if num_epochs_detection == 0:\n",
    "            compute_json_detection(detector, test_loader, TMP_TEST,dataset=data)\n",
    "\n",
    "        print('Inference run')\n",
    "\n",
    "        #Application of the aggregation function first for train then for val\n",
    "        matrix_metadata = metadata_to_matrix(TMP_TRAIN, \"json\")\n",
    "        names = matrix_metadata[:,-1]\n",
    "        train_data = np.zeros((len(names),num_archi_features))\n",
    "        train_label = np.zeros(len(names))\n",
    "        if data == \"MonumenAI\":\n",
    "            for i in range(len(names)):\n",
    "                im_name = names[i][2:-4]\n",
    "                idx = train_loader.images_loc['path'].str.contains(im_name)\n",
    "                train_data[idx] = matrix_metadata[i,:num_archi_features]\n",
    "                train_label[idx] = matrix_metadata[i,num_archi_features]\n",
    "        if data == \"PascalPart\":\n",
    "            for i in range(len(names)):\n",
    "                im_name = os.path.join(PATH_PASCAL+PASCAL_IMG,names[i].split('_')[1][:-5] + '.jpg')\n",
    "                idx = train_loader.images_loc.index(im_name)\n",
    "                train_data[idx] = matrix_metadata[i,:num_archi_features]\n",
    "                train_label[idx] = matrix_metadata[i,num_archi_features]\n",
    "        train_data = train_data.astype(np.float32)\n",
    "        train_label = to_categorical(train_label.astype(np.float32).astype(np.int8))\n",
    "\n",
    "        matrix_metadata = metadata_to_matrix(TMP_VAL, \"json\")\n",
    "        names = matrix_metadata[:,-1]\n",
    "        test_data = np.zeros((len(names),num_archi_features))\n",
    "        test_label = np.zeros(len(names))\n",
    "        if data == \"MonumenAI\":\n",
    "            for i in range(len(names)):\n",
    "                im_name = names[i][2:-4]\n",
    "                idx = val_loader.images_loc['path'].str.contains(im_name)\n",
    "                test_data[idx] = matrix_metadata[i,:num_archi_features]\n",
    "                test_label[idx] = matrix_metadata[i,num_archi_features]\n",
    "        if data == \"PascalPart\":\n",
    "            for i in range(len(names)):\n",
    "                im_name = os.path.join(PATH_PASCAL+PASCAL_IMG,names[i].split('_')[1][:-5] + '.jpg')\n",
    "                idx = val_loader.images_loc.index(im_name)\n",
    "                test_data[idx] = matrix_metadata[i,:num_archi_features]\n",
    "                test_label[idx] = matrix_metadata[i,num_archi_features]\n",
    "        test_data = test_data.astype(np.float32)\n",
    "        test_label = to_categorical(test_label.astype(np.float32).astype(np.int8))\n",
    "\n",
    "        #Classification training\n",
    "        #Initialize model\n",
    "        classificator = keras.Sequential()\n",
    "        classificator.add(keras.layers.Dense(units=n_neurons_classification, activation='relu', input_shape=(num_archi_features,)))\n",
    "        classificator.add(keras.layers.Dense(units=num_styles, activation='softmax'))\n",
    "        classificator.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        #Train model\n",
    "        history = classificator.fit(train_data, train_label, batch_size=batch_size_classification, epochs=num_epochs_classification, verbose=0)\n",
    "        loss, accuracy = classificator.evaluate(test_data, test_label, verbose=1)\n",
    "        #SHAP\n",
    "        elements = np.random.choice(len(train_data), int(0.3*len(train_data)), False)\n",
    "        explainer = shap.KernelExplainer(classificator.predict, train_data[elements])\n",
    "        #Apply aggregation function to test if necessary\n",
    "        if num_epochs_detection==0:\n",
    "            matrix_metadata = metadata_to_matrix(TMP_TEST, \"json\")\n",
    "            names = matrix_metadata[:,-1]\n",
    "            test_data = np.zeros((len(names),num_archi_features))\n",
    "            test_label = np.zeros(len(names))\n",
    "            if data == \"MonumenAI\":\n",
    "                for i in range(len(names)):\n",
    "                    im_name = names[i][2:-4]\n",
    "                    idx = test_loader.images_loc['path'].str.contains(im_name)\n",
    "                    test_data[idx] = matrix_metadata[i,:num_archi_features]\n",
    "                    test_label[idx] = matrix_metadata[i,num_archi_features]\n",
    "            if data == \"PascalPart\":\n",
    "                for i in range(len(names)):\n",
    "                    im_name = os.path.join(PATH_PASCAL+PASCAL_IMG,names[i].split('_')[1][:-5] + '.jpg')\n",
    "                    idx = test_loader.images_loc.index(im_name)\n",
    "                    test_data[idx] = matrix_metadata[i,:num_archi_features]\n",
    "                    test_label[idx] = matrix_metadata[i,num_archi_features]\n",
    "\n",
    "            test_data = test_data.astype(np.float32)\n",
    "            non_cat = np.copy(test_label)\n",
    "            test_label = to_categorical(test_label.astype(np.float32).astype(np.int8))\n",
    "        shap_values_test = explainer.shap_values(test_data, nsamples=30, l1_reg='bic')\n",
    "        #Compute GED based on shap \n",
    "        d = GED_metric(test_data, shap_values_test, dataset=data)\n",
    "        print('SHAP GED: ', d)\n",
    "        if j < num_epochs_detection:\n",
    "            #Compute relevant shap values & shap weights\n",
    "            shap_values_train = explainer.shap_values(train_data, nsamples=30, l1_reg='bic')\n",
    "            labels = np.argmax(train_label,axis=1)\n",
    "            if args.weight == \"instance_level\":\n",
    "                contributions_shap = compare_shap_and_KG(shap_values_train, labels, dataset=data)\n",
    "                shap_coeff = reduce_shap(contributions_shap,is_exponential)\n",
    "            elif args.weight == \"bbox_level\":\n",
    "                shap_weights = get_bbox_weight(shap_values_train,is_exponential, dataset=data)\n",
    "            print(\"Shap computed\")\n",
    "        print('Test loss: ', loss, '\\tTest accuracy: ', accuracy)\n",
    "    if j < num_epochs_detection:\n",
    "        #Train detection\n",
    "        metric_logger = uti.MetricLogger(delimiter=\"  \")\n",
    "        metric_logger.add_meter('lr', uti.SmoothedValue(window_size=1, fmt='{value:.6f}'))\n",
    "        header = 'Epoch: [{}]'.format(j+1)\n",
    "\n",
    "        index = 0\n",
    "        detector.train()\n",
    "        #for images, targets in metric_logger.log_every(train_loader, 250, header):\n",
    "        ###\n",
    "        max_batches = 5  # or any other small number\n",
    "        for j, (images, targets) in enumerate(metric_logger.log_every(train_loader, 2, header)):\n",
    "            if j >= max_batches:\n",
    "                break\n",
    "        ###\n",
    "            images = list(image.to('cuda') for image in images)\n",
    "            targets = [{k: v.to('cuda') for k, v in t.items()} for t in targets]\n",
    "            #SHAP if necessary\n",
    "            #-------\n",
    "            if (j > 0 or args.resume) and args.weight == \"bbox_level\":\n",
    "                loss_dict = detector(images, targets, weights=shap_weights[index][:,labels[index]])\n",
    "                index += 1\n",
    "            else :\n",
    "                loss_dict = detector(images, targets)\n",
    "            losses = sum(loss for loss in loss_dict.values())\n",
    "            if (j > 0 or args.resume) and args.weight == \"instance_level\":\n",
    "                losses = losses * shap_coeff[index]\n",
    "                index += 1            \n",
    "            #-------\n",
    "            optimizer.zero_grad()\n",
    "            losses.backward()\n",
    "            optimizer.step()\n",
    "            metric_logger.update(loss=losses, **loss_dict)\n",
    "            metric_logger.update(lr=optimizer.param_groups[0][\"lr\"])\n",
    "        scheduler.step()\n",
    "        #Saving model\n",
    "        if args.path_resume is None:\n",
    "            torch.save(detector.state_dict(), DETECTOR_PATH)\n",
    "        else:\n",
    "            torch.save(detector.state_dict(), \"../\"+args.path_resume)\n",
    "    #Evaluation\n",
    "    if num_epochs_detection == 0:\n",
    "        loss, accuracy = classificator.evaluate(test_data, test_label, verbose=1)\n",
    "        predict_test = classificator(test_data)\n",
    "        prediction = np.argmax(predict_test,axis=1)\n",
    "        from sklearn.metrics import confusion_matrix\n",
    "        cm = confusion_matrix(non_cat,prediction)\n",
    "        STYLES_HOTONE_ENCODE = {'M' : 0, 'G' : 1, 'R' : 2, 'B' : 3}\n",
    "        from sklearn.metrics import ConfusionMatrixDisplay\n",
    "        import matplotlib.pyplot as plt \n",
    "\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                                        display_labels=STYLES_HOTONE_ENCODE.keys())\n",
    "        disp.plot(include_values=True, cmap='viridis')\n",
    "        plt.savefig('confmatDeLDECAS.png')\n",
    "        shap_values_test = explainer.shap_values(test_data, nsamples=30, l1_reg='bic')\n",
    "        #Compute GED based on shap \n",
    "        d = GED_metric(test_data, shap_values_test, dataset=data)\n",
    "        print(d)\n",
    "        print(accuracy)\n",
    "    #if j < num_epochs_detection or num_epochs_detection==0:\n",
    "    if num_epochs_detection==0:\n",
    "        evaluate(detector, test_loader, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597b40a0-acb8-4cce-8152-f5f596ab2e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(TMP_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83d1842-48d9-4db5-abde-2a12ce917f62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
